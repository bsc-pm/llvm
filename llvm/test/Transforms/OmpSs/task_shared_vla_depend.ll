; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --function-signature --include-generated-funcs
; RUN: opt %s -passes=ompss-2 -S | FileCheck %s
; ModuleID = 'task_shared_vla_depend.c'
source_filename = "task_shared_vla_depend.c"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

; void foo(int x, int y, int z) {
;     int vla[x + 1][y + 2][z + 3];
;     #pragma oss task in(vla)
;     {
;         int size = sizeof(vla);
;     }
; }

%struct._depend_unpack_t = type { ptr, i64, i64, i64, i64, i64, i64, i64, i64, i64 }

; Function Attrs: noinline nounwind optnone
define dso_local void @foo(i32 noundef %x, i32 noundef %y, i32 noundef %z) #0 !dbg !5 {
entry:
  %x.addr = alloca i32, align 4
  %y.addr = alloca i32, align 4
  %z.addr = alloca i32, align 4
  %saved_stack = alloca ptr, align 8
  %__vla_expr0 = alloca i64, align 8
  %__vla_expr1 = alloca i64, align 8
  %__vla_expr2 = alloca i64, align 8
  store i32 %x, ptr %x.addr, align 4
  store i32 %y, ptr %y.addr, align 4
  store i32 %z, ptr %z.addr, align 4
  %0 = load i32, ptr %x.addr, align 4, !dbg !9
  %add = add nsw i32 %0, 1, !dbg !10
  %1 = zext i32 %add to i64, !dbg !11
  %2 = load i32, ptr %y.addr, align 4, !dbg !12
  %add1 = add nsw i32 %2, 2, !dbg !13
  %3 = zext i32 %add1 to i64, !dbg !11
  %4 = load i32, ptr %z.addr, align 4, !dbg !14
  %add2 = add nsw i32 %4, 3, !dbg !15
  %5 = zext i32 %add2 to i64, !dbg !11
  %6 = call ptr @llvm.stacksave(), !dbg !11
  store ptr %6, ptr %saved_stack, align 8, !dbg !11
  %7 = mul nuw i64 %1, %3, !dbg !11
  %8 = mul nuw i64 %7, %5, !dbg !11
  %vla = alloca i32, i64 %8, align 16, !dbg !11
  store i64 %1, ptr %__vla_expr0, align 8, !dbg !11
  store i64 %3, ptr %__vla_expr1, align 8, !dbg !11
  store i64 %5, ptr %__vla_expr2, align 8, !dbg !11
  %9 = call token @llvm.directive.region.entry() [ "DIR.OSS"([5 x i8] c"TASK\00"), "QUAL.OSS.SHARED"(ptr %vla, i32 undef), "QUAL.OSS.VLA.DIMS"(ptr %vla, i64 %1, i64 %3, i64 %5), "QUAL.OSS.CAPTURED"(i64 %1, i64 %3, i64 %5), "QUAL.OSS.DEP.IN"(ptr %vla, [4 x i8] c"vla\00", ptr @compute_dep, ptr %vla, i64 %1, i64 %3, i64 %5) ], !dbg !16
  %size = alloca i32, align 4
  %10 = mul nuw i64 %1, %3, !dbg !17
  %11 = mul nuw i64 %10, %5, !dbg !17
  %12 = mul nuw i64 4, %11, !dbg !17
  %conv = trunc i64 %12 to i32, !dbg !17
  store i32 %conv, ptr %size, align 4, !dbg !18
  call void @llvm.directive.region.exit(token %9), !dbg !19
  %13 = load ptr, ptr %saved_stack, align 8, !dbg !20
  call void @llvm.stackrestore(ptr %13), !dbg !20
  ret void, !dbg !20
}

; Function Attrs: nocallback nofree nosync nounwind willreturn
declare ptr @llvm.stacksave() #1

; Function Attrs: nounwind
declare token @llvm.directive.region.entry() #2

; Function Attrs: nounwind
declare void @llvm.directive.region.exit(token) #2

define internal %struct._depend_unpack_t @compute_dep(ptr %vla, i64 %0, i64 %1, i64 %2) #3 !dbg !21 {
entry:
  %retval = alloca %struct._depend_unpack_t, align 8
  %vla.addr = alloca ptr, align 8
  %.addr = alloca i64, align 8
  %.addr1 = alloca i64, align 8
  %.addr2 = alloca i64, align 8
  store ptr %vla, ptr %vla.addr, align 8
  store i64 %0, ptr %.addr, align 8
  store i64 %1, ptr %.addr1, align 8
  store i64 %2, ptr %.addr2, align 8
  %3 = mul i64 %2, 4
  %4 = mul i64 %2, 4
  %5 = getelementptr inbounds %struct._depend_unpack_t, ptr %retval, i32 0, i32 0
  store ptr %vla, ptr %5, align 8
  %6 = getelementptr inbounds %struct._depend_unpack_t, ptr %retval, i32 0, i32 1
  store i64 %3, ptr %6, align 8
  %7 = getelementptr inbounds %struct._depend_unpack_t, ptr %retval, i32 0, i32 2
  store i64 0, ptr %7, align 8
  %8 = getelementptr inbounds %struct._depend_unpack_t, ptr %retval, i32 0, i32 3
  store i64 %4, ptr %8, align 8
  %9 = getelementptr inbounds %struct._depend_unpack_t, ptr %retval, i32 0, i32 4
  store i64 %1, ptr %9, align 8
  %10 = getelementptr inbounds %struct._depend_unpack_t, ptr %retval, i32 0, i32 5
  store i64 0, ptr %10, align 8
  %11 = getelementptr inbounds %struct._depend_unpack_t, ptr %retval, i32 0, i32 6
  store i64 %1, ptr %11, align 8
  %12 = getelementptr inbounds %struct._depend_unpack_t, ptr %retval, i32 0, i32 7
  store i64 %0, ptr %12, align 8
  %13 = getelementptr inbounds %struct._depend_unpack_t, ptr %retval, i32 0, i32 8
  store i64 0, ptr %13, align 8
  %14 = getelementptr inbounds %struct._depend_unpack_t, ptr %retval, i32 0, i32 9
  store i64 %0, ptr %14, align 8
  %15 = load %struct._depend_unpack_t, ptr %retval, align 8
  ret %struct._depend_unpack_t %15
}

; Function Attrs: nocallback nofree nosync nounwind willreturn
declare void @llvm.stackrestore(ptr) #1

attributes #0 = { noinline nounwind optnone "frame-pointer"="none" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-features"="+cx8,+mmx,+sse,+sse2,+x87" }
attributes #1 = { nocallback nofree nosync nounwind willreturn }
attributes #2 = { nounwind }
attributes #3 = { "min-legal-vector-width"="0" }

!llvm.dbg.cu = !{!0}
!llvm.module.flags = !{!2, !3}
!llvm.ident = !{!4}

!0 = distinct !DICompileUnit(language: DW_LANG_C99, file: !1, producer: "", isOptimized: false, runtimeVersion: 0, emissionKind: NoDebug, splitDebugInlining: false, nameTableKind: None)
!1 = !DIFile(filename: "<stdin>", directory: "")
!2 = !{i32 2, !"Debug Info Version", i32 3}
!3 = !{i32 1, !"wchar_size", i32 4}
!4 = !{!""}
!5 = distinct !DISubprogram(name: "foo", scope: !6, file: !6, line: 1, type: !7, scopeLine: 1, flags: DIFlagPrototyped, spFlags: DISPFlagDefinition, unit: !0, retainedNodes: !8)
!6 = !DIFile(filename: "task_shared_vla_depend.ll", directory: "")
!7 = !DISubroutineType(types: !8)
!8 = !{}
!9 = !DILocation(line: 2, column: 13, scope: !5)
!10 = !DILocation(line: 2, column: 15, scope: !5)
!11 = !DILocation(line: 2, column: 5, scope: !5)
!12 = !DILocation(line: 2, column: 20, scope: !5)
!13 = !DILocation(line: 2, column: 22, scope: !5)
!14 = !DILocation(line: 2, column: 27, scope: !5)
!15 = !DILocation(line: 2, column: 29, scope: !5)
!16 = !DILocation(line: 3, column: 13, scope: !5)
!17 = !DILocation(line: 5, column: 20, scope: !5)
!18 = !DILocation(line: 5, column: 13, scope: !5)
!19 = !DILocation(line: 6, column: 5, scope: !5)
!20 = !DILocation(line: 7, column: 1, scope: !5)
!21 = distinct !DISubprogram(linkageName: "compute_dep", scope: !1, file: !1, type: !7, flags: DIFlagArtificial, spFlags: DISPFlagLocalToUnit | DISPFlagDefinition, unit: !0, retainedNodes: !8)
; CHECK-LABEL: define {{[^@]+}}@foo
; CHECK-SAME: (i32 noundef [[X:%.*]], i32 noundef [[Y:%.*]], i32 noundef [[Z:%.*]]) #[[ATTR0:[0-9]+]] !dbg [[DBG5:![0-9]+]] {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[X_ADDR:%.*]] = alloca i32, align 4
; CHECK-NEXT:    [[Y_ADDR:%.*]] = alloca i32, align 4
; CHECK-NEXT:    [[Z_ADDR:%.*]] = alloca i32, align 4
; CHECK-NEXT:    [[SAVED_STACK:%.*]] = alloca ptr, align 8
; CHECK-NEXT:    [[__VLA_EXPR0:%.*]] = alloca i64, align 8
; CHECK-NEXT:    [[__VLA_EXPR1:%.*]] = alloca i64, align 8
; CHECK-NEXT:    [[__VLA_EXPR2:%.*]] = alloca i64, align 8
; CHECK-NEXT:    store i32 [[X]], ptr [[X_ADDR]], align 4
; CHECK-NEXT:    store i32 [[Y]], ptr [[Y_ADDR]], align 4
; CHECK-NEXT:    store i32 [[Z]], ptr [[Z_ADDR]], align 4
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[X_ADDR]], align 4, !dbg [[DBG9:![0-9]+]]
; CHECK-NEXT:    [[ADD:%.*]] = add nsw i32 [[TMP0]], 1, !dbg [[DBG10:![0-9]+]]
; CHECK-NEXT:    [[TMP1:%.*]] = zext i32 [[ADD]] to i64, !dbg [[DBG11:![0-9]+]]
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y_ADDR]], align 4, !dbg [[DBG12:![0-9]+]]
; CHECK-NEXT:    [[ADD1:%.*]] = add nsw i32 [[TMP2]], 2, !dbg [[DBG13:![0-9]+]]
; CHECK-NEXT:    [[TMP3:%.*]] = zext i32 [[ADD1]] to i64, !dbg [[DBG11]]
; CHECK-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Z_ADDR]], align 4, !dbg [[DBG14:![0-9]+]]
; CHECK-NEXT:    [[ADD2:%.*]] = add nsw i32 [[TMP4]], 3, !dbg [[DBG15:![0-9]+]]
; CHECK-NEXT:    [[TMP5:%.*]] = zext i32 [[ADD2]] to i64, !dbg [[DBG11]]
; CHECK-NEXT:    [[TMP6:%.*]] = call ptr @llvm.stacksave.p0(), !dbg [[DBG11]]
; CHECK-NEXT:    store ptr [[TMP6]], ptr [[SAVED_STACK]], align 8, !dbg [[DBG11]]
; CHECK-NEXT:    [[TMP7:%.*]] = mul nuw i64 [[TMP1]], [[TMP3]], !dbg [[DBG11]]
; CHECK-NEXT:    [[TMP8:%.*]] = mul nuw i64 [[TMP7]], [[TMP5]], !dbg [[DBG11]]
; CHECK-NEXT:    [[VLA:%.*]] = alloca i32, i64 [[TMP8]], align 16, !dbg [[DBG11]]
; CHECK-NEXT:    store i64 [[TMP1]], ptr [[__VLA_EXPR0]], align 8, !dbg [[DBG11]]
; CHECK-NEXT:    store i64 [[TMP3]], ptr [[__VLA_EXPR1]], align 8, !dbg [[DBG11]]
; CHECK-NEXT:    store i64 [[TMP5]], ptr [[__VLA_EXPR2]], align 8, !dbg [[DBG11]]
; CHECK-NEXT:    [[SIZE_CLONE:%.*]] = alloca i32, align 4
; CHECK-NEXT:    [[TMP9:%.*]] = alloca ptr, align 8, !dbg [[DBG16:![0-9]+]]
; CHECK-NEXT:    [[TMP10:%.*]] = alloca ptr, align 8, !dbg [[DBG16]]
; CHECK-NEXT:    [[NUM_DEPS:%.*]] = alloca i64, align 8, !dbg [[DBG16]]
; CHECK-NEXT:    br label [[FINAL_COND:%.*]], !dbg [[DBG16]]
; CHECK:       codeRepl:
; CHECK-NEXT:    call void @llvm.lifetime.start.p0(i64 8, ptr [[TMP9]]), !dbg [[DBG16]]
; CHECK-NEXT:    call void @llvm.lifetime.start.p0(i64 8, ptr [[TMP10]]), !dbg [[DBG16]]
; CHECK-NEXT:    store i64 0, ptr [[NUM_DEPS]], align 8, !dbg [[DBG16]]
; CHECK-NEXT:    [[TMP11:%.*]] = load i64, ptr [[NUM_DEPS]], align 8, !dbg [[DBG16]]
; CHECK-NEXT:    [[TMP12:%.*]] = add i64 [[TMP11]], 1, !dbg [[DBG16]]
; CHECK-NEXT:    store i64 [[TMP12]], ptr [[NUM_DEPS]], align 8, !dbg [[DBG16]]
; CHECK-NEXT:    [[TMP13:%.*]] = load i64, ptr [[NUM_DEPS]], align 8, !dbg [[DBG16]]
; CHECK-NEXT:    call void @nanos6_create_task(ptr @task_info_var_foo, ptr @task_invocation_info_foo, ptr null, i64 32, ptr [[TMP9]], ptr [[TMP10]], i64 0, i64 [[TMP13]]), !dbg [[DBG16]]
; CHECK-NEXT:    [[TMP14:%.*]] = load ptr, ptr [[TMP9]], align 8, !dbg [[DBG16]]
; CHECK-NEXT:    [[ARGS_END:%.*]] = getelementptr i8, ptr [[TMP14]], i64 32, !dbg [[DBG16]]
; CHECK-NEXT:    [[GEP_VLA:%.*]] = getelementptr [[NANOS6_TASK_ARGS_FOO:%.*]], ptr [[TMP14]], i32 0, i32 0, !dbg [[DBG16]]
; CHECK-NEXT:    store ptr [[VLA]], ptr [[GEP_VLA]], align 8, !dbg [[DBG16]]
; CHECK-NEXT:    [[CAPT_GEP_:%.*]] = getelementptr [[NANOS6_TASK_ARGS_FOO]], ptr [[TMP14]], i32 0, i32 1, !dbg [[DBG16]]
; CHECK-NEXT:    store i64 [[TMP1]], ptr [[CAPT_GEP_]], align 8, !dbg [[DBG16]]
; CHECK-NEXT:    [[CAPT_GEP_1:%.*]] = getelementptr [[NANOS6_TASK_ARGS_FOO]], ptr [[TMP14]], i32 0, i32 2, !dbg [[DBG16]]
; CHECK-NEXT:    store i64 [[TMP3]], ptr [[CAPT_GEP_1]], align 8, !dbg [[DBG16]]
; CHECK-NEXT:    [[CAPT_GEP_2:%.*]] = getelementptr [[NANOS6_TASK_ARGS_FOO]], ptr [[TMP14]], i32 0, i32 3, !dbg [[DBG16]]
; CHECK-NEXT:    store i64 [[TMP5]], ptr [[CAPT_GEP_2]], align 8, !dbg [[DBG16]]
; CHECK-NEXT:    [[TMP15:%.*]] = load ptr, ptr [[TMP10]], align 8, !dbg [[DBG16]]
; CHECK-NEXT:    call void @nanos6_submit_task(ptr [[TMP15]]), !dbg [[DBG16]]
; CHECK-NEXT:    call void @llvm.lifetime.end.p0(i64 8, ptr [[TMP9]]), !dbg [[DBG16]]
; CHECK-NEXT:    call void @llvm.lifetime.end.p0(i64 8, ptr [[TMP10]]), !dbg [[DBG16]]
; CHECK-NEXT:    br label [[FINAL_END:%.*]], !dbg [[DBG16]]
; CHECK:       final.end:
; CHECK-NEXT:    [[TMP16:%.*]] = load ptr, ptr [[SAVED_STACK]], align 8, !dbg [[DBG17:![0-9]+]]
; CHECK-NEXT:    call void @llvm.stackrestore.p0(ptr [[TMP16]]), !dbg [[DBG17]]
; CHECK-NEXT:    ret void, !dbg [[DBG17]]
; CHECK:       final.then:
; CHECK-NEXT:    [[TMP17:%.*]] = mul nuw i64 [[TMP1]], [[TMP3]], !dbg [[DBG18:![0-9]+]]
; CHECK-NEXT:    [[TMP18:%.*]] = mul nuw i64 [[TMP17]], [[TMP5]], !dbg [[DBG18]]
; CHECK-NEXT:    [[TMP19:%.*]] = mul nuw i64 4, [[TMP18]], !dbg [[DBG18]]
; CHECK-NEXT:    [[CONV_CLONE:%.*]] = trunc i64 [[TMP19]] to i32, !dbg [[DBG18]]
; CHECK-NEXT:    store i32 [[CONV_CLONE]], ptr [[SIZE_CLONE]], align 4, !dbg [[DBG19:![0-9]+]]
; CHECK-NEXT:    br label [[FINAL_END]], !dbg [[DBG17]]
; CHECK:       final.cond:
; CHECK-NEXT:    [[TMP20:%.*]] = call i32 @nanos6_in_final(), !dbg [[DBG16]]
; CHECK-NEXT:    [[TMP21:%.*]] = icmp ne i32 [[TMP20]], 0, !dbg [[DBG16]]
; CHECK-NEXT:    br i1 [[TMP21]], label [[FINAL_THEN:%.*]], label [[CODEREPL:%.*]], !dbg [[DBG16]]
;
;
; CHECK-LABEL: define {{[^@]+}}@compute_dep
; CHECK-SAME: (ptr [[VLA:%.*]], i64 [[TMP0:%.*]], i64 [[TMP1:%.*]], i64 [[TMP2:%.*]]) #[[ATTR2:[0-9]+]] !dbg [[DBG20:![0-9]+]] {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T:%.*]], align 8
; CHECK-NEXT:    [[VLA_ADDR:%.*]] = alloca ptr, align 8
; CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i64, align 8
; CHECK-NEXT:    [[DOTADDR1:%.*]] = alloca i64, align 8
; CHECK-NEXT:    [[DOTADDR2:%.*]] = alloca i64, align 8
; CHECK-NEXT:    store ptr [[VLA]], ptr [[VLA_ADDR]], align 8
; CHECK-NEXT:    store i64 [[TMP0]], ptr [[DOTADDR]], align 8
; CHECK-NEXT:    store i64 [[TMP1]], ptr [[DOTADDR1]], align 8
; CHECK-NEXT:    store i64 [[TMP2]], ptr [[DOTADDR2]], align 8
; CHECK-NEXT:    [[TMP3:%.*]] = mul i64 [[TMP2]], 4
; CHECK-NEXT:    [[TMP4:%.*]] = mul i64 [[TMP2]], 4
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 0
; CHECK-NEXT:    store ptr [[VLA]], ptr [[TMP5]], align 8
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 1
; CHECK-NEXT:    store i64 [[TMP3]], ptr [[TMP6]], align 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 2
; CHECK-NEXT:    store i64 0, ptr [[TMP7]], align 8
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 3
; CHECK-NEXT:    store i64 [[TMP4]], ptr [[TMP8]], align 8
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 4
; CHECK-NEXT:    store i64 [[TMP1]], ptr [[TMP9]], align 8
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 5
; CHECK-NEXT:    store i64 0, ptr [[TMP10]], align 8
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 6
; CHECK-NEXT:    store i64 [[TMP1]], ptr [[TMP11]], align 8
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 7
; CHECK-NEXT:    store i64 [[TMP0]], ptr [[TMP12]], align 8
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 8
; CHECK-NEXT:    store i64 0, ptr [[TMP13]], align 8
; CHECK-NEXT:    [[TMP14:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 9
; CHECK-NEXT:    store i64 [[TMP0]], ptr [[TMP14]], align 8
; CHECK-NEXT:    [[TMP15:%.*]] = load [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], align 8
; CHECK-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T]] [[TMP15]]
;
;
; CHECK-LABEL: define {{[^@]+}}@nanos6_constructor_check_version() {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    call void @nanos6_check_version(i64 1, ptr @nanos6_versions, ptr @[[GLOB0:[0-9]+]])
; CHECK-NEXT:    ret void
;
;
; CHECK-LABEL: define {{[^@]+}}@nanos6_ol_duplicate_foo
; CHECK-SAME: (ptr [[TASK_ARGS_SRC:%.*]], ptr [[TASK_ARGS_DST:%.*]]) {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[TASK_ARGS_DST]], align 8
; CHECK-NEXT:    [[ARGS_END:%.*]] = getelementptr i8, ptr [[TMP0]], i64 32
; CHECK-NEXT:    [[GEP_SRC_VLA:%.*]] = getelementptr [[NANOS6_TASK_ARGS_FOO:%.*]], ptr [[TASK_ARGS_SRC]], i32 0, i32 0
; CHECK-NEXT:    [[GEP_DST_VLA:%.*]] = getelementptr [[NANOS6_TASK_ARGS_FOO]], ptr [[TMP0]], i32 0, i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[GEP_SRC_VLA]], align 8
; CHECK-NEXT:    store ptr [[TMP1]], ptr [[GEP_DST_VLA]], align 8
; CHECK-NEXT:    [[CAPT_GEP_SRC_:%.*]] = getelementptr [[NANOS6_TASK_ARGS_FOO]], ptr [[TASK_ARGS_SRC]], i32 0, i32 1
; CHECK-NEXT:    [[CAPT_GEP_DST_:%.*]] = getelementptr [[NANOS6_TASK_ARGS_FOO]], ptr [[TMP0]], i32 0, i32 1
; CHECK-NEXT:    [[TMP2:%.*]] = load i64, ptr [[CAPT_GEP_SRC_]], align 8
; CHECK-NEXT:    store i64 [[TMP2]], ptr [[CAPT_GEP_DST_]], align 8
; CHECK-NEXT:    [[CAPT_GEP_SRC_1:%.*]] = getelementptr [[NANOS6_TASK_ARGS_FOO]], ptr [[TASK_ARGS_SRC]], i32 0, i32 2
; CHECK-NEXT:    [[CAPT_GEP_DST_2:%.*]] = getelementptr [[NANOS6_TASK_ARGS_FOO]], ptr [[TMP0]], i32 0, i32 2
; CHECK-NEXT:    [[TMP3:%.*]] = load i64, ptr [[CAPT_GEP_SRC_1]], align 8
; CHECK-NEXT:    store i64 [[TMP3]], ptr [[CAPT_GEP_DST_2]], align 8
; CHECK-NEXT:    [[CAPT_GEP_SRC_3:%.*]] = getelementptr [[NANOS6_TASK_ARGS_FOO]], ptr [[TASK_ARGS_SRC]], i32 0, i32 3
; CHECK-NEXT:    [[CAPT_GEP_DST_4:%.*]] = getelementptr [[NANOS6_TASK_ARGS_FOO]], ptr [[TMP0]], i32 0, i32 3
; CHECK-NEXT:    [[TMP4:%.*]] = load i64, ptr [[CAPT_GEP_SRC_3]], align 8
; CHECK-NEXT:    store i64 [[TMP4]], ptr [[CAPT_GEP_DST_4]], align 8
; CHECK-NEXT:    ret void
;
;
; CHECK-LABEL: define {{[^@]+}}@nanos6_unpacked_task_region_foo
; CHECK-SAME: (ptr [[VLA:%.*]], i64 [[TMP0:%.*]], i64 [[TMP1:%.*]], i64 [[TMP2:%.*]], ptr [[DEVICE_ENV:%.*]], ptr [[ADDRESS_TRANSLATION_TABLE:%.*]]) !dbg [[DBG21:![0-9]+]] {
; CHECK-NEXT:  newFuncRoot:
; CHECK-NEXT:    [[SIZE:%.*]] = alloca i32, align 4
; CHECK-NEXT:    br label [[TMP3:%.*]], !dbg [[DBG22:![0-9]+]]
; CHECK:       3:
; CHECK-NEXT:    [[TMP4:%.*]] = mul nuw i64 [[TMP0]], [[TMP1]], !dbg [[DBG23:![0-9]+]]
; CHECK-NEXT:    [[TMP5:%.*]] = mul nuw i64 [[TMP4]], [[TMP2]], !dbg [[DBG23]]
; CHECK-NEXT:    [[TMP6:%.*]] = mul nuw i64 4, [[TMP5]], !dbg [[DBG23]]
; CHECK-NEXT:    [[CONV:%.*]] = trunc i64 [[TMP6]] to i32, !dbg [[DBG23]]
; CHECK-NEXT:    store i32 [[CONV]], ptr [[SIZE]], align 4, !dbg [[DBG24:![0-9]+]]
; CHECK-NEXT:    br label [[DOTEXITSTUB:%.*]], !dbg [[DBG25:![0-9]+]]
; CHECK:       .exitStub:
; CHECK-NEXT:    ret void
;
;
; CHECK-LABEL: define {{[^@]+}}@nanos6_ol_task_region_foo
; CHECK-SAME: (ptr [[TASK_ARGS:%.*]], ptr [[DEVICE_ENV:%.*]], ptr [[ADDRESS_TRANSLATION_TABLE:%.*]]) {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[GEP_VLA:%.*]] = getelementptr [[NANOS6_TASK_ARGS_FOO:%.*]], ptr [[TASK_ARGS]], i32 0, i32 0
; CHECK-NEXT:    [[LOAD_GEP_VLA:%.*]] = load ptr, ptr [[GEP_VLA]], align 8
; CHECK-NEXT:    [[CAPT_GEP:%.*]] = getelementptr [[NANOS6_TASK_ARGS_FOO]], ptr [[TASK_ARGS]], i32 0, i32 1
; CHECK-NEXT:    [[LOAD_CAPT_GEP:%.*]] = load i64, ptr [[CAPT_GEP]], align 8
; CHECK-NEXT:    [[CAPT_GEP1:%.*]] = getelementptr [[NANOS6_TASK_ARGS_FOO]], ptr [[TASK_ARGS]], i32 0, i32 2
; CHECK-NEXT:    [[LOAD_CAPT_GEP1:%.*]] = load i64, ptr [[CAPT_GEP1]], align 8
; CHECK-NEXT:    [[CAPT_GEP2:%.*]] = getelementptr [[NANOS6_TASK_ARGS_FOO]], ptr [[TASK_ARGS]], i32 0, i32 3
; CHECK-NEXT:    [[LOAD_CAPT_GEP2:%.*]] = load i64, ptr [[CAPT_GEP2]], align 8
; CHECK-NEXT:    [[TLATE_LOAD_GEP_VLA:%.*]] = alloca ptr, align 8
; CHECK-NEXT:    store ptr [[LOAD_GEP_VLA]], ptr [[TLATE_LOAD_GEP_VLA]], align 8
; CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[TLATE_LOAD_GEP_VLA]], align 8
; CHECK-NEXT:    [[TMP1:%.*]] = icmp ne ptr [[ADDRESS_TRANSLATION_TABLE]], null
; CHECK-NEXT:    br i1 [[TMP1]], label [[TLATE_IF:%.*]], label [[TLATE_END:%.*]]
; CHECK:       end:
; CHECK-NEXT:    call void @nanos6_unpacked_task_region_foo(ptr [[TMP7:%.*]], i64 [[LOAD_CAPT_GEP]], i64 [[LOAD_CAPT_GEP1]], i64 [[LOAD_CAPT_GEP2]], ptr [[DEVICE_ENV]], ptr [[ADDRESS_TRANSLATION_TABLE]])
; CHECK-NEXT:    ret void
; CHECK:       tlate.if:
; CHECK-NEXT:    [[LOCAL_LOOKUP_VLA:%.*]] = getelementptr [[NANOS6_ADDRESS_TRANSLATION_ENTRY_T:%.*]], ptr [[ADDRESS_TRANSLATION_TABLE]], i32 0, i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i64, ptr [[LOCAL_LOOKUP_VLA]], align 8
; CHECK-NEXT:    [[DEVICE_LOOKUP_VLA:%.*]] = getelementptr [[NANOS6_ADDRESS_TRANSLATION_ENTRY_T]], ptr [[ADDRESS_TRANSLATION_TABLE]], i32 0, i32 1
; CHECK-NEXT:    [[TMP3:%.*]] = load i64, ptr [[DEVICE_LOOKUP_VLA]], align 8
; CHECK-NEXT:    [[TMP4:%.*]] = sub i64 0, [[TMP2]]
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP0]], i64 [[TMP4]]
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP5]], i64 [[TMP3]]
; CHECK-NEXT:    store ptr [[TMP6]], ptr [[TLATE_LOAD_GEP_VLA]], align 8
; CHECK-NEXT:    br label [[TLATE_END]]
; CHECK:       tlate.end:
; CHECK-NEXT:    [[TMP7]] = load ptr, ptr [[TLATE_LOAD_GEP_VLA]], align 8
; CHECK-NEXT:    br label [[END:%.*]]
;
;
; CHECK-LABEL: define {{[^@]+}}@nanos6_unpacked_deps_foo
; CHECK-SAME: (ptr [[VLA:%.*]], i64 [[TMP0:%.*]], i64 [[TMP1:%.*]], i64 [[TMP2:%.*]], ptr [[LOOP_BOUNDS:%.*]], ptr [[HANDLER:%.*]]) {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP3:%.*]] = call [[STRUCT__DEPEND_UNPACK_T:%.*]] @[[COMPUTE_DEP:[a-zA-Z0-9_$\"\\.-]*[a-zA-Z_$\"\\.-][a-zA-Z0-9_$\"\\.-]*]](ptr [[VLA]], i64 [[TMP0]], i64 [[TMP1]], i64 [[TMP2]])
; CHECK-NEXT:    [[TMP4:%.*]] = call [[STRUCT__DEPEND_UNPACK_T]] @[[COMPUTE_DEP]](ptr [[VLA]], i64 [[TMP0]], i64 [[TMP1]], i64 [[TMP2]])
; CHECK-NEXT:    [[TMP5:%.*]] = extractvalue [[STRUCT__DEPEND_UNPACK_T]] [[TMP3]], 0
; CHECK-NEXT:    [[TMP6:%.*]] = extractvalue [[STRUCT__DEPEND_UNPACK_T]] [[TMP3]], 1
; CHECK-NEXT:    [[TMP7:%.*]] = extractvalue [[STRUCT__DEPEND_UNPACK_T]] [[TMP3]], 2
; CHECK-NEXT:    [[TMP8:%.*]] = extractvalue [[STRUCT__DEPEND_UNPACK_T]] [[TMP4]], 3
; CHECK-NEXT:    [[TMP9:%.*]] = extractvalue [[STRUCT__DEPEND_UNPACK_T]] [[TMP3]], 4
; CHECK-NEXT:    [[TMP10:%.*]] = extractvalue [[STRUCT__DEPEND_UNPACK_T]] [[TMP3]], 5
; CHECK-NEXT:    [[TMP11:%.*]] = extractvalue [[STRUCT__DEPEND_UNPACK_T]] [[TMP4]], 6
; CHECK-NEXT:    [[TMP12:%.*]] = extractvalue [[STRUCT__DEPEND_UNPACK_T]] [[TMP3]], 7
; CHECK-NEXT:    [[TMP13:%.*]] = extractvalue [[STRUCT__DEPEND_UNPACK_T]] [[TMP3]], 8
; CHECK-NEXT:    [[TMP14:%.*]] = extractvalue [[STRUCT__DEPEND_UNPACK_T]] [[TMP4]], 9
; CHECK-NEXT:    call void @nanos6_register_region_read_depinfo3(ptr [[HANDLER]], i32 0, ptr @[[GLOB2:[0-9]+]], ptr [[TMP5]], i64 [[TMP6]], i64 [[TMP7]], i64 [[TMP8]], i64 [[TMP9]], i64 [[TMP10]], i64 [[TMP11]], i64 [[TMP12]], i64 [[TMP13]], i64 [[TMP14]])
; CHECK-NEXT:    ret void
;
;
; CHECK-LABEL: define {{[^@]+}}@nanos6_ol_deps_foo
; CHECK-SAME: (ptr [[TASK_ARGS:%.*]], ptr [[LOOP_BOUNDS:%.*]], ptr [[HANDLER:%.*]]) {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[GEP_VLA:%.*]] = getelementptr [[NANOS6_TASK_ARGS_FOO:%.*]], ptr [[TASK_ARGS]], i32 0, i32 0
; CHECK-NEXT:    [[LOAD_GEP_VLA:%.*]] = load ptr, ptr [[GEP_VLA]], align 8
; CHECK-NEXT:    [[CAPT_GEP:%.*]] = getelementptr [[NANOS6_TASK_ARGS_FOO]], ptr [[TASK_ARGS]], i32 0, i32 1
; CHECK-NEXT:    [[LOAD_CAPT_GEP:%.*]] = load i64, ptr [[CAPT_GEP]], align 8
; CHECK-NEXT:    [[CAPT_GEP1:%.*]] = getelementptr [[NANOS6_TASK_ARGS_FOO]], ptr [[TASK_ARGS]], i32 0, i32 2
; CHECK-NEXT:    [[LOAD_CAPT_GEP1:%.*]] = load i64, ptr [[CAPT_GEP1]], align 8
; CHECK-NEXT:    [[CAPT_GEP2:%.*]] = getelementptr [[NANOS6_TASK_ARGS_FOO]], ptr [[TASK_ARGS]], i32 0, i32 3
; CHECK-NEXT:    [[LOAD_CAPT_GEP2:%.*]] = load i64, ptr [[CAPT_GEP2]], align 8
; CHECK-NEXT:    br label [[END:%.*]]
; CHECK:       end:
; CHECK-NEXT:    call void @nanos6_unpacked_deps_foo(ptr [[LOAD_GEP_VLA]], i64 [[LOAD_CAPT_GEP]], i64 [[LOAD_CAPT_GEP1]], i64 [[LOAD_CAPT_GEP2]], ptr [[LOOP_BOUNDS]], ptr [[HANDLER]])
; CHECK-NEXT:    ret void
;
;
; CHECK-LABEL: define {{[^@]+}}@nanos6_constructor_register_task_info() {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    call void @nanos6_register_task_info(ptr @task_info_var_foo)
; CHECK-NEXT:    ret void
;
