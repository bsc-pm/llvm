; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mtriple=riscv64 -mattr=+m,+f,+d,+a,+c,+epi -verify-machineinstrs < %s \
; RUN:    | FileCheck %s

define void @test_setvl()
; CHECK-LABEL: test_setvl:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vsetvli a0, a0, e8, m1
; CHECK-NEXT:    vsetvli a0, a0, e16, m1
; CHECK-NEXT:    vsetvli a0, a0, e32, m1
; CHECK-NEXT:    vsetvli a0, a0, e64, m1
; CHECK-NEXT:    vsetvli a0, a0, e128, m1
; CHECK-NEXT:    vsetvli a0, a0, e8, m2
; CHECK-NEXT:    vsetvli a0, a0, e8, m4
; CHECK-NEXT:    vsetvli a0, a0, e8, m8
; CHECK-NEXT:    ret
{
entry:
  %a1 = call i64 @llvm.epi.setvl(i64 undef, i64 0, i64 0)
  %a2 = call i64 @llvm.epi.setvl(i64 undef, i64 1, i64 0)
  %a3 = call i64 @llvm.epi.setvl(i64 undef, i64 2, i64 0)
  %a4 = call i64 @llvm.epi.setvl(i64 undef, i64 3, i64 0)
  %a5 = call i64 @llvm.epi.setvl(i64 undef, i64 4, i64 0)
  %a6 = call i64 @llvm.epi.setvl(i64 undef, i64 0, i64 1)
  %a7 = call i64 @llvm.epi.setvl(i64 undef, i64 0, i64 2)
  %a8 = call i64 @llvm.epi.setvl(i64 undef, i64 0, i64 3)
  ret void
}

declare i64 @llvm.epi.setvl(i64, i64, i64)

define i64 @test_vl()
; CHECK-LABEL: test_vl:
; CHECK:       # %bb.0:
; CHECK-NEXT:    readvl a0
; CHECK-NEXT:    ret
{
  %a = call i64 @llvm.epi.readvl()
  ret i64 %a
}

declare i64 @llvm.epi.readvl()


define void @test_load_stores()
; CHECK-LABEL: test_load_stores:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vlb.v v0, (a0)
; CHECK-NEXT:    vsb.v v0, (a0)
; CHECK-NEXT:    vlh.v v0, (a0)
; CHECK-NEXT:    vsh.v v0, (a0)
; CHECK-NEXT:    vlw.v v0, (a0)
; CHECK-NEXT:    vsw.v v0, (a0)
; CHECK-NEXT:    vle.v v0, (a0)
; CHECK-NEXT:    vse.v v0, (a0)
; CHECK-NEXT:    vlw.v v0, (a0)
; CHECK-NEXT:    vsw.v v0, (a0)
; CHECK-NEXT:    vle.v v0, (a0)
; CHECK-NEXT:    vse.v v0, (a0)
; CHECK-NEXT:    ret
{
  %a1 = call <vscale x 1 x i8> @llvm.epi.vload.i8(i8* undef)
  call void @llvm.epi.vstore.i8(<vscale x 1 x i8> %a1, i8* undef)

  %a2 = call <vscale x 1 x i16> @llvm.epi.vload.i16(i16* undef)
  call void @llvm.epi.vstore.i16(<vscale x 1 x i16> %a2, i16* undef)

  %a3 = call <vscale x 1 x i32> @llvm.epi.vload.i32(i32* undef)
  call void @llvm.epi.vstore.i32(<vscale x 1 x i32> %a3, i32* undef)

  %a4 = call <vscale x 1 x i64> @llvm.epi.vload.i64(i64* undef)
  call void @llvm.epi.vstore.i64(<vscale x 1 x i64> %a4, i64* undef)

  %a5 = call <vscale x 1 x float> @llvm.epi.vload.f32(float* undef)
  call void @llvm.epi.vstore.f32(<vscale x 1 x float> %a5, float* undef)

  %a6 = call <vscale x 1 x double> @llvm.epi.vload.f64(double* undef)
  call void @llvm.epi.vstore.f64(<vscale x 1 x double> %a6, double* undef)

  ret void
}

declare <vscale x 1 x i8> @llvm.epi.vload.i8(i8*)
declare void @llvm.epi.vstore.i8(<vscale x 1 x i8>, i8*)

declare <vscale x 1 x i16> @llvm.epi.vload.i16(i16*)
declare void @llvm.epi.vstore.i16(<vscale x 1 x i16>, i16*)

declare <vscale x 1 x i32> @llvm.epi.vload.i32(i32*)
declare void @llvm.epi.vstore.i32(<vscale x 1 x i32>, i32*)

declare <vscale x 1 x i64> @llvm.epi.vload.i64(i64*)
declare void @llvm.epi.vstore.i64(<vscale x 1 x i64>, i64*)

declare <vscale x 1 x float> @llvm.epi.vload.f32(float*)
declare void @llvm.epi.vstore.f32(<vscale x 1 x float>, float*)

declare <vscale x 1 x double> @llvm.epi.vload.f64(double*)
declare void @llvm.epi.vstore.f64(<vscale x 1 x double>, double*)

