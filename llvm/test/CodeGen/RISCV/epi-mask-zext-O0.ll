; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mtriple riscv64 -mattr +m,+a,+f,+d,+v -o - \
; RUN:     --verify-machineinstrs -O0 %s | FileCheck %s

define <vscale x 8 x i8> @foo_O0(<vscale x 8 x i1> %a) nounwind noinline optnone {
; CHECK-LABEL: foo_O0:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addi sp, sp, -16
; CHECK-NEXT:    addi s0, sp, 16
; CHECK-NEXT:    rdvtype a2
; CHECK-NEXT:    rdvl a1
; CHECK-NEXT:    vsetvli a0, zero, e8,m1
; CHECK-NEXT:    vsetvl zero, a1, a2
; CHECK-NEXT:    sub sp, sp, a0
; CHECK-NEXT:    andi sp, sp, -16
; CHECK-NEXT:    sd sp, -16(s0)
; CHECK-NEXT:    vsetvli a0, zero, e8,m1
; CHECK-NEXT:    ld a0, -16(s0)
; CHECK-NEXT:    vse.v v0, (a0)
; CHECK-NEXT:    vsetvli a0, zero, e8,m1
; CHECK-NEXT:    ld a0, -16(s0)
; CHECK-NEXT:    vle.v v0, (a0)
; CHECK-NEXT:    vsetvli a0, zero, e8,m1
; CHECK-NEXT:    vmv.v.i v1, 1
; CHECK-NEXT:    vsetvli a0, zero, e8,m1
; CHECK-NEXT:    vand.vv v16, v0, v1
; CHECK-NEXT:    addi sp, s0, -16
; CHECK-NEXT:    addi sp, sp, 16
; CHECK-NEXT:    ret
entry:
  %a.addr = alloca <vscale x 8 x i8>, align 1
  %frommask = zext <vscale x 8 x i1> %a to <vscale x 8 x i8>
  store <vscale x 8 x i8> %frommask, <vscale x 8 x i8>* %a.addr, align 1
  %0 = load <vscale x 8 x i8>, <vscale x 8 x i8>* %a.addr, align 1
  %tomask = trunc <vscale x 8 x i8> %0 to <vscale x 8 x i1>
  %1 = zext <vscale x 8 x i1> %tomask to <vscale x 8 x i8>
  ret <vscale x 8 x i8> %1
}

define <vscale x 8 x i8> @foo(<vscale x 8 x i1> %a) nounwind {
; CHECK-LABEL: foo:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addi sp, sp, -16
; CHECK-NEXT:    addi s0, sp, 16
; CHECK-NEXT:    rdvtype a2
; CHECK-NEXT:    rdvl a1
; CHECK-NEXT:    vsetvli a0, zero, e8,m1
; CHECK-NEXT:    vsetvl zero, a1, a2
; CHECK-NEXT:    sub sp, sp, a0
; CHECK-NEXT:    andi sp, sp, -16
; CHECK-NEXT:    sd sp, -16(s0)
; CHECK-NEXT:    vsetvli a0, zero, e8,m1
; CHECK-NEXT:    ld a0, -16(s0)
; CHECK-NEXT:    vse.v v0, (a0)
; CHECK-NEXT:    ld a0, -16(s0)
; CHECK-NEXT:    vle.v v0, (a0)
; CHECK-NEXT:    vmv.v.i v1, 1
; CHECK-NEXT:    vand.vv v16, v0, v1
; CHECK-NEXT:    addi sp, s0, -16
; CHECK-NEXT:    addi sp, sp, 16
; CHECK-NEXT:    ret
entry:
  %a.addr = alloca <vscale x 8 x i8>, align 1
  %frommask = zext <vscale x 8 x i1> %a to <vscale x 8 x i8>
  store <vscale x 8 x i8> %frommask, <vscale x 8 x i8>* %a.addr, align 1
  %0 = load <vscale x 8 x i8>, <vscale x 8 x i8>* %a.addr, align 1
  %tomask = trunc <vscale x 8 x i8> %0 to <vscale x 8 x i1>
  %1 = zext <vscale x 8 x i1> %tomask to <vscale x 8 x i8>
  ret <vscale x 8 x i8> %1
}
