; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mtriple=riscv64 -mattr=+epi < %s | FileCheck %s

define void @foo(i32* %p, i64 %gvl) nounwind optnone noinline
; CHECK-LABEL: foo:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addi sp, sp, -16
; CHECK-NEXT:    sd ra, 8(sp)
; CHECK-NEXT:    sd s0, 0(sp)
; CHECK-NEXT:    addi s0, sp, 16
; CHECK-NEXT:    slli a2, a1, 2
; CHECK-NEXT:    addi a2, a2, 15
; CHECK-NEXT:    andi a2, a2, -16
; CHECK-NEXT:    sub a2, sp, a2
; CHECK-NEXT:    mv sp, a2
; CHECK-NEXT:    vsetvli a3, a1, e32, m1
; CHECK-NEXT:    vle.v v0, (a0)
; CHECK-NEXT:    vsetvli a3, zero, e32, m1
; CHECK-NEXT:    vse.v v0, (a2)
; CHECK-NEXT:    vle.v v0, (a2)
; CHECK-NEXT:    vsetvli a2, a1, e32, m1
; CHECK-NEXT:    vse.v v0, (a0)
; CHECK-NEXT:    addi sp, s0, -16
; CHECK-NEXT:    ld s0, 0(sp)
; CHECK-NEXT:    ld ra, 8(sp)
; CHECK-NEXT:    addi sp, sp, 16
; CHECK-NEXT:    ret
{
  %x0 = alloca i32, i64 %gvl
  %x1 = bitcast i32* %x0 to <vscale x 2 x i32>*

  %x2 = bitcast i32* %p to <vscale x 2 x i32>*

  %x3 = call <vscale x 2 x i32> @llvm.epi.vload.v2i32(<vscale x 2 x i32>* %x2, i64 %gvl)

  store <vscale x 2 x i32> %x3, <vscale x 2 x i32>* %x1, align 4
  %x4 = load <vscale x 2 x i32>, <vscale x 2 x i32>* %x1, align 4

  call void @llvm.epi.vstore.v2i32(<vscale x 2 x i32> %x4, <vscale x 2 x i32>* %x2, i64 %gvl)
  ret void
}

declare <vscale x 2 x i32> @llvm.epi.vload.v2i32(<vscale x 2 x i32>*, i64);
declare void @llvm.epi.vstore.v2i32(<vscale x 2 x i32>, <vscale x 2 x i32>*, i64)
