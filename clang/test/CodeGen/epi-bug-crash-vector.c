// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// RUN: %clang_cc1 -disable-llvm-passes -triple riscv64 -mepi \
// RUN:            -emit-llvm -o- %s | FileCheck %s

// CHECK-LABEL: @second(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca <vscale x 2 x i32>, align 4
// CHECK-NEXT:    [[B_ADDR:%.*]] = alloca <vscale x 2 x i32>, align 4
// CHECK-NEXT:    store <vscale x 2 x i32> [[A:%.*]], <vscale x 2 x i32>* [[A_ADDR]], align 4
// CHECK-NEXT:    store <vscale x 2 x i32> [[B:%.*]], <vscale x 2 x i32>* [[B_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load <vscale x 2 x i32>, <vscale x 2 x i32>* [[B_ADDR]], align 4
// CHECK-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__attribute__((noinline)) __epi_2xi32 second(__epi_2xi32 a, __epi_2xi32 b) {

  return b;
}

// CHECK-LABEL: @main(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[RETVAL:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[ARGC_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[ARGV_ADDR:%.*]] = alloca i8**, align 8
// CHECK-NEXT:    [[GVL:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[VA:%.*]] = alloca <vscale x 2 x i32>, align 4
// CHECK-NEXT:    [[VB:%.*]] = alloca <vscale x 2 x i32>, align 4
// CHECK-NEXT:    [[VC:%.*]] = alloca <vscale x 2 x i32>, align 4
// CHECK-NEXT:    store i32 0, i32* [[RETVAL]], align 4
// CHECK-NEXT:    store i32 [[ARGC:%.*]], i32* [[ARGC_ADDR]], align 4
// CHECK-NEXT:    store i8** [[ARGV:%.*]], i8*** [[ARGV_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = call i64 @llvm.epi.vsetvlmax(i64 2, i64 0)
// CHECK-NEXT:    [[CONV:%.*]] = trunc i64 [[TMP0]] to i32
// CHECK-NEXT:    store i32 [[CONV]], i32* [[GVL]], align 4
// CHECK-NEXT:    [[TMP1:%.*]] = load i32, i32* [[GVL]], align 4
// CHECK-NEXT:    [[CONV1:%.*]] = sext i32 [[TMP1]] to i64
// CHECK-NEXT:    [[TMP2:%.*]] = call <vscale x 2 x i32> @llvm.epi.vmv.v.x.nxv2i32.i32(i32 1, i64 [[CONV1]])
// CHECK-NEXT:    store <vscale x 2 x i32> [[TMP2]], <vscale x 2 x i32>* [[VA]], align 4
// CHECK-NEXT:    [[TMP3:%.*]] = load i32, i32* [[GVL]], align 4
// CHECK-NEXT:    [[CONV2:%.*]] = sext i32 [[TMP3]] to i64
// CHECK-NEXT:    [[TMP4:%.*]] = call <vscale x 2 x i32> @llvm.epi.vmv.v.x.nxv2i32.i32(i32 2, i64 [[CONV2]])
// CHECK-NEXT:    store <vscale x 2 x i32> [[TMP4]], <vscale x 2 x i32>* [[VB]], align 4
// CHECK-NEXT:    [[TMP5:%.*]] = load <vscale x 2 x i32>, <vscale x 2 x i32>* [[VA]], align 4
// CHECK-NEXT:    [[TMP6:%.*]] = load <vscale x 2 x i32>, <vscale x 2 x i32>* [[VB]], align 4
// CHECK-NEXT:    [[CALL:%.*]] = call <vscale x 2 x i32> @second(<vscale x 2 x i32> [[TMP5]], <vscale x 2 x i32> [[TMP6]])
// CHECK-NEXT:    store <vscale x 2 x i32> [[CALL]], <vscale x 2 x i32>* [[VC]], align 4
// CHECK-NEXT:    ret i32 0
//
int main(int argc, char *argv[]) {

  int gvl = __builtin_epi_vsetvlmax(2, 0);

  __epi_2xi32 va = __builtin_epi_vmv_v_x_2xi32(1, gvl);
  __epi_2xi32 vb = __builtin_epi_vmv_v_x_2xi32(2, gvl);

  __epi_2xi32 vc = second(va, vb);

  return 0;
}
