// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// RUN: %clang --target=riscv64-unknown-linux-gnu -mepi -S -emit-llvm -O2 -o - %s \
// RUN:       | FileCheck --check-prefix=CHECK-O2 %s

// CHECK-O2-LABEL: @test_cast_8xi8_8xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.mask.cast.nxv8i8.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_cast_8xi8_8xi1(__epi_8xi1 arg_0)
{
    return __builtin_epi_cast_8xi8_8xi1(arg_0);
}

// CHECK-O2-LABEL: @test_cast_4xi16_4xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.mask.cast.nxv4i16.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_cast_4xi16_4xi1(__epi_4xi1 arg_0)
{
    return __builtin_epi_cast_4xi16_4xi1(arg_0);
}

// CHECK-O2-LABEL: @test_cast_2xi32_2xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.mask.cast.nxv2i32.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_cast_2xi32_2xi1(__epi_2xi1 arg_0)
{
    return __builtin_epi_cast_2xi32_2xi1(arg_0);
}

// CHECK-O2-LABEL: @test_cast_1xi64_1xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.mask.cast.nxv1i64.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_cast_1xi64_1xi1(__epi_1xi1 arg_0)
{
    return __builtin_epi_cast_1xi64_1xi1(arg_0);
}

// CHECK-O2-LABEL: @test_cast_8xi1_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.mask.cast.nxv8i1.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_cast_8xi1_8xi8(__epi_8xi8 arg_0)
{
    return __builtin_epi_cast_8xi1_8xi8(arg_0);
}

// CHECK-O2-LABEL: @test_cast_4xi1_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.mask.cast.nxv4i1.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_cast_4xi1_4xi16(__epi_4xi16 arg_0)
{
    return __builtin_epi_cast_4xi1_4xi16(arg_0);
}

// CHECK-O2-LABEL: @test_cast_2xi1_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.mask.cast.nxv2i1.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_cast_2xi1_2xi32(__epi_2xi32 arg_0)
{
    return __builtin_epi_cast_2xi1_2xi32(arg_0);
}

// CHECK-O2-LABEL: @test_cast_1xi1_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.mask.cast.nxv1i1.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_cast_1xi1_1xi64(__epi_1xi64 arg_0)
{
    return __builtin_epi_cast_1xi1_1xi64(arg_0);
}

// CHECK-O2-LABEL: @test_vaadd_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vaadd.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vaadd_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vaadd_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vaadd_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vaadd.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vaadd_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vaadd_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vaadd_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vaadd.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vaadd_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vaadd_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vaadd_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vaadd.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vaadd_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vaadd_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vaadd_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vaadd.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vaadd_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vaadd_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vaadd_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vaadd.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vaadd_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vaadd_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vaadd_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vaadd.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vaadd_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vaadd_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vaadd_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vaadd.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vaadd_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vaadd_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vaadd_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vaadd.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vaadd_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vaadd_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vaadd_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vaadd.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vaadd_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vaadd_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vaadd_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vaadd.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vaadd_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vaadd_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vaadd_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vaadd.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vaadd_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vaadd_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vaadd_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vaadd.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vaadd_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vaadd_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vaadd_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vaadd.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vaadd_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vaadd_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vaadd_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vaadd.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vaadd_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vaadd_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vaadd_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vaadd.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vaadd_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vaadd_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vaadd_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vaadd.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vaadd_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vaadd_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vaadd_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vaadd.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vaadd_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vaadd_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vaadd_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vaadd.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vaadd_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vaadd_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vaadd_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vaadd.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vaadd_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vaadd_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vaadd_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vaadd.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vaadd_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vaadd_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vaadd_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vaadd.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vaadd_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vaadd_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vaadd_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vaadd.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vaadd_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vaadd_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vaadd_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vaadd.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vaadd_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vaadd_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vadd_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vadd.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vadd_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vadd_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vadd_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vadd.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vadd_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vadd_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vadd_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vadd.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vadd_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vadd_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vadd_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vadd.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vadd_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vadd_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vadd_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vadd.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vadd_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vadd_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vadd_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vadd.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vadd_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vadd_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vadd_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vadd.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vadd_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vadd_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vadd_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vadd.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vadd_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vadd_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vadd_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vadd.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vadd_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vadd_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vadd_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vadd.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vadd_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vadd_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vadd_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vadd.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vadd_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vadd_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vadd_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vadd.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vadd_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vadd_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vadd_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vadd.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vadd_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vadd_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vadd_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vadd.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vadd_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vadd_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vadd_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vadd.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vadd_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vadd_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vadd_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vadd.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vadd_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vadd_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vadd_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vadd.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vadd_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vadd_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vadd_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vadd.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vadd_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vadd_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vadd_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vadd.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vadd_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vadd_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vadd_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vadd.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vadd_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vadd_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vadd_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vadd.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vadd_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vadd_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vadd_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vadd.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vadd_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vadd_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vadd_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vadd.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vadd_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vadd_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vadd_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vadd.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vadd_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vadd_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vand_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vand.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vand_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vand_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vand_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vand.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vand_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vand_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vand_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vand.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vand_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vand_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vand_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vand.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vand_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vand_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vand_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vand.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vand_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vand_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vand_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vand.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vand_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vand_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vand_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vand.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vand_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vand_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vand_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vand.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vand_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vand_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vand_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vand.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vand_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vand_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vand_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vand.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vand_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vand_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vand_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vand.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vand_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vand_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vand_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vand.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vand_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vand_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vand_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vand.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vand_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vand_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vand_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vand.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vand_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vand_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vand_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vand.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vand_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vand_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vand_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vand.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vand_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vand_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vand_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vand.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vand_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vand_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vand_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vand.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vand_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vand_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vand_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vand.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vand_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vand_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vand_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vand.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vand_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vand_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vand_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vand.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vand_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vand_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vand_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vand.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vand_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vand_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vand_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vand.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vand_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vand_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vand_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vand.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vand_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vand_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vasub_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vasub.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vasub_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vasub_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vasub_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vasub.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vasub_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vasub_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vasub_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vasub.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vasub_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vasub_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vasub_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vasub.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vasub_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vasub_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vasub_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vasub.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vasub_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vasub_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vasub_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vasub.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vasub_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vasub_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vasub_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vasub.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vasub_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vasub_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vasub_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vasub.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vasub_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vasub_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vasub_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vasub.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vasub_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vasub_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vasub_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vasub.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vasub_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vasub_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vasub_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vasub.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vasub_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vasub_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vasub_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vasub.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vasub_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vasub_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vasub_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vasub.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vasub_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vasub_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vasub_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vasub.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vasub_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vasub_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vasub_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vasub.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vasub_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vasub_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vasub_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vasub.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vasub_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vasub_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vasub_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vasub.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vasub_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vasub_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vasub_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vasub.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vasub_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vasub_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vasub_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vasub.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vasub_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vasub_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vasub_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vasub.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vasub_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vasub_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vasub_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vasub.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vasub_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vasub_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vasub_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vasub.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vasub_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vasub_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vasub_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vasub.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vasub_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vasub_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vasub_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vasub.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vasub_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vasub_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vbroadcast_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vbroadcast.nxv8i8.i8(i8 [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vbroadcast_8xi8(signed char arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vbroadcast_8xi8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vbroadcast_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vbroadcast.nxv4i16.i16(i16 [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vbroadcast_4xi16(signed short int arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vbroadcast_4xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vbroadcast_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vbroadcast.nxv2i32.i32(i32 [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vbroadcast_2xi32(signed int arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vbroadcast_2xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vbroadcast_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vbroadcast.nxv1i64.i64(i64 [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vbroadcast_1xi64(signed long int arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vbroadcast_1xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vbroadcast_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vbroadcast.nxv2f32.f32(float [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vbroadcast_2xf32(float arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vbroadcast_2xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vbroadcast_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vbroadcast.nxv1f64.f64(double [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vbroadcast_1xf64(double arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vbroadcast_1xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vbroadcast_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vbroadcast.nxv16i8.i8(i8 [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vbroadcast_16xi8(signed char arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vbroadcast_16xi8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vbroadcast_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vbroadcast.nxv8i16.i16(i16 [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vbroadcast_8xi16(signed short int arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vbroadcast_8xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vbroadcast_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vbroadcast.nxv4i32.i32(i32 [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vbroadcast_4xi32(signed int arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vbroadcast_4xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vbroadcast_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vbroadcast.nxv2i64.i64(i64 [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vbroadcast_2xi64(signed long int arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vbroadcast_2xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vbroadcast_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vbroadcast.nxv4f32.f32(float [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vbroadcast_4xf32(float arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vbroadcast_4xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vbroadcast_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vbroadcast.nxv2f64.f64(double [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vbroadcast_2xf64(double arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vbroadcast_2xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vbroadcast_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vbroadcast.nxv32i8.i8(i8 [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vbroadcast_32xi8(signed char arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vbroadcast_32xi8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vbroadcast_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vbroadcast.nxv16i16.i16(i16 [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vbroadcast_16xi16(signed short int arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vbroadcast_16xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vbroadcast_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vbroadcast.nxv8i32.i32(i32 [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vbroadcast_8xi32(signed int arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vbroadcast_8xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vbroadcast_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vbroadcast.nxv4i64.i64(i64 [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vbroadcast_4xi64(signed long int arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vbroadcast_4xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vbroadcast_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vbroadcast.nxv8f32.f32(float [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vbroadcast_8xf32(float arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vbroadcast_8xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vbroadcast_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vbroadcast.nxv4f64.f64(double [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vbroadcast_4xf64(double arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vbroadcast_4xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vcompress_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vcompress.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vcompress_8xi8(__epi_8xi8 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vcompress_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vcompress.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vcompress_4xi16(__epi_4xi16 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vcompress_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vcompress.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vcompress_2xi32(__epi_2xi32 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vcompress_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vcompress.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vcompress_1xi64(__epi_1xi64 arg_0, __epi_1xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vcompress_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vcompress.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vcompress_2xf32(__epi_2xf32 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vcompress_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vcompress.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vcompress_1xf64(__epi_1xf64 arg_0, __epi_1xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vcompress_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vcompress.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vcompress_16xi8(__epi_16xi8 arg_0, __epi_16xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vcompress_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vcompress.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vcompress_8xi16(__epi_8xi16 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vcompress_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vcompress.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vcompress_4xi32(__epi_4xi32 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vcompress_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vcompress.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vcompress_2xi64(__epi_2xi64 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vcompress_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vcompress.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vcompress_4xf32(__epi_4xf32 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vcompress_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vcompress.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vcompress_2xf64(__epi_2xf64 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vcompress_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vcompress.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vcompress_32xi8(__epi_32xi8 arg_0, __epi_32xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vcompress_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vcompress.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vcompress_16xi16(__epi_16xi16 arg_0, __epi_16xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vcompress_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vcompress.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vcompress_8xi32(__epi_8xi32 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vcompress_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vcompress.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vcompress_4xi64(__epi_4xi64 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vcompress_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vcompress.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vcompress_8xf32(__epi_8xf32 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vcompress_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vcompress.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vcompress_4xf64(__epi_4xf64 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdiv_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vdiv.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vdiv_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdiv_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdiv_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vdiv.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vdiv_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdiv_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdiv_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vdiv.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vdiv_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdiv_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdiv_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vdiv.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vdiv_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdiv_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdiv_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vdiv.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vdiv_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdiv_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdiv_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vdiv.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vdiv_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdiv_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdiv_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vdiv.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vdiv_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdiv_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdiv_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vdiv.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vdiv_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdiv_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdiv_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vdiv.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vdiv_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdiv_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdiv_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vdiv.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vdiv_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdiv_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdiv_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vdiv.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vdiv_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdiv_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdiv_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vdiv.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vdiv_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdiv_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdiv_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vdiv.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vdiv_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdiv_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdiv_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vdiv.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vdiv_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdiv_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdiv_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vdiv.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vdiv_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdiv_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdiv_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vdiv.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vdiv_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdiv_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdiv_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vdiv.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vdiv_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdiv_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdiv_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vdiv.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vdiv_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdiv_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdiv_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vdiv.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vdiv_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdiv_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdiv_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vdiv.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vdiv_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdiv_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdiv_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vdiv.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vdiv_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdiv_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdiv_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vdiv.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vdiv_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdiv_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdiv_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vdiv.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vdiv_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdiv_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdiv_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vdiv.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vdiv_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdiv_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdivu_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vdivu.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vdivu_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdivu_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdivu_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vdivu.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vdivu_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdivu_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdivu_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vdivu.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vdivu_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdivu_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdivu_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vdivu.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vdivu_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdivu_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdivu_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vdivu.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vdivu_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdivu_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdivu_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vdivu.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vdivu_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdivu_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdivu_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vdivu.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vdivu_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdivu_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdivu_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vdivu.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vdivu_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdivu_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdivu_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vdivu.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vdivu_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdivu_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdivu_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vdivu.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vdivu_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdivu_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdivu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vdivu.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vdivu_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdivu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdivu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vdivu.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vdivu_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdivu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdivu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vdivu.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vdivu_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdivu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdivu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vdivu.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vdivu_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdivu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdivu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vdivu.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vdivu_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdivu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdivu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vdivu.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vdivu_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdivu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdivu_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vdivu.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vdivu_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdivu_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdivu_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vdivu.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vdivu_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdivu_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdivu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vdivu.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vdivu_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdivu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdivu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vdivu.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vdivu_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdivu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdivu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vdivu.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vdivu_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdivu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdivu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vdivu.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vdivu_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdivu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdivu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vdivu.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vdivu_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdivu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdivu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vdivu.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vdivu_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdivu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdot_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vdot.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vdot_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdot_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdot_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vdot.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vdot_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdot_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdot_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vdot.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vdot_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdot_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdot_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vdot.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vdot_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdot_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdot_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vdot.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vdot_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdot_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdot_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vdot.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vdot_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdot_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdot_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vdot.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vdot_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdot_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdot_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vdot.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vdot_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdot_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdot_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vdot.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vdot_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdot_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdot_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vdot.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vdot_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdot_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdot_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vdot.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vdot_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdot_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdot_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vdot.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vdot_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdot_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdot_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vdot.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vdot_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdot_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdot_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vdot.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vdot_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdot_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdot_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vdot.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vdot_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdot_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdot_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vdot.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vdot_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdot_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdot_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vdot.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vdot_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdot_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdot_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vdot.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vdot_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdot_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdot_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vdot.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vdot_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdot_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdot_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vdot.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vdot_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdot_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdot_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vdot.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vdot_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdot_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdot_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vdot.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vdot_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdot_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdot_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vdot.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vdot_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdot_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdot_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vdot.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vdot_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdot_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdotu_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vdotu.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vdotu_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdotu_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdotu_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vdotu.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vdotu_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdotu_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdotu_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vdotu.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vdotu_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdotu_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdotu_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vdotu.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vdotu_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdotu_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdotu_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vdotu.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vdotu_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdotu_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdotu_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vdotu.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vdotu_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdotu_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdotu_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vdotu.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vdotu_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdotu_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdotu_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vdotu.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vdotu_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdotu_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdotu_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vdotu.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vdotu_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdotu_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdotu_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vdotu.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vdotu_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdotu_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdotu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vdotu.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vdotu_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdotu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdotu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vdotu.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vdotu_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdotu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdotu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vdotu.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vdotu_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdotu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdotu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vdotu.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vdotu_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdotu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdotu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vdotu.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vdotu_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdotu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdotu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vdotu.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vdotu_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdotu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdotu_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vdotu.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vdotu_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdotu_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdotu_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vdotu.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vdotu_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdotu_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdotu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vdotu.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vdotu_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdotu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdotu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vdotu.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vdotu_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdotu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdotu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vdotu.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vdotu_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdotu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdotu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vdotu.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vdotu_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdotu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdotu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vdotu.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vdotu_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdotu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdotu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vdotu.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vdotu_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdotu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vextract_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i8 @llvm.epi.vext.x.v.i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret i8 [[TMP0]]
//
signed char test_vextract_8xi8(__epi_8xi8 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vextract_8xi8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vextract_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i16 @llvm.epi.vext.x.v.i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret i16 [[TMP0]]
//
signed short int test_vextract_4xi16(__epi_4xi16 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vextract_4xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vextract_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.epi.vext.x.v.i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret i32 [[TMP0]]
//
signed int test_vextract_2xi32(__epi_2xi32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vextract_2xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vextract_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vext.x.v.i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vextract_1xi64(__epi_1xi64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vextract_1xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfadd_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfadd.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfadd_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfadd_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfadd_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfadd.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfadd_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfadd_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfadd_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfadd.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfadd_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfadd_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfadd_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfadd.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfadd_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfadd_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfadd_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfadd.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfadd_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfadd_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfadd_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfadd.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfadd_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfadd_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfadd_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfadd.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfadd_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfadd_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfadd_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfadd.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfadd_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfadd_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfadd_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfadd.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfadd_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfadd_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfadd_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfadd.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfadd_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfadd_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfadd_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfadd.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfadd_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfadd_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfadd_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfadd.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfadd_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfadd_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfcvt_f_x_2xf32_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfcvt.f.x.nxv2f32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfcvt_f_x_2xf32_2xi32(__epi_2xi32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_f_x_2xf32_2xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_f_x_2xf32_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfcvt.f.x.mask.nxv2f32.nxv2i32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfcvt_f_x_2xf32_2xi32_mask(__epi_2xf32 arg_0, __epi_2xi32 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_f_x_2xf32_2xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_f_x_1xf64_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfcvt.f.x.nxv1f64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfcvt_f_x_1xf64_1xi64(__epi_1xi64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_f_x_1xf64_1xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_f_x_1xf64_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfcvt.f.x.mask.nxv1f64.nxv1i64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfcvt_f_x_1xf64_1xi64_mask(__epi_1xf64 arg_0, __epi_1xi64 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_f_x_1xf64_1xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_f_x_4xf32_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfcvt.f.x.nxv4f32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfcvt_f_x_4xf32_4xi32(__epi_4xi32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_f_x_4xf32_4xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_f_x_4xf32_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfcvt.f.x.mask.nxv4f32.nxv4i32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfcvt_f_x_4xf32_4xi32_mask(__epi_4xf32 arg_0, __epi_4xi32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_f_x_4xf32_4xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_f_x_2xf64_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfcvt.f.x.nxv2f64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfcvt_f_x_2xf64_2xi64(__epi_2xi64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_f_x_2xf64_2xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_f_x_2xf64_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfcvt.f.x.mask.nxv2f64.nxv2i64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfcvt_f_x_2xf64_2xi64_mask(__epi_2xf64 arg_0, __epi_2xi64 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_f_x_2xf64_2xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_f_x_8xf32_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfcvt.f.x.nxv8f32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfcvt_f_x_8xf32_8xi32(__epi_8xi32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_f_x_8xf32_8xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_f_x_8xf32_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfcvt.f.x.mask.nxv8f32.nxv8i32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfcvt_f_x_8xf32_8xi32_mask(__epi_8xf32 arg_0, __epi_8xi32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_f_x_8xf32_8xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_f_x_4xf64_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfcvt.f.x.nxv4f64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfcvt_f_x_4xf64_4xi64(__epi_4xi64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_f_x_4xf64_4xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_f_x_4xf64_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfcvt.f.x.mask.nxv4f64.nxv4i64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfcvt_f_x_4xf64_4xi64_mask(__epi_4xf64 arg_0, __epi_4xi64 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_f_x_4xf64_4xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_f_xu_2xf32_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfcvt.f.xu.nxv2f32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfcvt_f_xu_2xf32_2xi32(__epi_2xi32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_f_xu_2xf32_2xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_f_xu_2xf32_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfcvt.f.xu.mask.nxv2f32.nxv2i32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfcvt_f_xu_2xf32_2xi32_mask(__epi_2xf32 arg_0, __epi_2xi32 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_f_xu_2xf32_2xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_f_xu_1xf64_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfcvt.f.xu.nxv1f64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfcvt_f_xu_1xf64_1xi64(__epi_1xi64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_f_xu_1xf64_1xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_f_xu_1xf64_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfcvt.f.xu.mask.nxv1f64.nxv1i64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfcvt_f_xu_1xf64_1xi64_mask(__epi_1xf64 arg_0, __epi_1xi64 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_f_xu_1xf64_1xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_f_xu_4xf32_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfcvt.f.xu.nxv4f32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfcvt_f_xu_4xf32_4xi32(__epi_4xi32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_f_xu_4xf32_4xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_f_xu_4xf32_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfcvt.f.xu.mask.nxv4f32.nxv4i32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfcvt_f_xu_4xf32_4xi32_mask(__epi_4xf32 arg_0, __epi_4xi32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_f_xu_4xf32_4xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_f_xu_2xf64_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfcvt.f.xu.nxv2f64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfcvt_f_xu_2xf64_2xi64(__epi_2xi64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_f_xu_2xf64_2xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_f_xu_2xf64_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfcvt.f.xu.mask.nxv2f64.nxv2i64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfcvt_f_xu_2xf64_2xi64_mask(__epi_2xf64 arg_0, __epi_2xi64 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_f_xu_2xf64_2xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_f_xu_8xf32_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfcvt.f.xu.nxv8f32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfcvt_f_xu_8xf32_8xi32(__epi_8xi32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_f_xu_8xf32_8xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_f_xu_8xf32_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfcvt.f.xu.mask.nxv8f32.nxv8i32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfcvt_f_xu_8xf32_8xi32_mask(__epi_8xf32 arg_0, __epi_8xi32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_f_xu_8xf32_8xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_f_xu_4xf64_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfcvt.f.xu.nxv4f64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfcvt_f_xu_4xf64_4xi64(__epi_4xi64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_f_xu_4xf64_4xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_f_xu_4xf64_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfcvt.f.xu.mask.nxv4f64.nxv4i64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfcvt_f_xu_4xf64_4xi64_mask(__epi_4xf64 arg_0, __epi_4xi64 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_f_xu_4xf64_4xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_x_f_2xi32_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vfcvt.x.f.nxv2i32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vfcvt_x_f_2xi32_2xf32(__epi_2xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_x_f_2xi32_2xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_x_f_2xi32_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vfcvt.x.f.mask.nxv2i32.nxv2f32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vfcvt_x_f_2xi32_2xf32_mask(__epi_2xi32 arg_0, __epi_2xf32 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_x_f_2xi32_2xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_x_f_1xi64_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vfcvt.x.f.nxv1i64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vfcvt_x_f_1xi64_1xf64(__epi_1xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_x_f_1xi64_1xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_x_f_1xi64_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vfcvt.x.f.mask.nxv1i64.nxv1f64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vfcvt_x_f_1xi64_1xf64_mask(__epi_1xi64 arg_0, __epi_1xf64 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_x_f_1xi64_1xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_x_f_4xi32_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vfcvt.x.f.nxv4i32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vfcvt_x_f_4xi32_4xf32(__epi_4xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_x_f_4xi32_4xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_x_f_4xi32_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vfcvt.x.f.mask.nxv4i32.nxv4f32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vfcvt_x_f_4xi32_4xf32_mask(__epi_4xi32 arg_0, __epi_4xf32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_x_f_4xi32_4xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_x_f_2xi64_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vfcvt.x.f.nxv2i64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vfcvt_x_f_2xi64_2xf64(__epi_2xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_x_f_2xi64_2xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_x_f_2xi64_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vfcvt.x.f.mask.nxv2i64.nxv2f64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vfcvt_x_f_2xi64_2xf64_mask(__epi_2xi64 arg_0, __epi_2xf64 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_x_f_2xi64_2xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_x_f_8xi32_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vfcvt.x.f.nxv8i32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vfcvt_x_f_8xi32_8xf32(__epi_8xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_x_f_8xi32_8xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_x_f_8xi32_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vfcvt.x.f.mask.nxv8i32.nxv8f32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vfcvt_x_f_8xi32_8xf32_mask(__epi_8xi32 arg_0, __epi_8xf32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_x_f_8xi32_8xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_x_f_4xi64_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vfcvt.x.f.nxv4i64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vfcvt_x_f_4xi64_4xf64(__epi_4xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_x_f_4xi64_4xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_x_f_4xi64_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vfcvt.x.f.mask.nxv4i64.nxv4f64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vfcvt_x_f_4xi64_4xf64_mask(__epi_4xi64 arg_0, __epi_4xf64 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_x_f_4xi64_4xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_xu_f_2xi32_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vfcvt.xu.f.nxv2i32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vfcvt_xu_f_2xi32_2xf32(__epi_2xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_xu_f_2xi32_2xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_xu_f_2xi32_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vfcvt.xu.f.mask.nxv2i32.nxv2f32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vfcvt_xu_f_2xi32_2xf32_mask(__epi_2xi32 arg_0, __epi_2xf32 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_xu_f_2xi32_2xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_xu_f_1xi64_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vfcvt.xu.f.nxv1i64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vfcvt_xu_f_1xi64_1xf64(__epi_1xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_xu_f_1xi64_1xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_xu_f_1xi64_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vfcvt.xu.f.mask.nxv1i64.nxv1f64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vfcvt_xu_f_1xi64_1xf64_mask(__epi_1xi64 arg_0, __epi_1xf64 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_xu_f_1xi64_1xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_xu_f_4xi32_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vfcvt.xu.f.nxv4i32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vfcvt_xu_f_4xi32_4xf32(__epi_4xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_xu_f_4xi32_4xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_xu_f_4xi32_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vfcvt.xu.f.mask.nxv4i32.nxv4f32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vfcvt_xu_f_4xi32_4xf32_mask(__epi_4xi32 arg_0, __epi_4xf32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_xu_f_4xi32_4xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_xu_f_2xi64_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vfcvt.xu.f.nxv2i64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vfcvt_xu_f_2xi64_2xf64(__epi_2xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_xu_f_2xi64_2xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_xu_f_2xi64_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vfcvt.xu.f.mask.nxv2i64.nxv2f64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vfcvt_xu_f_2xi64_2xf64_mask(__epi_2xi64 arg_0, __epi_2xf64 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_xu_f_2xi64_2xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_xu_f_8xi32_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vfcvt.xu.f.nxv8i32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vfcvt_xu_f_8xi32_8xf32(__epi_8xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_xu_f_8xi32_8xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_xu_f_8xi32_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vfcvt.xu.f.mask.nxv8i32.nxv8f32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vfcvt_xu_f_8xi32_8xf32_mask(__epi_8xi32 arg_0, __epi_8xf32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_xu_f_8xi32_8xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_xu_f_4xi64_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vfcvt.xu.f.nxv4i64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vfcvt_xu_f_4xi64_4xf64(__epi_4xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_xu_f_4xi64_4xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_xu_f_4xi64_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vfcvt.xu.f.mask.nxv4i64.nxv4f64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vfcvt_xu_f_4xi64_4xf64_mask(__epi_4xi64 arg_0, __epi_4xf64 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_xu_f_4xi64_4xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfdiv_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfdiv.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfdiv_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfdiv_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfdiv_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfdiv.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfdiv_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfdiv_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfdiv_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfdiv.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfdiv_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfdiv_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfdiv_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfdiv.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfdiv_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfdiv_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfdiv_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfdiv.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfdiv_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfdiv_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfdiv_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfdiv.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfdiv_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfdiv_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfdiv_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfdiv.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfdiv_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfdiv_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfdiv_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfdiv.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfdiv_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfdiv_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfdiv_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfdiv.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfdiv_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfdiv_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfdiv_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfdiv.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfdiv_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfdiv_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfdiv_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfdiv.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfdiv_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfdiv_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfdiv_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfdiv.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfdiv_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfdiv_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfdot_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfdot.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfdot_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfdot_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfdot_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfdot.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfdot_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfdot_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfdot_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfdot.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfdot_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfdot_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfdot_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfdot.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfdot_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfdot_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfdot_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfdot.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfdot_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfdot_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfdot_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfdot.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfdot_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfdot_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfdot_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfdot.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfdot_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfdot_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfdot_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfdot.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfdot_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfdot_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfdot_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfdot.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfdot_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfdot_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfdot_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfdot.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfdot_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfdot_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfdot_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfdot.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfdot_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfdot_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfdot_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfdot.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfdot_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfdot_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmacc_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfmacc.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfmacc_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmacc_2xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmacc_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfmacc.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfmacc_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmacc_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmacc_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfmacc.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfmacc_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmacc_1xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmacc_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfmacc.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfmacc_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmacc_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmacc_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfmacc.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfmacc_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmacc_4xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmacc_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfmacc.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfmacc_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmacc_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmacc_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfmacc.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfmacc_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmacc_2xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmacc_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfmacc.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfmacc_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmacc_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmacc_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfmacc.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfmacc_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmacc_8xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmacc_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfmacc.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfmacc_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmacc_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmacc_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfmacc.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfmacc_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmacc_4xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmacc_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfmacc.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfmacc_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmacc_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmadd_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfmadd.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfmadd_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmadd_2xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmadd_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfmadd.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfmadd_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmadd_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmadd_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfmadd.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfmadd_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmadd_1xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmadd_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfmadd.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfmadd_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmadd_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmadd_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfmadd.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfmadd_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmadd_4xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmadd_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfmadd.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfmadd_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmadd_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmadd_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfmadd.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfmadd_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmadd_2xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmadd_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfmadd.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfmadd_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmadd_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmadd_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfmadd.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfmadd_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmadd_8xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmadd_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfmadd.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfmadd_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmadd_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmadd_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfmadd.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfmadd_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmadd_4xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmadd_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfmadd.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfmadd_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmadd_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmax_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfmax.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfmax_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmax_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmax_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfmax.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfmax_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmax_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmax_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfmax.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfmax_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmax_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmax_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfmax.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfmax_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmax_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmax_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfmax.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfmax_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmax_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmax_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfmax.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfmax_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmax_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmax_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfmax.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfmax_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmax_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmax_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfmax.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfmax_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmax_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmax_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfmax.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfmax_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmax_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmax_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfmax.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfmax_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmax_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmax_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfmax.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfmax_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmax_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmax_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfmax.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfmax_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmax_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmerge_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfmerge.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfmerge_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmerge_2xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmerge_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfmerge.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfmerge_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmerge_1xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmerge_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfmerge.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfmerge_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmerge_4xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmerge_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfmerge.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfmerge_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmerge_2xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmerge_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfmerge.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfmerge_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmerge_8xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmerge_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfmerge.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfmerge_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmerge_4xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmin_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfmin.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfmin_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmin_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmin_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfmin.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfmin_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmin_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmin_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfmin.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfmin_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmin_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmin_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfmin.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfmin_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmin_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmin_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfmin.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfmin_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmin_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmin_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfmin.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfmin_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmin_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmin_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfmin.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfmin_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmin_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmin_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfmin.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfmin_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmin_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmin_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfmin.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfmin_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmin_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmin_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfmin.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfmin_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmin_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmin_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfmin.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfmin_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmin_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmin_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfmin.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfmin_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmin_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmsac_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfmsac.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfmsac_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmsac_2xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmsac_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfmsac.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfmsac_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmsac_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmsac_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfmsac.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfmsac_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmsac_1xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmsac_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfmsac.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfmsac_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmsac_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmsac_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfmsac.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfmsac_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmsac_4xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmsac_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfmsac.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfmsac_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmsac_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmsac_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfmsac.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfmsac_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmsac_2xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmsac_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfmsac.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfmsac_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmsac_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmsac_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfmsac.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfmsac_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmsac_8xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmsac_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfmsac.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfmsac_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmsac_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmsac_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfmsac.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfmsac_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmsac_4xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmsac_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfmsac.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfmsac_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmsac_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmsub_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfmsub.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfmsub_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmsub_2xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmsub_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfmsub.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfmsub_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmsub_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmsub_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfmsub.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfmsub_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmsub_1xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmsub_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfmsub.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfmsub_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmsub_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmsub_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfmsub.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfmsub_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmsub_4xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmsub_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfmsub.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfmsub_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmsub_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmsub_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfmsub.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfmsub_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmsub_2xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmsub_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfmsub.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfmsub_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmsub_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmsub_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfmsub.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfmsub_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmsub_8xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmsub_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfmsub.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfmsub_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmsub_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmsub_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfmsub.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfmsub_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmsub_4xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmsub_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfmsub.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfmsub_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmsub_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmul_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfmul.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfmul_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmul_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmul_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfmul.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfmul_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmul_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmul_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfmul.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfmul_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmul_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmul_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfmul.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfmul_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmul_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmul_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfmul.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfmul_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmul_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmul_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfmul.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfmul_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmul_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmul_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfmul.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfmul_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmul_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmul_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfmul.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfmul_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmul_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmul_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfmul.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfmul_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmul_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmul_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfmul.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfmul_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmul_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmul_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfmul.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfmul_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmul_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmul_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfmul.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfmul_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmul_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfncvt_f_f_2xf32_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfncvt.f.f.nxv2f32.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfncvt_f_f_2xf32_2xf64(__epi_2xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_f_f_2xf32_2xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_f_f_2xf32_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfncvt.f.f.mask.nxv2f32.nxv2f64.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfncvt_f_f_2xf32_2xf64_mask(__epi_2xf32 arg_0, __epi_2xf64 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_f_f_2xf32_2xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_f_f_4xf32_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfncvt.f.f.nxv4f32.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfncvt_f_f_4xf32_4xf64(__epi_4xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_f_f_4xf32_4xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_f_f_4xf32_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfncvt.f.f.mask.nxv4f32.nxv4f64.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfncvt_f_f_4xf32_4xf64_mask(__epi_4xf32 arg_0, __epi_4xf64 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_f_f_4xf32_4xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_f_f_8xf32_8xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfncvt.f.f.nxv8f32.nxv8f64(<vscale x 8 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfncvt_f_f_8xf32_8xf64(__epi_8xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_f_f_8xf32_8xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_f_f_8xf32_8xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfncvt.f.f.mask.nxv8f32.nxv8f64.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x double> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfncvt_f_f_8xf32_8xf64_mask(__epi_8xf32 arg_0, __epi_8xf64 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_f_f_8xf32_8xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_f_x_2xf32_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfncvt.f.x.nxv2f32.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfncvt_f_x_2xf32_2xi64(__epi_2xi64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_f_x_2xf32_2xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_f_x_2xf32_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfncvt.f.x.mask.nxv2f32.nxv2i64.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfncvt_f_x_2xf32_2xi64_mask(__epi_2xf32 arg_0, __epi_2xi64 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_f_x_2xf32_2xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_f_x_4xf32_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfncvt.f.x.nxv4f32.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfncvt_f_x_4xf32_4xi64(__epi_4xi64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_f_x_4xf32_4xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_f_x_4xf32_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfncvt.f.x.mask.nxv4f32.nxv4i64.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfncvt_f_x_4xf32_4xi64_mask(__epi_4xf32 arg_0, __epi_4xi64 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_f_x_4xf32_4xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_f_x_8xf32_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfncvt.f.x.nxv8f32.nxv8i64(<vscale x 8 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfncvt_f_x_8xf32_8xi64(__epi_8xi64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_f_x_8xf32_8xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_f_x_8xf32_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfncvt.f.x.mask.nxv8f32.nxv8i64.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x i64> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfncvt_f_x_8xf32_8xi64_mask(__epi_8xf32 arg_0, __epi_8xi64 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_f_x_8xf32_8xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_f_xu_2xf32_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfncvt.f.xu.nxv2f32.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfncvt_f_xu_2xf32_2xi64(__epi_2xi64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_f_xu_2xf32_2xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_f_xu_2xf32_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfncvt.f.xu.mask.nxv2f32.nxv2i64.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfncvt_f_xu_2xf32_2xi64_mask(__epi_2xf32 arg_0, __epi_2xi64 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_f_xu_2xf32_2xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_f_xu_4xf32_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfncvt.f.xu.nxv4f32.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfncvt_f_xu_4xf32_4xi64(__epi_4xi64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_f_xu_4xf32_4xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_f_xu_4xf32_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfncvt.f.xu.mask.nxv4f32.nxv4i64.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfncvt_f_xu_4xf32_4xi64_mask(__epi_4xf32 arg_0, __epi_4xi64 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_f_xu_4xf32_4xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_f_xu_8xf32_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfncvt.f.xu.nxv8f32.nxv8i64(<vscale x 8 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfncvt_f_xu_8xf32_8xi64(__epi_8xi64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_f_xu_8xf32_8xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_f_xu_8xf32_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfncvt.f.xu.mask.nxv8f32.nxv8i64.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x i64> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfncvt_f_xu_8xf32_8xi64_mask(__epi_8xf32 arg_0, __epi_8xi64 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_f_xu_8xf32_8xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_x_f_4xi16_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vfncvt.x.f.nxv4i16.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vfncvt_x_f_4xi16_4xf32(__epi_4xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_x_f_4xi16_4xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_x_f_4xi16_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vfncvt.x.f.mask.nxv4i16.nxv4f32.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vfncvt_x_f_4xi16_4xf32_mask(__epi_4xi16 arg_0, __epi_4xf32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_x_f_4xi16_4xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_x_f_2xi32_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vfncvt.x.f.nxv2i32.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vfncvt_x_f_2xi32_2xf64(__epi_2xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_x_f_2xi32_2xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_x_f_2xi32_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vfncvt.x.f.mask.nxv2i32.nxv2f64.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vfncvt_x_f_2xi32_2xf64_mask(__epi_2xi32 arg_0, __epi_2xf64 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_x_f_2xi32_2xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_x_f_8xi16_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vfncvt.x.f.nxv8i16.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vfncvt_x_f_8xi16_8xf32(__epi_8xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_x_f_8xi16_8xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_x_f_8xi16_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vfncvt.x.f.mask.nxv8i16.nxv8f32.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vfncvt_x_f_8xi16_8xf32_mask(__epi_8xi16 arg_0, __epi_8xf32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_x_f_8xi16_8xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_x_f_4xi32_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vfncvt.x.f.nxv4i32.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vfncvt_x_f_4xi32_4xf64(__epi_4xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_x_f_4xi32_4xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_x_f_4xi32_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vfncvt.x.f.mask.nxv4i32.nxv4f64.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vfncvt_x_f_4xi32_4xf64_mask(__epi_4xi32 arg_0, __epi_4xf64 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_x_f_4xi32_4xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_x_f_16xi16_16xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vfncvt.x.f.nxv16i16.nxv16f32(<vscale x 16 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vfncvt_x_f_16xi16_16xf32(__epi_16xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_x_f_16xi16_16xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_x_f_16xi16_16xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vfncvt.x.f.mask.nxv16i16.nxv16f32.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x float> [[ARG_1:%.*]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vfncvt_x_f_16xi16_16xf32_mask(__epi_16xi16 arg_0, __epi_16xf32 arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_x_f_16xi16_16xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_x_f_8xi32_8xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vfncvt.x.f.nxv8i32.nxv8f64(<vscale x 8 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vfncvt_x_f_8xi32_8xf64(__epi_8xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_x_f_8xi32_8xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_x_f_8xi32_8xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vfncvt.x.f.mask.nxv8i32.nxv8f64.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x double> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vfncvt_x_f_8xi32_8xf64_mask(__epi_8xi32 arg_0, __epi_8xf64 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_x_f_8xi32_8xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_xu_f_4xi16_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vfncvt.xu.f.nxv4i16.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vfncvt_xu_f_4xi16_4xf32(__epi_4xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_xu_f_4xi16_4xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_xu_f_4xi16_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vfncvt.xu.f.mask.nxv4i16.nxv4f32.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vfncvt_xu_f_4xi16_4xf32_mask(__epi_4xi16 arg_0, __epi_4xf32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_xu_f_4xi16_4xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_xu_f_2xi32_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vfncvt.xu.f.nxv2i32.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vfncvt_xu_f_2xi32_2xf64(__epi_2xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_xu_f_2xi32_2xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_xu_f_2xi32_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vfncvt.xu.f.mask.nxv2i32.nxv2f64.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vfncvt_xu_f_2xi32_2xf64_mask(__epi_2xi32 arg_0, __epi_2xf64 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_xu_f_2xi32_2xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_xu_f_8xi16_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vfncvt.xu.f.nxv8i16.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vfncvt_xu_f_8xi16_8xf32(__epi_8xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_xu_f_8xi16_8xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_xu_f_8xi16_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vfncvt.xu.f.mask.nxv8i16.nxv8f32.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vfncvt_xu_f_8xi16_8xf32_mask(__epi_8xi16 arg_0, __epi_8xf32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_xu_f_8xi16_8xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_xu_f_4xi32_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vfncvt.xu.f.nxv4i32.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vfncvt_xu_f_4xi32_4xf64(__epi_4xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_xu_f_4xi32_4xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_xu_f_4xi32_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vfncvt.xu.f.mask.nxv4i32.nxv4f64.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vfncvt_xu_f_4xi32_4xf64_mask(__epi_4xi32 arg_0, __epi_4xf64 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_xu_f_4xi32_4xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_xu_f_16xi16_16xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vfncvt.xu.f.nxv16i16.nxv16f32(<vscale x 16 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vfncvt_xu_f_16xi16_16xf32(__epi_16xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_xu_f_16xi16_16xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_xu_f_16xi16_16xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vfncvt.xu.f.mask.nxv16i16.nxv16f32.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x float> [[ARG_1:%.*]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vfncvt_xu_f_16xi16_16xf32_mask(__epi_16xi16 arg_0, __epi_16xf32 arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_xu_f_16xi16_16xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_xu_f_8xi32_8xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vfncvt.xu.f.nxv8i32.nxv8f64(<vscale x 8 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vfncvt_xu_f_8xi32_8xf64(__epi_8xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_xu_f_8xi32_8xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_xu_f_8xi32_8xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vfncvt.xu.f.mask.nxv8i32.nxv8f64.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x double> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vfncvt_xu_f_8xi32_8xf64_mask(__epi_8xi32 arg_0, __epi_8xf64 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_xu_f_8xi32_8xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmacc_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfnmacc.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfnmacc_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmacc_2xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmacc_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfnmacc.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfnmacc_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmacc_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmacc_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfnmacc.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfnmacc_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmacc_1xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmacc_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfnmacc.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfnmacc_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmacc_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmacc_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfnmacc.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfnmacc_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmacc_4xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmacc_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfnmacc.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfnmacc_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmacc_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmacc_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfnmacc.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfnmacc_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmacc_2xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmacc_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfnmacc.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfnmacc_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmacc_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmacc_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfnmacc.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfnmacc_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmacc_8xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmacc_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfnmacc.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfnmacc_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmacc_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmacc_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfnmacc.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfnmacc_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmacc_4xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmacc_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfnmacc.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfnmacc_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmacc_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmadd_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfnmadd.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfnmadd_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmadd_2xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmadd_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfnmadd.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfnmadd_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmadd_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmadd_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfnmadd.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfnmadd_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmadd_1xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmadd_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfnmadd.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfnmadd_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmadd_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmadd_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfnmadd.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfnmadd_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmadd_4xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmadd_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfnmadd.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfnmadd_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmadd_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmadd_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfnmadd.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfnmadd_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmadd_2xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmadd_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfnmadd.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfnmadd_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmadd_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmadd_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfnmadd.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfnmadd_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmadd_8xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmadd_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfnmadd.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfnmadd_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmadd_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmadd_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfnmadd.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfnmadd_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmadd_4xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmadd_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfnmadd.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfnmadd_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmadd_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmsac_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfnmsac.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfnmsac_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmsac_2xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmsac_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfnmsac.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfnmsac_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmsac_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmsac_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfnmsac.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfnmsac_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmsac_1xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmsac_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfnmsac.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfnmsac_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmsac_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmsac_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfnmsac.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfnmsac_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmsac_4xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmsac_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfnmsac.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfnmsac_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmsac_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmsac_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfnmsac.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfnmsac_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmsac_2xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmsac_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfnmsac.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfnmsac_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmsac_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmsac_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfnmsac.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfnmsac_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmsac_8xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmsac_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfnmsac.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfnmsac_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmsac_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmsac_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfnmsac.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfnmsac_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmsac_4xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmsac_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfnmsac.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfnmsac_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmsac_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmsub_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfnmsub.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfnmsub_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmsub_2xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmsub_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfnmsub.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfnmsub_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmsub_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmsub_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfnmsub.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfnmsub_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmsub_1xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmsub_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfnmsub.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfnmsub_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmsub_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmsub_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfnmsub.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfnmsub_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmsub_4xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmsub_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfnmsub.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfnmsub_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmsub_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmsub_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfnmsub.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfnmsub_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmsub_2xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmsub_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfnmsub.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfnmsub_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmsub_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmsub_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfnmsub.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfnmsub_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmsub_8xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmsub_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfnmsub.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfnmsub_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmsub_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmsub_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfnmsub.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfnmsub_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmsub_4xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmsub_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfnmsub.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfnmsub_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmsub_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredmax_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfredmax.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfredmax_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredmax_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredmax_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfredmax.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfredmax_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredmax_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredmax_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfredmax.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfredmax_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredmax_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredmax_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfredmax.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfredmax_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredmax_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredmax_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfredmax.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfredmax_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredmax_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredmax_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfredmax.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfredmax_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredmax_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredmax_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfredmax.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfredmax_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredmax_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredmax_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfredmax.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfredmax_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredmax_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredmax_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfredmax.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfredmax_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredmax_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredmax_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfredmax.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfredmax_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredmax_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredmax_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfredmax.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfredmax_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredmax_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredmax_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfredmax.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfredmax_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredmax_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredmin_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfredmin.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfredmin_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredmin_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredmin_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfredmin.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfredmin_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredmin_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredmin_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfredmin.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfredmin_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredmin_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredmin_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfredmin.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfredmin_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredmin_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredmin_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfredmin.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfredmin_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredmin_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredmin_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfredmin.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfredmin_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredmin_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredmin_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfredmin.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfredmin_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredmin_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredmin_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfredmin.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfredmin_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredmin_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredmin_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfredmin.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfredmin_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredmin_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredmin_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfredmin.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfredmin_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredmin_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredmin_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfredmin.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfredmin_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredmin_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredmin_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfredmin.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfredmin_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredmin_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredosum_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfredosum.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfredosum_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredosum_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredosum_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfredosum.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfredosum_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredosum_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredosum_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfredosum.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfredosum_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredosum_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredosum_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfredosum.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfredosum_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredosum_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredosum_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfredosum.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfredosum_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredosum_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredosum_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfredosum.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfredosum_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredosum_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredosum_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfredosum.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfredosum_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredosum_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredosum_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfredosum.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfredosum_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredosum_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredosum_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfredosum.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfredosum_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredosum_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredosum_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfredosum.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfredosum_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredosum_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredosum_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfredosum.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfredosum_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredosum_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredosum_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfredosum.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfredosum_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredosum_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredsum_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfredsum.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfredsum_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredsum_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredsum_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfredsum.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfredsum_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredsum_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredsum_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfredsum.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfredsum_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredsum_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredsum_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfredsum.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfredsum_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredsum_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredsum_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfredsum.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfredsum_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredsum_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredsum_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfredsum.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfredsum_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredsum_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredsum_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfredsum.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfredsum_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredsum_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredsum_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfredsum.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfredsum_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredsum_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredsum_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfredsum.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfredsum_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredsum_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredsum_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfredsum.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfredsum_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredsum_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredsum_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfredsum.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfredsum_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredsum_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredsum_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfredsum.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfredsum_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredsum_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnj_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfsgnj.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfsgnj_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnj_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnj_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfsgnj.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfsgnj_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnj_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnj_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfsgnj.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfsgnj_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnj_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnj_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfsgnj.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfsgnj_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnj_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnj_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfsgnj.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfsgnj_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnj_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnj_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfsgnj.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfsgnj_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnj_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnj_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfsgnj.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfsgnj_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnj_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnj_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfsgnj.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfsgnj_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnj_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnj_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfsgnj.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfsgnj_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnj_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnj_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfsgnj.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfsgnj_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnj_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnj_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfsgnj.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfsgnj_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnj_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnj_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfsgnj.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfsgnj_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnj_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnjn_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfsgnjn.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfsgnjn_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnjn_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnjn_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfsgnjn.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfsgnjn_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnjn_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnjn_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfsgnjn.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfsgnjn_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnjn_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnjn_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfsgnjn.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfsgnjn_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnjn_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnjn_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfsgnjn.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfsgnjn_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnjn_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnjn_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfsgnjn.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfsgnjn_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnjn_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnjn_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfsgnjn.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfsgnjn_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnjn_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnjn_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfsgnjn.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfsgnjn_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnjn_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnjn_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfsgnjn.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfsgnjn_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnjn_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnjn_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfsgnjn.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfsgnjn_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnjn_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnjn_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfsgnjn.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfsgnjn_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnjn_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnjn_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfsgnjn.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfsgnjn_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnjn_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnjx_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfsgnjx.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfsgnjx_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnjx_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnjx_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfsgnjx.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfsgnjx_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnjx_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnjx_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfsgnjx.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfsgnjx_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnjx_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnjx_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfsgnjx.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfsgnjx_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnjx_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnjx_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfsgnjx.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfsgnjx_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnjx_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnjx_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfsgnjx.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfsgnjx_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnjx_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnjx_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfsgnjx.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfsgnjx_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnjx_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnjx_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfsgnjx.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfsgnjx_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnjx_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnjx_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfsgnjx.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfsgnjx_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnjx_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnjx_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfsgnjx.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfsgnjx_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnjx_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnjx_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfsgnjx.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfsgnjx_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnjx_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnjx_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfsgnjx.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfsgnjx_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnjx_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsqrt_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfsqrt.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfsqrt_2xf32(__epi_2xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfsqrt_2xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfsqrt_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfsqrt.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfsqrt_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfsqrt_2xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfsqrt_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfsqrt.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfsqrt_1xf64(__epi_1xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfsqrt_1xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfsqrt_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfsqrt.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfsqrt_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfsqrt_1xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfsqrt_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfsqrt.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfsqrt_4xf32(__epi_4xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfsqrt_4xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfsqrt_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfsqrt.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfsqrt_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfsqrt_4xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfsqrt_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfsqrt.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfsqrt_2xf64(__epi_2xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfsqrt_2xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfsqrt_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfsqrt.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfsqrt_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfsqrt_2xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfsqrt_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfsqrt.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfsqrt_8xf32(__epi_8xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfsqrt_8xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfsqrt_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfsqrt.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfsqrt_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfsqrt_8xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfsqrt_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfsqrt.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfsqrt_4xf64(__epi_4xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfsqrt_4xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfsqrt_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfsqrt.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfsqrt_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfsqrt_4xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfsub_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfsub.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfsub_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsub_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsub_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfsub.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfsub_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsub_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsub_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfsub.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfsub_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsub_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsub_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfsub.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfsub_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsub_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsub_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfsub.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfsub_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsub_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsub_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfsub.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfsub_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsub_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsub_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfsub.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfsub_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsub_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsub_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfsub.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfsub_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsub_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsub_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfsub.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfsub_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsub_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsub_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfsub.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfsub_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsub_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsub_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfsub.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfsub_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsub_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsub_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfsub.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfsub_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsub_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwadd_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwadd.nxv2f64.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwadd_2xf64(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwadd_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwadd_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwadd.mask.nxv2f64.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwadd_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwadd_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwadd_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwadd.nxv4f64.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwadd_4xf64(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwadd_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwadd_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwadd.mask.nxv4f64.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwadd_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwadd_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwadd_8xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwadd.nxv8f64.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwadd_8xf64(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwadd_8xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwadd_8xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwadd.mask.nxv8f64.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x double> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwadd_8xf64_mask(__epi_8xf64 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwadd_8xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwadd_w_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwadd.w.nxv2f64.nxv2f32(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwadd_w_2xf64(__epi_2xf64 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwadd_w_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwadd_w_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwadd.w.mask.nxv2f64.nxv2f32.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwadd_w_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwadd_w_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwadd_w_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwadd.w.nxv4f64.nxv4f32(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwadd_w_4xf64(__epi_4xf64 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwadd_w_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwadd_w_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwadd.w.mask.nxv4f64.nxv4f32.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwadd_w_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwadd_w_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwadd_w_8xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwadd.w.nxv8f64.nxv8f32(<vscale x 8 x double> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwadd_w_8xf64(__epi_8xf64 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwadd_w_8xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwadd_w_8xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwadd.w.mask.nxv8f64.nxv8f32.nxv8i1(<vscale x 8 x double> [[ARG_0:%.*]], <vscale x 8 x double> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwadd_w_8xf64_mask(__epi_8xf64 arg_0, __epi_8xf64 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwadd_w_8xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_f_2xf64_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwcvt.f.f.nxv2f64.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwcvt_f_f_2xf64_2xf32(__epi_2xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_f_f_2xf64_2xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_f_2xf64_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwcvt.f.f.mask.nxv2f64.nxv2f32.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwcvt_f_f_2xf64_2xf32_mask(__epi_2xf64 arg_0, __epi_2xf32 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_f_f_2xf64_2xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_f_4xf64_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwcvt.f.f.nxv4f64.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwcvt_f_f_4xf64_4xf32(__epi_4xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_f_f_4xf64_4xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_f_4xf64_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwcvt.f.f.mask.nxv4f64.nxv4f32.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwcvt_f_f_4xf64_4xf32_mask(__epi_4xf64 arg_0, __epi_4xf32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_f_f_4xf64_4xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_f_8xf64_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwcvt.f.f.nxv8f64.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwcvt_f_f_8xf64_8xf32(__epi_8xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_f_f_8xf64_8xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_f_8xf64_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwcvt.f.f.mask.nxv8f64.nxv8f32.nxv8i1(<vscale x 8 x double> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwcvt_f_f_8xf64_8xf32_mask(__epi_8xf64 arg_0, __epi_8xf32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_f_f_8xf64_8xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_x_4xf32_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfwcvt.f.x.nxv4f32.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfwcvt_f_x_4xf32_4xi16(__epi_4xi16 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_f_x_4xf32_4xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_x_4xf32_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfwcvt.f.x.mask.nxv4f32.nxv4i16.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfwcvt_f_x_4xf32_4xi16_mask(__epi_4xf32 arg_0, __epi_4xi16 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_f_x_4xf32_4xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_x_2xf64_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwcvt.f.x.nxv2f64.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwcvt_f_x_2xf64_2xi32(__epi_2xi32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_f_x_2xf64_2xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_x_2xf64_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwcvt.f.x.mask.nxv2f64.nxv2i32.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwcvt_f_x_2xf64_2xi32_mask(__epi_2xf64 arg_0, __epi_2xi32 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_f_x_2xf64_2xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_x_8xf32_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfwcvt.f.x.nxv8f32.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfwcvt_f_x_8xf32_8xi16(__epi_8xi16 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_f_x_8xf32_8xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_x_8xf32_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfwcvt.f.x.mask.nxv8f32.nxv8i16.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfwcvt_f_x_8xf32_8xi16_mask(__epi_8xf32 arg_0, __epi_8xi16 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_f_x_8xf32_8xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_x_4xf64_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwcvt.f.x.nxv4f64.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwcvt_f_x_4xf64_4xi32(__epi_4xi32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_f_x_4xf64_4xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_x_4xf64_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwcvt.f.x.mask.nxv4f64.nxv4i32.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwcvt_f_x_4xf64_4xi32_mask(__epi_4xf64 arg_0, __epi_4xi32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_f_x_4xf64_4xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_x_16xf32_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x float> @llvm.epi.vfwcvt.f.x.nxv16f32.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x float> [[TMP0]]
//
__epi_16xf32 test_vfwcvt_f_x_16xf32_16xi16(__epi_16xi16 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_f_x_16xf32_16xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_x_16xf32_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x float> @llvm.epi.vfwcvt.f.x.mask.nxv16f32.nxv16i16.nxv16i1(<vscale x 16 x float> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x float> [[TMP0]]
//
__epi_16xf32 test_vfwcvt_f_x_16xf32_16xi16_mask(__epi_16xf32 arg_0, __epi_16xi16 arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_f_x_16xf32_16xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_x_8xf64_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwcvt.f.x.nxv8f64.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwcvt_f_x_8xf64_8xi32(__epi_8xi32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_f_x_8xf64_8xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_x_8xf64_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwcvt.f.x.mask.nxv8f64.nxv8i32.nxv8i1(<vscale x 8 x double> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwcvt_f_x_8xf64_8xi32_mask(__epi_8xf64 arg_0, __epi_8xi32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_f_x_8xf64_8xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_xu_4xf32_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfwcvt.f.xu.nxv4f32.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfwcvt_f_xu_4xf32_4xi16(__epi_4xi16 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_f_xu_4xf32_4xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_xu_4xf32_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfwcvt.f.xu.mask.nxv4f32.nxv4i16.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfwcvt_f_xu_4xf32_4xi16_mask(__epi_4xf32 arg_0, __epi_4xi16 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_f_xu_4xf32_4xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_xu_2xf64_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwcvt.f.xu.nxv2f64.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwcvt_f_xu_2xf64_2xi32(__epi_2xi32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_f_xu_2xf64_2xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_xu_2xf64_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwcvt.f.xu.mask.nxv2f64.nxv2i32.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwcvt_f_xu_2xf64_2xi32_mask(__epi_2xf64 arg_0, __epi_2xi32 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_f_xu_2xf64_2xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_xu_8xf32_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfwcvt.f.xu.nxv8f32.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfwcvt_f_xu_8xf32_8xi16(__epi_8xi16 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_f_xu_8xf32_8xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_xu_8xf32_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfwcvt.f.xu.mask.nxv8f32.nxv8i16.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfwcvt_f_xu_8xf32_8xi16_mask(__epi_8xf32 arg_0, __epi_8xi16 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_f_xu_8xf32_8xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_xu_4xf64_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwcvt.f.xu.nxv4f64.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwcvt_f_xu_4xf64_4xi32(__epi_4xi32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_f_xu_4xf64_4xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_xu_4xf64_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwcvt.f.xu.mask.nxv4f64.nxv4i32.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwcvt_f_xu_4xf64_4xi32_mask(__epi_4xf64 arg_0, __epi_4xi32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_f_xu_4xf64_4xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_xu_16xf32_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x float> @llvm.epi.vfwcvt.f.xu.nxv16f32.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x float> [[TMP0]]
//
__epi_16xf32 test_vfwcvt_f_xu_16xf32_16xi16(__epi_16xi16 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_f_xu_16xf32_16xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_xu_16xf32_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x float> @llvm.epi.vfwcvt.f.xu.mask.nxv16f32.nxv16i16.nxv16i1(<vscale x 16 x float> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x float> [[TMP0]]
//
__epi_16xf32 test_vfwcvt_f_xu_16xf32_16xi16_mask(__epi_16xf32 arg_0, __epi_16xi16 arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_f_xu_16xf32_16xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_xu_8xf64_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwcvt.f.xu.nxv8f64.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwcvt_f_xu_8xf64_8xi32(__epi_8xi32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_f_xu_8xf64_8xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_xu_8xf64_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwcvt.f.xu.mask.nxv8f64.nxv8i32.nxv8i1(<vscale x 8 x double> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwcvt_f_xu_8xf64_8xi32_mask(__epi_8xf64 arg_0, __epi_8xi32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_f_xu_8xf64_8xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_x_f_2xi64_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vfwcvt.x.f.nxv2i64.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vfwcvt_x_f_2xi64_2xf32(__epi_2xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_x_f_2xi64_2xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_x_f_2xi64_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vfwcvt.x.f.mask.nxv2i64.nxv2f32.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vfwcvt_x_f_2xi64_2xf32_mask(__epi_2xi64 arg_0, __epi_2xf32 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_x_f_2xi64_2xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_x_f_4xi64_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vfwcvt.x.f.nxv4i64.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vfwcvt_x_f_4xi64_4xf32(__epi_4xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_x_f_4xi64_4xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_x_f_4xi64_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vfwcvt.x.f.mask.nxv4i64.nxv4f32.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vfwcvt_x_f_4xi64_4xf32_mask(__epi_4xi64 arg_0, __epi_4xf32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_x_f_4xi64_4xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_x_f_8xi64_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vfwcvt.x.f.nxv8i64.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vfwcvt_x_f_8xi64_8xf32(__epi_8xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_x_f_8xi64_8xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_x_f_8xi64_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vfwcvt.x.f.mask.nxv8i64.nxv8f32.nxv8i1(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vfwcvt_x_f_8xi64_8xf32_mask(__epi_8xi64 arg_0, __epi_8xf32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_x_f_8xi64_8xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_xu_f_2xi64_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vfwcvt.xu.f.nxv2i64.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vfwcvt_xu_f_2xi64_2xf32(__epi_2xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_xu_f_2xi64_2xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_xu_f_2xi64_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vfwcvt.xu.f.mask.nxv2i64.nxv2f32.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vfwcvt_xu_f_2xi64_2xf32_mask(__epi_2xi64 arg_0, __epi_2xf32 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_xu_f_2xi64_2xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_xu_f_4xi64_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vfwcvt.xu.f.nxv4i64.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vfwcvt_xu_f_4xi64_4xf32(__epi_4xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_xu_f_4xi64_4xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_xu_f_4xi64_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vfwcvt.xu.f.mask.nxv4i64.nxv4f32.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vfwcvt_xu_f_4xi64_4xf32_mask(__epi_4xi64 arg_0, __epi_4xf32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_xu_f_4xi64_4xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_xu_f_8xi64_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vfwcvt.xu.f.nxv8i64.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vfwcvt_xu_f_8xi64_8xf32(__epi_8xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_xu_f_8xi64_8xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_xu_f_8xi64_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vfwcvt.xu.f.mask.nxv8i64.nxv8f32.nxv8i1(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vfwcvt_xu_f_8xi64_8xf32_mask(__epi_8xi64 arg_0, __epi_8xf32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_xu_f_8xi64_8xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwmacc_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwmacc.nxv2f64.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwmacc_2xf64(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwmacc_2xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwmacc_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwmacc.mask.nxv2f64.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwmacc_2xf64_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwmacc_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwmacc_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwmacc.nxv4f64.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwmacc_4xf64(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwmacc_4xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwmacc_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwmacc.mask.nxv4f64.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwmacc_4xf64_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwmacc_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwmacc_8xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwmacc.nxv8f64.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwmacc_8xf64(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwmacc_8xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwmacc_8xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwmacc.mask.nxv8f64.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x double> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwmacc_8xf64_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf64 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwmacc_8xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwmsac_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwmsac.nxv2f64.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwmsac_2xf64(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwmsac_2xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwmsac_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwmsac.mask.nxv2f64.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwmsac_2xf64_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwmsac_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwmsac_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwmsac.nxv4f64.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwmsac_4xf64(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwmsac_4xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwmsac_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwmsac.mask.nxv4f64.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwmsac_4xf64_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwmsac_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwmsac_8xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwmsac.nxv8f64.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwmsac_8xf64(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwmsac_8xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwmsac_8xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwmsac.mask.nxv8f64.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x double> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwmsac_8xf64_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf64 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwmsac_8xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwmul_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwmul.nxv2f64.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwmul_2xf64(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwmul_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwmul_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwmul.mask.nxv2f64.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwmul_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwmul_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwmul_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwmul.nxv4f64.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwmul_4xf64(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwmul_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwmul_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwmul.mask.nxv4f64.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwmul_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwmul_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwmul_8xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwmul.nxv8f64.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwmul_8xf64(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwmul_8xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwmul_8xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwmul.mask.nxv8f64.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x double> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwmul_8xf64_mask(__epi_8xf64 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwmul_8xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwnmacc_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwnmacc.nxv2f64.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwnmacc_2xf64(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwnmacc_2xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwnmacc_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwnmacc.mask.nxv2f64.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwnmacc_2xf64_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwnmacc_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwnmacc_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwnmacc.nxv4f64.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwnmacc_4xf64(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwnmacc_4xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwnmacc_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwnmacc.mask.nxv4f64.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwnmacc_4xf64_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwnmacc_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwnmacc_8xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwnmacc.nxv8f64.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwnmacc_8xf64(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwnmacc_8xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwnmacc_8xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwnmacc.mask.nxv8f64.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x double> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwnmacc_8xf64_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf64 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwnmacc_8xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwnmsac_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwnmsac.nxv2f64.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwnmsac_2xf64(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwnmsac_2xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwnmsac_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwnmsac.mask.nxv2f64.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwnmsac_2xf64_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwnmsac_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwnmsac_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwnmsac.nxv4f64.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwnmsac_4xf64(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwnmsac_4xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwnmsac_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwnmsac.mask.nxv4f64.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwnmsac_4xf64_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwnmsac_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwnmsac_8xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwnmsac.nxv8f64.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwnmsac_8xf64(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwnmsac_8xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwnmsac_8xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwnmsac.mask.nxv8f64.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x double> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwnmsac_8xf64_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf64 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwnmsac_8xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwredosum_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwredosum.nxv2f64.nxv2f32.nxv2f64(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwredosum_2xf64(__epi_2xf32 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwredosum_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwredosum_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwredosum.mask.nxv2f64.nxv2f32.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwredosum_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf32 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwredosum_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwredosum_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwredosum.nxv4f64.nxv4f32.nxv4f64(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwredosum_4xf64(__epi_4xf32 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwredosum_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwredosum_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwredosum.mask.nxv4f64.nxv4f32.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwredosum_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf32 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwredosum_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwredosum_8xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwredosum.nxv8f64.nxv8f32.nxv8f64(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwredosum_8xf64(__epi_8xf32 arg_0, __epi_8xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwredosum_8xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwredosum_8xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwredosum.mask.nxv8f64.nxv8f32.nxv8f64.nxv8i1(<vscale x 8 x double> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x double> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwredosum_8xf64_mask(__epi_8xf64 arg_0, __epi_8xf32 arg_1, __epi_8xf64 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwredosum_8xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwredsum_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwredsum.nxv2f64.nxv2f32.nxv2f64(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwredsum_2xf64(__epi_2xf32 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwredsum_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwredsum_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwredsum.mask.nxv2f64.nxv2f32.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwredsum_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf32 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwredsum_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwredsum_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwredsum.nxv4f64.nxv4f32.nxv4f64(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwredsum_4xf64(__epi_4xf32 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwredsum_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwredsum_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwredsum.mask.nxv4f64.nxv4f32.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwredsum_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf32 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwredsum_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwredsum_8xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwredsum.nxv8f64.nxv8f32.nxv8f64(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwredsum_8xf64(__epi_8xf32 arg_0, __epi_8xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwredsum_8xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwredsum_8xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwredsum.mask.nxv8f64.nxv8f32.nxv8f64.nxv8i1(<vscale x 8 x double> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x double> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwredsum_8xf64_mask(__epi_8xf64 arg_0, __epi_8xf32 arg_1, __epi_8xf64 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwredsum_8xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwsub_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwsub.nxv2f64.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwsub_2xf64(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwsub_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwsub_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwsub.mask.nxv2f64.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwsub_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwsub_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwsub_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwsub.nxv4f64.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwsub_4xf64(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwsub_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwsub_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwsub.mask.nxv4f64.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwsub_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwsub_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwsub_8xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwsub.nxv8f64.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwsub_8xf64(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwsub_8xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwsub_8xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwsub.mask.nxv8f64.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x double> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwsub_8xf64_mask(__epi_8xf64 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwsub_8xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwsub_w_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwsub.w.nxv2f64.nxv2f32(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwsub_w_2xf64(__epi_2xf64 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwsub_w_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwsub_w_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwsub.w.mask.nxv2f64.nxv2f32.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwsub_w_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwsub_w_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwsub_w_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwsub.w.nxv4f64.nxv4f32(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwsub_w_4xf64(__epi_4xf64 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwsub_w_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwsub_w_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwsub.w.mask.nxv4f64.nxv4f32.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwsub_w_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwsub_w_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwsub_w_8xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwsub.w.nxv8f64.nxv8f32(<vscale x 8 x double> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwsub_w_8xf64(__epi_8xf64 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwsub_w_8xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwsub_w_8xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwsub.w.mask.nxv8f64.nxv8f32.nxv8i1(<vscale x 8 x double> [[ARG_0:%.*]], <vscale x 8 x double> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwsub_w_8xf64_mask(__epi_8xf64 arg_0, __epi_8xf64 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwsub_w_8xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vgetfirst_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call float @llvm.epi.vfmv.f.s.f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret float [[TMP0]]
//
float test_vgetfirst_2xf32(__epi_2xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vgetfirst_2xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vgetfirst_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call double @llvm.epi.vfmv.f.s.f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret double [[TMP0]]
//
double test_vgetfirst_1xf64(__epi_1xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vgetfirst_1xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vgetfirst_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call float @llvm.epi.vfmv.f.s.f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret float [[TMP0]]
//
float test_vgetfirst_4xf32(__epi_4xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vgetfirst_4xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vgetfirst_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call double @llvm.epi.vfmv.f.s.f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret double [[TMP0]]
//
double test_vgetfirst_2xf64(__epi_2xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vgetfirst_2xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vgetfirst_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call float @llvm.epi.vfmv.f.s.f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret float [[TMP0]]
//
float test_vgetfirst_8xf32(__epi_8xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vgetfirst_8xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vgetfirst_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call double @llvm.epi.vfmv.f.s.f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret double [[TMP0]]
//
double test_vgetfirst_4xf64(__epi_4xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vgetfirst_4xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vid_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vid.nxv8i8(i64 [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vid_8xi8(unsigned long int arg_0)
{
    return __builtin_epi_vid_8xi8(arg_0);
}

// CHECK-O2-LABEL: @test_vid_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vid.mask.nxv8i8.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vid_8xi8_mask(__epi_8xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vid_8xi8_mask(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vid_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vid.nxv4i16(i64 [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vid_4xi16(unsigned long int arg_0)
{
    return __builtin_epi_vid_4xi16(arg_0);
}

// CHECK-O2-LABEL: @test_vid_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vid.mask.nxv4i16.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vid_4xi16_mask(__epi_4xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vid_4xi16_mask(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vid_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vid.nxv2i32(i64 [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vid_2xi32(unsigned long int arg_0)
{
    return __builtin_epi_vid_2xi32(arg_0);
}

// CHECK-O2-LABEL: @test_vid_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vid.mask.nxv2i32.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vid_2xi32_mask(__epi_2xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vid_2xi32_mask(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vid_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vid.nxv1i64(i64 [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vid_1xi64(unsigned long int arg_0)
{
    return __builtin_epi_vid_1xi64(arg_0);
}

// CHECK-O2-LABEL: @test_vid_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vid.mask.nxv1i64.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vid_1xi64_mask(__epi_1xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vid_1xi64_mask(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vid_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vid.nxv16i8(i64 [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vid_16xi8(unsigned long int arg_0)
{
    return __builtin_epi_vid_16xi8(arg_0);
}

// CHECK-O2-LABEL: @test_vid_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vid.mask.nxv16i8.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vid_16xi8_mask(__epi_16xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vid_16xi8_mask(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vid_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vid.nxv8i16(i64 [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vid_8xi16(unsigned long int arg_0)
{
    return __builtin_epi_vid_8xi16(arg_0);
}

// CHECK-O2-LABEL: @test_vid_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vid.mask.nxv8i16.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vid_8xi16_mask(__epi_8xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vid_8xi16_mask(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vid_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vid.nxv4i32(i64 [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vid_4xi32(unsigned long int arg_0)
{
    return __builtin_epi_vid_4xi32(arg_0);
}

// CHECK-O2-LABEL: @test_vid_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vid.mask.nxv4i32.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vid_4xi32_mask(__epi_4xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vid_4xi32_mask(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vid_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vid.nxv2i64(i64 [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vid_2xi64(unsigned long int arg_0)
{
    return __builtin_epi_vid_2xi64(arg_0);
}

// CHECK-O2-LABEL: @test_vid_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vid.mask.nxv2i64.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vid_2xi64_mask(__epi_2xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vid_2xi64_mask(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vid_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vid.nxv32i8(i64 [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vid_32xi8(unsigned long int arg_0)
{
    return __builtin_epi_vid_32xi8(arg_0);
}

// CHECK-O2-LABEL: @test_vid_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vid.mask.nxv32i8.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vid_32xi8_mask(__epi_32xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vid_32xi8_mask(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vid_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vid.nxv16i16(i64 [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vid_16xi16(unsigned long int arg_0)
{
    return __builtin_epi_vid_16xi16(arg_0);
}

// CHECK-O2-LABEL: @test_vid_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vid.mask.nxv16i16.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vid_16xi16_mask(__epi_16xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vid_16xi16_mask(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vid_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vid.nxv8i32(i64 [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vid_8xi32(unsigned long int arg_0)
{
    return __builtin_epi_vid_8xi32(arg_0);
}

// CHECK-O2-LABEL: @test_vid_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vid.mask.nxv8i32.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vid_8xi32_mask(__epi_8xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vid_8xi32_mask(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vid_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vid.nxv4i64(i64 [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vid_4xi64(unsigned long int arg_0)
{
    return __builtin_epi_vid_4xi64(arg_0);
}

// CHECK-O2-LABEL: @test_vid_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vid.mask.nxv4i64.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vid_4xi64_mask(__epi_4xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vid_4xi64_mask(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_viota_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.viota.nxv8i8.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_viota_8xi8(__epi_8xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_viota_8xi8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_viota_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.viota.mask.nxv8i8.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_viota_8xi8_mask(__epi_8xi1 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_viota_8xi8_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_viota_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.viota.nxv4i16.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_viota_4xi16(__epi_4xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_viota_4xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_viota_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.viota.mask.nxv4i16.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_viota_4xi16_mask(__epi_4xi1 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_viota_4xi16_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_viota_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.viota.nxv2i32.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_viota_2xi32(__epi_2xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_viota_2xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_viota_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.viota.mask.nxv2i32.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_viota_2xi32_mask(__epi_2xi1 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_viota_2xi32_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_viota_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.viota.nxv1i64.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_viota_1xi64(__epi_1xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_viota_1xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_viota_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.viota.mask.nxv1i64.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_viota_1xi64_mask(__epi_1xi1 arg_0, __epi_1xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_viota_1xi64_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_viota_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.viota.nxv16i8.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_viota_16xi8(__epi_16xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_viota_16xi8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_viota_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.viota.mask.nxv16i8.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_viota_16xi8_mask(__epi_16xi1 arg_0, __epi_16xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_viota_16xi8_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_viota_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.viota.nxv8i16.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_viota_8xi16(__epi_8xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_viota_8xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_viota_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.viota.mask.nxv8i16.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_viota_8xi16_mask(__epi_8xi1 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_viota_8xi16_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_viota_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.viota.nxv4i32.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_viota_4xi32(__epi_4xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_viota_4xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_viota_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.viota.mask.nxv4i32.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_viota_4xi32_mask(__epi_4xi1 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_viota_4xi32_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_viota_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.viota.nxv2i64.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_viota_2xi64(__epi_2xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_viota_2xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_viota_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.viota.mask.nxv2i64.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_viota_2xi64_mask(__epi_2xi1 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_viota_2xi64_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_viota_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.viota.nxv32i8.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_viota_32xi8(__epi_32xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_viota_32xi8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_viota_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.viota.mask.nxv32i8.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_viota_32xi8_mask(__epi_32xi1 arg_0, __epi_32xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_viota_32xi8_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_viota_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.viota.nxv16i16.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_viota_16xi16(__epi_16xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_viota_16xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_viota_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.viota.mask.nxv16i16.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_viota_16xi16_mask(__epi_16xi1 arg_0, __epi_16xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_viota_16xi16_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_viota_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.viota.nxv8i32.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_viota_8xi32(__epi_8xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_viota_8xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_viota_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.viota.mask.nxv8i32.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_viota_8xi32_mask(__epi_8xi1 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_viota_8xi32_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_viota_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.viota.nxv4i64.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_viota_4xi64(__epi_4xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_viota_4xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_viota_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.viota.mask.nxv4i64.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_viota_4xi64_mask(__epi_4xi1 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_viota_4xi64_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vload.nxv8i8(<vscale x 8 x i8>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP1]]
//
__epi_8xi8 test_vload_8xi8(const signed char*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_8xi8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vload.nxv4i16(<vscale x 4 x i16>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP1]]
//
__epi_4xi16 test_vload_4xi16(const signed short int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_4xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.nxv2i32(<vscale x 2 x i32>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP1]]
//
__epi_2xi32 test_vload_2xi32(const signed int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_2xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.nxv1i64(<vscale x 1 x i64>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP1]]
//
__epi_1xi64 test_vload_1xi64(const signed long int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_1xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 2 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vload.nxv2f32(<vscale x 2 x float>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP1]]
//
__epi_2xf32 test_vload_2xf32(const float*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_2xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 1 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vload.nxv1f64(<vscale x 1 x double>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP1]]
//
__epi_1xf64 test_vload_1xf64(const double*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_1xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vload.nxv16i8(<vscale x 16 x i8>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP1]]
//
__epi_16xi8 test_vload_16xi8(const signed char*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_16xi8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vload.nxv8i16(<vscale x 8 x i16>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP1]]
//
__epi_8xi16 test_vload_8xi16(const signed short int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_8xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vload.nxv4i32(<vscale x 4 x i32>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP1]]
//
__epi_4xi32 test_vload_4xi32(const signed int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_4xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vload.nxv2i64(<vscale x 2 x i64>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP1]]
//
__epi_2xi64 test_vload_2xi64(const signed long int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_2xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 4 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vload.nxv4f32(<vscale x 4 x float>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP1]]
//
__epi_4xf32 test_vload_4xf32(const float*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_4xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 2 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vload.nxv2f64(<vscale x 2 x double>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP1]]
//
__epi_2xf64 test_vload_2xf64(const double*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_2xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vload.nxv32i8(<vscale x 32 x i8>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP1]]
//
__epi_32xi8 test_vload_32xi8(const signed char*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_32xi8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vload.nxv16i16(<vscale x 16 x i16>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP1]]
//
__epi_16xi16 test_vload_16xi16(const signed short int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_16xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vload.nxv8i32(<vscale x 8 x i32>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP1]]
//
__epi_8xi32 test_vload_8xi32(const signed int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_8xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vload.nxv4i64(<vscale x 4 x i64>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP1]]
//
__epi_4xi64 test_vload_4xi64(const signed long int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_4xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 8 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vload.nxv8f32(<vscale x 8 x float>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP1]]
//
__epi_8xf32 test_vload_8xf32(const float*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_8xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 4 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vload.nxv4f64(<vscale x 4 x double>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP1]]
//
__epi_4xf64 test_vload_4xf64(const double*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_4xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_indexed_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vload.indexed.nxv8i8.nxv8i8(<vscale x 8 x i8>* [[TMP0]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP1]]
//
__epi_8xi8 test_vload_indexed_8xi8(const signed char*  arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vload.indexed.nxv4i16.nxv4i16(<vscale x 4 x i16>* [[TMP0]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP1]]
//
__epi_4xi16 test_vload_indexed_4xi16(const signed short int*  arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.indexed.nxv2i32.nxv2i32(<vscale x 2 x i32>* [[TMP0]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP1]]
//
__epi_2xi32 test_vload_indexed_2xi32(const signed int*  arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.indexed.nxv1i64.nxv1i64(<vscale x 1 x i64>* [[TMP0]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP1]]
//
__epi_1xi64 test_vload_indexed_1xi64(const signed long int*  arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 2 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vload.indexed.nxv2f32.nxv2i32(<vscale x 2 x float>* [[TMP0]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP1]]
//
__epi_2xf32 test_vload_indexed_2xf32(const float*  arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 1 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vload.indexed.nxv1f64.nxv1i64(<vscale x 1 x double>* [[TMP0]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP1]]
//
__epi_1xf64 test_vload_indexed_1xf64(const double*  arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vload.indexed.nxv16i8.nxv16i8(<vscale x 16 x i8>* [[TMP0]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP1]]
//
__epi_16xi8 test_vload_indexed_16xi8(const signed char*  arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vload.indexed.nxv8i16.nxv8i16(<vscale x 8 x i16>* [[TMP0]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP1]]
//
__epi_8xi16 test_vload_indexed_8xi16(const signed short int*  arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vload.indexed.nxv4i32.nxv4i32(<vscale x 4 x i32>* [[TMP0]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP1]]
//
__epi_4xi32 test_vload_indexed_4xi32(const signed int*  arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vload.indexed.nxv2i64.nxv2i64(<vscale x 2 x i64>* [[TMP0]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP1]]
//
__epi_2xi64 test_vload_indexed_2xi64(const signed long int*  arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 4 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vload.indexed.nxv4f32.nxv4i32(<vscale x 4 x float>* [[TMP0]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP1]]
//
__epi_4xf32 test_vload_indexed_4xf32(const float*  arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 2 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vload.indexed.nxv2f64.nxv2i64(<vscale x 2 x double>* [[TMP0]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP1]]
//
__epi_2xf64 test_vload_indexed_2xf64(const double*  arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vload.indexed.nxv32i8.nxv32i8(<vscale x 32 x i8>* [[TMP0]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP1]]
//
__epi_32xi8 test_vload_indexed_32xi8(const signed char*  arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vload.indexed.nxv16i16.nxv16i16(<vscale x 16 x i16>* [[TMP0]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP1]]
//
__epi_16xi16 test_vload_indexed_16xi16(const signed short int*  arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vload.indexed.nxv8i32.nxv8i32(<vscale x 8 x i32>* [[TMP0]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP1]]
//
__epi_8xi32 test_vload_indexed_8xi32(const signed int*  arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vload.indexed.nxv4i64.nxv4i64(<vscale x 4 x i64>* [[TMP0]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP1]]
//
__epi_4xi64 test_vload_indexed_4xi64(const signed long int*  arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 8 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vload.indexed.nxv8f32.nxv8i32(<vscale x 8 x float>* [[TMP0]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP1]]
//
__epi_8xf32 test_vload_indexed_8xf32(const float*  arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 4 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vload.indexed.nxv4f64.nxv4i64(<vscale x 4 x double>* [[TMP0]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP1]]
//
__epi_4xf64 test_vload_indexed_4xf64(const double*  arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vload.indexed.nxv8i8.nxv8i8(<vscale x 8 x i8>* [[TMP0]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP1]]
//
__epi_8xi8 test_vload_indexed_unsigned_8xi8(const unsigned char*  arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_unsigned_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vload.indexed.nxv4i16.nxv4i16(<vscale x 4 x i16>* [[TMP0]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP1]]
//
__epi_4xi16 test_vload_indexed_unsigned_4xi16(const unsigned short int*  arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_unsigned_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.indexed.nxv2i32.nxv2i32(<vscale x 2 x i32>* [[TMP0]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP1]]
//
__epi_2xi32 test_vload_indexed_unsigned_2xi32(const unsigned int*  arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_unsigned_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.indexed.nxv1i64.nxv1i64(<vscale x 1 x i64>* [[TMP0]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP1]]
//
__epi_1xi64 test_vload_indexed_unsigned_1xi64(const unsigned long int*  arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_unsigned_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vload.indexed.nxv16i8.nxv16i8(<vscale x 16 x i8>* [[TMP0]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP1]]
//
__epi_16xi8 test_vload_indexed_unsigned_16xi8(const unsigned char*  arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_unsigned_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vload.indexed.nxv8i16.nxv8i16(<vscale x 8 x i16>* [[TMP0]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP1]]
//
__epi_8xi16 test_vload_indexed_unsigned_8xi16(const unsigned short int*  arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_unsigned_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vload.indexed.nxv4i32.nxv4i32(<vscale x 4 x i32>* [[TMP0]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP1]]
//
__epi_4xi32 test_vload_indexed_unsigned_4xi32(const unsigned int*  arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_unsigned_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vload.indexed.nxv2i64.nxv2i64(<vscale x 2 x i64>* [[TMP0]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP1]]
//
__epi_2xi64 test_vload_indexed_unsigned_2xi64(const unsigned long int*  arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_unsigned_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vload.indexed.nxv32i8.nxv32i8(<vscale x 32 x i8>* [[TMP0]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP1]]
//
__epi_32xi8 test_vload_indexed_unsigned_32xi8(const unsigned char*  arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_unsigned_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vload.indexed.nxv16i16.nxv16i16(<vscale x 16 x i16>* [[TMP0]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP1]]
//
__epi_16xi16 test_vload_indexed_unsigned_16xi16(const unsigned short int*  arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_unsigned_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vload.indexed.nxv8i32.nxv8i32(<vscale x 8 x i32>* [[TMP0]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP1]]
//
__epi_8xi32 test_vload_indexed_unsigned_8xi32(const unsigned int*  arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_unsigned_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vload.indexed.nxv4i64.nxv4i64(<vscale x 4 x i64>* [[TMP0]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP1]]
//
__epi_4xi64 test_vload_indexed_unsigned_4xi64(const unsigned long int*  arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_unsigned_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_8xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i1>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = load <vscale x 8 x i1>, <vscale x 8 x i1>* [[TMP0]], align 1
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP1]]
//
__epi_8xi1 test_vload_8xi1(const unsigned char*  arg_0)
{
    return __builtin_epi_vload_8xi1(arg_0);
}

// CHECK-O2-LABEL: @test_vload_4xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i1>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = load <vscale x 4 x i1>, <vscale x 4 x i1>* [[TMP0]], align 2
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP1]]
//
__epi_4xi1 test_vload_4xi1(const unsigned short int*  arg_0)
{
    return __builtin_epi_vload_4xi1(arg_0);
}

// CHECK-O2-LABEL: @test_vload_2xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i1>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = load <vscale x 2 x i1>, <vscale x 2 x i1>* [[TMP0]], align 4
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP1]]
//
__epi_2xi1 test_vload_2xi1(const unsigned int*  arg_0)
{
    return __builtin_epi_vload_2xi1(arg_0);
}

// CHECK-O2-LABEL: @test_vload_1xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i1>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = load <vscale x 1 x i1>, <vscale x 1 x i1>* [[TMP0]], align 8
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP1]]
//
__epi_1xi1 test_vload_1xi1(const unsigned long int*  arg_0)
{
    return __builtin_epi_vload_1xi1(arg_0);
}

// CHECK-O2-LABEL: @test_vload_strided_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vload.strided.nxv8i8(<vscale x 8 x i8>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP1]]
//
__epi_8xi8 test_vload_strided_8xi8(const signed char*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vload.strided.nxv4i16(<vscale x 4 x i16>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP1]]
//
__epi_4xi16 test_vload_strided_4xi16(const signed short int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.strided.nxv2i32(<vscale x 2 x i32>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP1]]
//
__epi_2xi32 test_vload_strided_2xi32(const signed int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.strided.nxv1i64(<vscale x 1 x i64>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP1]]
//
__epi_1xi64 test_vload_strided_1xi64(const signed long int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 2 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vload.strided.nxv2f32(<vscale x 2 x float>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP1]]
//
__epi_2xf32 test_vload_strided_2xf32(const float*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 1 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vload.strided.nxv1f64(<vscale x 1 x double>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP1]]
//
__epi_1xf64 test_vload_strided_1xf64(const double*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vload.strided.nxv16i8(<vscale x 16 x i8>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP1]]
//
__epi_16xi8 test_vload_strided_16xi8(const signed char*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vload.strided.nxv8i16(<vscale x 8 x i16>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP1]]
//
__epi_8xi16 test_vload_strided_8xi16(const signed short int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vload.strided.nxv4i32(<vscale x 4 x i32>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP1]]
//
__epi_4xi32 test_vload_strided_4xi32(const signed int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vload.strided.nxv2i64(<vscale x 2 x i64>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP1]]
//
__epi_2xi64 test_vload_strided_2xi64(const signed long int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 4 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vload.strided.nxv4f32(<vscale x 4 x float>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP1]]
//
__epi_4xf32 test_vload_strided_4xf32(const float*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 2 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vload.strided.nxv2f64(<vscale x 2 x double>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP1]]
//
__epi_2xf64 test_vload_strided_2xf64(const double*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vload.strided.nxv32i8(<vscale x 32 x i8>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP1]]
//
__epi_32xi8 test_vload_strided_32xi8(const signed char*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vload.strided.nxv16i16(<vscale x 16 x i16>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP1]]
//
__epi_16xi16 test_vload_strided_16xi16(const signed short int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vload.strided.nxv8i32(<vscale x 8 x i32>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP1]]
//
__epi_8xi32 test_vload_strided_8xi32(const signed int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vload.strided.nxv4i64(<vscale x 4 x i64>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP1]]
//
__epi_4xi64 test_vload_strided_4xi64(const signed long int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 8 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vload.strided.nxv8f32(<vscale x 8 x float>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP1]]
//
__epi_8xf32 test_vload_strided_8xf32(const float*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 4 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vload.strided.nxv4f64(<vscale x 4 x double>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP1]]
//
__epi_4xf64 test_vload_strided_4xf64(const double*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vload.strided.nxv8i8(<vscale x 8 x i8>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP1]]
//
__epi_8xi8 test_vload_strided_unsigned_8xi8(const unsigned char*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_unsigned_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vload.strided.nxv4i16(<vscale x 4 x i16>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP1]]
//
__epi_4xi16 test_vload_strided_unsigned_4xi16(const unsigned short int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_unsigned_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.strided.nxv2i32(<vscale x 2 x i32>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP1]]
//
__epi_2xi32 test_vload_strided_unsigned_2xi32(const unsigned int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_unsigned_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.strided.nxv1i64(<vscale x 1 x i64>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP1]]
//
__epi_1xi64 test_vload_strided_unsigned_1xi64(const unsigned long int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_unsigned_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vload.strided.nxv16i8(<vscale x 16 x i8>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP1]]
//
__epi_16xi8 test_vload_strided_unsigned_16xi8(const unsigned char*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_unsigned_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vload.strided.nxv8i16(<vscale x 8 x i16>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP1]]
//
__epi_8xi16 test_vload_strided_unsigned_8xi16(const unsigned short int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_unsigned_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vload.strided.nxv4i32(<vscale x 4 x i32>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP1]]
//
__epi_4xi32 test_vload_strided_unsigned_4xi32(const unsigned int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_unsigned_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vload.strided.nxv2i64(<vscale x 2 x i64>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP1]]
//
__epi_2xi64 test_vload_strided_unsigned_2xi64(const unsigned long int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_unsigned_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vload.strided.nxv32i8(<vscale x 32 x i8>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP1]]
//
__epi_32xi8 test_vload_strided_unsigned_32xi8(const unsigned char*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_unsigned_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vload.strided.nxv16i16(<vscale x 16 x i16>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP1]]
//
__epi_16xi16 test_vload_strided_unsigned_16xi16(const unsigned short int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_unsigned_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vload.strided.nxv8i32(<vscale x 8 x i32>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP1]]
//
__epi_8xi32 test_vload_strided_unsigned_8xi32(const unsigned int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_unsigned_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vload.strided.nxv4i64(<vscale x 4 x i64>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP1]]
//
__epi_4xi64 test_vload_strided_unsigned_4xi64(const unsigned long int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_unsigned_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_unsigned_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vload.nxv8i8(<vscale x 8 x i8>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP1]]
//
__epi_8xi8 test_vload_unsigned_8xi8(const unsigned char*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_unsigned_8xi8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_unsigned_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vload.nxv4i16(<vscale x 4 x i16>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP1]]
//
__epi_4xi16 test_vload_unsigned_4xi16(const unsigned short int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_unsigned_4xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_unsigned_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.nxv2i32(<vscale x 2 x i32>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP1]]
//
__epi_2xi32 test_vload_unsigned_2xi32(const unsigned int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_unsigned_2xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_unsigned_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.nxv1i64(<vscale x 1 x i64>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP1]]
//
__epi_1xi64 test_vload_unsigned_1xi64(const unsigned long int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_unsigned_1xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_unsigned_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vload.nxv16i8(<vscale x 16 x i8>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP1]]
//
__epi_16xi8 test_vload_unsigned_16xi8(const unsigned char*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_unsigned_16xi8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_unsigned_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vload.nxv8i16(<vscale x 8 x i16>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP1]]
//
__epi_8xi16 test_vload_unsigned_8xi16(const unsigned short int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_unsigned_8xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_unsigned_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vload.nxv4i32(<vscale x 4 x i32>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP1]]
//
__epi_4xi32 test_vload_unsigned_4xi32(const unsigned int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_unsigned_4xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_unsigned_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vload.nxv2i64(<vscale x 2 x i64>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP1]]
//
__epi_2xi64 test_vload_unsigned_2xi64(const unsigned long int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_unsigned_2xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_unsigned_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vload.nxv32i8(<vscale x 32 x i8>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP1]]
//
__epi_32xi8 test_vload_unsigned_32xi8(const unsigned char*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_unsigned_32xi8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_unsigned_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vload.nxv16i16(<vscale x 16 x i16>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP1]]
//
__epi_16xi16 test_vload_unsigned_16xi16(const unsigned short int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_unsigned_16xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_unsigned_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vload.nxv8i32(<vscale x 8 x i32>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP1]]
//
__epi_8xi32 test_vload_unsigned_8xi32(const unsigned int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_unsigned_8xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_unsigned_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vload.nxv4i64(<vscale x 4 x i64>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP1]]
//
__epi_4xi64 test_vload_unsigned_4xi64(const unsigned long int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_unsigned_4xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmacc_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmacc.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmacc_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmacc_8xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmacc_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmacc.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmacc_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmacc_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmacc_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmacc.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmacc_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmacc_4xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmacc_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmacc.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmacc_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmacc_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmacc_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmacc.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmacc_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmacc_2xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmacc_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmacc.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmacc_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmacc_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmacc_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmacc.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmacc_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmacc_1xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmacc_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmacc.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmacc_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmacc_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmacc_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmacc.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmacc_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmacc_16xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmacc_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmacc.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmacc_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmacc_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmacc_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmacc.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmacc_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmacc_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmacc_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmacc.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmacc_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmacc_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmacc_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmacc.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmacc_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmacc_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmacc_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmacc.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmacc_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmacc_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmacc_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmacc.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmacc_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmacc_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmacc_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmacc.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmacc_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmacc_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmacc_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmacc.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmacc_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmacc_32xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmacc_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmacc.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmacc_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmacc_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmacc_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmacc.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmacc_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmacc_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmacc_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmacc.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmacc_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmacc_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmacc_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmacc.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmacc_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmacc_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmacc_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmacc.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmacc_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmacc_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmacc_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmacc.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmacc_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmacc_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmacc_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmacc.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmacc_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmacc_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmadd_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmadd.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmadd_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadd_8xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadd_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmadd.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmadd_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmadd_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmadd_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmadd.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmadd_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadd_4xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadd_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmadd.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmadd_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmadd_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmadd_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmadd.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmadd_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadd_2xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadd_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmadd.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmadd_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmadd_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmadd_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmadd.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmadd_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadd_1xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadd_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmadd.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmadd_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmadd_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmadd_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmadd.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmadd_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadd_16xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadd_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmadd.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmadd_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmadd_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmadd_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmadd.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmadd_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadd_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadd_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmadd.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmadd_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmadd_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmadd_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmadd.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmadd_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadd_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadd_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmadd.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmadd_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmadd_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmadd_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmadd.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmadd_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadd_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadd_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmadd.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmadd_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmadd_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmadd_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmadd.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmadd_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadd_32xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadd_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmadd.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmadd_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmadd_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmadd_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmadd.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmadd_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadd_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadd_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmadd.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmadd_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmadd_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmadd_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmadd.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmadd_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadd_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadd_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmadd.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmadd_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmadd_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmadd_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmadd.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmadd_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadd_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadd_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmadd.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmadd_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmadd_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmand_8xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmand.nxv8i1.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmand_8xi1(__epi_8xi1 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmand_8xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmand_4xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmand.nxv4i1.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmand_4xi1(__epi_4xi1 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmand_4xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmand_2xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmand.nxv2i1.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmand_2xi1(__epi_2xi1 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmand_2xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmand_1xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmand.nxv1i1.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmand_1xi1(__epi_1xi1 arg_0, __epi_1xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmand_1xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmand_16xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmand.nxv16i1.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmand_16xi1(__epi_16xi1 arg_0, __epi_16xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmand_16xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmand_32xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmand.nxv32i1.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmand_32xi1(__epi_32xi1 arg_0, __epi_32xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmand_32xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmandnot_8xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmandnot.nxv8i1.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmandnot_8xi1(__epi_8xi1 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmandnot_8xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmandnot_4xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmandnot.nxv4i1.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmandnot_4xi1(__epi_4xi1 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmandnot_4xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmandnot_2xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmandnot.nxv2i1.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmandnot_2xi1(__epi_2xi1 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmandnot_2xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmandnot_1xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmandnot.nxv1i1.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmandnot_1xi1(__epi_1xi1 arg_0, __epi_1xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmandnot_1xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmandnot_16xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmandnot.nxv16i1.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmandnot_16xi1(__epi_16xi1 arg_0, __epi_16xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmandnot_16xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmandnot_32xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmandnot.nxv32i1.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmandnot_32xi1(__epi_32xi1 arg_0, __epi_32xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmandnot_32xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmax_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmax.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmax_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmax_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmax_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmax.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmax_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmax_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmax_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmax.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmax_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmax_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmax_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmax.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmax_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmax_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmax_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmax.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmax_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmax_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmax_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmax.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmax_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmax_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmax_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmax.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmax_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmax_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmax_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmax.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmax_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmax_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmax_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmax.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmax_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmax_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmax_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmax.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmax_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmax_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmax_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmax.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmax_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmax_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmax_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmax.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmax_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmax_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmax_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmax.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmax_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmax_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmax_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmax.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmax_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmax_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmax_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmax.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmax_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmax_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmax_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmax.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmax_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmax_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmax_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmax.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmax_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmax_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmax_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmax.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmax_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmax_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmax_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmax.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmax_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmax_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmax_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmax.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmax_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmax_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmax_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmax.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmax_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmax_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmax_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmax.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmax_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmax_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmax_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmax.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmax_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmax_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmax_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmax.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmax_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmax_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmaxu_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmaxu.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmaxu_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmaxu_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmaxu_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmaxu.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmaxu_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmaxu_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmaxu_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmaxu.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmaxu_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmaxu_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmaxu_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmaxu.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmaxu_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmaxu_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmaxu_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmaxu.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmaxu_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmaxu_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmaxu_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmaxu.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmaxu_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmaxu_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmaxu_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmaxu.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmaxu_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmaxu_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmaxu_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmaxu.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmaxu_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmaxu_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmaxu_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmaxu.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmaxu_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmaxu_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmaxu_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmaxu.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmaxu_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmaxu_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmaxu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmaxu.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmaxu_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmaxu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmaxu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmaxu.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmaxu_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmaxu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmaxu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmaxu.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmaxu_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmaxu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmaxu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmaxu.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmaxu_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmaxu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmaxu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmaxu.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmaxu_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmaxu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmaxu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmaxu.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmaxu_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmaxu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmaxu_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmaxu.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmaxu_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmaxu_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmaxu_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmaxu.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmaxu_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmaxu_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmaxu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmaxu.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmaxu_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmaxu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmaxu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmaxu.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmaxu_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmaxu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmaxu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmaxu.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmaxu_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmaxu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmaxu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmaxu.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmaxu_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmaxu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmaxu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmaxu.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmaxu_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmaxu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmaxu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmaxu.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmaxu_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmaxu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmerge_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmerge.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmerge_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmerge_8xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmerge_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmerge.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmerge_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmerge_4xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmerge_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmerge.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmerge_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmerge_2xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmerge_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmerge.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmerge_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmerge_1xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmerge_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmerge.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmerge_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmerge_16xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmerge_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmerge.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmerge_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmerge_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmerge_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmerge.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmerge_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmerge_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmerge_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmerge.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmerge_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmerge_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmerge_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmerge.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmerge_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmerge_32xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmerge_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmerge.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmerge_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmerge_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmerge_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmerge.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmerge_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmerge_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmerge_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmerge.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmerge_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmerge_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmfeq_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfeq.nxv2i1.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfeq_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfeq_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfeq_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfeq.mask.nxv2i1.nxv2f32.nxv2f32(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfeq_2xf32_mask(__epi_2xi1 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfeq_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfeq_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmfeq.nxv1i1.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmfeq_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfeq_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfeq_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmfeq.mask.nxv1i1.nxv1f64.nxv1f64(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmfeq_1xf64_mask(__epi_1xi1 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfeq_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfeq_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfeq.nxv4i1.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfeq_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfeq_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfeq_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfeq.mask.nxv4i1.nxv4f32.nxv4f32(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfeq_4xf32_mask(__epi_4xi1 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfeq_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfeq_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfeq.nxv2i1.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfeq_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfeq_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfeq_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfeq.mask.nxv2i1.nxv2f64.nxv2f64(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfeq_2xf64_mask(__epi_2xi1 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfeq_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfeq_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmfeq.nxv8i1.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmfeq_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfeq_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfeq_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmfeq.mask.nxv8i1.nxv8f32.nxv8f32(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmfeq_8xf32_mask(__epi_8xi1 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfeq_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfeq_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfeq.nxv4i1.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfeq_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfeq_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfeq_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfeq.mask.nxv4i1.nxv4f64.nxv4f64(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfeq_4xf64_mask(__epi_4xi1 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfeq_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfge_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfge.nxv2i1.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfge_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfge_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfge_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfge.mask.nxv2i1.nxv2f32.nxv2f32(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfge_2xf32_mask(__epi_2xi1 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfge_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfge_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmfge.nxv1i1.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmfge_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfge_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfge_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmfge.mask.nxv1i1.nxv1f64.nxv1f64(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmfge_1xf64_mask(__epi_1xi1 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfge_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfge_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfge.nxv4i1.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfge_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfge_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfge_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfge.mask.nxv4i1.nxv4f32.nxv4f32(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfge_4xf32_mask(__epi_4xi1 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfge_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfge_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfge.nxv2i1.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfge_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfge_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfge_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfge.mask.nxv2i1.nxv2f64.nxv2f64(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfge_2xf64_mask(__epi_2xi1 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfge_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfge_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmfge.nxv8i1.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmfge_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfge_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfge_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmfge.mask.nxv8i1.nxv8f32.nxv8f32(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmfge_8xf32_mask(__epi_8xi1 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfge_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfge_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfge.nxv4i1.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfge_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfge_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfge_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfge.mask.nxv4i1.nxv4f64.nxv4f64(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfge_4xf64_mask(__epi_4xi1 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfge_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfgt_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfgt.nxv2i1.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfgt_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfgt_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfgt_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfgt.mask.nxv2i1.nxv2f32.nxv2f32(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfgt_2xf32_mask(__epi_2xi1 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfgt_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfgt_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmfgt.nxv1i1.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmfgt_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfgt_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfgt_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmfgt.mask.nxv1i1.nxv1f64.nxv1f64(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmfgt_1xf64_mask(__epi_1xi1 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfgt_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfgt_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfgt.nxv4i1.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfgt_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfgt_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfgt_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfgt.mask.nxv4i1.nxv4f32.nxv4f32(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfgt_4xf32_mask(__epi_4xi1 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfgt_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfgt_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfgt.nxv2i1.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfgt_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfgt_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfgt_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfgt.mask.nxv2i1.nxv2f64.nxv2f64(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfgt_2xf64_mask(__epi_2xi1 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfgt_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfgt_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmfgt.nxv8i1.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmfgt_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfgt_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfgt_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmfgt.mask.nxv8i1.nxv8f32.nxv8f32(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmfgt_8xf32_mask(__epi_8xi1 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfgt_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfgt_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfgt.nxv4i1.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfgt_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfgt_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfgt_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfgt.mask.nxv4i1.nxv4f64.nxv4f64(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfgt_4xf64_mask(__epi_4xi1 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfgt_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfirst_8xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vmfirst.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vmfirst_8xi1(__epi_8xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmfirst_8xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmfirst_8xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vmfirst.mask.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vmfirst_8xi1_mask(__epi_8xi1 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfirst_8xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfirst_4xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vmfirst.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vmfirst_4xi1(__epi_4xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmfirst_4xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmfirst_4xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vmfirst.mask.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vmfirst_4xi1_mask(__epi_4xi1 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfirst_4xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfirst_2xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vmfirst.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vmfirst_2xi1(__epi_2xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmfirst_2xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmfirst_2xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vmfirst.mask.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vmfirst_2xi1_mask(__epi_2xi1 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfirst_2xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfirst_1xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vmfirst.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vmfirst_1xi1(__epi_1xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmfirst_1xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmfirst_1xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vmfirst.mask.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vmfirst_1xi1_mask(__epi_1xi1 arg_0, __epi_1xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfirst_1xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfle_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfle.nxv2i1.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfle_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfle_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfle_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfle.mask.nxv2i1.nxv2f32.nxv2f32(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfle_2xf32_mask(__epi_2xi1 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfle_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfle_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmfle.nxv1i1.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmfle_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfle_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfle_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmfle.mask.nxv1i1.nxv1f64.nxv1f64(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmfle_1xf64_mask(__epi_1xi1 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfle_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfle_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfle.nxv4i1.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfle_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfle_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfle_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfle.mask.nxv4i1.nxv4f32.nxv4f32(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfle_4xf32_mask(__epi_4xi1 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfle_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfle_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfle.nxv2i1.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfle_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfle_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfle_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfle.mask.nxv2i1.nxv2f64.nxv2f64(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfle_2xf64_mask(__epi_2xi1 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfle_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfle_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmfle.nxv8i1.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmfle_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfle_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfle_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmfle.mask.nxv8i1.nxv8f32.nxv8f32(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmfle_8xf32_mask(__epi_8xi1 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfle_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfle_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfle.nxv4i1.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfle_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfle_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfle_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfle.mask.nxv4i1.nxv4f64.nxv4f64(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfle_4xf64_mask(__epi_4xi1 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfle_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmflt_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmflt.nxv2i1.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmflt_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmflt_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmflt_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmflt.mask.nxv2i1.nxv2f32.nxv2f32(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmflt_2xf32_mask(__epi_2xi1 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmflt_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmflt_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmflt.nxv1i1.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmflt_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmflt_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmflt_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmflt.mask.nxv1i1.nxv1f64.nxv1f64(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmflt_1xf64_mask(__epi_1xi1 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmflt_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmflt_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmflt.nxv4i1.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmflt_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmflt_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmflt_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmflt.mask.nxv4i1.nxv4f32.nxv4f32(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmflt_4xf32_mask(__epi_4xi1 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmflt_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmflt_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmflt.nxv2i1.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmflt_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmflt_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmflt_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmflt.mask.nxv2i1.nxv2f64.nxv2f64(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmflt_2xf64_mask(__epi_2xi1 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmflt_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmflt_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmflt.nxv8i1.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmflt_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmflt_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmflt_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmflt.mask.nxv8i1.nxv8f32.nxv8f32(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmflt_8xf32_mask(__epi_8xi1 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmflt_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmflt_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmflt.nxv4i1.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmflt_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmflt_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmflt_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmflt.mask.nxv4i1.nxv4f64.nxv4f64(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmflt_4xf64_mask(__epi_4xi1 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmflt_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfne_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfne.nxv2i1.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfne_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfne_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfne_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfne.mask.nxv2i1.nxv2f32.nxv2f32(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfne_2xf32_mask(__epi_2xi1 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfne_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfne_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmfne.nxv1i1.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmfne_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfne_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfne_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmfne.mask.nxv1i1.nxv1f64.nxv1f64(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmfne_1xf64_mask(__epi_1xi1 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfne_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfne_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfne.nxv4i1.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfne_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfne_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfne_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfne.mask.nxv4i1.nxv4f32.nxv4f32(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfne_4xf32_mask(__epi_4xi1 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfne_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfne_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfne.nxv2i1.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfne_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfne_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfne_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfne.mask.nxv2i1.nxv2f64.nxv2f64(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfne_2xf64_mask(__epi_2xi1 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfne_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfne_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmfne.nxv8i1.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmfne_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfne_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfne_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmfne.mask.nxv8i1.nxv8f32.nxv8f32(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmfne_8xf32_mask(__epi_8xi1 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfne_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfne_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfne.nxv4i1.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfne_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfne_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfne_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfne.mask.nxv4i1.nxv4f64.nxv4f64(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfne_4xf64_mask(__epi_4xi1 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfne_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmford_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmford.nxv2i1.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmford_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmford_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmford_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmford.mask.nxv2i1.nxv2f32.nxv2f32(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmford_2xf32_mask(__epi_2xi1 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmford_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmford_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmford.nxv1i1.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmford_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmford_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmford_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmford.mask.nxv1i1.nxv1f64.nxv1f64(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmford_1xf64_mask(__epi_1xi1 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmford_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmford_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmford.nxv4i1.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmford_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmford_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmford_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmford.mask.nxv4i1.nxv4f32.nxv4f32(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmford_4xf32_mask(__epi_4xi1 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmford_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmford_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmford.nxv2i1.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmford_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmford_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmford_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmford.mask.nxv2i1.nxv2f64.nxv2f64(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmford_2xf64_mask(__epi_2xi1 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmford_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmford_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmford.nxv8i1.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmford_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmford_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmford_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmford.mask.nxv8i1.nxv8f32.nxv8f32(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmford_8xf32_mask(__epi_8xi1 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmford_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmford_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmford.nxv4i1.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmford_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmford_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmford_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmford.mask.nxv4i1.nxv4f64.nxv4f64(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmford_4xf64_mask(__epi_4xi1 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmford_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmin_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmin.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmin_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmin_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmin_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmin.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmin_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmin_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmin_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmin.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmin_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmin_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmin_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmin.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmin_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmin_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmin_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmin.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmin_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmin_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmin_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmin.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmin_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmin_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmin_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmin.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmin_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmin_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmin_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmin.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmin_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmin_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmin_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmin.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmin_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmin_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmin_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmin.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmin_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmin_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmin_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmin.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmin_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmin_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmin_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmin.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmin_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmin_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmin_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmin.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmin_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmin_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmin_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmin.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmin_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmin_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmin_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmin.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmin_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmin_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmin_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmin.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmin_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmin_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmin_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmin.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmin_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmin_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmin_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmin.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmin_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmin_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmin_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmin.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmin_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmin_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmin_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmin.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmin_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmin_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmin_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmin.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmin_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmin_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmin_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmin.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmin_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmin_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmin_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmin.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmin_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmin_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmin_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmin.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmin_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmin_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vminu_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vminu.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vminu_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vminu_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vminu_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vminu.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vminu_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vminu_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vminu_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vminu.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vminu_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vminu_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vminu_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vminu.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vminu_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vminu_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vminu_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vminu.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vminu_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vminu_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vminu_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vminu.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vminu_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vminu_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vminu_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vminu.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vminu_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vminu_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vminu_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vminu.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vminu_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vminu_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vminu_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vminu.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vminu_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vminu_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vminu_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vminu.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vminu_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vminu_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vminu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vminu.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vminu_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vminu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vminu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vminu.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vminu_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vminu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vminu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vminu.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vminu_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vminu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vminu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vminu.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vminu_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vminu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vminu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vminu.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vminu_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vminu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vminu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vminu.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vminu_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vminu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vminu_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vminu.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vminu_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vminu_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vminu_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vminu.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vminu_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vminu_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vminu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vminu.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vminu_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vminu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vminu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vminu.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vminu_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vminu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vminu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vminu.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vminu_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vminu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vminu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vminu.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vminu_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vminu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vminu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vminu.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vminu_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vminu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vminu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vminu.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vminu_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vminu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmnand_8xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmnand.nxv8i1.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmnand_8xi1(__epi_8xi1 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmnand_8xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmnand_4xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmnand.nxv4i1.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmnand_4xi1(__epi_4xi1 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmnand_4xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmnand_2xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmnand.nxv2i1.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmnand_2xi1(__epi_2xi1 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmnand_2xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmnand_1xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmnand.nxv1i1.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmnand_1xi1(__epi_1xi1 arg_0, __epi_1xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmnand_1xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmnand_16xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmnand.nxv16i1.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmnand_16xi1(__epi_16xi1 arg_0, __epi_16xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmnand_16xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmnand_32xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmnand.nxv32i1.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmnand_32xi1(__epi_32xi1 arg_0, __epi_32xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmnand_32xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmnor_8xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmnor.nxv8i1.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmnor_8xi1(__epi_8xi1 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmnor_8xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmnor_4xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmnor.nxv4i1.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmnor_4xi1(__epi_4xi1 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmnor_4xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmnor_2xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmnor.nxv2i1.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmnor_2xi1(__epi_2xi1 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmnor_2xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmnor_1xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmnor.nxv1i1.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmnor_1xi1(__epi_1xi1 arg_0, __epi_1xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmnor_1xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmnor_16xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmnor.nxv16i1.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmnor_16xi1(__epi_16xi1 arg_0, __epi_16xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmnor_16xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmnor_32xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmnor.nxv32i1.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmnor_32xi1(__epi_32xi1 arg_0, __epi_32xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmnor_32xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmor_8xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmor.nxv8i1.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmor_8xi1(__epi_8xi1 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmor_8xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmor_4xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmor.nxv4i1.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmor_4xi1(__epi_4xi1 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmor_4xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmor_2xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmor.nxv2i1.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmor_2xi1(__epi_2xi1 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmor_2xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmor_1xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmor.nxv1i1.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmor_1xi1(__epi_1xi1 arg_0, __epi_1xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmor_1xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmor_16xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmor.nxv16i1.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmor_16xi1(__epi_16xi1 arg_0, __epi_16xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmor_16xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmor_32xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmor.nxv32i1.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmor_32xi1(__epi_32xi1 arg_0, __epi_32xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmor_32xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmornot_8xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmornot.nxv8i1.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmornot_8xi1(__epi_8xi1 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmornot_8xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmornot_4xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmornot.nxv4i1.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmornot_4xi1(__epi_4xi1 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmornot_4xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmornot_2xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmornot.nxv2i1.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmornot_2xi1(__epi_2xi1 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmornot_2xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmornot_1xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmornot.nxv1i1.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmornot_1xi1(__epi_1xi1 arg_0, __epi_1xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmornot_1xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmornot_16xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmornot.nxv16i1.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmornot_16xi1(__epi_16xi1 arg_0, __epi_16xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmornot_16xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmornot_32xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmornot.nxv32i1.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmornot_32xi1(__epi_32xi1 arg_0, __epi_32xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmornot_32xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmpopc_8xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vmpopc.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vmpopc_8xi1(__epi_8xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmpopc_8xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmpopc_8xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vmpopc.mask.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vmpopc_8xi1_mask(__epi_8xi1 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmpopc_8xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmpopc_4xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vmpopc.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vmpopc_4xi1(__epi_4xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmpopc_4xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmpopc_4xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vmpopc.mask.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vmpopc_4xi1_mask(__epi_4xi1 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmpopc_4xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmpopc_2xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vmpopc.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vmpopc_2xi1(__epi_2xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmpopc_2xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmpopc_2xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vmpopc.mask.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vmpopc_2xi1_mask(__epi_2xi1 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmpopc_2xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmpopc_1xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vmpopc.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vmpopc_1xi1(__epi_1xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmpopc_1xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmpopc_1xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vmpopc.mask.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vmpopc_1xi1_mask(__epi_1xi1 arg_0, __epi_1xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmpopc_1xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsac_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmsac.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmsac_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsac_8xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsac_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmsac.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmsac_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsac_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsac_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmsac.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmsac_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsac_4xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsac_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmsac.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmsac_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsac_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsac_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmsac.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmsac_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsac_2xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsac_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmsac.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmsac_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsac_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsac_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmsac.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmsac_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsac_1xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsac_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmsac.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmsac_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsac_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsac_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmsac.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmsac_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsac_16xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsac_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmsac.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmsac_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsac_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsac_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmsac.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmsac_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsac_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsac_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmsac.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmsac_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsac_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsac_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmsac.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmsac_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsac_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsac_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmsac.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmsac_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsac_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsac_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmsac.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmsac_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsac_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsac_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmsac.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmsac_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsac_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsac_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmsac.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmsac_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsac_32xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsac_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmsac.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmsac_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsac_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsac_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmsac.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmsac_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsac_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsac_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmsac.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmsac_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsac_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsac_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmsac.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmsac_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsac_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsac_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmsac.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmsac_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsac_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsac_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmsac.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmsac_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsac_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsac_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmsac.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmsac_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsac_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsbf_8xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsbf.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsbf_8xi1(__epi_8xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsbf_8xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsbf_8xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsbf.mask.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsbf_8xi1_mask(__epi_8xi1 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsbf_8xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsbf_4xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsbf.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsbf_4xi1(__epi_4xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsbf_4xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsbf_4xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsbf.mask.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsbf_4xi1_mask(__epi_4xi1 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsbf_4xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsbf_2xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsbf.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsbf_2xi1(__epi_2xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsbf_2xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsbf_2xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsbf.mask.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsbf_2xi1_mask(__epi_2xi1 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsbf_2xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsbf_1xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsbf.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsbf_1xi1(__epi_1xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsbf_1xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsbf_1xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsbf.mask.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsbf_1xi1_mask(__epi_1xi1 arg_0, __epi_1xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsbf_1xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsbf_16xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsbf.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsbf_16xi1(__epi_16xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsbf_16xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsbf_16xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsbf.mask.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsbf_16xi1_mask(__epi_16xi1 arg_0, __epi_16xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsbf_16xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsbf_32xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsbf.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsbf_32xi1(__epi_32xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsbf_32xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsbf_32xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsbf.mask.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsbf_32xi1_mask(__epi_32xi1 arg_0, __epi_32xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsbf_32xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmseq_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmseq.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmseq_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmseq_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmseq_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmseq.mask.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmseq_8xi8_mask(__epi_8xi1 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmseq_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmseq_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmseq.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmseq_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmseq_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmseq_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmseq.mask.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmseq_4xi16_mask(__epi_4xi1 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmseq_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmseq_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmseq.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmseq_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmseq_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmseq_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmseq.mask.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmseq_2xi32_mask(__epi_2xi1 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmseq_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmseq_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmseq.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmseq_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmseq_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmseq_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmseq.mask.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmseq_1xi64_mask(__epi_1xi1 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmseq_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmseq_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmseq.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmseq_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmseq_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmseq_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmseq.mask.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmseq_16xi8_mask(__epi_16xi1 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmseq_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmseq_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmseq.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmseq_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmseq_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmseq_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmseq.mask.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmseq_8xi16_mask(__epi_8xi1 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmseq_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmseq_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmseq.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmseq_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmseq_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmseq_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmseq.mask.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmseq_4xi32_mask(__epi_4xi1 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmseq_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmseq_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmseq.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmseq_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmseq_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmseq_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmseq.mask.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmseq_2xi64_mask(__epi_2xi1 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmseq_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmseq_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmseq.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmseq_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmseq_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmseq_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmseq.mask.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmseq_32xi8_mask(__epi_32xi1 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmseq_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmseq_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmseq.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmseq_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmseq_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmseq_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmseq.mask.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmseq_16xi16_mask(__epi_16xi1 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmseq_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmseq_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmseq.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmseq_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmseq_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmseq_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmseq.mask.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmseq_8xi32_mask(__epi_8xi1 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmseq_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmseq_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmseq.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmseq_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmseq_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmseq_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmseq.mask.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmseq_4xi64_mask(__epi_4xi1 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmseq_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgt_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsgt.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsgt_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgt_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgt_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsgt.mask.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsgt_8xi8_mask(__epi_8xi1 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgt_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgt_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsgt.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsgt_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgt_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgt_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsgt.mask.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsgt_4xi16_mask(__epi_4xi1 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgt_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgt_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsgt.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsgt_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgt_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgt_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsgt.mask.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsgt_2xi32_mask(__epi_2xi1 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgt_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgt_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsgt.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsgt_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgt_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgt_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsgt.mask.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsgt_1xi64_mask(__epi_1xi1 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgt_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgt_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsgt.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsgt_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgt_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgt_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsgt.mask.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsgt_16xi8_mask(__epi_16xi1 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgt_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgt_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsgt.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsgt_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgt_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgt_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsgt.mask.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsgt_8xi16_mask(__epi_8xi1 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgt_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgt_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsgt.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsgt_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgt_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgt_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsgt.mask.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsgt_4xi32_mask(__epi_4xi1 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgt_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgt_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsgt.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsgt_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgt_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgt_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsgt.mask.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsgt_2xi64_mask(__epi_2xi1 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgt_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgt_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsgt.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsgt_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgt_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgt_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsgt.mask.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsgt_32xi8_mask(__epi_32xi1 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgt_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgt_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsgt.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsgt_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgt_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgt_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsgt.mask.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsgt_16xi16_mask(__epi_16xi1 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgt_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgt_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsgt.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsgt_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgt_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgt_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsgt.mask.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsgt_8xi32_mask(__epi_8xi1 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgt_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgt_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsgt.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsgt_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgt_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgt_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsgt.mask.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsgt_4xi64_mask(__epi_4xi1 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgt_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgtu_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsgtu.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsgtu_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgtu_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgtu_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsgtu.mask.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsgtu_8xi8_mask(__epi_8xi1 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgtu_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgtu_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsgtu.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsgtu_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgtu_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgtu_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsgtu.mask.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsgtu_4xi16_mask(__epi_4xi1 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgtu_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgtu_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsgtu.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsgtu_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgtu_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgtu_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsgtu.mask.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsgtu_2xi32_mask(__epi_2xi1 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgtu_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgtu_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsgtu.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsgtu_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgtu_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgtu_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsgtu.mask.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsgtu_1xi64_mask(__epi_1xi1 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgtu_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgtu_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsgtu.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsgtu_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgtu_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgtu_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsgtu.mask.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsgtu_16xi8_mask(__epi_16xi1 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgtu_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgtu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsgtu.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsgtu_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgtu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgtu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsgtu.mask.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsgtu_8xi16_mask(__epi_8xi1 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgtu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgtu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsgtu.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsgtu_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgtu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgtu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsgtu.mask.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsgtu_4xi32_mask(__epi_4xi1 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgtu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgtu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsgtu.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsgtu_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgtu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgtu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsgtu.mask.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsgtu_2xi64_mask(__epi_2xi1 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgtu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgtu_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsgtu.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsgtu_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgtu_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgtu_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsgtu.mask.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsgtu_32xi8_mask(__epi_32xi1 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgtu_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgtu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsgtu.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsgtu_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgtu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgtu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsgtu.mask.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsgtu_16xi16_mask(__epi_16xi1 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgtu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgtu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsgtu.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsgtu_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgtu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgtu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsgtu.mask.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsgtu_8xi32_mask(__epi_8xi1 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgtu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgtu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsgtu.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsgtu_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgtu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgtu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsgtu.mask.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsgtu_4xi64_mask(__epi_4xi1 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgtu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsif_8xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsif.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsif_8xi1(__epi_8xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsif_8xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsif_8xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsif.mask.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsif_8xi1_mask(__epi_8xi1 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsif_8xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsif_4xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsif.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsif_4xi1(__epi_4xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsif_4xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsif_4xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsif.mask.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsif_4xi1_mask(__epi_4xi1 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsif_4xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsif_2xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsif.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsif_2xi1(__epi_2xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsif_2xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsif_2xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsif.mask.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsif_2xi1_mask(__epi_2xi1 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsif_2xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsif_1xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsif.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsif_1xi1(__epi_1xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsif_1xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsif_1xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsif.mask.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsif_1xi1_mask(__epi_1xi1 arg_0, __epi_1xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsif_1xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsif_16xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsif.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsif_16xi1(__epi_16xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsif_16xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsif_16xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsif.mask.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsif_16xi1_mask(__epi_16xi1 arg_0, __epi_16xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsif_16xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsif_32xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsif.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsif_32xi1(__epi_32xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsif_32xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsif_32xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsif.mask.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsif_32xi1_mask(__epi_32xi1 arg_0, __epi_32xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsif_32xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsle_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsle.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsle_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsle_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsle_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsle.mask.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsle_8xi8_mask(__epi_8xi1 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsle_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsle_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsle.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsle_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsle_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsle_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsle.mask.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsle_4xi16_mask(__epi_4xi1 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsle_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsle_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsle.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsle_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsle_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsle_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsle.mask.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsle_2xi32_mask(__epi_2xi1 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsle_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsle_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsle.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsle_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsle_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsle_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsle.mask.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsle_1xi64_mask(__epi_1xi1 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsle_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsle_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsle.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsle_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsle_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsle_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsle.mask.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsle_16xi8_mask(__epi_16xi1 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsle_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsle_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsle.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsle_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsle_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsle_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsle.mask.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsle_8xi16_mask(__epi_8xi1 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsle_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsle_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsle.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsle_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsle_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsle_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsle.mask.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsle_4xi32_mask(__epi_4xi1 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsle_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsle_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsle.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsle_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsle_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsle_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsle.mask.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsle_2xi64_mask(__epi_2xi1 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsle_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsle_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsle.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsle_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsle_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsle_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsle.mask.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsle_32xi8_mask(__epi_32xi1 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsle_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsle_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsle.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsle_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsle_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsle_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsle.mask.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsle_16xi16_mask(__epi_16xi1 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsle_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsle_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsle.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsle_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsle_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsle_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsle.mask.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsle_8xi32_mask(__epi_8xi1 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsle_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsle_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsle.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsle_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsle_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsle_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsle.mask.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsle_4xi64_mask(__epi_4xi1 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsle_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsleu_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsleu.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsleu_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsleu_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsleu_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsleu.mask.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsleu_8xi8_mask(__epi_8xi1 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsleu_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsleu_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsleu.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsleu_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsleu_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsleu_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsleu.mask.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsleu_4xi16_mask(__epi_4xi1 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsleu_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsleu_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsleu.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsleu_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsleu_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsleu_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsleu.mask.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsleu_2xi32_mask(__epi_2xi1 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsleu_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsleu_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsleu.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsleu_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsleu_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsleu_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsleu.mask.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsleu_1xi64_mask(__epi_1xi1 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsleu_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsleu_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsleu.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsleu_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsleu_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsleu_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsleu.mask.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsleu_16xi8_mask(__epi_16xi1 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsleu_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsleu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsleu.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsleu_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsleu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsleu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsleu.mask.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsleu_8xi16_mask(__epi_8xi1 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsleu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsleu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsleu.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsleu_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsleu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsleu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsleu.mask.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsleu_4xi32_mask(__epi_4xi1 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsleu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsleu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsleu.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsleu_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsleu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsleu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsleu.mask.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsleu_2xi64_mask(__epi_2xi1 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsleu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsleu_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsleu.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsleu_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsleu_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsleu_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsleu.mask.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsleu_32xi8_mask(__epi_32xi1 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsleu_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsleu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsleu.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsleu_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsleu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsleu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsleu.mask.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsleu_16xi16_mask(__epi_16xi1 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsleu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsleu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsleu.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsleu_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsleu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsleu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsleu.mask.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsleu_8xi32_mask(__epi_8xi1 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsleu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsleu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsleu.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsleu_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsleu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsleu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsleu.mask.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsleu_4xi64_mask(__epi_4xi1 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsleu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmslt_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmslt.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmslt_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmslt_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmslt_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmslt.mask.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmslt_8xi8_mask(__epi_8xi1 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmslt_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmslt_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmslt.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmslt_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmslt_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmslt_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmslt.mask.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmslt_4xi16_mask(__epi_4xi1 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmslt_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmslt_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmslt.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmslt_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmslt_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmslt_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmslt.mask.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmslt_2xi32_mask(__epi_2xi1 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmslt_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmslt_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmslt.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmslt_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmslt_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmslt_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmslt.mask.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmslt_1xi64_mask(__epi_1xi1 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmslt_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmslt_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmslt.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmslt_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmslt_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmslt_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmslt.mask.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmslt_16xi8_mask(__epi_16xi1 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmslt_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmslt_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmslt.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmslt_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmslt_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmslt_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmslt.mask.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmslt_8xi16_mask(__epi_8xi1 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmslt_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmslt_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmslt.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmslt_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmslt_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmslt_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmslt.mask.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmslt_4xi32_mask(__epi_4xi1 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmslt_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmslt_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmslt.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmslt_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmslt_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmslt_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmslt.mask.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmslt_2xi64_mask(__epi_2xi1 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmslt_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmslt_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmslt.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmslt_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmslt_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmslt_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmslt.mask.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmslt_32xi8_mask(__epi_32xi1 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmslt_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmslt_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmslt.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmslt_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmslt_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmslt_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmslt.mask.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmslt_16xi16_mask(__epi_16xi1 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmslt_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmslt_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmslt.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmslt_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmslt_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmslt_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmslt.mask.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmslt_8xi32_mask(__epi_8xi1 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmslt_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmslt_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmslt.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmslt_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmslt_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmslt_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmslt.mask.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmslt_4xi64_mask(__epi_4xi1 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmslt_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsltu_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsltu.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsltu_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsltu_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsltu_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsltu.mask.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsltu_8xi8_mask(__epi_8xi1 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsltu_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsltu_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsltu.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsltu_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsltu_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsltu_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsltu.mask.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsltu_4xi16_mask(__epi_4xi1 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsltu_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsltu_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsltu.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsltu_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsltu_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsltu_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsltu.mask.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsltu_2xi32_mask(__epi_2xi1 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsltu_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsltu_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsltu.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsltu_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsltu_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsltu_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsltu.mask.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsltu_1xi64_mask(__epi_1xi1 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsltu_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsltu_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsltu.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsltu_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsltu_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsltu_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsltu.mask.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsltu_16xi8_mask(__epi_16xi1 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsltu_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsltu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsltu.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsltu_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsltu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsltu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsltu.mask.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsltu_8xi16_mask(__epi_8xi1 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsltu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsltu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsltu.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsltu_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsltu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsltu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsltu.mask.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsltu_4xi32_mask(__epi_4xi1 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsltu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsltu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsltu.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsltu_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsltu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsltu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsltu.mask.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsltu_2xi64_mask(__epi_2xi1 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsltu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsltu_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsltu.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsltu_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsltu_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsltu_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsltu.mask.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsltu_32xi8_mask(__epi_32xi1 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsltu_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsltu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsltu.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsltu_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsltu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsltu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsltu.mask.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsltu_16xi16_mask(__epi_16xi1 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsltu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsltu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsltu.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsltu_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsltu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsltu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsltu.mask.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsltu_8xi32_mask(__epi_8xi1 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsltu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsltu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsltu.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsltu_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsltu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsltu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsltu.mask.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsltu_4xi64_mask(__epi_4xi1 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsltu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsne_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsne.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsne_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsne_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsne_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsne.mask.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsne_8xi8_mask(__epi_8xi1 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsne_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsne_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsne.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsne_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsne_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsne_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsne.mask.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsne_4xi16_mask(__epi_4xi1 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsne_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsne_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsne.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsne_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsne_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsne_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsne.mask.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsne_2xi32_mask(__epi_2xi1 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsne_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsne_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsne.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsne_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsne_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsne_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsne.mask.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsne_1xi64_mask(__epi_1xi1 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsne_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsne_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsne.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsne_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsne_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsne_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsne.mask.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsne_16xi8_mask(__epi_16xi1 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsne_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsne_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsne.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsne_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsne_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsne_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsne.mask.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsne_8xi16_mask(__epi_8xi1 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsne_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsne_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsne.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsne_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsne_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsne_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsne.mask.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsne_4xi32_mask(__epi_4xi1 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsne_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsne_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsne.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsne_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsne_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsne_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsne.mask.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsne_2xi64_mask(__epi_2xi1 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsne_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsne_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsne.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsne_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsne_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsne_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsne.mask.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsne_32xi8_mask(__epi_32xi1 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsne_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsne_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsne.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsne_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsne_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsne_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsne.mask.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsne_16xi16_mask(__epi_16xi1 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsne_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsne_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsne.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsne_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsne_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsne_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsne.mask.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsne_8xi32_mask(__epi_8xi1 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsne_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsne_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsne.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsne_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsne_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsne_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsne.mask.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsne_4xi64_mask(__epi_4xi1 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsne_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsof_8xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsof.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsof_8xi1(__epi_8xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsof_8xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsof_8xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsof.mask.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsof_8xi1_mask(__epi_8xi1 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsof_8xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsof_4xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsof.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsof_4xi1(__epi_4xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsof_4xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsof_4xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsof.mask.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsof_4xi1_mask(__epi_4xi1 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsof_4xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsof_2xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsof.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsof_2xi1(__epi_2xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsof_2xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsof_2xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsof.mask.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsof_2xi1_mask(__epi_2xi1 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsof_2xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsof_1xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsof.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsof_1xi1(__epi_1xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsof_1xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsof_1xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsof.mask.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsof_1xi1_mask(__epi_1xi1 arg_0, __epi_1xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsof_1xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsof_16xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsof.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsof_16xi1(__epi_16xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsof_16xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsof_16xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsof.mask.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsof_16xi1_mask(__epi_16xi1 arg_0, __epi_16xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsof_16xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsof_32xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsof.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsof_32xi1(__epi_32xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsof_32xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsof_32xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsof.mask.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsof_32xi1_mask(__epi_32xi1 arg_0, __epi_32xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsof_32xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsub_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmsub.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmsub_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsub_8xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsub_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmsub.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmsub_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsub_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsub_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmsub.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmsub_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsub_4xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsub_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmsub.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmsub_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsub_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsub_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmsub.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmsub_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsub_2xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsub_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmsub.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmsub_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsub_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsub_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmsub.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmsub_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsub_1xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsub_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmsub.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmsub_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsub_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsub_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmsub.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmsub_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsub_16xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsub_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmsub.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmsub_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsub_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsub_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmsub.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmsub_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsub_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsub_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmsub.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmsub_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsub_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsub_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmsub.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmsub_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsub_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsub_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmsub.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmsub_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsub_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsub_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmsub.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmsub_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsub_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsub_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmsub.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmsub_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsub_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsub_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmsub.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmsub_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsub_32xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsub_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmsub.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmsub_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsub_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsub_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmsub.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmsub_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsub_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsub_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmsub.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmsub_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsub_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsub_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmsub.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmsub_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsub_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsub_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmsub.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmsub_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsub_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsub_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmsub.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmsub_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsub_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsub_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmsub.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmsub_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsub_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmul_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmul.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmul_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmul_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmul_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmul.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmul_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmul_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmul_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmul.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmul_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmul_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmul_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmul.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmul_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmul_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmul_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmul.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmul_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmul_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmul_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmul.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmul_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmul_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmul_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmul.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmul_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmul_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmul_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmul.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmul_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmul_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmul_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmul.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmul_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmul_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmul_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmul.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmul_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmul_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmul_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmul.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmul_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmul_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmul_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmul.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmul_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmul_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmul_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmul.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmul_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmul_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmul_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmul.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmul_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmul_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmul_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmul.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmul_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmul_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmul_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmul.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmul_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmul_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmul_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmul.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmul_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmul_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmul_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmul.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmul_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmul_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmul_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmul.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmul_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmul_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmul_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmul.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmul_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmul_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmul_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmul.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmul_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmul_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmul_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmul.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmul_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmul_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmul_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmul.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmul_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmul_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmul_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmul.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmul_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmul_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulh_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmulh.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmulh_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulh_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulh_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmulh.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmulh_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulh_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulh_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmulh.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmulh_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulh_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulh_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmulh.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmulh_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulh_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulh_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmulh.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmulh_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulh_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulh_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmulh.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmulh_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulh_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulh_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmulh.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmulh_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulh_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulh_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmulh.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmulh_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulh_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulh_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmulh.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmulh_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulh_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulh_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmulh.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmulh_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulh_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulh_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmulh.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmulh_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulh_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulh_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmulh.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmulh_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulh_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulh_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmulh.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmulh_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulh_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulh_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmulh.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmulh_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulh_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulh_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmulh.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmulh_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulh_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulh_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmulh.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmulh_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulh_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulh_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmulh.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmulh_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulh_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulh_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmulh.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmulh_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulh_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulh_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmulh.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmulh_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulh_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulh_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmulh.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmulh_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulh_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulh_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmulh.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmulh_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulh_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulh_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmulh.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmulh_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulh_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulh_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmulh.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmulh_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulh_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulh_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmulh.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmulh_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulh_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhsu_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmulhsu.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmulhsu_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhsu_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhsu_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmulhsu.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmulhsu_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhsu_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhsu_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmulhsu.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmulhsu_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhsu_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhsu_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmulhsu.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmulhsu_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhsu_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhsu_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmulhsu.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmulhsu_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhsu_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhsu_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmulhsu.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmulhsu_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhsu_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhsu_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmulhsu.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmulhsu_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhsu_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhsu_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmulhsu.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmulhsu_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhsu_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhsu_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmulhsu.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmulhsu_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhsu_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhsu_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmulhsu.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmulhsu_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhsu_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhsu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmulhsu.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmulhsu_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhsu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhsu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmulhsu.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmulhsu_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhsu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhsu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmulhsu.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmulhsu_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhsu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhsu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmulhsu.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmulhsu_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhsu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhsu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmulhsu.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmulhsu_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhsu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhsu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmulhsu.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmulhsu_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhsu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhsu_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmulhsu.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmulhsu_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhsu_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhsu_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmulhsu.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmulhsu_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhsu_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhsu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmulhsu.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmulhsu_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhsu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhsu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmulhsu.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmulhsu_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhsu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhsu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmulhsu.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmulhsu_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhsu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhsu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmulhsu.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmulhsu_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhsu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhsu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmulhsu.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmulhsu_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhsu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhsu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmulhsu.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmulhsu_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhsu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhu_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmulhu.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmulhu_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhu_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhu_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmulhu.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmulhu_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhu_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhu_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmulhu.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmulhu_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhu_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhu_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmulhu.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmulhu_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhu_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhu_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmulhu.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmulhu_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhu_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhu_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmulhu.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmulhu_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhu_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhu_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmulhu.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmulhu_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhu_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhu_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmulhu.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmulhu_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhu_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhu_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmulhu.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmulhu_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhu_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhu_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmulhu.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmulhu_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhu_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmulhu.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmulhu_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmulhu.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmulhu_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmulhu.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmulhu_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmulhu.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmulhu_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmulhu.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmulhu_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmulhu.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmulhu_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhu_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmulhu.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmulhu_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhu_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhu_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmulhu.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmulhu_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhu_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmulhu.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmulhu_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmulhu.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmulhu_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmulhu.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmulhu_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmulhu.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmulhu_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmulhu.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmulhu_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmulhu.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmulhu_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmxnor_8xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmxnor.nxv8i1.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmxnor_8xi1(__epi_8xi1 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmxnor_8xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmxnor_4xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmxnor.nxv4i1.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmxnor_4xi1(__epi_4xi1 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmxnor_4xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmxnor_2xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmxnor.nxv2i1.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmxnor_2xi1(__epi_2xi1 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmxnor_2xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmxnor_1xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmxnor.nxv1i1.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmxnor_1xi1(__epi_1xi1 arg_0, __epi_1xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmxnor_1xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmxnor_16xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmxnor.nxv16i1.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmxnor_16xi1(__epi_16xi1 arg_0, __epi_16xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmxnor_16xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmxnor_32xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmxnor.nxv32i1.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmxnor_32xi1(__epi_32xi1 arg_0, __epi_32xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmxnor_32xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmxor_8xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmxor.nxv8i1.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmxor_8xi1(__epi_8xi1 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmxor_8xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmxor_4xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmxor.nxv4i1.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmxor_4xi1(__epi_4xi1 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmxor_4xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmxor_2xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmxor.nxv2i1.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmxor_2xi1(__epi_2xi1 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmxor_2xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmxor_1xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmxor.nxv1i1.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmxor_1xi1(__epi_1xi1 arg_0, __epi_1xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmxor_1xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmxor_16xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmxor.nxv16i1.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmxor_16xi1(__epi_16xi1 arg_0, __epi_16xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmxor_16xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmxor_32xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmxor.nxv32i1.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmxor_32xi1(__epi_32xi1 arg_0, __epi_32xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmxor_32xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsra_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vnsra.nxv8i8.nxv8i16.nxv8i8(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vnsra_8xi8(__epi_8xi16 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsra_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsra_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vnsra.mask.nxv8i8.nxv8i16.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vnsra_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi16 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsra_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnsra_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vnsra.nxv4i16.nxv4i32.nxv4i16(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vnsra_4xi16(__epi_4xi32 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsra_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsra_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vnsra.mask.nxv4i16.nxv4i32.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vnsra_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi32 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsra_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnsra_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vnsra.nxv2i32.nxv2i64.nxv2i32(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vnsra_2xi32(__epi_2xi64 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsra_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsra_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vnsra.mask.nxv2i32.nxv2i64.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vnsra_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi64 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsra_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnsra_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vnsra.nxv16i8.nxv16i16.nxv16i8(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vnsra_16xi8(__epi_16xi16 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsra_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsra_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vnsra.mask.nxv16i8.nxv16i16.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vnsra_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi16 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsra_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnsra_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vnsra.nxv8i16.nxv8i32.nxv8i16(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vnsra_8xi16(__epi_8xi32 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsra_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsra_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vnsra.mask.nxv8i16.nxv8i32.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vnsra_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi32 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsra_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnsra_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vnsra.nxv4i32.nxv4i64.nxv4i32(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vnsra_4xi32(__epi_4xi64 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsra_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsra_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vnsra.mask.nxv4i32.nxv4i64.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vnsra_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi64 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsra_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnsra_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vnsra.nxv32i8.nxv32i16.nxv32i8(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vnsra_32xi8(__epi_32xi16 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsra_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsra_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vnsra.mask.nxv32i8.nxv32i16.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i16> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vnsra_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi16 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsra_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnsra_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vnsra.nxv16i16.nxv16i32.nxv16i16(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vnsra_16xi16(__epi_16xi32 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsra_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsra_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vnsra.mask.nxv16i16.nxv16i32.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i32> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vnsra_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi32 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsra_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnsra_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vnsra.nxv8i32.nxv8i64.nxv8i32(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vnsra_8xi32(__epi_8xi64 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsra_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsra_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vnsra.mask.nxv8i32.nxv8i64.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i64> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vnsra_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi64 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsra_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnsrl_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vnsrl.nxv8i8.nxv8i16.nxv8i8(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vnsrl_8xi8(__epi_8xi16 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsrl_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsrl_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vnsrl.mask.nxv8i8.nxv8i16.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vnsrl_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi16 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsrl_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnsrl_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vnsrl.nxv4i16.nxv4i32.nxv4i16(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vnsrl_4xi16(__epi_4xi32 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsrl_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsrl_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vnsrl.mask.nxv4i16.nxv4i32.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vnsrl_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi32 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsrl_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnsrl_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vnsrl.nxv2i32.nxv2i64.nxv2i32(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vnsrl_2xi32(__epi_2xi64 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsrl_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsrl_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vnsrl.mask.nxv2i32.nxv2i64.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vnsrl_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi64 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsrl_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnsrl_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vnsrl.nxv16i8.nxv16i16.nxv16i8(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vnsrl_16xi8(__epi_16xi16 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsrl_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsrl_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vnsrl.mask.nxv16i8.nxv16i16.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vnsrl_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi16 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsrl_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnsrl_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vnsrl.nxv8i16.nxv8i32.nxv8i16(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vnsrl_8xi16(__epi_8xi32 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsrl_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsrl_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vnsrl.mask.nxv8i16.nxv8i32.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vnsrl_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi32 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsrl_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnsrl_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vnsrl.nxv4i32.nxv4i64.nxv4i32(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vnsrl_4xi32(__epi_4xi64 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsrl_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsrl_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vnsrl.mask.nxv4i32.nxv4i64.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vnsrl_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi64 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsrl_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnsrl_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vnsrl.nxv32i8.nxv32i16.nxv32i8(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vnsrl_32xi8(__epi_32xi16 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsrl_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsrl_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vnsrl.mask.nxv32i8.nxv32i16.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i16> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vnsrl_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi16 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsrl_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnsrl_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vnsrl.nxv16i16.nxv16i32.nxv16i16(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vnsrl_16xi16(__epi_16xi32 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsrl_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsrl_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vnsrl.mask.nxv16i16.nxv16i32.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i32> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vnsrl_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi32 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsrl_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnsrl_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vnsrl.nxv8i32.nxv8i64.nxv8i32(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vnsrl_8xi32(__epi_8xi64 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsrl_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsrl_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vnsrl.mask.nxv8i32.nxv8i64.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i64> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vnsrl_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi64 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsrl_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vor_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vor.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vor_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vor_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vor_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vor.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vor_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vor_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vor_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vor.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vor_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vor_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vor_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vor.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vor_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vor_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vor_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vor.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vor_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vor_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vor_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vor.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vor_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vor_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vor_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vor.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vor_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vor_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vor_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vor.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vor_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vor_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vor_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vor.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vor_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vor_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vor_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vor.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vor_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vor_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vor_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vor.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vor_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vor_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vor_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vor.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vor_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vor_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vor_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vor.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vor_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vor_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vor_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vor.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vor_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vor_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vor_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vor.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vor_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vor_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vor_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vor.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vor_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vor_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vor_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vor.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vor_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vor_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vor_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vor.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vor_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vor_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vor_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vor.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vor_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vor_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vor_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vor.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vor_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vor_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vor_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vor.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vor_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vor_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vor_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vor.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vor_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vor_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vor_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vor.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vor_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vor_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vor_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vor.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vor_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vor_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vreadvl(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vreadvl()
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
unsigned long int test_vreadvl()
{
    return __builtin_epi_vreadvl();
}

// CHECK-O2-LABEL: @test_vredand_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vredand.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vredand_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredand_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredand_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vredand.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vredand_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredand_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredand_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vredand.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vredand_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredand_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredand_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vredand.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vredand_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredand_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredand_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vredand.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vredand_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredand_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredand_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vredand.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vredand_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredand_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredand_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vredand.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vredand_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredand_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredand_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vredand.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vredand_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredand_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredand_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vredand.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vredand_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredand_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredand_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vredand.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vredand_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredand_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredand_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vredand.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vredand_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredand_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredand_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vredand.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vredand_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredand_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredand_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vredand.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vredand_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredand_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredand_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vredand.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vredand_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredand_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredand_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vredand.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vredand_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredand_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredand_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vredand.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vredand_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredand_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredand_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vredand.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vredand_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredand_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredand_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vredand.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vredand_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredand_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredand_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vredand.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vredand_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredand_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredand_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vredand.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vredand_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredand_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredand_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vredand.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vredand_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredand_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredand_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vredand.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vredand_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredand_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredand_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vredand.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vredand_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredand_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredand_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vredand.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vredand_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredand_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmax_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vredmax.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vredmax_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmax_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmax_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vredmax.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vredmax_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmax_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmax_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vredmax.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vredmax_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmax_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmax_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vredmax.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vredmax_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmax_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmax_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vredmax.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vredmax_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmax_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmax_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vredmax.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vredmax_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmax_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmax_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vredmax.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vredmax_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmax_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmax_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vredmax.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vredmax_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmax_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmax_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vredmax.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vredmax_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmax_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmax_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vredmax.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vredmax_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmax_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmax_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vredmax.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vredmax_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmax_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmax_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vredmax.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vredmax_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmax_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmax_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vredmax.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vredmax_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmax_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmax_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vredmax.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vredmax_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmax_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmax_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vredmax.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vredmax_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmax_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmax_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vredmax.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vredmax_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmax_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmax_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vredmax.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vredmax_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmax_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmax_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vredmax.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vredmax_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmax_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmax_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vredmax.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vredmax_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmax_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmax_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vredmax.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vredmax_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmax_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmax_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vredmax.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vredmax_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmax_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmax_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vredmax.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vredmax_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmax_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmax_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vredmax.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vredmax_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmax_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmax_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vredmax.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vredmax_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmax_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmaxu_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vredmaxu.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vredmaxu_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmaxu_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmaxu_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vredmaxu.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vredmaxu_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmaxu_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmaxu_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vredmaxu.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vredmaxu_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmaxu_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmaxu_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vredmaxu.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vredmaxu_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmaxu_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmaxu_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vredmaxu.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vredmaxu_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmaxu_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmaxu_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vredmaxu.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vredmaxu_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmaxu_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmaxu_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vredmaxu.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vredmaxu_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmaxu_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmaxu_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vredmaxu.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vredmaxu_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmaxu_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmaxu_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vredmaxu.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vredmaxu_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmaxu_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmaxu_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vredmaxu.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vredmaxu_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmaxu_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmaxu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vredmaxu.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vredmaxu_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmaxu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmaxu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vredmaxu.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vredmaxu_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmaxu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmaxu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vredmaxu.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vredmaxu_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmaxu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmaxu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vredmaxu.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vredmaxu_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmaxu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmaxu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vredmaxu.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vredmaxu_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmaxu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmaxu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vredmaxu.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vredmaxu_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmaxu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmaxu_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vredmaxu.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vredmaxu_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmaxu_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmaxu_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vredmaxu.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vredmaxu_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmaxu_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmaxu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vredmaxu.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vredmaxu_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmaxu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmaxu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vredmaxu.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vredmaxu_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmaxu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmaxu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vredmaxu.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vredmaxu_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmaxu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmaxu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vredmaxu.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vredmaxu_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmaxu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmaxu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vredmaxu.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vredmaxu_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmaxu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmaxu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vredmaxu.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vredmaxu_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmaxu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmin_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vredmin.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vredmin_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmin_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmin_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vredmin.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vredmin_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmin_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmin_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vredmin.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vredmin_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmin_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmin_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vredmin.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vredmin_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmin_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmin_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vredmin.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vredmin_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmin_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmin_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vredmin.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vredmin_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmin_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmin_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vredmin.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vredmin_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmin_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmin_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vredmin.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vredmin_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmin_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmin_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vredmin.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vredmin_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmin_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmin_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vredmin.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vredmin_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmin_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmin_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vredmin.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vredmin_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmin_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmin_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vredmin.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vredmin_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmin_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmin_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vredmin.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vredmin_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmin_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmin_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vredmin.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vredmin_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmin_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmin_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vredmin.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vredmin_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmin_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmin_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vredmin.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vredmin_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmin_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmin_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vredmin.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vredmin_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmin_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmin_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vredmin.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vredmin_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmin_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmin_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vredmin.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vredmin_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmin_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmin_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vredmin.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vredmin_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmin_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmin_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vredmin.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vredmin_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmin_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmin_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vredmin.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vredmin_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmin_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmin_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vredmin.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vredmin_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmin_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmin_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vredmin.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vredmin_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmin_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredminu_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vredminu.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vredminu_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredminu_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredminu_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vredminu.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vredminu_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredminu_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredminu_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vredminu.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vredminu_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredminu_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredminu_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vredminu.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vredminu_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredminu_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredminu_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vredminu.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vredminu_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredminu_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredminu_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vredminu.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vredminu_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredminu_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredminu_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vredminu.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vredminu_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredminu_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredminu_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vredminu.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vredminu_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredminu_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredminu_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vredminu.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vredminu_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredminu_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredminu_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vredminu.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vredminu_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredminu_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredminu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vredminu.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vredminu_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredminu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredminu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vredminu.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vredminu_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredminu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredminu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vredminu.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vredminu_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredminu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredminu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vredminu.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vredminu_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredminu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredminu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vredminu.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vredminu_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredminu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredminu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vredminu.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vredminu_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredminu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredminu_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vredminu.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vredminu_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredminu_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredminu_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vredminu.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vredminu_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredminu_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredminu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vredminu.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vredminu_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredminu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredminu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vredminu.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vredminu_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredminu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredminu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vredminu.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vredminu_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredminu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredminu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vredminu.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vredminu_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredminu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredminu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vredminu.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vredminu_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredminu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredminu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vredminu.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vredminu_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredminu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredor_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vredor.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vredor_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredor_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredor_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vredor.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vredor_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredor_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredor_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vredor.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vredor_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredor_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredor_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vredor.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vredor_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredor_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredor_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vredor.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vredor_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredor_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredor_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vredor.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vredor_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredor_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredor_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vredor.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vredor_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredor_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredor_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vredor.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vredor_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredor_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredor_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vredor.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vredor_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredor_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredor_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vredor.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vredor_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredor_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredor_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vredor.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vredor_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredor_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredor_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vredor.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vredor_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredor_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredor_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vredor.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vredor_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredor_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredor_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vredor.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vredor_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredor_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredor_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vredor.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vredor_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredor_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredor_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vredor.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vredor_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredor_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredor_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vredor.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vredor_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredor_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredor_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vredor.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vredor_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredor_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredor_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vredor.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vredor_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredor_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredor_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vredor.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vredor_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredor_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredor_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vredor.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vredor_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredor_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredor_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vredor.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vredor_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredor_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredor_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vredor.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vredor_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredor_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredor_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vredor.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vredor_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredor_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredsum_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vredsum.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vredsum_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredsum_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredsum_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vredsum.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vredsum_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredsum_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredsum_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vredsum.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vredsum_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredsum_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredsum_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vredsum.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vredsum_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredsum_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredsum_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vredsum.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vredsum_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredsum_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredsum_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vredsum.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vredsum_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredsum_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredsum_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vredsum.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vredsum_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredsum_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredsum_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vredsum.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vredsum_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredsum_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredsum_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vredsum.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vredsum_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredsum_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredsum_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vredsum.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vredsum_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredsum_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredsum_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vredsum.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vredsum_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredsum_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredsum_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vredsum.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vredsum_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredsum_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredsum_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vredsum.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vredsum_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredsum_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredsum_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vredsum.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vredsum_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredsum_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredsum_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vredsum.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vredsum_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredsum_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredsum_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vredsum.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vredsum_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredsum_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredsum_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vredsum.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vredsum_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredsum_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredsum_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vredsum.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vredsum_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredsum_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredsum_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vredsum.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vredsum_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredsum_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredsum_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vredsum.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vredsum_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredsum_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredsum_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vredsum.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vredsum_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredsum_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredsum_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vredsum.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vredsum_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredsum_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredsum_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vredsum.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vredsum_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredsum_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredsum_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vredsum.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vredsum_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredsum_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredxor_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vredxor.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vredxor_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredxor_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredxor_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vredxor.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vredxor_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredxor_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredxor_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vredxor.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vredxor_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredxor_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredxor_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vredxor.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vredxor_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredxor_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredxor_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vredxor.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vredxor_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredxor_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredxor_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vredxor.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vredxor_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredxor_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredxor_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vredxor.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vredxor_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredxor_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredxor_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vredxor.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vredxor_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredxor_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredxor_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vredxor.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vredxor_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredxor_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredxor_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vredxor.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vredxor_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredxor_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredxor_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vredxor.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vredxor_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredxor_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredxor_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vredxor.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vredxor_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredxor_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredxor_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vredxor.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vredxor_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredxor_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredxor_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vredxor.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vredxor_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredxor_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredxor_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vredxor.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vredxor_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredxor_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredxor_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vredxor.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vredxor_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredxor_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredxor_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vredxor.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vredxor_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredxor_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredxor_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vredxor.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vredxor_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredxor_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredxor_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vredxor.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vredxor_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredxor_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredxor_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vredxor.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vredxor_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredxor_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredxor_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vredxor.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vredxor_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredxor_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredxor_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vredxor.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vredxor_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredxor_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredxor_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vredxor.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vredxor_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredxor_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredxor_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vredxor.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vredxor_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredxor_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrem_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vrem.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vrem_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrem_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrem_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vrem.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vrem_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrem_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrem_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vrem.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vrem_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrem_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrem_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vrem.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vrem_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrem_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrem_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vrem.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vrem_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrem_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrem_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vrem.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vrem_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrem_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrem_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vrem.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vrem_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrem_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrem_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vrem.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vrem_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrem_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrem_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vrem.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vrem_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrem_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrem_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vrem.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vrem_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrem_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrem_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vrem.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vrem_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrem_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrem_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vrem.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vrem_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrem_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrem_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vrem.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vrem_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrem_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrem_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vrem.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vrem_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrem_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrem_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vrem.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vrem_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrem_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrem_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vrem.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vrem_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrem_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrem_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vrem.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vrem_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrem_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrem_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vrem.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vrem_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrem_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrem_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vrem.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vrem_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrem_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrem_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vrem.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vrem_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrem_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrem_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vrem.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vrem_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrem_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrem_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vrem.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vrem_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrem_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrem_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vrem.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vrem_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrem_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrem_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vrem.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vrem_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrem_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vremu_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vremu.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vremu_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vremu_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vremu_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vremu.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vremu_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vremu_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vremu_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vremu.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vremu_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vremu_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vremu_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vremu.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vremu_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vremu_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vremu_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vremu.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vremu_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vremu_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vremu_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vremu.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vremu_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vremu_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vremu_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vremu.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vremu_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vremu_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vremu_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vremu.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vremu_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vremu_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vremu_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vremu.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vremu_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vremu_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vremu_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vremu.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vremu_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vremu_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vremu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vremu.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vremu_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vremu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vremu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vremu.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vremu_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vremu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vremu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vremu.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vremu_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vremu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vremu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vremu.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vremu_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vremu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vremu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vremu.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vremu_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vremu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vremu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vremu.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vremu_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vremu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vremu_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vremu.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vremu_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vremu_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vremu_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vremu.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vremu_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vremu_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vremu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vremu.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vremu_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vremu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vremu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vremu.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vremu_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vremu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vremu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vremu.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vremu_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vremu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vremu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vremu.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vremu_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vremu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vremu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vremu.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vremu_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vremu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vremu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vremu.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vremu_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vremu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vrgather.nxv8i8.i64(<vscale x 8 x i8> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vrgather_8xi8(__epi_8xi8 arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vrgather.mask.nxv8i8.i64.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vrgather_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vrgather.nxv4i16.i64(<vscale x 4 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vrgather_4xi16(__epi_4xi16 arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vrgather.mask.nxv4i16.i64.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vrgather_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vrgather.nxv2i32.i64(<vscale x 2 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vrgather_2xi32(__epi_2xi32 arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vrgather.mask.nxv2i32.i64.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vrgather_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vrgather.nxv1i64.i64(<vscale x 1 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vrgather_1xi64(__epi_1xi64 arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vrgather.mask.nxv1i64.i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vrgather_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vrgather.nxv2f32.i64(<vscale x 2 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vrgather_2xf32(__epi_2xf32 arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vrgather.mask.nxv2f32.i64.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vrgather_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vrgather.nxv1f64.i64(<vscale x 1 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vrgather_1xf64(__epi_1xf64 arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vrgather.mask.nxv1f64.i64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vrgather_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vrgather.nxv16i8.i64(<vscale x 16 x i8> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vrgather_16xi8(__epi_16xi8 arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vrgather.mask.nxv16i8.i64.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vrgather_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, signed long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vrgather.nxv8i16.i64(<vscale x 8 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vrgather_8xi16(__epi_8xi16 arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vrgather.mask.nxv8i16.i64.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vrgather_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vrgather.nxv4i32.i64(<vscale x 4 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vrgather_4xi32(__epi_4xi32 arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vrgather.mask.nxv4i32.i64.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vrgather_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vrgather.nxv2i64.i64(<vscale x 2 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vrgather_2xi64(__epi_2xi64 arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vrgather.mask.nxv2i64.i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vrgather_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vrgather.nxv4f32.i64(<vscale x 4 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vrgather_4xf32(__epi_4xf32 arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vrgather.mask.nxv4f32.i64.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vrgather_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vrgather.nxv2f64.i64(<vscale x 2 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vrgather_2xf64(__epi_2xf64 arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vrgather.mask.nxv2f64.i64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vrgather_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vrgather.nxv32i8.i64(<vscale x 32 x i8> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vrgather_32xi8(__epi_32xi8 arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vrgather.mask.nxv32i8.i64.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vrgather_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, signed long int arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vrgather.nxv16i16.i64(<vscale x 16 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vrgather_16xi16(__epi_16xi16 arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vrgather.mask.nxv16i16.i64.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vrgather_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, signed long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vrgather.nxv8i32.i64(<vscale x 8 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vrgather_8xi32(__epi_8xi32 arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vrgather.mask.nxv8i32.i64.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vrgather_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vrgather.nxv4i64.i64(<vscale x 4 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vrgather_4xi64(__epi_4xi64 arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vrgather.mask.nxv4i64.i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vrgather_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vrgather.nxv8f32.i64(<vscale x 8 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vrgather_8xf32(__epi_8xf32 arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vrgather.mask.nxv8f32.i64.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vrgather_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vrgather.nxv4f64.i64(<vscale x 4 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vrgather_4xf64(__epi_4xf64 arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vrgather.mask.nxv4f64.i64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vrgather_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrsub_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vrsub.nxv8i8.i8(<vscale x 8 x i8> [[ARG_0:%.*]], i8 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vrsub_8xi8(__epi_8xi8 arg_0, signed char arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrsub_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrsub_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vrsub.mask.nxv8i8.i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i8 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vrsub_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, signed char arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrsub_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrsub_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vrsub.nxv4i16.i16(<vscale x 4 x i16> [[ARG_0:%.*]], i16 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vrsub_4xi16(__epi_4xi16 arg_0, signed short int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrsub_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrsub_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vrsub.mask.nxv4i16.i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i16 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vrsub_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, signed short int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrsub_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrsub_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vrsub.nxv2i32.i32(<vscale x 2 x i32> [[ARG_0:%.*]], i32 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vrsub_2xi32(__epi_2xi32 arg_0, signed int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrsub_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrsub_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vrsub.mask.nxv2i32.i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i32 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vrsub_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, signed int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrsub_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrsub_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vrsub.nxv1i64.i64(<vscale x 1 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vrsub_1xi64(__epi_1xi64 arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrsub_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrsub_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vrsub.mask.nxv1i64.i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vrsub_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrsub_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrsub_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vrsub.nxv16i8.i8(<vscale x 16 x i8> [[ARG_0:%.*]], i8 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vrsub_16xi8(__epi_16xi8 arg_0, signed char arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrsub_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrsub_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vrsub.mask.nxv16i8.i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i8 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vrsub_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, signed char arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrsub_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrsub_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vrsub.nxv8i16.i16(<vscale x 8 x i16> [[ARG_0:%.*]], i16 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vrsub_8xi16(__epi_8xi16 arg_0, signed short int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrsub_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrsub_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vrsub.mask.nxv8i16.i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i16 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vrsub_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, signed short int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrsub_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrsub_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vrsub.nxv4i32.i32(<vscale x 4 x i32> [[ARG_0:%.*]], i32 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vrsub_4xi32(__epi_4xi32 arg_0, signed int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrsub_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrsub_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vrsub.mask.nxv4i32.i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i32 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vrsub_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, signed int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrsub_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrsub_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vrsub.nxv2i64.i64(<vscale x 2 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vrsub_2xi64(__epi_2xi64 arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrsub_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrsub_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vrsub.mask.nxv2i64.i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vrsub_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrsub_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrsub_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vrsub.nxv32i8.i8(<vscale x 32 x i8> [[ARG_0:%.*]], i8 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vrsub_32xi8(__epi_32xi8 arg_0, signed char arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrsub_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrsub_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vrsub.mask.nxv32i8.i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i8 [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vrsub_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, signed char arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrsub_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrsub_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vrsub.nxv16i16.i16(<vscale x 16 x i16> [[ARG_0:%.*]], i16 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vrsub_16xi16(__epi_16xi16 arg_0, signed short int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrsub_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrsub_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vrsub.mask.nxv16i16.i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i16 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vrsub_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, signed short int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrsub_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrsub_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vrsub.nxv8i32.i32(<vscale x 8 x i32> [[ARG_0:%.*]], i32 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vrsub_8xi32(__epi_8xi32 arg_0, signed int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrsub_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrsub_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vrsub.mask.nxv8i32.i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i32 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vrsub_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, signed int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrsub_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrsub_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vrsub.nxv4i64.i64(<vscale x 4 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vrsub_4xi64(__epi_4xi64 arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrsub_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrsub_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vrsub.mask.nxv4i64.i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vrsub_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrsub_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsadd_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vsadd.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vsadd_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsadd_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsadd_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vsadd.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vsadd_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsadd_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsadd_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vsadd.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vsadd_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsadd_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsadd_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vsadd.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vsadd_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsadd_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsadd_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vsadd.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vsadd_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsadd_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsadd_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vsadd.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vsadd_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsadd_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsadd_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vsadd.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vsadd_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsadd_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsadd_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vsadd.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vsadd_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsadd_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsadd_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vsadd.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vsadd_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsadd_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsadd_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vsadd.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vsadd_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsadd_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsadd_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vsadd.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vsadd_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsadd_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsadd_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vsadd.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vsadd_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsadd_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsadd_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vsadd.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vsadd_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsadd_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsadd_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vsadd.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vsadd_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsadd_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsadd_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vsadd.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vsadd_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsadd_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsadd_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vsadd.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vsadd_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsadd_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsadd_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vsadd.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vsadd_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsadd_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsadd_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vsadd.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vsadd_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsadd_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsadd_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vsadd.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vsadd_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsadd_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsadd_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vsadd.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vsadd_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsadd_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsadd_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vsadd.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vsadd_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsadd_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsadd_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vsadd.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vsadd_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsadd_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsadd_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vsadd.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vsadd_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsadd_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsadd_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vsadd.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vsadd_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsadd_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsaddu_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vsaddu.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vsaddu_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsaddu_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsaddu_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vsaddu.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vsaddu_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsaddu_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsaddu_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vsaddu.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vsaddu_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsaddu_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsaddu_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vsaddu.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vsaddu_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsaddu_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsaddu_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vsaddu.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vsaddu_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsaddu_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsaddu_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vsaddu.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vsaddu_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsaddu_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsaddu_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vsaddu.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vsaddu_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsaddu_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsaddu_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vsaddu.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vsaddu_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsaddu_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsaddu_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vsaddu.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vsaddu_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsaddu_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsaddu_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vsaddu.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vsaddu_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsaddu_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsaddu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vsaddu.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vsaddu_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsaddu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsaddu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vsaddu.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vsaddu_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsaddu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsaddu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vsaddu.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vsaddu_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsaddu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsaddu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vsaddu.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vsaddu_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsaddu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsaddu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vsaddu.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vsaddu_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsaddu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsaddu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vsaddu.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vsaddu_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsaddu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsaddu_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vsaddu.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vsaddu_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsaddu_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsaddu_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vsaddu.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vsaddu_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsaddu_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsaddu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vsaddu.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vsaddu_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsaddu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsaddu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vsaddu.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vsaddu_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsaddu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsaddu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vsaddu.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vsaddu_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsaddu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsaddu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vsaddu.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vsaddu_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsaddu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsaddu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vsaddu.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vsaddu_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsaddu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsaddu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vsaddu.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vsaddu_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsaddu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsetfirst_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfmv.s.f.nxv2f32.f32(float [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vsetfirst_2xf32(float arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vsetfirst_2xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vsetfirst_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfmv.s.f.nxv1f64.f64(double [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vsetfirst_1xf64(double arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vsetfirst_1xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vsetfirst_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmv.s.x.nxv8i8.i8(i8 [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vsetfirst_8xi8(signed char arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vsetfirst_8xi8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vsetfirst_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmv.s.x.nxv4i16.i16(i16 [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vsetfirst_4xi16(signed short int arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vsetfirst_4xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vsetfirst_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmv.s.x.nxv2i32.i32(i32 [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vsetfirst_2xi32(signed int arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vsetfirst_2xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vsetfirst_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmv.s.x.nxv1i64.i64(i64 [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vsetfirst_1xi64(signed long int arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vsetfirst_1xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vslide1down_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vslide1down.nxv8i8.i64(<vscale x 8 x i8> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vslide1down_8xi8(__epi_8xi8 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vslide1down.mask.nxv8i8.i64.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vslide1down_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1down_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vslide1down.nxv4i16.i64(<vscale x 4 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vslide1down_4xi16(__epi_4xi16 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vslide1down.mask.nxv4i16.i64.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vslide1down_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1down_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vslide1down.nxv2i32.i64(<vscale x 2 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vslide1down_2xi32(__epi_2xi32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vslide1down.mask.nxv2i32.i64.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vslide1down_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1down_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vslide1down.nxv1i64.i64(<vscale x 1 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vslide1down_1xi64(__epi_1xi64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vslide1down.mask.nxv1i64.i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vslide1down_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1down_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vslide1down.nxv2f32.i64(<vscale x 2 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vslide1down_2xf32(__epi_2xf32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vslide1down.mask.nxv2f32.i64.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vslide1down_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1down_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vslide1down.nxv1f64.i64(<vscale x 1 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vslide1down_1xf64(__epi_1xf64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vslide1down.mask.nxv1f64.i64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vslide1down_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1down_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vslide1down.nxv16i8.i64(<vscale x 16 x i8> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vslide1down_16xi8(__epi_16xi8 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vslide1down.mask.nxv16i8.i64.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vslide1down_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1down_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vslide1down.nxv8i16.i64(<vscale x 8 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vslide1down_8xi16(__epi_8xi16 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vslide1down.mask.nxv8i16.i64.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vslide1down_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1down_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vslide1down.nxv4i32.i64(<vscale x 4 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vslide1down_4xi32(__epi_4xi32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vslide1down.mask.nxv4i32.i64.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vslide1down_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1down_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vslide1down.nxv2i64.i64(<vscale x 2 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vslide1down_2xi64(__epi_2xi64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vslide1down.mask.nxv2i64.i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vslide1down_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1down_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vslide1down.nxv4f32.i64(<vscale x 4 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vslide1down_4xf32(__epi_4xf32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vslide1down.mask.nxv4f32.i64.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vslide1down_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1down_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vslide1down.nxv2f64.i64(<vscale x 2 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vslide1down_2xf64(__epi_2xf64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vslide1down.mask.nxv2f64.i64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vslide1down_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1down_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vslide1down.nxv32i8.i64(<vscale x 32 x i8> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vslide1down_32xi8(__epi_32xi8 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vslide1down.mask.nxv32i8.i64.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vslide1down_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1down_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vslide1down.nxv16i16.i64(<vscale x 16 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vslide1down_16xi16(__epi_16xi16 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vslide1down.mask.nxv16i16.i64.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vslide1down_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1down_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vslide1down.nxv8i32.i64(<vscale x 8 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vslide1down_8xi32(__epi_8xi32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vslide1down.mask.nxv8i32.i64.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vslide1down_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1down_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vslide1down.nxv4i64.i64(<vscale x 4 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vslide1down_4xi64(__epi_4xi64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vslide1down.mask.nxv4i64.i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vslide1down_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1down_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vslide1down.nxv8f32.i64(<vscale x 8 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vslide1down_8xf32(__epi_8xf32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vslide1down.mask.nxv8f32.i64.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vslide1down_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1down_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vslide1down.nxv4f64.i64(<vscale x 4 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vslide1down_4xf64(__epi_4xf64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vslide1down.mask.nxv4f64.i64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vslide1down_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vslide1up.nxv8i8.i64(<vscale x 8 x i8> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vslide1up_8xi8(__epi_8xi8 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vslide1up.mask.nxv8i8.i64.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vslide1up_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vslide1up.nxv4i16.i64(<vscale x 4 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vslide1up_4xi16(__epi_4xi16 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vslide1up.mask.nxv4i16.i64.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vslide1up_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vslide1up.nxv2i32.i64(<vscale x 2 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vslide1up_2xi32(__epi_2xi32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vslide1up.mask.nxv2i32.i64.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vslide1up_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vslide1up.nxv1i64.i64(<vscale x 1 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vslide1up_1xi64(__epi_1xi64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vslide1up.mask.nxv1i64.i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vslide1up_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vslide1up.nxv2f32.i64(<vscale x 2 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vslide1up_2xf32(__epi_2xf32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vslide1up.mask.nxv2f32.i64.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vslide1up_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vslide1up.nxv1f64.i64(<vscale x 1 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vslide1up_1xf64(__epi_1xf64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vslide1up.mask.nxv1f64.i64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vslide1up_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vslide1up.nxv16i8.i64(<vscale x 16 x i8> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vslide1up_16xi8(__epi_16xi8 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vslide1up.mask.nxv16i8.i64.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vslide1up_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vslide1up.nxv8i16.i64(<vscale x 8 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vslide1up_8xi16(__epi_8xi16 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vslide1up.mask.nxv8i16.i64.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vslide1up_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vslide1up.nxv4i32.i64(<vscale x 4 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vslide1up_4xi32(__epi_4xi32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vslide1up.mask.nxv4i32.i64.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vslide1up_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vslide1up.nxv2i64.i64(<vscale x 2 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vslide1up_2xi64(__epi_2xi64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vslide1up.mask.nxv2i64.i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vslide1up_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vslide1up.nxv4f32.i64(<vscale x 4 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vslide1up_4xf32(__epi_4xf32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vslide1up.mask.nxv4f32.i64.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vslide1up_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vslide1up.nxv2f64.i64(<vscale x 2 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vslide1up_2xf64(__epi_2xf64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vslide1up.mask.nxv2f64.i64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vslide1up_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vslide1up.nxv32i8.i64(<vscale x 32 x i8> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vslide1up_32xi8(__epi_32xi8 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vslide1up.mask.nxv32i8.i64.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vslide1up_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vslide1up.nxv16i16.i64(<vscale x 16 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vslide1up_16xi16(__epi_16xi16 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vslide1up.mask.nxv16i16.i64.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vslide1up_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vslide1up.nxv8i32.i64(<vscale x 8 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vslide1up_8xi32(__epi_8xi32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vslide1up.mask.nxv8i32.i64.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vslide1up_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vslide1up.nxv4i64.i64(<vscale x 4 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vslide1up_4xi64(__epi_4xi64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vslide1up.mask.nxv4i64.i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vslide1up_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vslide1up.nxv8f32.i64(<vscale x 8 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vslide1up_8xf32(__epi_8xf32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vslide1up.mask.nxv8f32.i64.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vslide1up_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vslide1up.nxv4f64.i64(<vscale x 4 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vslide1up_4xf64(__epi_4xf64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vslide1up.mask.nxv4f64.i64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vslide1up_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vslidedown.nxv8i8.i64(<vscale x 8 x i8> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vslidedown_8xi8(__epi_8xi8 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vslidedown.mask.nxv8i8.i64.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vslidedown_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vslidedown.nxv4i16.i64(<vscale x 4 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vslidedown_4xi16(__epi_4xi16 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vslidedown.mask.nxv4i16.i64.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vslidedown_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vslidedown.nxv2i32.i64(<vscale x 2 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vslidedown_2xi32(__epi_2xi32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vslidedown.mask.nxv2i32.i64.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vslidedown_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vslidedown.nxv1i64.i64(<vscale x 1 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vslidedown_1xi64(__epi_1xi64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vslidedown.mask.nxv1i64.i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vslidedown_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vslidedown.nxv2f32.i64(<vscale x 2 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vslidedown_2xf32(__epi_2xf32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vslidedown.mask.nxv2f32.i64.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vslidedown_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vslidedown.nxv1f64.i64(<vscale x 1 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vslidedown_1xf64(__epi_1xf64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vslidedown.mask.nxv1f64.i64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vslidedown_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vslidedown.nxv16i8.i64(<vscale x 16 x i8> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vslidedown_16xi8(__epi_16xi8 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vslidedown.mask.nxv16i8.i64.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vslidedown_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vslidedown.nxv8i16.i64(<vscale x 8 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vslidedown_8xi16(__epi_8xi16 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vslidedown.mask.nxv8i16.i64.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vslidedown_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vslidedown.nxv4i32.i64(<vscale x 4 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vslidedown_4xi32(__epi_4xi32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vslidedown.mask.nxv4i32.i64.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vslidedown_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vslidedown.nxv2i64.i64(<vscale x 2 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vslidedown_2xi64(__epi_2xi64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vslidedown.mask.nxv2i64.i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vslidedown_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vslidedown.nxv4f32.i64(<vscale x 4 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vslidedown_4xf32(__epi_4xf32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vslidedown.mask.nxv4f32.i64.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vslidedown_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vslidedown.nxv2f64.i64(<vscale x 2 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vslidedown_2xf64(__epi_2xf64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vslidedown.mask.nxv2f64.i64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vslidedown_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vslidedown.nxv32i8.i64(<vscale x 32 x i8> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vslidedown_32xi8(__epi_32xi8 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vslidedown.mask.nxv32i8.i64.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vslidedown_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vslidedown.nxv16i16.i64(<vscale x 16 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vslidedown_16xi16(__epi_16xi16 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vslidedown.mask.nxv16i16.i64.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vslidedown_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vslidedown.nxv8i32.i64(<vscale x 8 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vslidedown_8xi32(__epi_8xi32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vslidedown.mask.nxv8i32.i64.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vslidedown_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vslidedown.nxv4i64.i64(<vscale x 4 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vslidedown_4xi64(__epi_4xi64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vslidedown.mask.nxv4i64.i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vslidedown_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vslidedown.nxv8f32.i64(<vscale x 8 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vslidedown_8xf32(__epi_8xf32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vslidedown.mask.nxv8f32.i64.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vslidedown_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vslidedown.nxv4f64.i64(<vscale x 4 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vslidedown_4xf64(__epi_4xf64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vslidedown.mask.nxv4f64.i64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vslidedown_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vslideup.nxv8i8.i64(<vscale x 8 x i8> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vslideup_8xi8(__epi_8xi8 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vslideup.mask.nxv8i8.i64.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vslideup_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vslideup.nxv4i16.i64(<vscale x 4 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vslideup_4xi16(__epi_4xi16 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vslideup.mask.nxv4i16.i64.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vslideup_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vslideup.nxv2i32.i64(<vscale x 2 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vslideup_2xi32(__epi_2xi32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vslideup.mask.nxv2i32.i64.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vslideup_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vslideup.nxv1i64.i64(<vscale x 1 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vslideup_1xi64(__epi_1xi64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vslideup.mask.nxv1i64.i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vslideup_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vslideup.nxv2f32.i64(<vscale x 2 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vslideup_2xf32(__epi_2xf32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vslideup.mask.nxv2f32.i64.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vslideup_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vslideup.nxv1f64.i64(<vscale x 1 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vslideup_1xf64(__epi_1xf64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vslideup.mask.nxv1f64.i64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vslideup_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vslideup.nxv16i8.i64(<vscale x 16 x i8> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vslideup_16xi8(__epi_16xi8 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vslideup.mask.nxv16i8.i64.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vslideup_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vslideup.nxv8i16.i64(<vscale x 8 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vslideup_8xi16(__epi_8xi16 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vslideup.mask.nxv8i16.i64.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vslideup_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vslideup.nxv4i32.i64(<vscale x 4 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vslideup_4xi32(__epi_4xi32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vslideup.mask.nxv4i32.i64.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vslideup_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vslideup.nxv2i64.i64(<vscale x 2 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vslideup_2xi64(__epi_2xi64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vslideup.mask.nxv2i64.i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vslideup_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vslideup.nxv4f32.i64(<vscale x 4 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vslideup_4xf32(__epi_4xf32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vslideup.mask.nxv4f32.i64.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vslideup_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vslideup.nxv2f64.i64(<vscale x 2 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vslideup_2xf64(__epi_2xf64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vslideup.mask.nxv2f64.i64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vslideup_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vslideup.nxv32i8.i64(<vscale x 32 x i8> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vslideup_32xi8(__epi_32xi8 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vslideup.mask.nxv32i8.i64.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vslideup_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vslideup.nxv16i16.i64(<vscale x 16 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vslideup_16xi16(__epi_16xi16 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vslideup.mask.nxv16i16.i64.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vslideup_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vslideup.nxv8i32.i64(<vscale x 8 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vslideup_8xi32(__epi_8xi32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vslideup.mask.nxv8i32.i64.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vslideup_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vslideup.nxv4i64.i64(<vscale x 4 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vslideup_4xi64(__epi_4xi64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vslideup.mask.nxv4i64.i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vslideup_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vslideup.nxv8f32.i64(<vscale x 8 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vslideup_8xf32(__epi_8xf32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vslideup.mask.nxv8f32.i64.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vslideup_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vslideup.nxv4f64.i64(<vscale x 4 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vslideup_4xf64(__epi_4xf64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vslideup.mask.nxv4f64.i64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vslideup_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsll_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vsll.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vsll_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsll_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsll_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vsll.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vsll_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsll_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsll_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vsll.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vsll_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsll_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsll_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vsll.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vsll_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsll_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsll_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vsll.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vsll_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsll_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsll_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vsll.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vsll_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsll_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsll_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vsll.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vsll_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsll_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsll_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vsll.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vsll_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsll_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsll_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vsll.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vsll_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsll_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsll_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vsll.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vsll_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsll_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsll_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vsll.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vsll_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsll_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsll_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vsll.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vsll_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsll_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsll_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vsll.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vsll_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsll_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsll_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vsll.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vsll_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsll_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsll_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vsll.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vsll_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsll_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsll_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vsll.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vsll_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsll_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsll_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vsll.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vsll_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsll_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsll_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vsll.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vsll_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsll_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsll_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vsll.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vsll_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsll_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsll_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vsll.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vsll_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsll_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsll_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vsll.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vsll_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsll_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsll_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vsll.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vsll_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsll_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsll_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vsll.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vsll_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsll_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsll_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vsll.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vsll_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsll_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsmul_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vsmul.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vsmul_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsmul_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsmul_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vsmul.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vsmul_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsmul_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsmul_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vsmul.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vsmul_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsmul_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsmul_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vsmul.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vsmul_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsmul_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsmul_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vsmul.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vsmul_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsmul_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsmul_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vsmul.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vsmul_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsmul_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsmul_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vsmul.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vsmul_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsmul_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsmul_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vsmul.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vsmul_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsmul_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsmul_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vsmul.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vsmul_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsmul_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsmul_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vsmul.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vsmul_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsmul_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsmul_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vsmul.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vsmul_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsmul_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsmul_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vsmul.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vsmul_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsmul_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsmul_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vsmul.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vsmul_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsmul_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsmul_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vsmul.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vsmul_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsmul_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsmul_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vsmul.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vsmul_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsmul_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsmul_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vsmul.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vsmul_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsmul_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsmul_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vsmul.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vsmul_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsmul_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsmul_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vsmul.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vsmul_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsmul_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsmul_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vsmul.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vsmul_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsmul_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsmul_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vsmul.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vsmul_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsmul_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsmul_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vsmul.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vsmul_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsmul_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsmul_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vsmul.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vsmul_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsmul_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsmul_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vsmul.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vsmul_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsmul_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsmul_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vsmul.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vsmul_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsmul_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsra_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vsra.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vsra_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsra_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsra_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vsra.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vsra_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsra_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsra_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vsra.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vsra_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsra_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsra_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vsra.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vsra_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsra_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsra_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vsra.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vsra_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsra_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsra_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vsra.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vsra_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsra_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsra_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vsra.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vsra_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsra_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsra_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vsra.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vsra_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsra_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsra_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vsra.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vsra_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsra_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsra_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vsra.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vsra_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsra_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsra_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vsra.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vsra_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsra_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsra_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vsra.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vsra_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsra_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsra_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vsra.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vsra_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsra_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsra_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vsra.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vsra_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsra_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsra_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vsra.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vsra_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsra_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsra_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vsra.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vsra_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsra_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsra_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vsra.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vsra_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsra_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsra_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vsra.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vsra_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsra_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsra_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vsra.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vsra_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsra_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsra_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vsra.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vsra_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsra_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsra_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vsra.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vsra_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsra_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsra_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vsra.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vsra_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsra_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsra_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vsra.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vsra_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsra_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsra_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vsra.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vsra_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsra_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsrl_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vsrl.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vsrl_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsrl_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsrl_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vsrl.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vsrl_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsrl_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsrl_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vsrl.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vsrl_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsrl_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsrl_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vsrl.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vsrl_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsrl_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsrl_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vsrl.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vsrl_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsrl_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsrl_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vsrl.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vsrl_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsrl_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsrl_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vsrl.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vsrl_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsrl_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsrl_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vsrl.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vsrl_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsrl_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsrl_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vsrl.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vsrl_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsrl_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsrl_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vsrl.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vsrl_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsrl_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsrl_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vsrl.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vsrl_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsrl_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsrl_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vsrl.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vsrl_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsrl_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsrl_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vsrl.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vsrl_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsrl_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsrl_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vsrl.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vsrl_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsrl_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsrl_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vsrl.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vsrl_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsrl_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsrl_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vsrl.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vsrl_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsrl_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsrl_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vsrl.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vsrl_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsrl_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsrl_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vsrl.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vsrl_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsrl_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsrl_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vsrl.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vsrl_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsrl_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsrl_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vsrl.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vsrl_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsrl_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsrl_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vsrl.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vsrl_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsrl_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsrl_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vsrl.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vsrl_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsrl_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsrl_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vsrl.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vsrl_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsrl_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsrl_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vsrl.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vsrl_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsrl_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssra_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vssra.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vssra_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssra_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssra_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vssra.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vssra_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssra_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssra_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vssra.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vssra_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssra_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssra_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vssra.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vssra_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssra_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssra_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vssra.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vssra_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssra_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssra_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vssra.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vssra_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssra_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssra_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vssra.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vssra_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssra_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssra_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vssra.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vssra_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssra_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssra_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vssra.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vssra_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssra_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssra_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vssra.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vssra_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssra_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssra_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vssra.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vssra_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssra_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssra_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vssra.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vssra_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssra_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssra_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vssra.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vssra_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssra_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssra_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vssra.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vssra_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssra_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssra_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vssra.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vssra_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssra_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssra_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vssra.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vssra_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssra_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssra_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vssra.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vssra_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssra_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssra_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vssra.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vssra_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssra_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssra_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vssra.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vssra_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssra_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssra_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vssra.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vssra_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssra_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssra_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vssra.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vssra_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssra_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssra_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vssra.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vssra_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssra_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssra_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vssra.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vssra_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssra_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssra_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vssra.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vssra_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssra_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssrl_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vssrl.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vssrl_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssrl_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssrl_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vssrl.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vssrl_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssrl_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssrl_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vssrl.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vssrl_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssrl_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssrl_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vssrl.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vssrl_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssrl_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssrl_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vssrl.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vssrl_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssrl_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssrl_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vssrl.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vssrl_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssrl_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssrl_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vssrl.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vssrl_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssrl_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssrl_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vssrl.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vssrl_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssrl_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssrl_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vssrl.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vssrl_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssrl_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssrl_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vssrl.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vssrl_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssrl_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssrl_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vssrl.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vssrl_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssrl_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssrl_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vssrl.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vssrl_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssrl_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssrl_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vssrl.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vssrl_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssrl_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssrl_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vssrl.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vssrl_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssrl_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssrl_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vssrl.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vssrl_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssrl_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssrl_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vssrl.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vssrl_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssrl_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssrl_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vssrl.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vssrl_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssrl_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssrl_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vssrl.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vssrl_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssrl_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssrl_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vssrl.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vssrl_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssrl_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssrl_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vssrl.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vssrl_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssrl_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssrl_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vssrl.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vssrl_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssrl_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssrl_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vssrl.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vssrl_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssrl_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssrl_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vssrl.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vssrl_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssrl_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssrl_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vssrl.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vssrl_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssrl_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssub_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vssub.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vssub_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssub_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssub_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vssub.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vssub_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssub_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssub_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vssub.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vssub_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssub_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssub_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vssub.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vssub_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssub_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssub_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vssub.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vssub_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssub_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssub_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vssub.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vssub_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssub_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssub_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vssub.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vssub_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssub_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssub_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vssub.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vssub_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssub_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssub_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vssub.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vssub_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssub_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssub_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vssub.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vssub_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssub_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssub_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vssub.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vssub_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssub_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssub_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vssub.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vssub_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssub_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssub_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vssub.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vssub_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssub_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssub_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vssub.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vssub_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssub_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssub_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vssub.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vssub_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssub_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssub_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vssub.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vssub_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssub_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssub_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vssub.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vssub_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssub_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssub_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vssub.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vssub_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssub_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssub_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vssub.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vssub_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssub_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssub_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vssub.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vssub_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssub_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssub_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vssub.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vssub_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssub_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssub_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vssub.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vssub_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssub_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssub_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vssub.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vssub_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssub_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssub_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vssub.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vssub_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssub_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssubu_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vssubu.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vssubu_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssubu_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssubu_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vssubu.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vssubu_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssubu_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssubu_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vssubu.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vssubu_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssubu_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssubu_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vssubu.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vssubu_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssubu_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssubu_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vssubu.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vssubu_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssubu_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssubu_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vssubu.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vssubu_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssubu_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssubu_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vssubu.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vssubu_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssubu_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssubu_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vssubu.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vssubu_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssubu_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssubu_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vssubu.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vssubu_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssubu_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssubu_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vssubu.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vssubu_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssubu_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssubu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vssubu.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vssubu_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssubu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssubu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vssubu.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vssubu_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssubu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssubu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vssubu.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vssubu_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssubu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssubu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vssubu.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vssubu_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssubu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssubu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vssubu.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vssubu_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssubu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssubu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vssubu.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vssubu_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssubu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssubu_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vssubu.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vssubu_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssubu_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssubu_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vssubu.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vssubu_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssubu_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssubu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vssubu.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vssubu_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssubu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssubu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vssubu.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vssubu_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssubu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssubu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vssubu.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vssubu_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssubu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssubu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vssubu.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vssubu_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssubu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssubu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vssubu.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vssubu_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssubu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssubu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vssubu.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vssubu_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssubu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv8i8(<vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_8xi8(signed char*  arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv4i16(<vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_4xi16(signed short int*  arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv2i32(<vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_2xi32(signed int*  arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv1i64(<vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_1xi64(signed long int*  arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 2 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv2f32(<vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_2xf32(float*  arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 1 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv1f64(<vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_1xf64(double*  arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv16i8(<vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_16xi8(signed char*  arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv8i16(<vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_8xi16(signed short int*  arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv4i32(<vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_4xi32(signed int*  arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv2i64(<vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_2xi64(signed long int*  arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 4 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv4f32(<vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_4xf32(float*  arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 2 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv2f64(<vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_2xf64(double*  arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv32i8(<vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_32xi8(signed char*  arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv16i16(<vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_16xi16(signed short int*  arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv8i32(<vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_8xi32(signed int*  arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv4i64(<vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_4xi64(signed long int*  arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 8 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv8f32(<vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_8xf32(float*  arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 4 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv4f64(<vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_4xf64(double*  arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_indexed_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8>* [[TMP0]], <vscale x 8 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_8xi8(signed char*  arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_8xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16>* [[TMP0]], <vscale x 4 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_4xi16(signed short int*  arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_4xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32>* [[TMP0]], <vscale x 2 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_2xi32(signed int*  arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_2xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64>* [[TMP0]], <vscale x 1 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_1xi64(signed long int*  arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_1xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 2 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv2f32.nxv2i32(<vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float>* [[TMP0]], <vscale x 2 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_2xf32(float*  arg_0, __epi_2xf32 arg_1, __epi_2xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_2xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 1 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv1f64.nxv1i64(<vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double>* [[TMP0]], <vscale x 1 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_1xf64(double*  arg_0, __epi_1xf64 arg_1, __epi_1xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_1xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8>* [[TMP0]], <vscale x 16 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_16xi8(signed char*  arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_16xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16>* [[TMP0]], <vscale x 8 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_8xi16(signed short int*  arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32>* [[TMP0]], <vscale x 4 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_4xi32(signed int*  arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64>* [[TMP0]], <vscale x 2 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_2xi64(signed long int*  arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 4 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv4f32.nxv4i32(<vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float>* [[TMP0]], <vscale x 4 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_4xf32(float*  arg_0, __epi_4xf32 arg_1, __epi_4xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_4xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 2 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv2f64.nxv2i64(<vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double>* [[TMP0]], <vscale x 2 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_2xf64(double*  arg_0, __epi_2xf64 arg_1, __epi_2xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_2xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8>* [[TMP0]], <vscale x 32 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_32xi8(signed char*  arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_32xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16>* [[TMP0]], <vscale x 16 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_16xi16(signed short int*  arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32>* [[TMP0]], <vscale x 8 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_8xi32(signed int*  arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64>* [[TMP0]], <vscale x 4 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_4xi64(signed long int*  arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 8 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv8f32.nxv8i32(<vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float>* [[TMP0]], <vscale x 8 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_8xf32(float*  arg_0, __epi_8xf32 arg_1, __epi_8xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_8xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 4 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv4f64.nxv4i64(<vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double>* [[TMP0]], <vscale x 4 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_4xf64(double*  arg_0, __epi_4xf64 arg_1, __epi_4xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_4xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8>* [[TMP0]], <vscale x 8 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_8xi8(unsigned char*  arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_unsigned_8xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16>* [[TMP0]], <vscale x 4 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_4xi16(unsigned short int*  arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_unsigned_4xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32>* [[TMP0]], <vscale x 2 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_2xi32(unsigned int*  arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_unsigned_2xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64>* [[TMP0]], <vscale x 1 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_1xi64(unsigned long int*  arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_unsigned_1xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8>* [[TMP0]], <vscale x 16 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_16xi8(unsigned char*  arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_unsigned_16xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16>* [[TMP0]], <vscale x 8 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_8xi16(unsigned short int*  arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_unsigned_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32>* [[TMP0]], <vscale x 4 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_4xi32(unsigned int*  arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_unsigned_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64>* [[TMP0]], <vscale x 2 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_2xi64(unsigned long int*  arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_unsigned_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8>* [[TMP0]], <vscale x 32 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_32xi8(unsigned char*  arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_unsigned_32xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16>* [[TMP0]], <vscale x 16 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_16xi16(unsigned short int*  arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_unsigned_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32>* [[TMP0]], <vscale x 8 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_8xi32(unsigned int*  arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_unsigned_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64>* [[TMP0]], <vscale x 4 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_4xi64(unsigned long int*  arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_unsigned_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_8xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i1>*
// CHECK-O2-NEXT:    store <vscale x 8 x i1> [[ARG_1:%.*]], <vscale x 8 x i1>* [[TMP0]], align 1
// CHECK-O2-NEXT:    ret void
//
void test_vstore_8xi1(unsigned char*  arg_0, __epi_8xi1 arg_1)
{
    return __builtin_epi_vstore_8xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vstore_4xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i1>*
// CHECK-O2-NEXT:    store <vscale x 4 x i1> [[ARG_1:%.*]], <vscale x 4 x i1>* [[TMP0]], align 2
// CHECK-O2-NEXT:    ret void
//
void test_vstore_4xi1(unsigned short int*  arg_0, __epi_4xi1 arg_1)
{
    return __builtin_epi_vstore_4xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vstore_2xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i1>*
// CHECK-O2-NEXT:    store <vscale x 2 x i1> [[ARG_1:%.*]], <vscale x 2 x i1>* [[TMP0]], align 4
// CHECK-O2-NEXT:    ret void
//
void test_vstore_2xi1(unsigned int*  arg_0, __epi_2xi1 arg_1)
{
    return __builtin_epi_vstore_2xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vstore_1xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i1>*
// CHECK-O2-NEXT:    store <vscale x 1 x i1> [[ARG_1:%.*]], <vscale x 1 x i1>* [[TMP0]], align 8
// CHECK-O2-NEXT:    ret void
//
void test_vstore_1xi1(unsigned long int*  arg_0, __epi_1xi1 arg_1)
{
    return __builtin_epi_vstore_1xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vstore_strided_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv8i8(<vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_8xi8(signed char*  arg_0, __epi_8xi8 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_8xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv4i16(<vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_4xi16(signed short int*  arg_0, __epi_4xi16 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_4xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv2i32(<vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_2xi32(signed int*  arg_0, __epi_2xi32 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_2xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv1i64(<vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_1xi64(signed long int*  arg_0, __epi_1xi64 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_1xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 2 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv2f32(<vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_2xf32(float*  arg_0, __epi_2xf32 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_2xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 1 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv1f64(<vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_1xf64(double*  arg_0, __epi_1xf64 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_1xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv16i8(<vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_16xi8(signed char*  arg_0, __epi_16xi8 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_16xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv8i16(<vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_8xi16(signed short int*  arg_0, __epi_8xi16 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv4i32(<vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_4xi32(signed int*  arg_0, __epi_4xi32 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv2i64(<vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_2xi64(signed long int*  arg_0, __epi_2xi64 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 4 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv4f32(<vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_4xf32(float*  arg_0, __epi_4xf32 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_4xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 2 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv2f64(<vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_2xf64(double*  arg_0, __epi_2xf64 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_2xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv32i8(<vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_32xi8(signed char*  arg_0, __epi_32xi8 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_32xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv16i16(<vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_16xi16(signed short int*  arg_0, __epi_16xi16 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv8i32(<vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_8xi32(signed int*  arg_0, __epi_8xi32 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv4i64(<vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_4xi64(signed long int*  arg_0, __epi_4xi64 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 8 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv8f32(<vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_8xf32(float*  arg_0, __epi_8xf32 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_8xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 4 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv4f64(<vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_4xf64(double*  arg_0, __epi_4xf64 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_4xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv8i8(<vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_8xi8(unsigned char*  arg_0, __epi_8xi8 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_unsigned_8xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv4i16(<vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_4xi16(unsigned short int*  arg_0, __epi_4xi16 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_unsigned_4xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv2i32(<vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_2xi32(unsigned int*  arg_0, __epi_2xi32 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_unsigned_2xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv1i64(<vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_1xi64(unsigned long int*  arg_0, __epi_1xi64 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_unsigned_1xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv16i8(<vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_16xi8(unsigned char*  arg_0, __epi_16xi8 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_unsigned_16xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv8i16(<vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_8xi16(unsigned short int*  arg_0, __epi_8xi16 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_unsigned_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv4i32(<vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_4xi32(unsigned int*  arg_0, __epi_4xi32 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_unsigned_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv2i64(<vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_2xi64(unsigned long int*  arg_0, __epi_2xi64 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_unsigned_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv32i8(<vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_32xi8(unsigned char*  arg_0, __epi_32xi8 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_unsigned_32xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv16i16(<vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_16xi16(unsigned short int*  arg_0, __epi_16xi16 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_unsigned_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv8i32(<vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_8xi32(unsigned int*  arg_0, __epi_8xi32 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_unsigned_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv4i64(<vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_4xi64(unsigned long int*  arg_0, __epi_4xi64 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_unsigned_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv8i8(<vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_8xi8(unsigned char*  arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_unsigned_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv4i16(<vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_4xi16(unsigned short int*  arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_unsigned_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv2i32(<vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_2xi32(unsigned int*  arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_unsigned_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv1i64(<vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_1xi64(unsigned long int*  arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_unsigned_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv16i8(<vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_16xi8(unsigned char*  arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_unsigned_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv8i16(<vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_8xi16(unsigned short int*  arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_unsigned_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv4i32(<vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_4xi32(unsigned int*  arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_unsigned_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv2i64(<vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_2xi64(unsigned long int*  arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_unsigned_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv32i8(<vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_32xi8(unsigned char*  arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_unsigned_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv16i16(<vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_16xi16(unsigned short int*  arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_unsigned_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv8i32(<vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_8xi32(unsigned int*  arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_unsigned_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv4i64(<vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_4xi64(unsigned long int*  arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_unsigned_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsub_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vsub.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vsub_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsub_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsub_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vsub.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vsub_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsub_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsub_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vsub.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vsub_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsub_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsub_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vsub.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vsub_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsub_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsub_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vsub.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vsub_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsub_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsub_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vsub.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vsub_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsub_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsub_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vsub.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vsub_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsub_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsub_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vsub.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vsub_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsub_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsub_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vsub.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vsub_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsub_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsub_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vsub.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vsub_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsub_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsub_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vsub.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vsub_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsub_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsub_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vsub.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vsub_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsub_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsub_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vsub.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vsub_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsub_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsub_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vsub.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vsub_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsub_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsub_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vsub.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vsub_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsub_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsub_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vsub.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vsub_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsub_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsub_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vsub.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vsub_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsub_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsub_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vsub.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vsub_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsub_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsub_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vsub.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vsub_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsub_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsub_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vsub.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vsub_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsub_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsub_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vsub.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vsub_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsub_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsub_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vsub.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vsub_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsub_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsub_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vsub.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vsub_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsub_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsub_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vsub.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vsub_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsub_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwadd_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwadd.nxv8i16.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwadd_8xi16(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwadd.mask.nxv8i16.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwadd_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwadd_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwadd.nxv4i32.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwadd_4xi32(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwadd.mask.nxv4i32.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwadd_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwadd_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwadd.nxv2i64.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwadd_2xi64(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwadd.mask.nxv2i64.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwadd_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwadd_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwadd.nxv16i16.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwadd_16xi16(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwadd.mask.nxv16i16.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwadd_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwadd_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwadd.nxv8i32.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwadd_8xi32(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwadd.mask.nxv8i32.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwadd_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwadd_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwadd.nxv4i64.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwadd_4xi64(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwadd.mask.nxv4i64.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwadd_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwadd_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwadd.nxv32i16.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwadd_32xi16(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_32xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwadd.mask.nxv32i16.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwadd_32xi16_mask(__epi_32xi16 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwadd_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwadd.nxv16i32.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwadd_16xi32(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_16xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwadd.mask.nxv16i32.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwadd_16xi32_mask(__epi_16xi32 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwadd_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwadd.nxv8i64.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwadd_8xi64(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_8xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwadd.mask.nxv8i64.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwadd_8xi64_mask(__epi_8xi64 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwadd_w_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwadd.w.nxv8i16.nxv8i8(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwadd_w_8xi16(__epi_8xi16 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_w_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_w_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwadd.w.mask.nxv8i16.nxv8i8.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwadd_w_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_w_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwadd_w_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwadd.w.nxv4i32.nxv4i16(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwadd_w_4xi32(__epi_4xi32 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_w_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_w_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwadd.w.mask.nxv4i32.nxv4i16.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwadd_w_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_w_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwadd_w_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwadd.w.nxv2i64.nxv2i32(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwadd_w_2xi64(__epi_2xi64 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_w_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_w_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwadd.w.mask.nxv2i64.nxv2i32.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwadd_w_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_w_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwadd_w_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwadd.w.nxv16i16.nxv16i8(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwadd_w_16xi16(__epi_16xi16 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_w_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_w_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwadd.w.mask.nxv16i16.nxv16i8.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwadd_w_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_w_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwadd_w_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwadd.w.nxv8i32.nxv8i16(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwadd_w_8xi32(__epi_8xi32 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_w_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_w_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwadd.w.mask.nxv8i32.nxv8i16.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwadd_w_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_w_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwadd_w_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwadd.w.nxv4i64.nxv4i32(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwadd_w_4xi64(__epi_4xi64 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_w_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_w_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwadd.w.mask.nxv4i64.nxv4i32.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwadd_w_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_w_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwadd_w_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwadd.w.nxv32i16.nxv32i8(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwadd_w_32xi16(__epi_32xi16 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_w_32xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_w_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwadd.w.mask.nxv32i16.nxv32i8.nxv32i1(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i16> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwadd_w_32xi16_mask(__epi_32xi16 arg_0, __epi_32xi16 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_w_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwadd_w_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwadd.w.nxv16i32.nxv16i16(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwadd_w_16xi32(__epi_16xi32 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_w_16xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_w_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwadd.w.mask.nxv16i32.nxv16i16.nxv16i1(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i32> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwadd_w_16xi32_mask(__epi_16xi32 arg_0, __epi_16xi32 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_w_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwadd_w_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwadd.w.nxv8i64.nxv8i32(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwadd_w_8xi64(__epi_8xi64 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_w_8xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_w_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwadd.w.mask.nxv8i64.nxv8i32.nxv8i1(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i64> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwadd_w_8xi64_mask(__epi_8xi64 arg_0, __epi_8xi64 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_w_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwaddu.nxv8i16.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwaddu_8xi16(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwaddu.mask.nxv8i16.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwaddu_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwaddu.nxv4i32.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwaddu_4xi32(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwaddu.mask.nxv4i32.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwaddu_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwaddu.nxv2i64.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwaddu_2xi64(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwaddu.mask.nxv2i64.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwaddu_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwaddu.nxv16i16.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwaddu_16xi16(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwaddu.mask.nxv16i16.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwaddu_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwaddu.nxv8i32.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwaddu_8xi32(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwaddu.mask.nxv8i32.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwaddu_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwaddu.nxv4i64.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwaddu_4xi64(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwaddu.mask.nxv4i64.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwaddu_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwaddu.nxv32i16.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwaddu_32xi16(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_32xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwaddu.mask.nxv32i16.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwaddu_32xi16_mask(__epi_32xi16 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwaddu.nxv16i32.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwaddu_16xi32(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_16xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwaddu.mask.nxv16i32.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwaddu_16xi32_mask(__epi_16xi32 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwaddu.nxv8i64.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwaddu_8xi64(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_8xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwaddu.mask.nxv8i64.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwaddu_8xi64_mask(__epi_8xi64 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_w_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwaddu.w.nxv8i16.nxv8i8(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwaddu_w_8xi16(__epi_8xi16 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_w_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_w_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwaddu.w.mask.nxv8i16.nxv8i8.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwaddu_w_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_w_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_w_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwaddu.w.nxv4i32.nxv4i16(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwaddu_w_4xi32(__epi_4xi32 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_w_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_w_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwaddu.w.mask.nxv4i32.nxv4i16.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwaddu_w_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_w_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_w_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwaddu.w.nxv2i64.nxv2i32(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwaddu_w_2xi64(__epi_2xi64 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_w_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_w_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwaddu.w.mask.nxv2i64.nxv2i32.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwaddu_w_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_w_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_w_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwaddu.w.nxv16i16.nxv16i8(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwaddu_w_16xi16(__epi_16xi16 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_w_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_w_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwaddu.w.mask.nxv16i16.nxv16i8.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwaddu_w_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_w_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_w_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwaddu.w.nxv8i32.nxv8i16(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwaddu_w_8xi32(__epi_8xi32 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_w_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_w_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwaddu.w.mask.nxv8i32.nxv8i16.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwaddu_w_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_w_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_w_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwaddu.w.nxv4i64.nxv4i32(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwaddu_w_4xi64(__epi_4xi64 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_w_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_w_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwaddu.w.mask.nxv4i64.nxv4i32.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwaddu_w_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_w_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_w_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwaddu.w.nxv32i16.nxv32i8(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwaddu_w_32xi16(__epi_32xi16 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_w_32xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_w_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwaddu.w.mask.nxv32i16.nxv32i8.nxv32i1(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i16> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwaddu_w_32xi16_mask(__epi_32xi16 arg_0, __epi_32xi16 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_w_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_w_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwaddu.w.nxv16i32.nxv16i16(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwaddu_w_16xi32(__epi_16xi32 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_w_16xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_w_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwaddu.w.mask.nxv16i32.nxv16i16.nxv16i1(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i32> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwaddu_w_16xi32_mask(__epi_16xi32 arg_0, __epi_16xi32 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_w_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_w_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwaddu.w.nxv8i64.nxv8i32(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwaddu_w_8xi64(__epi_8xi64 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_w_8xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_w_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwaddu.w.mask.nxv8i64.nxv8i32.nxv8i1(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i64> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwaddu_w_8xi64_mask(__epi_8xi64 arg_0, __epi_8xi64 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_w_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmacc_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwmacc.nxv8i16.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwmacc_8xi16(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmacc_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmacc_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwmacc.mask.nxv8i16.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwmacc_8xi16_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmacc_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmacc_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwmacc.nxv4i32.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwmacc_4xi32(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmacc_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmacc_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwmacc.mask.nxv4i32.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwmacc_4xi32_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmacc_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmacc_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwmacc.nxv2i64.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwmacc_2xi64(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmacc_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmacc_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwmacc.mask.nxv2i64.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwmacc_2xi64_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmacc_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmacc_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwmacc.nxv16i16.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwmacc_16xi16(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmacc_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmacc_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwmacc.mask.nxv16i16.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwmacc_16xi16_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmacc_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmacc_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwmacc.nxv8i32.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwmacc_8xi32(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmacc_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmacc_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwmacc.mask.nxv8i32.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwmacc_8xi32_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmacc_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmacc_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwmacc.nxv4i64.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwmacc_4xi64(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmacc_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmacc_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwmacc.mask.nxv4i64.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwmacc_4xi64_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmacc_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmacc_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwmacc.nxv32i16.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwmacc_32xi16(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmacc_32xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmacc_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwmacc.mask.nxv32i16.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i16> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwmacc_32xi16_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi16 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmacc_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmacc_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwmacc.nxv16i32.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwmacc_16xi32(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmacc_16xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmacc_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwmacc.mask.nxv16i32.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i32> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwmacc_16xi32_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi32 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmacc_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmacc_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwmacc.nxv8i64.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwmacc_8xi64(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmacc_8xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmacc_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwmacc.mask.nxv8i64.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i64> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwmacc_8xi64_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi64 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmacc_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmaccu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwmaccu.nxv8i16.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwmaccu_8xi16(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmaccu_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmaccu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwmaccu.mask.nxv8i16.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwmaccu_8xi16_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmaccu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmaccu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwmaccu.nxv4i32.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwmaccu_4xi32(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmaccu_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmaccu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwmaccu.mask.nxv4i32.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwmaccu_4xi32_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmaccu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmaccu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwmaccu.nxv2i64.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwmaccu_2xi64(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmaccu_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmaccu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwmaccu.mask.nxv2i64.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwmaccu_2xi64_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmaccu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmaccu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwmaccu.nxv16i16.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwmaccu_16xi16(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmaccu_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmaccu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwmaccu.mask.nxv16i16.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwmaccu_16xi16_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmaccu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmaccu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwmaccu.nxv8i32.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwmaccu_8xi32(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmaccu_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmaccu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwmaccu.mask.nxv8i32.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwmaccu_8xi32_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmaccu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmaccu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwmaccu.nxv4i64.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwmaccu_4xi64(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmaccu_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmaccu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwmaccu.mask.nxv4i64.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwmaccu_4xi64_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmaccu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmaccu_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwmaccu.nxv32i16.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwmaccu_32xi16(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmaccu_32xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmaccu_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwmaccu.mask.nxv32i16.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i16> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwmaccu_32xi16_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi16 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmaccu_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmaccu_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwmaccu.nxv16i32.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwmaccu_16xi32(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmaccu_16xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmaccu_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwmaccu.mask.nxv16i32.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i32> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwmaccu_16xi32_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi32 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmaccu_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmaccu_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwmaccu.nxv8i64.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwmaccu_8xi64(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmaccu_8xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmaccu_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwmaccu.mask.nxv8i64.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i64> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwmaccu_8xi64_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi64 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmaccu_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsac_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwmsac.nxv8i16.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwmsac_8xi16(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsac_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsac_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwmsac.mask.nxv8i16.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwmsac_8xi16_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsac_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsac_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwmsac.nxv4i32.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwmsac_4xi32(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsac_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsac_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwmsac.mask.nxv4i32.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwmsac_4xi32_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsac_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsac_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwmsac.nxv2i64.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwmsac_2xi64(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsac_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsac_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwmsac.mask.nxv2i64.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwmsac_2xi64_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsac_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsac_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwmsac.nxv16i16.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwmsac_16xi16(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsac_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsac_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwmsac.mask.nxv16i16.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwmsac_16xi16_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsac_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsac_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwmsac.nxv8i32.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwmsac_8xi32(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsac_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsac_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwmsac.mask.nxv8i32.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwmsac_8xi32_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsac_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsac_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwmsac.nxv4i64.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwmsac_4xi64(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsac_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsac_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwmsac.mask.nxv4i64.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwmsac_4xi64_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsac_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsac_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwmsac.nxv32i16.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwmsac_32xi16(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsac_32xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsac_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwmsac.mask.nxv32i16.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i16> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwmsac_32xi16_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi16 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsac_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsac_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwmsac.nxv16i32.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwmsac_16xi32(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsac_16xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsac_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwmsac.mask.nxv16i32.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i32> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwmsac_16xi32_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi32 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsac_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsac_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwmsac.nxv8i64.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwmsac_8xi64(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsac_8xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsac_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwmsac.mask.nxv8i64.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i64> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwmsac_8xi64_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi64 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsac_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsacu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwmsacu.nxv8i16.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwmsacu_8xi16(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsacu_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsacu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwmsacu.mask.nxv8i16.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwmsacu_8xi16_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsacu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsacu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwmsacu.nxv4i32.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwmsacu_4xi32(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsacu_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsacu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwmsacu.mask.nxv4i32.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwmsacu_4xi32_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsacu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsacu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwmsacu.nxv2i64.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwmsacu_2xi64(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsacu_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsacu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwmsacu.mask.nxv2i64.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwmsacu_2xi64_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsacu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsacu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwmsacu.nxv16i16.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwmsacu_16xi16(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsacu_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsacu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwmsacu.mask.nxv16i16.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwmsacu_16xi16_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsacu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsacu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwmsacu.nxv8i32.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwmsacu_8xi32(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsacu_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsacu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwmsacu.mask.nxv8i32.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwmsacu_8xi32_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsacu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsacu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwmsacu.nxv4i64.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwmsacu_4xi64(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsacu_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsacu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwmsacu.mask.nxv4i64.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwmsacu_4xi64_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsacu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsacu_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwmsacu.nxv32i16.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwmsacu_32xi16(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsacu_32xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsacu_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwmsacu.mask.nxv32i16.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i16> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwmsacu_32xi16_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi16 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsacu_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsacu_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwmsacu.nxv16i32.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwmsacu_16xi32(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsacu_16xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsacu_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwmsacu.mask.nxv16i32.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i32> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwmsacu_16xi32_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi32 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsacu_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsacu_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwmsacu.nxv8i64.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwmsacu_8xi64(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsacu_8xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsacu_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwmsacu.mask.nxv8i64.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i64> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwmsacu_8xi64_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi64 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsacu_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmul_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwmul.nxv8i16.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwmul_8xi16(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmul_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmul_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwmul.mask.nxv8i16.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwmul_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmul_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmul_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwmul.nxv4i32.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwmul_4xi32(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmul_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmul_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwmul.mask.nxv4i32.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwmul_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmul_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmul_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwmul.nxv2i64.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwmul_2xi64(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmul_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmul_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwmul.mask.nxv2i64.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwmul_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmul_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmul_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwmul.nxv16i16.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwmul_16xi16(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmul_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmul_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwmul.mask.nxv16i16.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwmul_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmul_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmul_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwmul.nxv8i32.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwmul_8xi32(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmul_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmul_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwmul.mask.nxv8i32.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwmul_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmul_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmul_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwmul.nxv4i64.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwmul_4xi64(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmul_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmul_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwmul.mask.nxv4i64.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwmul_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmul_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmul_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwmul.nxv32i16.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwmul_32xi16(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmul_32xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmul_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwmul.mask.nxv32i16.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwmul_32xi16_mask(__epi_32xi16 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmul_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmul_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwmul.nxv16i32.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwmul_16xi32(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmul_16xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmul_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwmul.mask.nxv16i32.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwmul_16xi32_mask(__epi_16xi32 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmul_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmul_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwmul.nxv8i64.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwmul_8xi64(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmul_8xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmul_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwmul.mask.nxv8i64.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwmul_8xi64_mask(__epi_8xi64 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmul_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulsu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwmulsu.nxv8i16.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwmulsu_8xi16(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulsu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulsu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwmulsu.mask.nxv8i16.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwmulsu_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulsu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulsu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwmulsu.nxv4i32.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwmulsu_4xi32(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulsu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulsu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwmulsu.mask.nxv4i32.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwmulsu_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulsu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulsu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwmulsu.nxv2i64.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwmulsu_2xi64(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulsu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulsu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwmulsu.mask.nxv2i64.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwmulsu_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulsu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulsu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwmulsu.nxv16i16.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwmulsu_16xi16(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulsu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulsu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwmulsu.mask.nxv16i16.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwmulsu_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulsu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulsu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwmulsu.nxv8i32.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwmulsu_8xi32(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulsu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulsu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwmulsu.mask.nxv8i32.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwmulsu_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulsu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulsu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwmulsu.nxv4i64.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwmulsu_4xi64(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulsu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulsu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwmulsu.mask.nxv4i64.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwmulsu_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulsu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulsu_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwmulsu.nxv32i16.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwmulsu_32xi16(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulsu_32xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulsu_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwmulsu.mask.nxv32i16.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwmulsu_32xi16_mask(__epi_32xi16 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulsu_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulsu_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwmulsu.nxv16i32.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwmulsu_16xi32(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulsu_16xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulsu_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwmulsu.mask.nxv16i32.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwmulsu_16xi32_mask(__epi_16xi32 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulsu_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulsu_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwmulsu.nxv8i64.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwmulsu_8xi64(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulsu_8xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulsu_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwmulsu.mask.nxv8i64.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwmulsu_8xi64_mask(__epi_8xi64 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulsu_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwmulu.nxv8i16.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwmulu_8xi16(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwmulu.mask.nxv8i16.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwmulu_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwmulu.nxv4i32.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwmulu_4xi32(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwmulu.mask.nxv4i32.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwmulu_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwmulu.nxv2i64.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwmulu_2xi64(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwmulu.mask.nxv2i64.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwmulu_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwmulu.nxv16i16.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwmulu_16xi16(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwmulu.mask.nxv16i16.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwmulu_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwmulu.nxv8i32.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwmulu_8xi32(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwmulu.mask.nxv8i32.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwmulu_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwmulu.nxv4i64.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwmulu_4xi64(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwmulu.mask.nxv4i64.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwmulu_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulu_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwmulu.nxv32i16.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwmulu_32xi16(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulu_32xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulu_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwmulu.mask.nxv32i16.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwmulu_32xi16_mask(__epi_32xi16 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulu_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulu_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwmulu.nxv16i32.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwmulu_16xi32(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulu_16xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulu_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwmulu.mask.nxv16i32.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwmulu_16xi32_mask(__epi_16xi32 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulu_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulu_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwmulu.nxv8i64.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwmulu_8xi64(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulu_8xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulu_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwmulu.mask.nxv8i64.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwmulu_8xi64_mask(__epi_8xi64 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulu_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmacc_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwsmacc.nxv8i16.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwsmacc_8xi16(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmacc_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmacc_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwsmacc.mask.nxv8i16.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwsmacc_8xi16_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmacc_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmacc_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwsmacc.nxv4i32.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwsmacc_4xi32(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmacc_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmacc_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwsmacc.mask.nxv4i32.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwsmacc_4xi32_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmacc_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmacc_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwsmacc.nxv2i64.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwsmacc_2xi64(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmacc_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmacc_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwsmacc.mask.nxv2i64.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwsmacc_2xi64_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmacc_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmacc_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwsmacc.nxv16i16.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwsmacc_16xi16(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmacc_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmacc_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwsmacc.mask.nxv16i16.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwsmacc_16xi16_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmacc_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmacc_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwsmacc.nxv8i32.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwsmacc_8xi32(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmacc_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmacc_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwsmacc.mask.nxv8i32.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwsmacc_8xi32_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmacc_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmacc_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwsmacc.nxv4i64.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwsmacc_4xi64(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmacc_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmacc_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwsmacc.mask.nxv4i64.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwsmacc_4xi64_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmacc_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmacc_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwsmacc.nxv32i16.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwsmacc_32xi16(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmacc_32xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmacc_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwsmacc.mask.nxv32i16.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i16> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwsmacc_32xi16_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi16 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmacc_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmacc_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwsmacc.nxv16i32.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwsmacc_16xi32(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmacc_16xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmacc_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwsmacc.mask.nxv16i32.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i32> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwsmacc_16xi32_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi32 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmacc_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmacc_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwsmacc.nxv8i64.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwsmacc_8xi64(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmacc_8xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmacc_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwsmacc.mask.nxv8i64.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i64> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwsmacc_8xi64_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi64 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmacc_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmaccu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwsmaccu.nxv8i16.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwsmaccu_8xi16(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmaccu_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmaccu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwsmaccu.mask.nxv8i16.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwsmaccu_8xi16_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmaccu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmaccu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwsmaccu.nxv4i32.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwsmaccu_4xi32(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmaccu_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmaccu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwsmaccu.mask.nxv4i32.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwsmaccu_4xi32_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmaccu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmaccu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwsmaccu.nxv2i64.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwsmaccu_2xi64(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmaccu_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmaccu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwsmaccu.mask.nxv2i64.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwsmaccu_2xi64_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmaccu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmaccu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwsmaccu.nxv16i16.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwsmaccu_16xi16(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmaccu_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmaccu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwsmaccu.mask.nxv16i16.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwsmaccu_16xi16_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmaccu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmaccu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwsmaccu.nxv8i32.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwsmaccu_8xi32(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmaccu_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmaccu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwsmaccu.mask.nxv8i32.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwsmaccu_8xi32_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmaccu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmaccu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwsmaccu.nxv4i64.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwsmaccu_4xi64(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmaccu_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmaccu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwsmaccu.mask.nxv4i64.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwsmaccu_4xi64_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmaccu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmaccu_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwsmaccu.nxv32i16.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwsmaccu_32xi16(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmaccu_32xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmaccu_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwsmaccu.mask.nxv32i16.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i16> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwsmaccu_32xi16_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi16 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmaccu_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmaccu_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwsmaccu.nxv16i32.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwsmaccu_16xi32(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmaccu_16xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmaccu_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwsmaccu.mask.nxv16i32.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i32> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwsmaccu_16xi32_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi32 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmaccu_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmaccu_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwsmaccu.nxv8i64.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwsmaccu_8xi64(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmaccu_8xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmaccu_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwsmaccu.mask.nxv8i64.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i64> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwsmaccu_8xi64_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi64 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmaccu_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsac_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwsmsac.nxv8i16.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwsmsac_8xi16(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsac_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsac_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwsmsac.mask.nxv8i16.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwsmsac_8xi16_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsac_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsac_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwsmsac.nxv4i32.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwsmsac_4xi32(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsac_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsac_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwsmsac.mask.nxv4i32.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwsmsac_4xi32_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsac_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsac_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwsmsac.nxv2i64.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwsmsac_2xi64(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsac_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsac_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwsmsac.mask.nxv2i64.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwsmsac_2xi64_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsac_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsac_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwsmsac.nxv16i16.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwsmsac_16xi16(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsac_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsac_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwsmsac.mask.nxv16i16.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwsmsac_16xi16_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsac_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsac_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwsmsac.nxv8i32.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwsmsac_8xi32(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsac_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsac_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwsmsac.mask.nxv8i32.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwsmsac_8xi32_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsac_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsac_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwsmsac.nxv4i64.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwsmsac_4xi64(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsac_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsac_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwsmsac.mask.nxv4i64.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwsmsac_4xi64_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsac_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsac_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwsmsac.nxv32i16.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwsmsac_32xi16(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsac_32xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsac_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwsmsac.mask.nxv32i16.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i16> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwsmsac_32xi16_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi16 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsac_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsac_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwsmsac.nxv16i32.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwsmsac_16xi32(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsac_16xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsac_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwsmsac.mask.nxv16i32.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i32> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwsmsac_16xi32_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi32 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsac_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsac_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwsmsac.nxv8i64.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwsmsac_8xi64(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsac_8xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsac_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwsmsac.mask.nxv8i64.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i64> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwsmsac_8xi64_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi64 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsac_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsacu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwsmsacu.nxv8i16.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwsmsacu_8xi16(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsacu_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsacu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwsmsacu.mask.nxv8i16.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwsmsacu_8xi16_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsacu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsacu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwsmsacu.nxv4i32.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwsmsacu_4xi32(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsacu_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsacu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwsmsacu.mask.nxv4i32.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwsmsacu_4xi32_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsacu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsacu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwsmsacu.nxv2i64.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwsmsacu_2xi64(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsacu_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsacu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwsmsacu.mask.nxv2i64.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwsmsacu_2xi64_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsacu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsacu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwsmsacu.nxv16i16.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwsmsacu_16xi16(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsacu_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsacu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwsmsacu.mask.nxv16i16.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwsmsacu_16xi16_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsacu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsacu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwsmsacu.nxv8i32.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwsmsacu_8xi32(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsacu_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsacu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwsmsacu.mask.nxv8i32.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwsmsacu_8xi32_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsacu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsacu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwsmsacu.nxv4i64.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwsmsacu_4xi64(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsacu_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsacu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwsmsacu.mask.nxv4i64.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwsmsacu_4xi64_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsacu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsacu_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwsmsacu.nxv32i16.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwsmsacu_32xi16(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsacu_32xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsacu_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwsmsacu.mask.nxv32i16.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i16> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwsmsacu_32xi16_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi16 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsacu_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsacu_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwsmsacu.nxv16i32.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwsmsacu_16xi32(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsacu_16xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsacu_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwsmsacu.mask.nxv16i32.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i32> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwsmsacu_16xi32_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi32 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsacu_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsacu_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwsmsacu.nxv8i64.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwsmsacu_8xi64(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsacu_8xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsacu_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwsmsacu.mask.nxv8i64.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i64> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwsmsacu_8xi64_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi64 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsacu_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwsub.nxv8i16.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwsub_8xi16(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwsub.mask.nxv8i16.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwsub_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwsub.nxv4i32.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwsub_4xi32(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwsub.mask.nxv4i32.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwsub_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwsub.nxv2i64.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwsub_2xi64(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwsub.mask.nxv2i64.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwsub_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwsub.nxv16i16.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwsub_16xi16(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwsub.mask.nxv16i16.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwsub_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwsub.nxv8i32.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwsub_8xi32(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwsub.mask.nxv8i32.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwsub_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwsub.nxv4i64.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwsub_4xi64(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwsub.mask.nxv4i64.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwsub_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwsub.nxv32i16.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwsub_32xi16(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_32xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwsub.mask.nxv32i16.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwsub_32xi16_mask(__epi_32xi16 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwsub.nxv16i32.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwsub_16xi32(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_16xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwsub.mask.nxv16i32.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwsub_16xi32_mask(__epi_16xi32 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwsub.nxv8i64.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwsub_8xi64(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_8xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwsub.mask.nxv8i64.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwsub_8xi64_mask(__epi_8xi64 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_w_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwsub.w.nxv8i16.nxv8i8(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwsub_w_8xi16(__epi_8xi16 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_w_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_w_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwsub.w.mask.nxv8i16.nxv8i8.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwsub_w_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_w_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_w_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwsub.w.nxv4i32.nxv4i16(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwsub_w_4xi32(__epi_4xi32 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_w_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_w_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwsub.w.mask.nxv4i32.nxv4i16.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwsub_w_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_w_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_w_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwsub.w.nxv2i64.nxv2i32(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwsub_w_2xi64(__epi_2xi64 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_w_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_w_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwsub.w.mask.nxv2i64.nxv2i32.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwsub_w_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_w_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_w_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwsub.w.nxv16i16.nxv16i8(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwsub_w_16xi16(__epi_16xi16 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_w_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_w_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwsub.w.mask.nxv16i16.nxv16i8.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwsub_w_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_w_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_w_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwsub.w.nxv8i32.nxv8i16(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwsub_w_8xi32(__epi_8xi32 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_w_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_w_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwsub.w.mask.nxv8i32.nxv8i16.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwsub_w_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_w_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_w_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwsub.w.nxv4i64.nxv4i32(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwsub_w_4xi64(__epi_4xi64 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_w_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_w_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwsub.w.mask.nxv4i64.nxv4i32.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwsub_w_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_w_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_w_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwsub.w.nxv32i16.nxv32i8(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwsub_w_32xi16(__epi_32xi16 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_w_32xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_w_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwsub.w.mask.nxv32i16.nxv32i8.nxv32i1(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i16> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwsub_w_32xi16_mask(__epi_32xi16 arg_0, __epi_32xi16 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_w_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_w_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwsub.w.nxv16i32.nxv16i16(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwsub_w_16xi32(__epi_16xi32 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_w_16xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_w_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwsub.w.mask.nxv16i32.nxv16i16.nxv16i1(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i32> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwsub_w_16xi32_mask(__epi_16xi32 arg_0, __epi_16xi32 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_w_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_w_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwsub.w.nxv8i64.nxv8i32(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwsub_w_8xi64(__epi_8xi64 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_w_8xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_w_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwsub.w.mask.nxv8i64.nxv8i32.nxv8i1(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i64> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwsub_w_8xi64_mask(__epi_8xi64 arg_0, __epi_8xi64 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_w_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwsubu.nxv8i16.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwsubu_8xi16(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwsubu.mask.nxv8i16.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwsubu_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwsubu.nxv4i32.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwsubu_4xi32(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwsubu.mask.nxv4i32.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwsubu_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwsubu.nxv2i64.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwsubu_2xi64(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwsubu.mask.nxv2i64.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwsubu_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwsubu.nxv16i16.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwsubu_16xi16(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwsubu.mask.nxv16i16.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwsubu_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwsubu.nxv8i32.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwsubu_8xi32(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwsubu.mask.nxv8i32.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwsubu_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwsubu.nxv4i64.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwsubu_4xi64(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwsubu.mask.nxv4i64.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwsubu_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwsubu.nxv32i16.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwsubu_32xi16(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_32xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwsubu.mask.nxv32i16.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwsubu_32xi16_mask(__epi_32xi16 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwsubu.nxv16i32.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwsubu_16xi32(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_16xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwsubu.mask.nxv16i32.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwsubu_16xi32_mask(__epi_16xi32 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwsubu.nxv8i64.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwsubu_8xi64(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_8xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwsubu.mask.nxv8i64.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwsubu_8xi64_mask(__epi_8xi64 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_w_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwsubu.w.nxv8i16.nxv8i8(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwsubu_w_8xi16(__epi_8xi16 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_w_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_w_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwsubu.w.mask.nxv8i16.nxv8i8.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwsubu_w_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_w_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_w_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwsubu.w.nxv4i32.nxv4i16(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwsubu_w_4xi32(__epi_4xi32 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_w_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_w_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwsubu.w.mask.nxv4i32.nxv4i16.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwsubu_w_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_w_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_w_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwsubu.w.nxv2i64.nxv2i32(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwsubu_w_2xi64(__epi_2xi64 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_w_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_w_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwsubu.w.mask.nxv2i64.nxv2i32.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwsubu_w_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_w_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_w_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwsubu.w.nxv16i16.nxv16i8(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwsubu_w_16xi16(__epi_16xi16 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_w_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_w_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwsubu.w.mask.nxv16i16.nxv16i8.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwsubu_w_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_w_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_w_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwsubu.w.nxv8i32.nxv8i16(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwsubu_w_8xi32(__epi_8xi32 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_w_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_w_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwsubu.w.mask.nxv8i32.nxv8i16.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwsubu_w_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_w_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_w_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwsubu.w.nxv4i64.nxv4i32(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwsubu_w_4xi64(__epi_4xi64 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_w_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_w_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwsubu.w.mask.nxv4i64.nxv4i32.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwsubu_w_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_w_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_w_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwsubu.w.nxv32i16.nxv32i8(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwsubu_w_32xi16(__epi_32xi16 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_w_32xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_w_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwsubu.w.mask.nxv32i16.nxv32i8.nxv32i1(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i16> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwsubu_w_32xi16_mask(__epi_32xi16 arg_0, __epi_32xi16 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_w_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_w_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwsubu.w.nxv16i32.nxv16i16(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwsubu_w_16xi32(__epi_16xi32 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_w_16xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_w_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwsubu.w.mask.nxv16i32.nxv16i16.nxv16i1(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i32> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwsubu_w_16xi32_mask(__epi_16xi32 arg_0, __epi_16xi32 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_w_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_w_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwsubu.w.nxv8i64.nxv8i32(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwsubu_w_8xi64(__epi_8xi64 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_w_8xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_w_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwsubu.w.mask.nxv8i64.nxv8i32.nxv8i1(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i64> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwsubu_w_8xi64_mask(__epi_8xi64 arg_0, __epi_8xi64 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_w_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vxor_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vxor.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vxor_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vxor_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vxor_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vxor.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vxor_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vxor_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vxor_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vxor.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vxor_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vxor_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vxor_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vxor.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vxor_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vxor_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vxor_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vxor.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vxor_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vxor_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vxor_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vxor.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vxor_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vxor_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vxor_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vxor.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vxor_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vxor_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vxor_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vxor.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vxor_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vxor_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vxor_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vxor.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vxor_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vxor_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vxor_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vxor.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vxor_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vxor_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vxor_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vxor.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vxor_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vxor_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vxor_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vxor.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vxor_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vxor_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vxor_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vxor.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vxor_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vxor_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vxor_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vxor.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vxor_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vxor_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vxor_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vxor.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vxor_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vxor_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vxor_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vxor.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vxor_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vxor_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vxor_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vxor.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vxor_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vxor_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vxor_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vxor.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vxor_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vxor_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vxor_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vxor.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vxor_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vxor_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vxor_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vxor.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vxor_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vxor_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vxor_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vxor.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vxor_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vxor_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vxor_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vxor.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vxor_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vxor_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vxor_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vxor.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vxor_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vxor_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vxor_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vxor.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vxor_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vxor_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

