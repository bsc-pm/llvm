// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --include-generated-funcs
// REQUIRES: x86-registered-target
// RUN: %clang_cc1 -triple x86_64 -verify -fompss-2 -disable-llvm-passes -ferror-limit 100 %s -S -emit-llvm -o - | FileCheck %s
// expected-no-diagnostics
int y = 0;
int &ry = y;

extern int &rz;

int main() {
  int x = 0;
  int &rx = x;
  #pragma oss task depend(in : x, rx)
  { rx++; x++; }
  #pragma oss task depend(in : y, ry)
  { ry++; y++; }
  #pragma oss task depend(in : rz)
  { rz++; }
}









void foo1(int &ri) {
  #pragma oss task depend(in: ri)
  { ri++; }
}



struct S {
  static int &srx;
};
void foo2() {
  #pragma oss task depend(in: S::srx)
  { S::srx = 3; }
  static int &rx = y;
  #pragma oss task depend(in: rx)
  { rx = 3; }
  #pragma oss task
  {
      int x;
      extern int &rex;
      static int &rsx = x;
      rex = rsx;
  }
}






void foo3(bool b) {
    #pragma oss task in(b)
    {}
}

// CHECK-LABEL: @main(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[X:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[RX:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    store i32 0, ptr [[X]], align 4, !dbg [[DBG9:![0-9]+]]
// CHECK-NEXT:    store ptr [[X]], ptr [[RX]], align 8, !dbg [[DBG10:![0-9]+]]
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[RX]], align 8, !dbg [[DBG11:![0-9]+]]
// CHECK-NEXT:    [[TMP1:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OSS"([5 x i8] c"TASK\00"), "QUAL.OSS.SHARED"(ptr [[X]], i32 undef), "QUAL.OSS.SHARED"(ptr [[TMP0]], i32 undef), "QUAL.OSS.DEP.IN"(ptr [[X]], [2 x i8] c"x\00", ptr @compute_dep, ptr [[X]]), "QUAL.OSS.DEP.IN"(ptr [[TMP0]], [3 x i8] c"rx\00", ptr @compute_dep.1, ptr [[TMP0]]) ], !dbg [[DBG11]]
// CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4, !dbg [[DBG12:![0-9]+]]
// CHECK-NEXT:    [[INC:%.*]] = add nsw i32 [[TMP2]], 1, !dbg [[DBG12]]
// CHECK-NEXT:    store i32 [[INC]], ptr [[TMP0]], align 4, !dbg [[DBG12]]
// CHECK-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 4, !dbg [[DBG13:![0-9]+]]
// CHECK-NEXT:    [[INC1:%.*]] = add nsw i32 [[TMP3]], 1, !dbg [[DBG13]]
// CHECK-NEXT:    store i32 [[INC1]], ptr [[X]], align 4, !dbg [[DBG13]]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP1]]), !dbg [[DBG14:![0-9]+]]
// CHECK-NEXT:    [[TMP4:%.*]] = load ptr, ptr @ry, align 8, !dbg [[DBG15:![0-9]+]]
// CHECK-NEXT:    [[TMP5:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OSS"([5 x i8] c"TASK\00"), "QUAL.OSS.SHARED"(ptr @y, i32 undef), "QUAL.OSS.SHARED"(ptr [[TMP4]], i32 undef), "QUAL.OSS.DEP.IN"(ptr @y, [2 x i8] c"y\00", ptr @compute_dep.2, ptr @y), "QUAL.OSS.DEP.IN"(ptr [[TMP4]], [3 x i8] c"ry\00", ptr @compute_dep.3, ptr [[TMP4]]) ], !dbg [[DBG15]]
// CHECK-NEXT:    [[TMP6:%.*]] = load i32, ptr [[TMP4]], align 4, !dbg [[DBG16:![0-9]+]]
// CHECK-NEXT:    [[INC2:%.*]] = add nsw i32 [[TMP6]], 1, !dbg [[DBG16]]
// CHECK-NEXT:    store i32 [[INC2]], ptr [[TMP4]], align 4, !dbg [[DBG16]]
// CHECK-NEXT:    [[TMP7:%.*]] = load i32, ptr @y, align 4, !dbg [[DBG17:![0-9]+]]
// CHECK-NEXT:    [[INC3:%.*]] = add nsw i32 [[TMP7]], 1, !dbg [[DBG17]]
// CHECK-NEXT:    store i32 [[INC3]], ptr @y, align 4, !dbg [[DBG17]]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP5]]), !dbg [[DBG18:![0-9]+]]
// CHECK-NEXT:    [[TMP8:%.*]] = load ptr, ptr @rz, align 8, !dbg [[DBG19:![0-9]+]]
// CHECK-NEXT:    [[TMP9:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OSS"([5 x i8] c"TASK\00"), "QUAL.OSS.SHARED"(ptr [[TMP8]], i32 undef), "QUAL.OSS.DEP.IN"(ptr [[TMP8]], [3 x i8] c"rz\00", ptr @compute_dep.4, ptr [[TMP8]]) ], !dbg [[DBG19]]
// CHECK-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 4, !dbg [[DBG20:![0-9]+]]
// CHECK-NEXT:    [[INC4:%.*]] = add nsw i32 [[TMP10]], 1, !dbg [[DBG20]]
// CHECK-NEXT:    store i32 [[INC4]], ptr [[TMP8]], align 4, !dbg [[DBG20]]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP9]]), !dbg [[DBG21:![0-9]+]]
// CHECK-NEXT:    ret i32 0, !dbg [[DBG22:![0-9]+]]
//
//
// CHECK-LABEL: @compute_dep(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T:%.*]], align 8
// CHECK-NEXT:    [[X_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    store ptr [[X:%.*]], ptr [[X_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[X]], ptr [[TMP0]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 1
// CHECK-NEXT:    store i64 4, ptr [[TMP1]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 2
// CHECK-NEXT:    store i64 0, ptr [[TMP2]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 3
// CHECK-NEXT:    store i64 4, ptr [[TMP3]], align 8
// CHECK-NEXT:    [[TMP4:%.*]] = load [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], align 8
// CHECK-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T]] [[TMP4]]
//
//
// CHECK-LABEL: @compute_dep.1(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T_0:%.*]], align 8
// CHECK-NEXT:    [[RX_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    store ptr [[RX:%.*]], ptr [[RX_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[RX]], ptr [[TMP0]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 1
// CHECK-NEXT:    store i64 4, ptr [[TMP1]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 2
// CHECK-NEXT:    store i64 0, ptr [[TMP2]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 3
// CHECK-NEXT:    store i64 4, ptr [[TMP3]], align 8
// CHECK-NEXT:    [[TMP4:%.*]] = load [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], align 8
// CHECK-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T_0]] [[TMP4]]
//
//
// CHECK-LABEL: @compute_dep.2(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T_1:%.*]], align 8
// CHECK-NEXT:    [[Y_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    store ptr [[Y:%.*]], ptr [[Y_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_1]], ptr [[RETVAL]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[Y]], ptr [[TMP0]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_1]], ptr [[RETVAL]], i32 0, i32 1
// CHECK-NEXT:    store i64 4, ptr [[TMP1]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_1]], ptr [[RETVAL]], i32 0, i32 2
// CHECK-NEXT:    store i64 0, ptr [[TMP2]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_1]], ptr [[RETVAL]], i32 0, i32 3
// CHECK-NEXT:    store i64 4, ptr [[TMP3]], align 8
// CHECK-NEXT:    [[TMP4:%.*]] = load [[STRUCT__DEPEND_UNPACK_T_1]], ptr [[RETVAL]], align 8
// CHECK-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T_1]] [[TMP4]]
//
//
// CHECK-LABEL: @compute_dep.3(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T_2:%.*]], align 8
// CHECK-NEXT:    [[RY_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    store ptr [[RY:%.*]], ptr [[RY_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_2]], ptr [[RETVAL]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[RY]], ptr [[TMP0]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_2]], ptr [[RETVAL]], i32 0, i32 1
// CHECK-NEXT:    store i64 4, ptr [[TMP1]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_2]], ptr [[RETVAL]], i32 0, i32 2
// CHECK-NEXT:    store i64 0, ptr [[TMP2]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_2]], ptr [[RETVAL]], i32 0, i32 3
// CHECK-NEXT:    store i64 4, ptr [[TMP3]], align 8
// CHECK-NEXT:    [[TMP4:%.*]] = load [[STRUCT__DEPEND_UNPACK_T_2]], ptr [[RETVAL]], align 8
// CHECK-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T_2]] [[TMP4]]
//
//
// CHECK-LABEL: @compute_dep.4(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T_3:%.*]], align 8
// CHECK-NEXT:    [[RZ_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    store ptr [[RZ:%.*]], ptr [[RZ_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_3]], ptr [[RETVAL]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[RZ]], ptr [[TMP0]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_3]], ptr [[RETVAL]], i32 0, i32 1
// CHECK-NEXT:    store i64 4, ptr [[TMP1]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_3]], ptr [[RETVAL]], i32 0, i32 2
// CHECK-NEXT:    store i64 0, ptr [[TMP2]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_3]], ptr [[RETVAL]], i32 0, i32 3
// CHECK-NEXT:    store i64 4, ptr [[TMP3]], align 8
// CHECK-NEXT:    [[TMP4:%.*]] = load [[STRUCT__DEPEND_UNPACK_T_3]], ptr [[RETVAL]], align 8
// CHECK-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T_3]] [[TMP4]]
//
//
// CHECK-LABEL: @_Z4foo1Ri(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[RI_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    store ptr [[RI:%.*]], ptr [[RI_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[RI_ADDR]], align 8, !dbg [[DBG29:![0-9]+]]
// CHECK-NEXT:    [[TMP1:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OSS"([5 x i8] c"TASK\00"), "QUAL.OSS.SHARED"(ptr [[TMP0]], i32 undef), "QUAL.OSS.DEP.IN"(ptr [[TMP0]], [3 x i8] c"ri\00", ptr @compute_dep.5, ptr [[TMP0]]) ], !dbg [[DBG29]]
// CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4, !dbg [[DBG30:![0-9]+]]
// CHECK-NEXT:    [[INC:%.*]] = add nsw i32 [[TMP2]], 1, !dbg [[DBG30]]
// CHECK-NEXT:    store i32 [[INC]], ptr [[TMP0]], align 4, !dbg [[DBG30]]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP1]]), !dbg [[DBG31:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG32:![0-9]+]]
//
//
// CHECK-LABEL: @compute_dep.5(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T_4:%.*]], align 8
// CHECK-NEXT:    [[RI_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    store ptr [[RI:%.*]], ptr [[RI_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_4]], ptr [[RETVAL]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[RI]], ptr [[TMP0]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_4]], ptr [[RETVAL]], i32 0, i32 1
// CHECK-NEXT:    store i64 4, ptr [[TMP1]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_4]], ptr [[RETVAL]], i32 0, i32 2
// CHECK-NEXT:    store i64 0, ptr [[TMP2]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_4]], ptr [[RETVAL]], i32 0, i32 3
// CHECK-NEXT:    store i64 4, ptr [[TMP3]], align 8
// CHECK-NEXT:    [[TMP4:%.*]] = load [[STRUCT__DEPEND_UNPACK_T_4]], ptr [[RETVAL]], align 8
// CHECK-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T_4]] [[TMP4]]
//
//
// CHECK-LABEL: @_Z4foo2v(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr @_ZN1S3srxE, align 8, !dbg [[DBG35:![0-9]+]]
// CHECK-NEXT:    [[TMP1:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OSS"([5 x i8] c"TASK\00"), "QUAL.OSS.SHARED"(ptr [[TMP0]], i32 undef), "QUAL.OSS.DEP.IN"(ptr [[TMP0]], [7 x i8] c"S::srx\00", ptr @compute_dep.6, ptr [[TMP0]]) ], !dbg [[DBG35]]
// CHECK-NEXT:    store i32 3, ptr [[TMP0]], align 4, !dbg [[DBG36:![0-9]+]]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP1]]), !dbg [[DBG37:![0-9]+]]
// CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr @_ZZ4foo2vE2rx, align 8, !dbg [[DBG38:![0-9]+]]
// CHECK-NEXT:    [[TMP3:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OSS"([5 x i8] c"TASK\00"), "QUAL.OSS.SHARED"(ptr [[TMP2]], i32 undef), "QUAL.OSS.DEP.IN"(ptr [[TMP2]], [3 x i8] c"rx\00", ptr @compute_dep.7, ptr [[TMP2]]) ], !dbg [[DBG38]]
// CHECK-NEXT:    store i32 3, ptr [[TMP2]], align 4, !dbg [[DBG39:![0-9]+]]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP3]]), !dbg [[DBG40:![0-9]+]]
// CHECK-NEXT:    [[TMP4:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OSS"([5 x i8] c"TASK\00") ], !dbg [[DBG41:![0-9]+]]
// CHECK-NEXT:    [[X:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[TMP5:%.*]] = load atomic i8, ptr @_ZGVZ4foo2vE3rsx acquire, align 8, !dbg [[DBG42:![0-9]+]]
// CHECK-NEXT:    [[GUARD_UNINITIALIZED:%.*]] = icmp eq i8 [[TMP5]], 0, !dbg [[DBG42]]
// CHECK-NEXT:    br i1 [[GUARD_UNINITIALIZED]], label [[INIT_CHECK:%.*]], label [[INIT_END:%.*]], !dbg [[DBG42]], !prof [[PROF43:![0-9]+]]
// CHECK:       init.check:
// CHECK-NEXT:    [[TMP6:%.*]] = call i32 @__cxa_guard_acquire(ptr @_ZGVZ4foo2vE3rsx) #[[ATTR1:[0-9]+]], !dbg [[DBG42]]
// CHECK-NEXT:    [[TOBOOL:%.*]] = icmp ne i32 [[TMP6]], 0, !dbg [[DBG42]]
// CHECK-NEXT:    br i1 [[TOBOOL]], label [[INIT:%.*]], label [[INIT_END]], !dbg [[DBG42]]
// CHECK:       init:
// CHECK-NEXT:    store ptr [[X]], ptr @_ZZ4foo2vE3rsx, align 8, !dbg [[DBG42]]
// CHECK-NEXT:    call void @__cxa_guard_release(ptr @_ZGVZ4foo2vE3rsx) #[[ATTR1]], !dbg [[DBG42]]
// CHECK-NEXT:    br label [[INIT_END]], !dbg [[DBG42]]
// CHECK:       init.end:
// CHECK-NEXT:    [[TMP7:%.*]] = load ptr, ptr @_ZZ4foo2vE3rsx, align 8, !dbg [[DBG44:![0-9]+]]
// CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP7]], align 4, !dbg [[DBG44]]
// CHECK-NEXT:    [[TMP9:%.*]] = load ptr, ptr @rex, align 8, !dbg [[DBG45:![0-9]+]]
// CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP9]], align 4, !dbg [[DBG46:![0-9]+]]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP4]]), !dbg [[DBG47:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG48:![0-9]+]]
//
//
// CHECK-LABEL: @compute_dep.6(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T_5:%.*]], align 8
// CHECK-NEXT:    [[SRX_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    store ptr [[SRX:%.*]], ptr [[SRX_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_5]], ptr [[RETVAL]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[SRX]], ptr [[TMP0]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_5]], ptr [[RETVAL]], i32 0, i32 1
// CHECK-NEXT:    store i64 4, ptr [[TMP1]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_5]], ptr [[RETVAL]], i32 0, i32 2
// CHECK-NEXT:    store i64 0, ptr [[TMP2]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_5]], ptr [[RETVAL]], i32 0, i32 3
// CHECK-NEXT:    store i64 4, ptr [[TMP3]], align 8
// CHECK-NEXT:    [[TMP4:%.*]] = load [[STRUCT__DEPEND_UNPACK_T_5]], ptr [[RETVAL]], align 8
// CHECK-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T_5]] [[TMP4]]
//
//
// CHECK-LABEL: @compute_dep.7(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T_6:%.*]], align 8
// CHECK-NEXT:    [[RX_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    store ptr [[RX:%.*]], ptr [[RX_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_6]], ptr [[RETVAL]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[RX]], ptr [[TMP0]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_6]], ptr [[RETVAL]], i32 0, i32 1
// CHECK-NEXT:    store i64 4, ptr [[TMP1]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_6]], ptr [[RETVAL]], i32 0, i32 2
// CHECK-NEXT:    store i64 0, ptr [[TMP2]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_6]], ptr [[RETVAL]], i32 0, i32 3
// CHECK-NEXT:    store i64 4, ptr [[TMP3]], align 8
// CHECK-NEXT:    [[TMP4:%.*]] = load [[STRUCT__DEPEND_UNPACK_T_6]], ptr [[RETVAL]], align 8
// CHECK-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T_6]] [[TMP4]]
//
//
// CHECK-LABEL: @_Z4foo3b(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[B_ADDR:%.*]] = alloca i8, align 1
// CHECK-NEXT:    [[FROMBOOL:%.*]] = zext i1 [[B:%.*]] to i8
// CHECK-NEXT:    store i8 [[FROMBOOL]], ptr [[B_ADDR]], align 1
// CHECK-NEXT:    [[TMP0:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OSS"([5 x i8] c"TASK\00"), "QUAL.OSS.SHARED"(ptr [[B_ADDR]], i1 undef), "QUAL.OSS.DEP.IN"(ptr [[B_ADDR]], [2 x i8] c"b\00", ptr @compute_dep.8, ptr [[B_ADDR]]) ], !dbg [[DBG52:![0-9]+]]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP0]]), !dbg [[DBG53:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG54:![0-9]+]]
//
//
// CHECK-LABEL: @compute_dep.8(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T_7:%.*]], align 8
// CHECK-NEXT:    [[B_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    store ptr [[B:%.*]], ptr [[B_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_7]], ptr [[RETVAL]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[B]], ptr [[TMP0]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_7]], ptr [[RETVAL]], i32 0, i32 1
// CHECK-NEXT:    store i64 1, ptr [[TMP1]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_7]], ptr [[RETVAL]], i32 0, i32 2
// CHECK-NEXT:    store i64 0, ptr [[TMP2]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_7]], ptr [[RETVAL]], i32 0, i32 3
// CHECK-NEXT:    store i64 1, ptr [[TMP3]], align 8
// CHECK-NEXT:    [[TMP4:%.*]] = load [[STRUCT__DEPEND_UNPACK_T_7]], ptr [[RETVAL]], align 8
// CHECK-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T_7]] [[TMP4]]
//
