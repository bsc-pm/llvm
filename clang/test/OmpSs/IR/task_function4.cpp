// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --function-signature --include-generated-funcs
// RUN: %clang_cc1 -triple x86_64-gnu-linux -verify -fompss-2 -disable-llvm-passes -ferror-limit 100 %s -S -emit-llvm -o - | FileCheck %s --check-prefixes=LIN64
// RUN: %clang_cc1 -triple ppc64 -verify -fompss-2 -disable-llvm-passes -ferror-limit 100 %s -S -emit-llvm -o - | FileCheck %s --check-prefixes=PPC64
// RUN: %clang_cc1 -triple aarch64 -verify -fompss-2 -disable-llvm-passes -ferror-limit 100 %s -S -emit-llvm -o - | FileCheck %s --check-prefixes=AARCH64
// expected-no-diagnostics

struct S {
  #pragma oss declare reduction(asdf : int : omp_out += omp_in) initializer(omp_priv = 0)
};

#pragma oss task reduction(S::asdf : [1]p)
void foo(int *p);

int main() {
  int x;
  foo(&x);
}

// LIN64-LABEL: define {{[^@]+}}@main
// LIN64-SAME: () #[[ATTR0:[0-9]+]] !dbg [[DBG5:![0-9]+]] {
// LIN64-NEXT:  entry:
// LIN64-NEXT:    [[X:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[CALL_ARG:%.*]] = alloca ptr, align 8
// LIN64-NEXT:    store ptr [[X]], ptr [[CALL_ARG]], align 8, !dbg [[DBG9:![0-9]+]]
// LIN64-NEXT:    [[TMP0:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OSS"([5 x i8] c"TASK\00"), "QUAL.OSS.FIRSTPRIVATE"(ptr [[CALL_ARG]], ptr undef), "QUAL.OSS.DEP.REDUCTION"(i32 -1, ptr [[CALL_ARG]], [5 x i8] c"[1]p\00", ptr @compute_dep, ptr [[CALL_ARG]]), "QUAL.OSS.DEP.REDUCTION.INIT"(ptr [[CALL_ARG]], ptr @red_init), "QUAL.OSS.DEP.REDUCTION.COMBINE"(ptr [[CALL_ARG]], ptr @red_comb), "QUAL.OSS.DECL.SOURCE"([24 x i8] c"task_function4.cpp:11:9\00") ], !dbg [[DBG10:![0-9]+]]
// LIN64-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[CALL_ARG]], align 8, !dbg [[DBG9]]
// LIN64-NEXT:    call void @_Z3fooPi(ptr noundef [[TMP1]]), !dbg [[DBG10]]
// LIN64-NEXT:    call void @llvm.directive.region.exit(token [[TMP0]]), !dbg [[DBG10]]
// LIN64-NEXT:    ret i32 0, !dbg [[DBG11:![0-9]+]]
//
//
// LIN64-LABEL: define {{[^@]+}}@red_init
// LIN64-SAME: (ptr noundef [[TMP0:%.*]], ptr noundef [[TMP1:%.*]], i64 noundef [[TMP2:%.*]]) #[[ATTR2:[0-9]+]] !dbg [[DBG12:![0-9]+]] {
// LIN64-NEXT:  entry:
// LIN64-NEXT:    [[DOTADDR:%.*]] = alloca ptr, align 8
// LIN64-NEXT:    [[DOTADDR1:%.*]] = alloca ptr, align 8
// LIN64-NEXT:    [[DOTADDR2:%.*]] = alloca i64, align 8
// LIN64-NEXT:    store ptr [[TMP0]], ptr [[DOTADDR]], align 8
// LIN64-NEXT:    store ptr [[TMP1]], ptr [[DOTADDR1]], align 8
// LIN64-NEXT:    store i64 [[TMP2]], ptr [[DOTADDR2]], align 8
// LIN64-NEXT:    [[TMP3:%.*]] = load ptr, ptr [[DOTADDR]], align 8
// LIN64-NEXT:    [[TMP4:%.*]] = load ptr, ptr [[DOTADDR1]], align 8
// LIN64-NEXT:    [[TMP5:%.*]] = load i64, ptr [[DOTADDR2]], align 8
// LIN64-NEXT:    [[TMP6:%.*]] = udiv exact i64 [[TMP5]], 4
// LIN64-NEXT:    [[ARRAYCTOR_DST_END:%.*]] = getelementptr inbounds i32, ptr [[TMP3]], i64 [[TMP6]]
// LIN64-NEXT:    br label [[ARRAYCTOR_LOOP:%.*]]
// LIN64:       arrayctor.loop:
// LIN64-NEXT:    [[ARRAYCTOR_DST_CUR:%.*]] = phi ptr [ [[TMP3]], [[ENTRY:%.*]] ], [ [[ARRAYCTOR_DST_NEXT:%.*]], [[ARRAYCTOR_LOOP]] ]
// LIN64-NEXT:    [[ARRAYCTOR_SRC_CUR:%.*]] = phi ptr [ [[TMP4]], [[ENTRY]] ], [ [[ARRAYCTOR_SRC_NEXT:%.*]], [[ARRAYCTOR_LOOP]] ]
// LIN64-NEXT:    store i32 0, ptr [[ARRAYCTOR_DST_CUR]], align 4
// LIN64-NEXT:    [[ARRAYCTOR_DST_NEXT]] = getelementptr inbounds i32, ptr [[ARRAYCTOR_DST_CUR]], i64 1
// LIN64-NEXT:    [[ARRAYCTOR_SRC_NEXT]] = getelementptr inbounds i32, ptr [[ARRAYCTOR_SRC_CUR]], i64 1
// LIN64-NEXT:    [[ARRAYCTOR_DONE:%.*]] = icmp eq ptr [[ARRAYCTOR_DST_NEXT]], [[ARRAYCTOR_DST_END]]
// LIN64-NEXT:    br i1 [[ARRAYCTOR_DONE]], label [[ARRAYCTOR_CONT:%.*]], label [[ARRAYCTOR_LOOP]]
// LIN64:       arrayctor.cont:
// LIN64-NEXT:    ret void, !dbg [[DBG13:![0-9]+]]
//
//
// LIN64-LABEL: define {{[^@]+}}@red_comb
// LIN64-SAME: (ptr noundef [[TMP0:%.*]], ptr noundef [[TMP1:%.*]], i64 noundef [[TMP2:%.*]]) #[[ATTR2]] !dbg [[DBG15:![0-9]+]] {
// LIN64-NEXT:  entry:
// LIN64-NEXT:    [[DOTADDR:%.*]] = alloca ptr, align 8
// LIN64-NEXT:    [[DOTADDR1:%.*]] = alloca ptr, align 8
// LIN64-NEXT:    [[DOTADDR2:%.*]] = alloca i64, align 8
// LIN64-NEXT:    store ptr [[TMP0]], ptr [[DOTADDR]], align 8
// LIN64-NEXT:    store ptr [[TMP1]], ptr [[DOTADDR1]], align 8
// LIN64-NEXT:    store i64 [[TMP2]], ptr [[DOTADDR2]], align 8
// LIN64-NEXT:    [[TMP3:%.*]] = load ptr, ptr [[DOTADDR]], align 8
// LIN64-NEXT:    [[TMP4:%.*]] = load ptr, ptr [[DOTADDR1]], align 8
// LIN64-NEXT:    [[TMP5:%.*]] = load i64, ptr [[DOTADDR2]], align 8
// LIN64-NEXT:    [[TMP6:%.*]] = udiv exact i64 [[TMP5]], 4
// LIN64-NEXT:    [[ARRAYCTOR_DST_END:%.*]] = getelementptr inbounds i32, ptr [[TMP3]], i64 [[TMP6]]
// LIN64-NEXT:    br label [[ARRAYCTOR_LOOP:%.*]]
// LIN64:       arrayctor.loop:
// LIN64-NEXT:    [[ARRAYCTOR_DST_CUR:%.*]] = phi ptr [ [[TMP3]], [[ENTRY:%.*]] ], [ [[ARRAYCTOR_DST_NEXT:%.*]], [[ARRAYCTOR_LOOP]] ]
// LIN64-NEXT:    [[ARRAYCTOR_SRC_CUR:%.*]] = phi ptr [ [[TMP4]], [[ENTRY]] ], [ [[ARRAYCTOR_SRC_NEXT:%.*]], [[ARRAYCTOR_LOOP]] ]
// LIN64-NEXT:    [[TMP7:%.*]] = load i32, ptr [[ARRAYCTOR_SRC_CUR]], align 4, !dbg [[DBG16:![0-9]+]]
// LIN64-NEXT:    [[TMP8:%.*]] = load i32, ptr [[ARRAYCTOR_DST_CUR]], align 4, !dbg [[DBG18:![0-9]+]]
// LIN64-NEXT:    [[ADD:%.*]] = add nsw i32 [[TMP8]], [[TMP7]], !dbg [[DBG18]]
// LIN64-NEXT:    store i32 [[ADD]], ptr [[ARRAYCTOR_DST_CUR]], align 4, !dbg [[DBG18]]
// LIN64-NEXT:    [[ARRAYCTOR_DST_NEXT]] = getelementptr inbounds i32, ptr [[ARRAYCTOR_DST_CUR]], i64 1
// LIN64-NEXT:    [[ARRAYCTOR_SRC_NEXT]] = getelementptr inbounds i32, ptr [[ARRAYCTOR_SRC_CUR]], i64 1
// LIN64-NEXT:    [[ARRAYCTOR_DONE:%.*]] = icmp eq ptr [[ARRAYCTOR_DST_NEXT]], [[ARRAYCTOR_DST_END]]
// LIN64-NEXT:    br i1 [[ARRAYCTOR_DONE]], label [[ARRAYCTOR_CONT:%.*]], label [[ARRAYCTOR_LOOP]]
// LIN64:       arrayctor.cont:
// LIN64-NEXT:    ret void, !dbg [[DBG19:![0-9]+]]
//
//
// LIN64-LABEL: define {{[^@]+}}@compute_dep
// LIN64-SAME: (ptr [[P:%.*]]) #[[ATTR3:[0-9]+]] !dbg [[DBG20:![0-9]+]] {
// LIN64-NEXT:  entry:
// LIN64-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T:%.*]], align 8
// LIN64-NEXT:    [[P_ADDR:%.*]] = alloca ptr, align 8
// LIN64-NEXT:    store ptr [[P]], ptr [[P_ADDR]], align 8
// LIN64-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[P]], align 8, !dbg [[DBG21:![0-9]+]]
// LIN64-NEXT:    [[TMP1:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 0
// LIN64-NEXT:    store ptr [[TMP0]], ptr [[TMP1]], align 8
// LIN64-NEXT:    [[TMP2:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 1
// LIN64-NEXT:    store i64 4, ptr [[TMP2]], align 8
// LIN64-NEXT:    [[TMP3:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 2
// LIN64-NEXT:    store i64 0, ptr [[TMP3]], align 8
// LIN64-NEXT:    [[TMP4:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 3
// LIN64-NEXT:    store i64 4, ptr [[TMP4]], align 8
// LIN64-NEXT:    [[TMP5:%.*]] = load [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], align 8, !dbg [[DBG21]]
// LIN64-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T]] [[TMP5]], !dbg [[DBG21]]
//
//
// PPC64-LABEL: define {{[^@]+}}@main
// PPC64-SAME: () #[[ATTR0:[0-9]+]] !dbg [[DBG5:![0-9]+]] {
// PPC64-NEXT:  entry:
// PPC64-NEXT:    [[X:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[CALL_ARG:%.*]] = alloca ptr, align 8
// PPC64-NEXT:    store ptr [[X]], ptr [[CALL_ARG]], align 8, !dbg [[DBG9:![0-9]+]]
// PPC64-NEXT:    [[TMP0:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OSS"([5 x i8] c"TASK\00"), "QUAL.OSS.FIRSTPRIVATE"(ptr [[CALL_ARG]], ptr undef), "QUAL.OSS.DEP.REDUCTION"(i32 -1, ptr [[CALL_ARG]], [5 x i8] c"[1]p\00", ptr @compute_dep, ptr [[CALL_ARG]]), "QUAL.OSS.DEP.REDUCTION.INIT"(ptr [[CALL_ARG]], ptr @red_init), "QUAL.OSS.DEP.REDUCTION.COMBINE"(ptr [[CALL_ARG]], ptr @red_comb), "QUAL.OSS.DECL.SOURCE"([24 x i8] c"task_function4.cpp:11:9\00") ], !dbg [[DBG10:![0-9]+]]
// PPC64-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[CALL_ARG]], align 8, !dbg [[DBG9]]
// PPC64-NEXT:    call void @_Z3fooPi(ptr noundef [[TMP1]]), !dbg [[DBG10]]
// PPC64-NEXT:    call void @llvm.directive.region.exit(token [[TMP0]]), !dbg [[DBG10]]
// PPC64-NEXT:    ret i32 0, !dbg [[DBG11:![0-9]+]]
//
//
// PPC64-LABEL: define {{[^@]+}}@red_init
// PPC64-SAME: (ptr noundef [[TMP0:%.*]], ptr noundef [[TMP1:%.*]], i64 noundef [[TMP2:%.*]]) #[[ATTR2:[0-9]+]] !dbg [[DBG12:![0-9]+]] {
// PPC64-NEXT:  entry:
// PPC64-NEXT:    [[DOTADDR:%.*]] = alloca ptr, align 8
// PPC64-NEXT:    [[DOTADDR1:%.*]] = alloca ptr, align 8
// PPC64-NEXT:    [[DOTADDR2:%.*]] = alloca i64, align 8
// PPC64-NEXT:    store ptr [[TMP0]], ptr [[DOTADDR]], align 8
// PPC64-NEXT:    store ptr [[TMP1]], ptr [[DOTADDR1]], align 8
// PPC64-NEXT:    store i64 [[TMP2]], ptr [[DOTADDR2]], align 8
// PPC64-NEXT:    [[TMP3:%.*]] = load ptr, ptr [[DOTADDR]], align 8
// PPC64-NEXT:    [[TMP4:%.*]] = load ptr, ptr [[DOTADDR1]], align 8
// PPC64-NEXT:    [[TMP5:%.*]] = load i64, ptr [[DOTADDR2]], align 8
// PPC64-NEXT:    [[TMP6:%.*]] = udiv exact i64 [[TMP5]], 4
// PPC64-NEXT:    [[ARRAYCTOR_DST_END:%.*]] = getelementptr inbounds i32, ptr [[TMP3]], i64 [[TMP6]]
// PPC64-NEXT:    br label [[ARRAYCTOR_LOOP:%.*]]
// PPC64:       arrayctor.loop:
// PPC64-NEXT:    [[ARRAYCTOR_DST_CUR:%.*]] = phi ptr [ [[TMP3]], [[ENTRY:%.*]] ], [ [[ARRAYCTOR_DST_NEXT:%.*]], [[ARRAYCTOR_LOOP]] ]
// PPC64-NEXT:    [[ARRAYCTOR_SRC_CUR:%.*]] = phi ptr [ [[TMP4]], [[ENTRY]] ], [ [[ARRAYCTOR_SRC_NEXT:%.*]], [[ARRAYCTOR_LOOP]] ]
// PPC64-NEXT:    store i32 0, ptr [[ARRAYCTOR_DST_CUR]], align 4
// PPC64-NEXT:    [[ARRAYCTOR_DST_NEXT]] = getelementptr inbounds i32, ptr [[ARRAYCTOR_DST_CUR]], i64 1
// PPC64-NEXT:    [[ARRAYCTOR_SRC_NEXT]] = getelementptr inbounds i32, ptr [[ARRAYCTOR_SRC_CUR]], i64 1
// PPC64-NEXT:    [[ARRAYCTOR_DONE:%.*]] = icmp eq ptr [[ARRAYCTOR_DST_NEXT]], [[ARRAYCTOR_DST_END]]
// PPC64-NEXT:    br i1 [[ARRAYCTOR_DONE]], label [[ARRAYCTOR_CONT:%.*]], label [[ARRAYCTOR_LOOP]]
// PPC64:       arrayctor.cont:
// PPC64-NEXT:    ret void, !dbg [[DBG13:![0-9]+]]
//
//
// PPC64-LABEL: define {{[^@]+}}@red_comb
// PPC64-SAME: (ptr noundef [[TMP0:%.*]], ptr noundef [[TMP1:%.*]], i64 noundef [[TMP2:%.*]]) #[[ATTR2]] !dbg [[DBG15:![0-9]+]] {
// PPC64-NEXT:  entry:
// PPC64-NEXT:    [[DOTADDR:%.*]] = alloca ptr, align 8
// PPC64-NEXT:    [[DOTADDR1:%.*]] = alloca ptr, align 8
// PPC64-NEXT:    [[DOTADDR2:%.*]] = alloca i64, align 8
// PPC64-NEXT:    store ptr [[TMP0]], ptr [[DOTADDR]], align 8
// PPC64-NEXT:    store ptr [[TMP1]], ptr [[DOTADDR1]], align 8
// PPC64-NEXT:    store i64 [[TMP2]], ptr [[DOTADDR2]], align 8
// PPC64-NEXT:    [[TMP3:%.*]] = load ptr, ptr [[DOTADDR]], align 8
// PPC64-NEXT:    [[TMP4:%.*]] = load ptr, ptr [[DOTADDR1]], align 8
// PPC64-NEXT:    [[TMP5:%.*]] = load i64, ptr [[DOTADDR2]], align 8
// PPC64-NEXT:    [[TMP6:%.*]] = udiv exact i64 [[TMP5]], 4
// PPC64-NEXT:    [[ARRAYCTOR_DST_END:%.*]] = getelementptr inbounds i32, ptr [[TMP3]], i64 [[TMP6]]
// PPC64-NEXT:    br label [[ARRAYCTOR_LOOP:%.*]]
// PPC64:       arrayctor.loop:
// PPC64-NEXT:    [[ARRAYCTOR_DST_CUR:%.*]] = phi ptr [ [[TMP3]], [[ENTRY:%.*]] ], [ [[ARRAYCTOR_DST_NEXT:%.*]], [[ARRAYCTOR_LOOP]] ]
// PPC64-NEXT:    [[ARRAYCTOR_SRC_CUR:%.*]] = phi ptr [ [[TMP4]], [[ENTRY]] ], [ [[ARRAYCTOR_SRC_NEXT:%.*]], [[ARRAYCTOR_LOOP]] ]
// PPC64-NEXT:    [[TMP7:%.*]] = load i32, ptr [[ARRAYCTOR_SRC_CUR]], align 4, !dbg [[DBG16:![0-9]+]]
// PPC64-NEXT:    [[TMP8:%.*]] = load i32, ptr [[ARRAYCTOR_DST_CUR]], align 4, !dbg [[DBG18:![0-9]+]]
// PPC64-NEXT:    [[ADD:%.*]] = add nsw i32 [[TMP8]], [[TMP7]], !dbg [[DBG18]]
// PPC64-NEXT:    store i32 [[ADD]], ptr [[ARRAYCTOR_DST_CUR]], align 4, !dbg [[DBG18]]
// PPC64-NEXT:    [[ARRAYCTOR_DST_NEXT]] = getelementptr inbounds i32, ptr [[ARRAYCTOR_DST_CUR]], i64 1
// PPC64-NEXT:    [[ARRAYCTOR_SRC_NEXT]] = getelementptr inbounds i32, ptr [[ARRAYCTOR_SRC_CUR]], i64 1
// PPC64-NEXT:    [[ARRAYCTOR_DONE:%.*]] = icmp eq ptr [[ARRAYCTOR_DST_NEXT]], [[ARRAYCTOR_DST_END]]
// PPC64-NEXT:    br i1 [[ARRAYCTOR_DONE]], label [[ARRAYCTOR_CONT:%.*]], label [[ARRAYCTOR_LOOP]]
// PPC64:       arrayctor.cont:
// PPC64-NEXT:    ret void, !dbg [[DBG19:![0-9]+]]
//
//
// PPC64-LABEL: define {{[^@]+}}@compute_dep
// PPC64-SAME: (ptr [[P:%.*]]) !dbg [[DBG20:![0-9]+]] {
// PPC64-NEXT:  entry:
// PPC64-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T:%.*]], align 8
// PPC64-NEXT:    [[P_ADDR:%.*]] = alloca ptr, align 8
// PPC64-NEXT:    store ptr [[P]], ptr [[P_ADDR]], align 8
// PPC64-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[P]], align 8, !dbg [[DBG21:![0-9]+]]
// PPC64-NEXT:    [[TMP1:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 0
// PPC64-NEXT:    store ptr [[TMP0]], ptr [[TMP1]], align 8
// PPC64-NEXT:    [[TMP2:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 1
// PPC64-NEXT:    store i64 4, ptr [[TMP2]], align 8
// PPC64-NEXT:    [[TMP3:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 2
// PPC64-NEXT:    store i64 0, ptr [[TMP3]], align 8
// PPC64-NEXT:    [[TMP4:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 3
// PPC64-NEXT:    store i64 4, ptr [[TMP4]], align 8
// PPC64-NEXT:    [[TMP5:%.*]] = load [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], align 8, !dbg [[DBG21]]
// PPC64-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T]] [[TMP5]], !dbg [[DBG21]]
//
//
// AARCH64-LABEL: define {{[^@]+}}@main
// AARCH64-SAME: () #[[ATTR0:[0-9]+]] !dbg [[DBG5:![0-9]+]] {
// AARCH64-NEXT:  entry:
// AARCH64-NEXT:    [[X:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[CALL_ARG:%.*]] = alloca ptr, align 8
// AARCH64-NEXT:    store ptr [[X]], ptr [[CALL_ARG]], align 8, !dbg [[DBG9:![0-9]+]]
// AARCH64-NEXT:    [[TMP0:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OSS"([5 x i8] c"TASK\00"), "QUAL.OSS.FIRSTPRIVATE"(ptr [[CALL_ARG]], ptr undef), "QUAL.OSS.DEP.REDUCTION"(i32 -1, ptr [[CALL_ARG]], [5 x i8] c"[1]p\00", ptr @compute_dep, ptr [[CALL_ARG]]), "QUAL.OSS.DEP.REDUCTION.INIT"(ptr [[CALL_ARG]], ptr @red_init), "QUAL.OSS.DEP.REDUCTION.COMBINE"(ptr [[CALL_ARG]], ptr @red_comb), "QUAL.OSS.DECL.SOURCE"([24 x i8] c"task_function4.cpp:11:9\00") ], !dbg [[DBG10:![0-9]+]]
// AARCH64-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[CALL_ARG]], align 8, !dbg [[DBG9]]
// AARCH64-NEXT:    call void @_Z3fooPi(ptr noundef [[TMP1]]), !dbg [[DBG10]]
// AARCH64-NEXT:    call void @llvm.directive.region.exit(token [[TMP0]]), !dbg [[DBG10]]
// AARCH64-NEXT:    ret i32 0, !dbg [[DBG11:![0-9]+]]
//
//
// AARCH64-LABEL: define {{[^@]+}}@red_init
// AARCH64-SAME: (ptr noundef [[TMP0:%.*]], ptr noundef [[TMP1:%.*]], i64 noundef [[TMP2:%.*]]) #[[ATTR2:[0-9]+]] !dbg [[DBG12:![0-9]+]] {
// AARCH64-NEXT:  entry:
// AARCH64-NEXT:    [[DOTADDR:%.*]] = alloca ptr, align 8
// AARCH64-NEXT:    [[DOTADDR1:%.*]] = alloca ptr, align 8
// AARCH64-NEXT:    [[DOTADDR2:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    store ptr [[TMP0]], ptr [[DOTADDR]], align 8
// AARCH64-NEXT:    store ptr [[TMP1]], ptr [[DOTADDR1]], align 8
// AARCH64-NEXT:    store i64 [[TMP2]], ptr [[DOTADDR2]], align 8
// AARCH64-NEXT:    [[TMP3:%.*]] = load ptr, ptr [[DOTADDR]], align 8
// AARCH64-NEXT:    [[TMP4:%.*]] = load ptr, ptr [[DOTADDR1]], align 8
// AARCH64-NEXT:    [[TMP5:%.*]] = load i64, ptr [[DOTADDR2]], align 8
// AARCH64-NEXT:    [[TMP6:%.*]] = udiv exact i64 [[TMP5]], 4
// AARCH64-NEXT:    [[ARRAYCTOR_DST_END:%.*]] = getelementptr inbounds i32, ptr [[TMP3]], i64 [[TMP6]]
// AARCH64-NEXT:    br label [[ARRAYCTOR_LOOP:%.*]]
// AARCH64:       arrayctor.loop:
// AARCH64-NEXT:    [[ARRAYCTOR_DST_CUR:%.*]] = phi ptr [ [[TMP3]], [[ENTRY:%.*]] ], [ [[ARRAYCTOR_DST_NEXT:%.*]], [[ARRAYCTOR_LOOP]] ]
// AARCH64-NEXT:    [[ARRAYCTOR_SRC_CUR:%.*]] = phi ptr [ [[TMP4]], [[ENTRY]] ], [ [[ARRAYCTOR_SRC_NEXT:%.*]], [[ARRAYCTOR_LOOP]] ]
// AARCH64-NEXT:    store i32 0, ptr [[ARRAYCTOR_DST_CUR]], align 4
// AARCH64-NEXT:    [[ARRAYCTOR_DST_NEXT]] = getelementptr inbounds i32, ptr [[ARRAYCTOR_DST_CUR]], i64 1
// AARCH64-NEXT:    [[ARRAYCTOR_SRC_NEXT]] = getelementptr inbounds i32, ptr [[ARRAYCTOR_SRC_CUR]], i64 1
// AARCH64-NEXT:    [[ARRAYCTOR_DONE:%.*]] = icmp eq ptr [[ARRAYCTOR_DST_NEXT]], [[ARRAYCTOR_DST_END]]
// AARCH64-NEXT:    br i1 [[ARRAYCTOR_DONE]], label [[ARRAYCTOR_CONT:%.*]], label [[ARRAYCTOR_LOOP]]
// AARCH64:       arrayctor.cont:
// AARCH64-NEXT:    ret void, !dbg [[DBG13:![0-9]+]]
//
//
// AARCH64-LABEL: define {{[^@]+}}@red_comb
// AARCH64-SAME: (ptr noundef [[TMP0:%.*]], ptr noundef [[TMP1:%.*]], i64 noundef [[TMP2:%.*]]) #[[ATTR2]] !dbg [[DBG15:![0-9]+]] {
// AARCH64-NEXT:  entry:
// AARCH64-NEXT:    [[DOTADDR:%.*]] = alloca ptr, align 8
// AARCH64-NEXT:    [[DOTADDR1:%.*]] = alloca ptr, align 8
// AARCH64-NEXT:    [[DOTADDR2:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    store ptr [[TMP0]], ptr [[DOTADDR]], align 8
// AARCH64-NEXT:    store ptr [[TMP1]], ptr [[DOTADDR1]], align 8
// AARCH64-NEXT:    store i64 [[TMP2]], ptr [[DOTADDR2]], align 8
// AARCH64-NEXT:    [[TMP3:%.*]] = load ptr, ptr [[DOTADDR]], align 8
// AARCH64-NEXT:    [[TMP4:%.*]] = load ptr, ptr [[DOTADDR1]], align 8
// AARCH64-NEXT:    [[TMP5:%.*]] = load i64, ptr [[DOTADDR2]], align 8
// AARCH64-NEXT:    [[TMP6:%.*]] = udiv exact i64 [[TMP5]], 4
// AARCH64-NEXT:    [[ARRAYCTOR_DST_END:%.*]] = getelementptr inbounds i32, ptr [[TMP3]], i64 [[TMP6]]
// AARCH64-NEXT:    br label [[ARRAYCTOR_LOOP:%.*]]
// AARCH64:       arrayctor.loop:
// AARCH64-NEXT:    [[ARRAYCTOR_DST_CUR:%.*]] = phi ptr [ [[TMP3]], [[ENTRY:%.*]] ], [ [[ARRAYCTOR_DST_NEXT:%.*]], [[ARRAYCTOR_LOOP]] ]
// AARCH64-NEXT:    [[ARRAYCTOR_SRC_CUR:%.*]] = phi ptr [ [[TMP4]], [[ENTRY]] ], [ [[ARRAYCTOR_SRC_NEXT:%.*]], [[ARRAYCTOR_LOOP]] ]
// AARCH64-NEXT:    [[TMP7:%.*]] = load i32, ptr [[ARRAYCTOR_SRC_CUR]], align 4, !dbg [[DBG16:![0-9]+]]
// AARCH64-NEXT:    [[TMP8:%.*]] = load i32, ptr [[ARRAYCTOR_DST_CUR]], align 4, !dbg [[DBG18:![0-9]+]]
// AARCH64-NEXT:    [[ADD:%.*]] = add nsw i32 [[TMP8]], [[TMP7]], !dbg [[DBG18]]
// AARCH64-NEXT:    store i32 [[ADD]], ptr [[ARRAYCTOR_DST_CUR]], align 4, !dbg [[DBG18]]
// AARCH64-NEXT:    [[ARRAYCTOR_DST_NEXT]] = getelementptr inbounds i32, ptr [[ARRAYCTOR_DST_CUR]], i64 1
// AARCH64-NEXT:    [[ARRAYCTOR_SRC_NEXT]] = getelementptr inbounds i32, ptr [[ARRAYCTOR_SRC_CUR]], i64 1
// AARCH64-NEXT:    [[ARRAYCTOR_DONE:%.*]] = icmp eq ptr [[ARRAYCTOR_DST_NEXT]], [[ARRAYCTOR_DST_END]]
// AARCH64-NEXT:    br i1 [[ARRAYCTOR_DONE]], label [[ARRAYCTOR_CONT:%.*]], label [[ARRAYCTOR_LOOP]]
// AARCH64:       arrayctor.cont:
// AARCH64-NEXT:    ret void, !dbg [[DBG19:![0-9]+]]
//
//
// AARCH64-LABEL: define {{[^@]+}}@compute_dep
// AARCH64-SAME: (ptr [[P:%.*]]) !dbg [[DBG20:![0-9]+]] {
// AARCH64-NEXT:  entry:
// AARCH64-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T:%.*]], align 8
// AARCH64-NEXT:    [[P_ADDR:%.*]] = alloca ptr, align 8
// AARCH64-NEXT:    store ptr [[P]], ptr [[P_ADDR]], align 8
// AARCH64-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[P]], align 8, !dbg [[DBG21:![0-9]+]]
// AARCH64-NEXT:    [[TMP1:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 0
// AARCH64-NEXT:    store ptr [[TMP0]], ptr [[TMP1]], align 8
// AARCH64-NEXT:    [[TMP2:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 1
// AARCH64-NEXT:    store i64 4, ptr [[TMP2]], align 8
// AARCH64-NEXT:    [[TMP3:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 2
// AARCH64-NEXT:    store i64 0, ptr [[TMP3]], align 8
// AARCH64-NEXT:    [[TMP4:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 3
// AARCH64-NEXT:    store i64 4, ptr [[TMP4]], align 8
// AARCH64-NEXT:    [[TMP5:%.*]] = load [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], align 8, !dbg [[DBG21]]
// AARCH64-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T]] [[TMP5]], !dbg [[DBG21]]
//
