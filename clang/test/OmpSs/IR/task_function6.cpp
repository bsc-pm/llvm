// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --function-signature --include-generated-funcs
// RUN: %clang_cc1 -triple x86_64-gnu-linux -verify -fompss-2 -disable-llvm-passes -ferror-limit 100 %s -S -emit-llvm -o - | FileCheck %s --check-prefixes=LIN64
// RUN: %clang_cc1 -triple ppc64 -verify -fompss-2 -disable-llvm-passes -ferror-limit 100 %s -S -emit-llvm -o - | FileCheck %s --check-prefixes=PPC64
// RUN: %clang_cc1 -triple aarch64 -verify -fompss-2 -disable-llvm-passes -ferror-limit 100 %s -S -emit-llvm -o - | FileCheck %s --check-prefixes=AARCH64
// expected-no-diagnostics

// Before the fix the load ptr, ptr @rx was emitted in every dependency
int x;
int &rx = x;
#pragma oss task in(rx, rx)
void foo();

int main(){
    foo();
    #pragma oss taskwait
}
// LIN64-LABEL: define {{[^@]+}}@main
// LIN64-SAME: () #[[ATTR0:[0-9]+]] !dbg [[DBG5:![0-9]+]] {
// LIN64-NEXT:  entry:
// LIN64-NEXT:    [[TMP0:%.*]] = load ptr, ptr @rx, align 8, !dbg [[DBG9:![0-9]+]]
// LIN64-NEXT:    [[TMP1:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OSS"([5 x i8] c"TASK\00"), "QUAL.OSS.SHARED"(ptr [[TMP0]], i32 undef), "QUAL.OSS.SHARED"(ptr [[TMP0]], i32 undef), "QUAL.OSS.DEP.IN"(ptr [[TMP0]], [3 x i8] c"rx\00", ptr @compute_dep, ptr [[TMP0]]), "QUAL.OSS.DEP.IN"(ptr [[TMP0]], [3 x i8] c"rx\00", ptr @compute_dep.1, ptr [[TMP0]]), "QUAL.OSS.DECL.SOURCE"([24 x i8] c"task_function6.cpp:10:9\00") ], !dbg [[DBG10:![0-9]+]]
// LIN64-NEXT:    call void @_Z3foov(), !dbg [[DBG10]]
// LIN64-NEXT:    call void @llvm.directive.region.exit(token [[TMP1]]), !dbg [[DBG10]]
// LIN64-NEXT:    [[TMP2:%.*]] = call i1 @llvm.directive.marker() [ "DIR.OSS"([9 x i8] c"TASKWAIT\00") ], !dbg [[DBG11:![0-9]+]]
// LIN64-NEXT:    ret i32 0, !dbg [[DBG12:![0-9]+]]
//
//
// LIN64-LABEL: define {{[^@]+}}@compute_dep
// LIN64-SAME: (ptr [[RX:%.*]]) #[[ATTR2:[0-9]+]] !dbg [[DBG13:![0-9]+]] {
// LIN64-NEXT:  entry:
// LIN64-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T:%.*]], align 8
// LIN64-NEXT:    [[RX_ADDR:%.*]] = alloca ptr, align 8
// LIN64-NEXT:    store ptr [[RX]], ptr [[RX_ADDR]], align 8
// LIN64-NEXT:    [[TMP0:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 0
// LIN64-NEXT:    store ptr [[RX]], ptr [[TMP0]], align 8
// LIN64-NEXT:    [[TMP1:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 1
// LIN64-NEXT:    store i64 4, ptr [[TMP1]], align 8
// LIN64-NEXT:    [[TMP2:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 2
// LIN64-NEXT:    store i64 0, ptr [[TMP2]], align 8
// LIN64-NEXT:    [[TMP3:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 3
// LIN64-NEXT:    store i64 4, ptr [[TMP3]], align 8
// LIN64-NEXT:    [[TMP4:%.*]] = load [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], align 8
// LIN64-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T]] [[TMP4]]
//
//
// LIN64-LABEL: define {{[^@]+}}@compute_dep.1
// LIN64-SAME: (ptr [[RX:%.*]]) #[[ATTR2]] !dbg [[DBG14:![0-9]+]] {
// LIN64-NEXT:  entry:
// LIN64-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T_0:%.*]], align 8
// LIN64-NEXT:    [[RX_ADDR:%.*]] = alloca ptr, align 8
// LIN64-NEXT:    store ptr [[RX]], ptr [[RX_ADDR]], align 8
// LIN64-NEXT:    [[TMP0:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 0
// LIN64-NEXT:    store ptr [[RX]], ptr [[TMP0]], align 8
// LIN64-NEXT:    [[TMP1:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 1
// LIN64-NEXT:    store i64 4, ptr [[TMP1]], align 8
// LIN64-NEXT:    [[TMP2:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 2
// LIN64-NEXT:    store i64 0, ptr [[TMP2]], align 8
// LIN64-NEXT:    [[TMP3:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 3
// LIN64-NEXT:    store i64 4, ptr [[TMP3]], align 8
// LIN64-NEXT:    [[TMP4:%.*]] = load [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], align 8
// LIN64-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T_0]] [[TMP4]]
//
//
// PPC64-LABEL: define {{[^@]+}}@main
// PPC64-SAME: () #[[ATTR0:[0-9]+]] !dbg [[DBG5:![0-9]+]] {
// PPC64-NEXT:  entry:
// PPC64-NEXT:    [[TMP0:%.*]] = load ptr, ptr @rx, align 8, !dbg [[DBG9:![0-9]+]]
// PPC64-NEXT:    [[TMP1:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OSS"([5 x i8] c"TASK\00"), "QUAL.OSS.SHARED"(ptr [[TMP0]], i32 undef), "QUAL.OSS.SHARED"(ptr [[TMP0]], i32 undef), "QUAL.OSS.DEP.IN"(ptr [[TMP0]], [3 x i8] c"rx\00", ptr @compute_dep, ptr [[TMP0]]), "QUAL.OSS.DEP.IN"(ptr [[TMP0]], [3 x i8] c"rx\00", ptr @compute_dep.1, ptr [[TMP0]]), "QUAL.OSS.DECL.SOURCE"([24 x i8] c"task_function6.cpp:10:9\00") ], !dbg [[DBG10:![0-9]+]]
// PPC64-NEXT:    call void @_Z3foov(), !dbg [[DBG10]]
// PPC64-NEXT:    call void @llvm.directive.region.exit(token [[TMP1]]), !dbg [[DBG10]]
// PPC64-NEXT:    [[TMP2:%.*]] = call i1 @llvm.directive.marker() [ "DIR.OSS"([9 x i8] c"TASKWAIT\00") ], !dbg [[DBG11:![0-9]+]]
// PPC64-NEXT:    ret i32 0, !dbg [[DBG12:![0-9]+]]
//
//
// PPC64-LABEL: define {{[^@]+}}@compute_dep
// PPC64-SAME: (ptr [[RX:%.*]]) !dbg [[DBG13:![0-9]+]] {
// PPC64-NEXT:  entry:
// PPC64-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T:%.*]], align 8
// PPC64-NEXT:    [[RX_ADDR:%.*]] = alloca ptr, align 8
// PPC64-NEXT:    store ptr [[RX]], ptr [[RX_ADDR]], align 8
// PPC64-NEXT:    [[TMP0:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 0
// PPC64-NEXT:    store ptr [[RX]], ptr [[TMP0]], align 8
// PPC64-NEXT:    [[TMP1:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 1
// PPC64-NEXT:    store i64 4, ptr [[TMP1]], align 8
// PPC64-NEXT:    [[TMP2:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 2
// PPC64-NEXT:    store i64 0, ptr [[TMP2]], align 8
// PPC64-NEXT:    [[TMP3:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 3
// PPC64-NEXT:    store i64 4, ptr [[TMP3]], align 8
// PPC64-NEXT:    [[TMP4:%.*]] = load [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], align 8
// PPC64-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T]] [[TMP4]]
//
//
// PPC64-LABEL: define {{[^@]+}}@compute_dep.1
// PPC64-SAME: (ptr [[RX:%.*]]) !dbg [[DBG14:![0-9]+]] {
// PPC64-NEXT:  entry:
// PPC64-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T_0:%.*]], align 8
// PPC64-NEXT:    [[RX_ADDR:%.*]] = alloca ptr, align 8
// PPC64-NEXT:    store ptr [[RX]], ptr [[RX_ADDR]], align 8
// PPC64-NEXT:    [[TMP0:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 0
// PPC64-NEXT:    store ptr [[RX]], ptr [[TMP0]], align 8
// PPC64-NEXT:    [[TMP1:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 1
// PPC64-NEXT:    store i64 4, ptr [[TMP1]], align 8
// PPC64-NEXT:    [[TMP2:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 2
// PPC64-NEXT:    store i64 0, ptr [[TMP2]], align 8
// PPC64-NEXT:    [[TMP3:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 3
// PPC64-NEXT:    store i64 4, ptr [[TMP3]], align 8
// PPC64-NEXT:    [[TMP4:%.*]] = load [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], align 8
// PPC64-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T_0]] [[TMP4]]
//
//
// AARCH64-LABEL: define {{[^@]+}}@main
// AARCH64-SAME: () #[[ATTR0:[0-9]+]] !dbg [[DBG5:![0-9]+]] {
// AARCH64-NEXT:  entry:
// AARCH64-NEXT:    [[TMP0:%.*]] = load ptr, ptr @rx, align 8, !dbg [[DBG9:![0-9]+]]
// AARCH64-NEXT:    [[TMP1:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OSS"([5 x i8] c"TASK\00"), "QUAL.OSS.SHARED"(ptr [[TMP0]], i32 undef), "QUAL.OSS.SHARED"(ptr [[TMP0]], i32 undef), "QUAL.OSS.DEP.IN"(ptr [[TMP0]], [3 x i8] c"rx\00", ptr @compute_dep, ptr [[TMP0]]), "QUAL.OSS.DEP.IN"(ptr [[TMP0]], [3 x i8] c"rx\00", ptr @compute_dep.1, ptr [[TMP0]]), "QUAL.OSS.DECL.SOURCE"([24 x i8] c"task_function6.cpp:10:9\00") ], !dbg [[DBG10:![0-9]+]]
// AARCH64-NEXT:    call void @_Z3foov(), !dbg [[DBG10]]
// AARCH64-NEXT:    call void @llvm.directive.region.exit(token [[TMP1]]), !dbg [[DBG10]]
// AARCH64-NEXT:    [[TMP2:%.*]] = call i1 @llvm.directive.marker() [ "DIR.OSS"([9 x i8] c"TASKWAIT\00") ], !dbg [[DBG11:![0-9]+]]
// AARCH64-NEXT:    ret i32 0, !dbg [[DBG12:![0-9]+]]
//
//
// AARCH64-LABEL: define {{[^@]+}}@compute_dep
// AARCH64-SAME: (ptr [[RX:%.*]]) !dbg [[DBG13:![0-9]+]] {
// AARCH64-NEXT:  entry:
// AARCH64-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T:%.*]], align 8
// AARCH64-NEXT:    [[RX_ADDR:%.*]] = alloca ptr, align 8
// AARCH64-NEXT:    store ptr [[RX]], ptr [[RX_ADDR]], align 8
// AARCH64-NEXT:    [[TMP0:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 0
// AARCH64-NEXT:    store ptr [[RX]], ptr [[TMP0]], align 8
// AARCH64-NEXT:    [[TMP1:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 1
// AARCH64-NEXT:    store i64 4, ptr [[TMP1]], align 8
// AARCH64-NEXT:    [[TMP2:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 2
// AARCH64-NEXT:    store i64 0, ptr [[TMP2]], align 8
// AARCH64-NEXT:    [[TMP3:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 3
// AARCH64-NEXT:    store i64 4, ptr [[TMP3]], align 8
// AARCH64-NEXT:    [[TMP4:%.*]] = load [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], align 8
// AARCH64-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T]] [[TMP4]]
//
//
// AARCH64-LABEL: define {{[^@]+}}@compute_dep.1
// AARCH64-SAME: (ptr [[RX:%.*]]) !dbg [[DBG14:![0-9]+]] {
// AARCH64-NEXT:  entry:
// AARCH64-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T_0:%.*]], align 8
// AARCH64-NEXT:    [[RX_ADDR:%.*]] = alloca ptr, align 8
// AARCH64-NEXT:    store ptr [[RX]], ptr [[RX_ADDR]], align 8
// AARCH64-NEXT:    [[TMP0:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 0
// AARCH64-NEXT:    store ptr [[RX]], ptr [[TMP0]], align 8
// AARCH64-NEXT:    [[TMP1:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 1
// AARCH64-NEXT:    store i64 4, ptr [[TMP1]], align 8
// AARCH64-NEXT:    [[TMP2:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 2
// AARCH64-NEXT:    store i64 0, ptr [[TMP2]], align 8
// AARCH64-NEXT:    [[TMP3:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 3
// AARCH64-NEXT:    store i64 4, ptr [[TMP3]], align 8
// AARCH64-NEXT:    [[TMP4:%.*]] = load [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], align 8
// AARCH64-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T_0]] [[TMP4]]
//
