// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --function-signature --include-generated-funcs
// RUN: %clang_cc1 -triple x86_64-gnu-linux -verify -fompss-2 -disable-llvm-passes -ferror-limit 100 %s -S -emit-llvm -o - | FileCheck %s --check-prefixes=LIN64
// RUN: %clang_cc1 -triple ppc64 -verify -fompss-2 -disable-llvm-passes -ferror-limit 100 %s -S -emit-llvm -o - | FileCheck %s --check-prefixes=PPC64
// RUN: %clang_cc1 -triple aarch64 -verify -fompss-2 -disable-llvm-passes -ferror-limit 100 %s -S -emit-llvm -o - | FileCheck %s --check-prefixes=AARCH64
// expected-no-diagnostics

int v[10][20];
template<typename T>
void constants() {
  #pragma oss task in( { v[i][j], i = {0, 1, 2}, j={3, 4, 5} } )
  {}
}

template<typename T>
void nonconstants() {
  T lb1, ub1, step1;
  T lb2, ub2, step2;
  #pragma oss task in( { v[i][j], i = {lb1, lb1 + 1, lb1 + 2}, j={lb2, lb2 + 1, lb2 + 2} } )
  {}
}

void f() {
  constants<int>();
  nonconstants<int>();
  nonconstants<short>();
}

// LIN64-LABEL: define {{[^@]+}}@_Z1fv
// LIN64-SAME: () #[[ATTR0:[0-9]+]] !dbg [[DBG5:![0-9]+]] {
// LIN64-NEXT:  entry:
// LIN64-NEXT:    call void @_Z9constantsIiEvv(), !dbg [[DBG9:![0-9]+]]
// LIN64-NEXT:    call void @_Z12nonconstantsIiEvv(), !dbg [[DBG10:![0-9]+]]
// LIN64-NEXT:    call void @_Z12nonconstantsIsEvv(), !dbg [[DBG11:![0-9]+]]
// LIN64-NEXT:    ret void, !dbg [[DBG12:![0-9]+]]
//
//
// LIN64-LABEL: define {{[^@]+}}@_Z9constantsIiEvv
// LIN64-SAME: () #[[ATTR0]] comdat !dbg [[DBG13:![0-9]+]] {
// LIN64-NEXT:  entry:
// LIN64-NEXT:    [[I:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[J:%.*]] = alloca i32, align 4
// LIN64-NEXT:    store i32 0, ptr [[I]], align 4, !dbg [[DBG14:![0-9]+]]
// LIN64-NEXT:    store i32 0, ptr [[J]], align 4, !dbg [[DBG15:![0-9]+]]
// LIN64-NEXT:    [[TMP0:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OSS"([5 x i8] c"TASK\00"), "QUAL.OSS.SHARED"(ptr @v, [10 x [20 x i32]] undef), "QUAL.OSS.PRIVATE"(ptr [[I]], i32 undef), "QUAL.OSS.PRIVATE"(ptr [[J]], i32 undef), "QUAL.OSS.MULTIDEP.RANGE.IN"(ptr [[I]], ptr [[J]], ptr @compute_dep, ptr [[I]], ptr [[J]], ptr @v, [40 x i8] c"{ v[i][j], i = {0, 1, 2}, j={3, 4, 5} }\00", ptr @compute_dep.2, ptr [[I]], ptr [[J]], ptr @v) ], !dbg [[DBG16:![0-9]+]]
// LIN64-NEXT:    call void @llvm.directive.region.exit(token [[TMP0]]), !dbg [[DBG17:![0-9]+]]
// LIN64-NEXT:    ret void, !dbg [[DBG18:![0-9]+]]
//
//
// LIN64-LABEL: define {{[^@]+}}@_Z12nonconstantsIiEvv
// LIN64-SAME: () #[[ATTR0]] comdat !dbg [[DBG19:![0-9]+]] {
// LIN64-NEXT:  entry:
// LIN64-NEXT:    [[LB1:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[UB1:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[STEP1:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[LB2:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[UB2:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[STEP2:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[I:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[J:%.*]] = alloca i32, align 4
// LIN64-NEXT:    store i32 0, ptr [[I]], align 4, !dbg [[DBG20:![0-9]+]]
// LIN64-NEXT:    store i32 0, ptr [[J]], align 4, !dbg [[DBG21:![0-9]+]]
// LIN64-NEXT:    [[TMP0:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OSS"([5 x i8] c"TASK\00"), "QUAL.OSS.SHARED"(ptr @v, [10 x [20 x i32]] undef), "QUAL.OSS.PRIVATE"(ptr [[I]], i32 undef), "QUAL.OSS.PRIVATE"(ptr [[J]], i32 undef), "QUAL.OSS.FIRSTPRIVATE"(ptr [[LB1]], i32 undef), "QUAL.OSS.FIRSTPRIVATE"(ptr [[LB2]], i32 undef), "QUAL.OSS.MULTIDEP.RANGE.IN"(ptr [[I]], ptr [[J]], ptr @compute_dep.3, ptr [[I]], ptr [[LB1]], ptr [[J]], ptr [[LB2]], ptr @v, [68 x i8] c"{ v[i][j], i = {lb1, lb1 + 1, lb1 + 2}, j={lb2, lb2 + 1, lb2 + 2} }\00", ptr @compute_dep.4, ptr [[I]], ptr [[J]], ptr [[LB1]], ptr [[LB2]], ptr @v) ], !dbg [[DBG22:![0-9]+]]
// LIN64-NEXT:    call void @llvm.directive.region.exit(token [[TMP0]]), !dbg [[DBG23:![0-9]+]]
// LIN64-NEXT:    ret void, !dbg [[DBG24:![0-9]+]]
//
//
// LIN64-LABEL: define {{[^@]+}}@_Z12nonconstantsIsEvv
// LIN64-SAME: () #[[ATTR0]] comdat !dbg [[DBG25:![0-9]+]] {
// LIN64-NEXT:  entry:
// LIN64-NEXT:    [[LB1:%.*]] = alloca i16, align 2
// LIN64-NEXT:    [[UB1:%.*]] = alloca i16, align 2
// LIN64-NEXT:    [[STEP1:%.*]] = alloca i16, align 2
// LIN64-NEXT:    [[LB2:%.*]] = alloca i16, align 2
// LIN64-NEXT:    [[UB2:%.*]] = alloca i16, align 2
// LIN64-NEXT:    [[STEP2:%.*]] = alloca i16, align 2
// LIN64-NEXT:    [[I:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[J:%.*]] = alloca i32, align 4
// LIN64-NEXT:    store i32 0, ptr [[I]], align 4, !dbg [[DBG26:![0-9]+]]
// LIN64-NEXT:    store i32 0, ptr [[J]], align 4, !dbg [[DBG27:![0-9]+]]
// LIN64-NEXT:    [[TMP0:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OSS"([5 x i8] c"TASK\00"), "QUAL.OSS.SHARED"(ptr @v, [10 x [20 x i32]] undef), "QUAL.OSS.PRIVATE"(ptr [[I]], i32 undef), "QUAL.OSS.PRIVATE"(ptr [[J]], i32 undef), "QUAL.OSS.FIRSTPRIVATE"(ptr [[LB1]], i16 undef), "QUAL.OSS.FIRSTPRIVATE"(ptr [[LB2]], i16 undef), "QUAL.OSS.MULTIDEP.RANGE.IN"(ptr [[I]], ptr [[J]], ptr @compute_dep.5, ptr [[I]], ptr [[LB1]], ptr [[J]], ptr [[LB2]], ptr @v, [68 x i8] c"{ v[i][j], i = {lb1, lb1 + 1, lb1 + 2}, j={lb2, lb2 + 1, lb2 + 2} }\00", ptr @compute_dep.6, ptr [[I]], ptr [[J]], ptr [[LB1]], ptr [[LB2]], ptr @v) ], !dbg [[DBG28:![0-9]+]]
// LIN64-NEXT:    call void @llvm.directive.region.exit(token [[TMP0]]), !dbg [[DBG29:![0-9]+]]
// LIN64-NEXT:    ret void, !dbg [[DBG30:![0-9]+]]
//
//
// LIN64-LABEL: define {{[^@]+}}@compute_dep
// LIN64-SAME: (ptr [[I:%.*]], ptr [[J:%.*]], i64 [[TMP0:%.*]]) #[[ATTR2:[0-9]+]] !dbg [[DBG31:![0-9]+]] {
// LIN64-NEXT:  entry:
// LIN64-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T:%.*]], align 4
// LIN64-NEXT:    [[I_ADDR:%.*]] = alloca ptr, align 8
// LIN64-NEXT:    [[J_ADDR:%.*]] = alloca ptr, align 8
// LIN64-NEXT:    [[DOTADDR:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[DISCRETE_ARRAY:%.*]] = alloca [3 x i32], align 4
// LIN64-NEXT:    [[DISCRETE_ARRAY1:%.*]] = alloca [3 x i32], align 4
// LIN64-NEXT:    store ptr [[I]], ptr [[I_ADDR]], align 8
// LIN64-NEXT:    store ptr [[J]], ptr [[J_ADDR]], align 8
// LIN64-NEXT:    store i64 [[TMP0]], ptr [[DOTADDR]], align 8
// LIN64-NEXT:    switch i64 [[TMP0]], label [[TMP3:%.*]] [
// LIN64-NEXT:    i64 0, label [[TMP4:%.*]]
// LIN64-NEXT:    i64 1, label [[TMP11:%.*]]
// LIN64-NEXT:    ]
// LIN64:       1:
// LIN64-NEXT:    [[TMP2:%.*]] = load [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], align 4, !dbg [[DBG33:![0-9]+]]
// LIN64-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T]] [[TMP2]], !dbg [[DBG33]]
// LIN64:       3:
// LIN64-NEXT:    br label [[TMP1:%.*]]
// LIN64:       4:
// LIN64-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 4 [[DISCRETE_ARRAY]], ptr align 4 @__const._Z9constantsIiEvv.discrete.array, i64 12, i1 false), !dbg [[DBG35:![0-9]+]]
// LIN64-NEXT:    [[TMP5:%.*]] = load i32, ptr [[I]], align 4, !dbg [[DBG36:![0-9]+]]
// LIN64-NEXT:    [[DISCRETEIDX:%.*]] = getelementptr [3 x i32], ptr [[DISCRETE_ARRAY]], i32 0, i32 [[TMP5]]
// LIN64-NEXT:    [[TMP6:%.*]] = load i32, ptr [[DISCRETEIDX]], align 4
// LIN64-NEXT:    [[TMP7:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 0
// LIN64-NEXT:    store i32 0, ptr [[TMP7]], align 4
// LIN64-NEXT:    [[TMP8:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 1
// LIN64-NEXT:    store i32 [[TMP6]], ptr [[TMP8]], align 4
// LIN64-NEXT:    [[TMP9:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 2
// LIN64-NEXT:    store i32 2, ptr [[TMP9]], align 4
// LIN64-NEXT:    [[TMP10:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 3
// LIN64-NEXT:    store i32 1, ptr [[TMP10]], align 4
// LIN64-NEXT:    br label [[TMP1]]
// LIN64:       11:
// LIN64-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 4 [[DISCRETE_ARRAY1]], ptr align 4 @__const._Z9constantsIiEvv.discrete.array.1, i64 12, i1 false), !dbg [[DBG37:![0-9]+]]
// LIN64-NEXT:    [[TMP12:%.*]] = load i32, ptr [[J]], align 4, !dbg [[DBG33]]
// LIN64-NEXT:    [[DISCRETEIDX2:%.*]] = getelementptr [3 x i32], ptr [[DISCRETE_ARRAY1]], i32 0, i32 [[TMP12]]
// LIN64-NEXT:    [[TMP13:%.*]] = load i32, ptr [[DISCRETEIDX2]], align 4
// LIN64-NEXT:    [[TMP14:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 4
// LIN64-NEXT:    store i32 0, ptr [[TMP14]], align 4
// LIN64-NEXT:    [[TMP15:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 5
// LIN64-NEXT:    store i32 [[TMP13]], ptr [[TMP15]], align 4
// LIN64-NEXT:    [[TMP16:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 6
// LIN64-NEXT:    store i32 2, ptr [[TMP16]], align 4
// LIN64-NEXT:    [[TMP17:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 7
// LIN64-NEXT:    store i32 1, ptr [[TMP17]], align 4
// LIN64-NEXT:    br label [[TMP1]]
//
//
// LIN64-LABEL: define {{[^@]+}}@compute_dep.2
// LIN64-SAME: (ptr [[I:%.*]], ptr [[J:%.*]], ptr [[V:%.*]]) #[[ATTR2]] !dbg [[DBG38:![0-9]+]] {
// LIN64-NEXT:  entry:
// LIN64-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T_0:%.*]], align 8
// LIN64-NEXT:    [[I_ADDR:%.*]] = alloca ptr, align 8
// LIN64-NEXT:    [[J_ADDR:%.*]] = alloca ptr, align 8
// LIN64-NEXT:    [[V_ADDR:%.*]] = alloca ptr, align 8
// LIN64-NEXT:    store ptr [[I]], ptr [[I_ADDR]], align 8
// LIN64-NEXT:    store ptr [[J]], ptr [[J_ADDR]], align 8
// LIN64-NEXT:    store ptr [[V]], ptr [[V_ADDR]], align 8
// LIN64-NEXT:    [[TMP0:%.*]] = load i32, ptr [[J]], align 4, !dbg [[DBG39:![0-9]+]]
// LIN64-NEXT:    [[TMP1:%.*]] = sext i32 [[TMP0]] to i64
// LIN64-NEXT:    [[TMP2:%.*]] = add i64 [[TMP1]], 1
// LIN64-NEXT:    [[TMP3:%.*]] = load i32, ptr [[I]], align 4, !dbg [[DBG41:![0-9]+]]
// LIN64-NEXT:    [[TMP4:%.*]] = sext i32 [[TMP3]] to i64
// LIN64-NEXT:    [[TMP5:%.*]] = add i64 [[TMP4]], 1
// LIN64-NEXT:    [[ARRAYDECAY:%.*]] = getelementptr inbounds [10 x [20 x i32]], ptr [[V]], i64 0, i64 0, !dbg [[DBG42:![0-9]+]]
// LIN64-NEXT:    [[TMP6:%.*]] = mul i64 [[TMP1]], 4
// LIN64-NEXT:    [[TMP7:%.*]] = mul i64 [[TMP2]], 4
// LIN64-NEXT:    [[TMP8:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 0
// LIN64-NEXT:    store ptr [[ARRAYDECAY]], ptr [[TMP8]], align 8
// LIN64-NEXT:    [[TMP9:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 1
// LIN64-NEXT:    store i64 80, ptr [[TMP9]], align 8
// LIN64-NEXT:    [[TMP10:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 2
// LIN64-NEXT:    store i64 [[TMP6]], ptr [[TMP10]], align 8
// LIN64-NEXT:    [[TMP11:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 3
// LIN64-NEXT:    store i64 [[TMP7]], ptr [[TMP11]], align 8
// LIN64-NEXT:    [[TMP12:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 4
// LIN64-NEXT:    store i64 10, ptr [[TMP12]], align 8
// LIN64-NEXT:    [[TMP13:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 5
// LIN64-NEXT:    store i64 [[TMP4]], ptr [[TMP13]], align 8
// LIN64-NEXT:    [[TMP14:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 6
// LIN64-NEXT:    store i64 [[TMP5]], ptr [[TMP14]], align 8
// LIN64-NEXT:    [[TMP15:%.*]] = load [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], align 8, !dbg [[DBG42]]
// LIN64-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T_0]] [[TMP15]], !dbg [[DBG42]]
//
//
// LIN64-LABEL: define {{[^@]+}}@compute_dep.3
// LIN64-SAME: (ptr [[I:%.*]], ptr [[LB1:%.*]], ptr [[J:%.*]], ptr [[LB2:%.*]], i64 [[TMP0:%.*]]) #[[ATTR2]] !dbg [[DBG43:![0-9]+]] {
// LIN64-NEXT:  entry:
// LIN64-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T_1:%.*]], align 4
// LIN64-NEXT:    [[I_ADDR:%.*]] = alloca ptr, align 8
// LIN64-NEXT:    [[LB1_ADDR:%.*]] = alloca ptr, align 8
// LIN64-NEXT:    [[J_ADDR:%.*]] = alloca ptr, align 8
// LIN64-NEXT:    [[LB2_ADDR:%.*]] = alloca ptr, align 8
// LIN64-NEXT:    [[DOTADDR:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[DISCRETE_ARRAY:%.*]] = alloca [3 x i32], align 4
// LIN64-NEXT:    [[DISCRETE_ARRAY3:%.*]] = alloca [3 x i32], align 4
// LIN64-NEXT:    store ptr [[I]], ptr [[I_ADDR]], align 8
// LIN64-NEXT:    store ptr [[LB1]], ptr [[LB1_ADDR]], align 8
// LIN64-NEXT:    store ptr [[J]], ptr [[J_ADDR]], align 8
// LIN64-NEXT:    store ptr [[LB2]], ptr [[LB2_ADDR]], align 8
// LIN64-NEXT:    store i64 [[TMP0]], ptr [[DOTADDR]], align 8
// LIN64-NEXT:    switch i64 [[TMP0]], label [[TMP3:%.*]] [
// LIN64-NEXT:    i64 0, label [[TMP4:%.*]]
// LIN64-NEXT:    i64 1, label [[TMP14:%.*]]
// LIN64-NEXT:    ]
// LIN64:       1:
// LIN64-NEXT:    [[TMP2:%.*]] = load [[STRUCT__DEPEND_UNPACK_T_1]], ptr [[RETVAL]], align 4, !dbg [[DBG44:![0-9]+]]
// LIN64-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T_1]] [[TMP2]], !dbg [[DBG44]]
// LIN64:       3:
// LIN64-NEXT:    br label [[TMP1:%.*]]
// LIN64:       4:
// LIN64-NEXT:    [[ARRAYINIT_BEGIN:%.*]] = getelementptr inbounds [3 x i32], ptr [[DISCRETE_ARRAY]], i64 0, i64 0, !dbg [[DBG46:![0-9]+]]
// LIN64-NEXT:    [[TMP5:%.*]] = load i32, ptr [[LB1]], align 4, !dbg [[DBG47:![0-9]+]]
// LIN64-NEXT:    store i32 [[TMP5]], ptr [[ARRAYINIT_BEGIN]], align 4, !dbg [[DBG46]]
// LIN64-NEXT:    [[ARRAYINIT_ELEMENT:%.*]] = getelementptr inbounds i32, ptr [[ARRAYINIT_BEGIN]], i64 1, !dbg [[DBG46]]
// LIN64-NEXT:    [[TMP6:%.*]] = load i32, ptr [[LB1]], align 4, !dbg [[DBG48:![0-9]+]]
// LIN64-NEXT:    [[ADD:%.*]] = add nsw i32 [[TMP6]], 1, !dbg [[DBG49:![0-9]+]]
// LIN64-NEXT:    store i32 [[ADD]], ptr [[ARRAYINIT_ELEMENT]], align 4, !dbg [[DBG46]]
// LIN64-NEXT:    [[ARRAYINIT_ELEMENT1:%.*]] = getelementptr inbounds i32, ptr [[ARRAYINIT_ELEMENT]], i64 1, !dbg [[DBG46]]
// LIN64-NEXT:    [[TMP7:%.*]] = load i32, ptr [[LB1]], align 4, !dbg [[DBG50:![0-9]+]]
// LIN64-NEXT:    [[ADD2:%.*]] = add nsw i32 [[TMP7]], 2, !dbg [[DBG51:![0-9]+]]
// LIN64-NEXT:    store i32 [[ADD2]], ptr [[ARRAYINIT_ELEMENT1]], align 4, !dbg [[DBG46]]
// LIN64-NEXT:    [[TMP8:%.*]] = load i32, ptr [[I]], align 4, !dbg [[DBG52:![0-9]+]]
// LIN64-NEXT:    [[DISCRETEIDX:%.*]] = getelementptr [3 x i32], ptr [[DISCRETE_ARRAY]], i32 0, i32 [[TMP8]]
// LIN64-NEXT:    [[TMP9:%.*]] = load i32, ptr [[DISCRETEIDX]], align 4
// LIN64-NEXT:    [[TMP10:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_1]], ptr [[RETVAL]], i32 0, i32 0
// LIN64-NEXT:    store i32 0, ptr [[TMP10]], align 4
// LIN64-NEXT:    [[TMP11:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_1]], ptr [[RETVAL]], i32 0, i32 1
// LIN64-NEXT:    store i32 [[TMP9]], ptr [[TMP11]], align 4
// LIN64-NEXT:    [[TMP12:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_1]], ptr [[RETVAL]], i32 0, i32 2
// LIN64-NEXT:    store i32 2, ptr [[TMP12]], align 4
// LIN64-NEXT:    [[TMP13:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_1]], ptr [[RETVAL]], i32 0, i32 3
// LIN64-NEXT:    store i32 1, ptr [[TMP13]], align 4
// LIN64-NEXT:    br label [[TMP1]]
// LIN64:       14:
// LIN64-NEXT:    [[ARRAYINIT_BEGIN4:%.*]] = getelementptr inbounds [3 x i32], ptr [[DISCRETE_ARRAY3]], i64 0, i64 0, !dbg [[DBG53:![0-9]+]]
// LIN64-NEXT:    [[TMP15:%.*]] = load i32, ptr [[LB2]], align 4, !dbg [[DBG54:![0-9]+]]
// LIN64-NEXT:    store i32 [[TMP15]], ptr [[ARRAYINIT_BEGIN4]], align 4, !dbg [[DBG53]]
// LIN64-NEXT:    [[ARRAYINIT_ELEMENT5:%.*]] = getelementptr inbounds i32, ptr [[ARRAYINIT_BEGIN4]], i64 1, !dbg [[DBG53]]
// LIN64-NEXT:    [[TMP16:%.*]] = load i32, ptr [[LB2]], align 4, !dbg [[DBG55:![0-9]+]]
// LIN64-NEXT:    [[ADD6:%.*]] = add nsw i32 [[TMP16]], 1, !dbg [[DBG56:![0-9]+]]
// LIN64-NEXT:    store i32 [[ADD6]], ptr [[ARRAYINIT_ELEMENT5]], align 4, !dbg [[DBG53]]
// LIN64-NEXT:    [[ARRAYINIT_ELEMENT7:%.*]] = getelementptr inbounds i32, ptr [[ARRAYINIT_ELEMENT5]], i64 1, !dbg [[DBG53]]
// LIN64-NEXT:    [[TMP17:%.*]] = load i32, ptr [[LB2]], align 4, !dbg [[DBG57:![0-9]+]]
// LIN64-NEXT:    [[ADD8:%.*]] = add nsw i32 [[TMP17]], 2, !dbg [[DBG58:![0-9]+]]
// LIN64-NEXT:    store i32 [[ADD8]], ptr [[ARRAYINIT_ELEMENT7]], align 4, !dbg [[DBG53]]
// LIN64-NEXT:    [[TMP18:%.*]] = load i32, ptr [[J]], align 4, !dbg [[DBG44]]
// LIN64-NEXT:    [[DISCRETEIDX9:%.*]] = getelementptr [3 x i32], ptr [[DISCRETE_ARRAY3]], i32 0, i32 [[TMP18]]
// LIN64-NEXT:    [[TMP19:%.*]] = load i32, ptr [[DISCRETEIDX9]], align 4
// LIN64-NEXT:    [[TMP20:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_1]], ptr [[RETVAL]], i32 0, i32 4
// LIN64-NEXT:    store i32 0, ptr [[TMP20]], align 4
// LIN64-NEXT:    [[TMP21:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_1]], ptr [[RETVAL]], i32 0, i32 5
// LIN64-NEXT:    store i32 [[TMP19]], ptr [[TMP21]], align 4
// LIN64-NEXT:    [[TMP22:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_1]], ptr [[RETVAL]], i32 0, i32 6
// LIN64-NEXT:    store i32 2, ptr [[TMP22]], align 4
// LIN64-NEXT:    [[TMP23:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_1]], ptr [[RETVAL]], i32 0, i32 7
// LIN64-NEXT:    store i32 1, ptr [[TMP23]], align 4
// LIN64-NEXT:    br label [[TMP1]]
//
//
// LIN64-LABEL: define {{[^@]+}}@compute_dep.4
// LIN64-SAME: (ptr [[I:%.*]], ptr [[J:%.*]], ptr [[LB1:%.*]], ptr [[LB2:%.*]], ptr [[V:%.*]]) #[[ATTR2]] !dbg [[DBG59:![0-9]+]] {
// LIN64-NEXT:  entry:
// LIN64-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T_2:%.*]], align 8
// LIN64-NEXT:    [[I_ADDR:%.*]] = alloca ptr, align 8
// LIN64-NEXT:    [[J_ADDR:%.*]] = alloca ptr, align 8
// LIN64-NEXT:    [[LB1_ADDR:%.*]] = alloca ptr, align 8
// LIN64-NEXT:    [[LB2_ADDR:%.*]] = alloca ptr, align 8
// LIN64-NEXT:    [[V_ADDR:%.*]] = alloca ptr, align 8
// LIN64-NEXT:    store ptr [[I]], ptr [[I_ADDR]], align 8
// LIN64-NEXT:    store ptr [[J]], ptr [[J_ADDR]], align 8
// LIN64-NEXT:    store ptr [[LB1]], ptr [[LB1_ADDR]], align 8
// LIN64-NEXT:    store ptr [[LB2]], ptr [[LB2_ADDR]], align 8
// LIN64-NEXT:    store ptr [[V]], ptr [[V_ADDR]], align 8
// LIN64-NEXT:    [[TMP0:%.*]] = load i32, ptr [[J]], align 4, !dbg [[DBG60:![0-9]+]]
// LIN64-NEXT:    [[TMP1:%.*]] = sext i32 [[TMP0]] to i64
// LIN64-NEXT:    [[TMP2:%.*]] = add i64 [[TMP1]], 1
// LIN64-NEXT:    [[TMP3:%.*]] = load i32, ptr [[I]], align 4, !dbg [[DBG62:![0-9]+]]
// LIN64-NEXT:    [[TMP4:%.*]] = sext i32 [[TMP3]] to i64
// LIN64-NEXT:    [[TMP5:%.*]] = add i64 [[TMP4]], 1
// LIN64-NEXT:    [[ARRAYDECAY:%.*]] = getelementptr inbounds [10 x [20 x i32]], ptr [[V]], i64 0, i64 0, !dbg [[DBG63:![0-9]+]]
// LIN64-NEXT:    [[TMP6:%.*]] = mul i64 [[TMP1]], 4
// LIN64-NEXT:    [[TMP7:%.*]] = mul i64 [[TMP2]], 4
// LIN64-NEXT:    [[TMP8:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_2]], ptr [[RETVAL]], i32 0, i32 0
// LIN64-NEXT:    store ptr [[ARRAYDECAY]], ptr [[TMP8]], align 8
// LIN64-NEXT:    [[TMP9:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_2]], ptr [[RETVAL]], i32 0, i32 1
// LIN64-NEXT:    store i64 80, ptr [[TMP9]], align 8
// LIN64-NEXT:    [[TMP10:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_2]], ptr [[RETVAL]], i32 0, i32 2
// LIN64-NEXT:    store i64 [[TMP6]], ptr [[TMP10]], align 8
// LIN64-NEXT:    [[TMP11:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_2]], ptr [[RETVAL]], i32 0, i32 3
// LIN64-NEXT:    store i64 [[TMP7]], ptr [[TMP11]], align 8
// LIN64-NEXT:    [[TMP12:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_2]], ptr [[RETVAL]], i32 0, i32 4
// LIN64-NEXT:    store i64 10, ptr [[TMP12]], align 8
// LIN64-NEXT:    [[TMP13:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_2]], ptr [[RETVAL]], i32 0, i32 5
// LIN64-NEXT:    store i64 [[TMP4]], ptr [[TMP13]], align 8
// LIN64-NEXT:    [[TMP14:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_2]], ptr [[RETVAL]], i32 0, i32 6
// LIN64-NEXT:    store i64 [[TMP5]], ptr [[TMP14]], align 8
// LIN64-NEXT:    [[TMP15:%.*]] = load [[STRUCT__DEPEND_UNPACK_T_2]], ptr [[RETVAL]], align 8, !dbg [[DBG63]]
// LIN64-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T_2]] [[TMP15]], !dbg [[DBG63]]
//
//
// LIN64-LABEL: define {{[^@]+}}@compute_dep.5
// LIN64-SAME: (ptr [[I:%.*]], ptr [[LB1:%.*]], ptr [[J:%.*]], ptr [[LB2:%.*]], i64 [[TMP0:%.*]]) #[[ATTR2]] !dbg [[DBG64:![0-9]+]] {
// LIN64-NEXT:  entry:
// LIN64-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T_3:%.*]], align 4
// LIN64-NEXT:    [[I_ADDR:%.*]] = alloca ptr, align 8
// LIN64-NEXT:    [[LB1_ADDR:%.*]] = alloca ptr, align 8
// LIN64-NEXT:    [[J_ADDR:%.*]] = alloca ptr, align 8
// LIN64-NEXT:    [[LB2_ADDR:%.*]] = alloca ptr, align 8
// LIN64-NEXT:    [[DOTADDR:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[DISCRETE_ARRAY:%.*]] = alloca [3 x i32], align 4
// LIN64-NEXT:    [[DISCRETE_ARRAY5:%.*]] = alloca [3 x i32], align 4
// LIN64-NEXT:    store ptr [[I]], ptr [[I_ADDR]], align 8
// LIN64-NEXT:    store ptr [[LB1]], ptr [[LB1_ADDR]], align 8
// LIN64-NEXT:    store ptr [[J]], ptr [[J_ADDR]], align 8
// LIN64-NEXT:    store ptr [[LB2]], ptr [[LB2_ADDR]], align 8
// LIN64-NEXT:    store i64 [[TMP0]], ptr [[DOTADDR]], align 8
// LIN64-NEXT:    switch i64 [[TMP0]], label [[TMP3:%.*]] [
// LIN64-NEXT:    i64 0, label [[TMP4:%.*]]
// LIN64-NEXT:    i64 1, label [[TMP14:%.*]]
// LIN64-NEXT:    ]
// LIN64:       1:
// LIN64-NEXT:    [[TMP2:%.*]] = load [[STRUCT__DEPEND_UNPACK_T_3]], ptr [[RETVAL]], align 4, !dbg [[DBG65:![0-9]+]]
// LIN64-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T_3]] [[TMP2]], !dbg [[DBG65]]
// LIN64:       3:
// LIN64-NEXT:    br label [[TMP1:%.*]]
// LIN64:       4:
// LIN64-NEXT:    [[ARRAYINIT_BEGIN:%.*]] = getelementptr inbounds [3 x i32], ptr [[DISCRETE_ARRAY]], i64 0, i64 0, !dbg [[DBG67:![0-9]+]]
// LIN64-NEXT:    [[TMP5:%.*]] = load i16, ptr [[LB1]], align 2, !dbg [[DBG68:![0-9]+]]
// LIN64-NEXT:    [[CONV:%.*]] = sext i16 [[TMP5]] to i32, !dbg [[DBG68]]
// LIN64-NEXT:    store i32 [[CONV]], ptr [[ARRAYINIT_BEGIN]], align 4, !dbg [[DBG67]]
// LIN64-NEXT:    [[ARRAYINIT_ELEMENT:%.*]] = getelementptr inbounds i32, ptr [[ARRAYINIT_BEGIN]], i64 1, !dbg [[DBG67]]
// LIN64-NEXT:    [[TMP6:%.*]] = load i16, ptr [[LB1]], align 2, !dbg [[DBG69:![0-9]+]]
// LIN64-NEXT:    [[CONV1:%.*]] = sext i16 [[TMP6]] to i32, !dbg [[DBG69]]
// LIN64-NEXT:    [[ADD:%.*]] = add nsw i32 [[CONV1]], 1, !dbg [[DBG70:![0-9]+]]
// LIN64-NEXT:    store i32 [[ADD]], ptr [[ARRAYINIT_ELEMENT]], align 4, !dbg [[DBG67]]
// LIN64-NEXT:    [[ARRAYINIT_ELEMENT2:%.*]] = getelementptr inbounds i32, ptr [[ARRAYINIT_ELEMENT]], i64 1, !dbg [[DBG67]]
// LIN64-NEXT:    [[TMP7:%.*]] = load i16, ptr [[LB1]], align 2, !dbg [[DBG71:![0-9]+]]
// LIN64-NEXT:    [[CONV3:%.*]] = sext i16 [[TMP7]] to i32, !dbg [[DBG71]]
// LIN64-NEXT:    [[ADD4:%.*]] = add nsw i32 [[CONV3]], 2, !dbg [[DBG72:![0-9]+]]
// LIN64-NEXT:    store i32 [[ADD4]], ptr [[ARRAYINIT_ELEMENT2]], align 4, !dbg [[DBG67]]
// LIN64-NEXT:    [[TMP8:%.*]] = load i32, ptr [[I]], align 4, !dbg [[DBG73:![0-9]+]]
// LIN64-NEXT:    [[DISCRETEIDX:%.*]] = getelementptr [3 x i32], ptr [[DISCRETE_ARRAY]], i32 0, i32 [[TMP8]]
// LIN64-NEXT:    [[TMP9:%.*]] = load i32, ptr [[DISCRETEIDX]], align 4
// LIN64-NEXT:    [[TMP10:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_3]], ptr [[RETVAL]], i32 0, i32 0
// LIN64-NEXT:    store i32 0, ptr [[TMP10]], align 4
// LIN64-NEXT:    [[TMP11:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_3]], ptr [[RETVAL]], i32 0, i32 1
// LIN64-NEXT:    store i32 [[TMP9]], ptr [[TMP11]], align 4
// LIN64-NEXT:    [[TMP12:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_3]], ptr [[RETVAL]], i32 0, i32 2
// LIN64-NEXT:    store i32 2, ptr [[TMP12]], align 4
// LIN64-NEXT:    [[TMP13:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_3]], ptr [[RETVAL]], i32 0, i32 3
// LIN64-NEXT:    store i32 1, ptr [[TMP13]], align 4
// LIN64-NEXT:    br label [[TMP1]]
// LIN64:       14:
// LIN64-NEXT:    [[ARRAYINIT_BEGIN6:%.*]] = getelementptr inbounds [3 x i32], ptr [[DISCRETE_ARRAY5]], i64 0, i64 0, !dbg [[DBG74:![0-9]+]]
// LIN64-NEXT:    [[TMP15:%.*]] = load i16, ptr [[LB2]], align 2, !dbg [[DBG75:![0-9]+]]
// LIN64-NEXT:    [[CONV7:%.*]] = sext i16 [[TMP15]] to i32, !dbg [[DBG75]]
// LIN64-NEXT:    store i32 [[CONV7]], ptr [[ARRAYINIT_BEGIN6]], align 4, !dbg [[DBG74]]
// LIN64-NEXT:    [[ARRAYINIT_ELEMENT8:%.*]] = getelementptr inbounds i32, ptr [[ARRAYINIT_BEGIN6]], i64 1, !dbg [[DBG74]]
// LIN64-NEXT:    [[TMP16:%.*]] = load i16, ptr [[LB2]], align 2, !dbg [[DBG76:![0-9]+]]
// LIN64-NEXT:    [[CONV9:%.*]] = sext i16 [[TMP16]] to i32, !dbg [[DBG76]]
// LIN64-NEXT:    [[ADD10:%.*]] = add nsw i32 [[CONV9]], 1, !dbg [[DBG77:![0-9]+]]
// LIN64-NEXT:    store i32 [[ADD10]], ptr [[ARRAYINIT_ELEMENT8]], align 4, !dbg [[DBG74]]
// LIN64-NEXT:    [[ARRAYINIT_ELEMENT11:%.*]] = getelementptr inbounds i32, ptr [[ARRAYINIT_ELEMENT8]], i64 1, !dbg [[DBG74]]
// LIN64-NEXT:    [[TMP17:%.*]] = load i16, ptr [[LB2]], align 2, !dbg [[DBG78:![0-9]+]]
// LIN64-NEXT:    [[CONV12:%.*]] = sext i16 [[TMP17]] to i32, !dbg [[DBG78]]
// LIN64-NEXT:    [[ADD13:%.*]] = add nsw i32 [[CONV12]], 2, !dbg [[DBG79:![0-9]+]]
// LIN64-NEXT:    store i32 [[ADD13]], ptr [[ARRAYINIT_ELEMENT11]], align 4, !dbg [[DBG74]]
// LIN64-NEXT:    [[TMP18:%.*]] = load i32, ptr [[J]], align 4, !dbg [[DBG65]]
// LIN64-NEXT:    [[DISCRETEIDX14:%.*]] = getelementptr [3 x i32], ptr [[DISCRETE_ARRAY5]], i32 0, i32 [[TMP18]]
// LIN64-NEXT:    [[TMP19:%.*]] = load i32, ptr [[DISCRETEIDX14]], align 4
// LIN64-NEXT:    [[TMP20:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_3]], ptr [[RETVAL]], i32 0, i32 4
// LIN64-NEXT:    store i32 0, ptr [[TMP20]], align 4
// LIN64-NEXT:    [[TMP21:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_3]], ptr [[RETVAL]], i32 0, i32 5
// LIN64-NEXT:    store i32 [[TMP19]], ptr [[TMP21]], align 4
// LIN64-NEXT:    [[TMP22:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_3]], ptr [[RETVAL]], i32 0, i32 6
// LIN64-NEXT:    store i32 2, ptr [[TMP22]], align 4
// LIN64-NEXT:    [[TMP23:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_3]], ptr [[RETVAL]], i32 0, i32 7
// LIN64-NEXT:    store i32 1, ptr [[TMP23]], align 4
// LIN64-NEXT:    br label [[TMP1]]
//
//
// LIN64-LABEL: define {{[^@]+}}@compute_dep.6
// LIN64-SAME: (ptr [[I:%.*]], ptr [[J:%.*]], ptr [[LB1:%.*]], ptr [[LB2:%.*]], ptr [[V:%.*]]) #[[ATTR2]] !dbg [[DBG80:![0-9]+]] {
// LIN64-NEXT:  entry:
// LIN64-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T_4:%.*]], align 8
// LIN64-NEXT:    [[I_ADDR:%.*]] = alloca ptr, align 8
// LIN64-NEXT:    [[J_ADDR:%.*]] = alloca ptr, align 8
// LIN64-NEXT:    [[LB1_ADDR:%.*]] = alloca ptr, align 8
// LIN64-NEXT:    [[LB2_ADDR:%.*]] = alloca ptr, align 8
// LIN64-NEXT:    [[V_ADDR:%.*]] = alloca ptr, align 8
// LIN64-NEXT:    store ptr [[I]], ptr [[I_ADDR]], align 8
// LIN64-NEXT:    store ptr [[J]], ptr [[J_ADDR]], align 8
// LIN64-NEXT:    store ptr [[LB1]], ptr [[LB1_ADDR]], align 8
// LIN64-NEXT:    store ptr [[LB2]], ptr [[LB2_ADDR]], align 8
// LIN64-NEXT:    store ptr [[V]], ptr [[V_ADDR]], align 8
// LIN64-NEXT:    [[TMP0:%.*]] = load i32, ptr [[J]], align 4, !dbg [[DBG81:![0-9]+]]
// LIN64-NEXT:    [[TMP1:%.*]] = sext i32 [[TMP0]] to i64
// LIN64-NEXT:    [[TMP2:%.*]] = add i64 [[TMP1]], 1
// LIN64-NEXT:    [[TMP3:%.*]] = load i32, ptr [[I]], align 4, !dbg [[DBG83:![0-9]+]]
// LIN64-NEXT:    [[TMP4:%.*]] = sext i32 [[TMP3]] to i64
// LIN64-NEXT:    [[TMP5:%.*]] = add i64 [[TMP4]], 1
// LIN64-NEXT:    [[ARRAYDECAY:%.*]] = getelementptr inbounds [10 x [20 x i32]], ptr [[V]], i64 0, i64 0, !dbg [[DBG84:![0-9]+]]
// LIN64-NEXT:    [[TMP6:%.*]] = mul i64 [[TMP1]], 4
// LIN64-NEXT:    [[TMP7:%.*]] = mul i64 [[TMP2]], 4
// LIN64-NEXT:    [[TMP8:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_4]], ptr [[RETVAL]], i32 0, i32 0
// LIN64-NEXT:    store ptr [[ARRAYDECAY]], ptr [[TMP8]], align 8
// LIN64-NEXT:    [[TMP9:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_4]], ptr [[RETVAL]], i32 0, i32 1
// LIN64-NEXT:    store i64 80, ptr [[TMP9]], align 8
// LIN64-NEXT:    [[TMP10:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_4]], ptr [[RETVAL]], i32 0, i32 2
// LIN64-NEXT:    store i64 [[TMP6]], ptr [[TMP10]], align 8
// LIN64-NEXT:    [[TMP11:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_4]], ptr [[RETVAL]], i32 0, i32 3
// LIN64-NEXT:    store i64 [[TMP7]], ptr [[TMP11]], align 8
// LIN64-NEXT:    [[TMP12:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_4]], ptr [[RETVAL]], i32 0, i32 4
// LIN64-NEXT:    store i64 10, ptr [[TMP12]], align 8
// LIN64-NEXT:    [[TMP13:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_4]], ptr [[RETVAL]], i32 0, i32 5
// LIN64-NEXT:    store i64 [[TMP4]], ptr [[TMP13]], align 8
// LIN64-NEXT:    [[TMP14:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_4]], ptr [[RETVAL]], i32 0, i32 6
// LIN64-NEXT:    store i64 [[TMP5]], ptr [[TMP14]], align 8
// LIN64-NEXT:    [[TMP15:%.*]] = load [[STRUCT__DEPEND_UNPACK_T_4]], ptr [[RETVAL]], align 8, !dbg [[DBG84]]
// LIN64-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T_4]] [[TMP15]], !dbg [[DBG84]]
//
//
// PPC64-LABEL: define {{[^@]+}}@_Z1fv
// PPC64-SAME: () #[[ATTR0:[0-9]+]] !dbg [[DBG5:![0-9]+]] {
// PPC64-NEXT:  entry:
// PPC64-NEXT:    call void @_Z9constantsIiEvv(), !dbg [[DBG9:![0-9]+]]
// PPC64-NEXT:    call void @_Z12nonconstantsIiEvv(), !dbg [[DBG10:![0-9]+]]
// PPC64-NEXT:    call void @_Z12nonconstantsIsEvv(), !dbg [[DBG11:![0-9]+]]
// PPC64-NEXT:    ret void, !dbg [[DBG12:![0-9]+]]
//
//
// PPC64-LABEL: define {{[^@]+}}@_Z9constantsIiEvv
// PPC64-SAME: () #[[ATTR0]] comdat !dbg [[DBG13:![0-9]+]] {
// PPC64-NEXT:  entry:
// PPC64-NEXT:    [[I:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[J:%.*]] = alloca i32, align 4
// PPC64-NEXT:    store i32 0, ptr [[I]], align 4, !dbg [[DBG14:![0-9]+]]
// PPC64-NEXT:    store i32 0, ptr [[J]], align 4, !dbg [[DBG15:![0-9]+]]
// PPC64-NEXT:    [[TMP0:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OSS"([5 x i8] c"TASK\00"), "QUAL.OSS.SHARED"(ptr @v, [10 x [20 x i32]] undef), "QUAL.OSS.PRIVATE"(ptr [[I]], i32 undef), "QUAL.OSS.PRIVATE"(ptr [[J]], i32 undef), "QUAL.OSS.MULTIDEP.RANGE.IN"(ptr [[I]], ptr [[J]], ptr @compute_dep, ptr [[I]], ptr [[J]], ptr @v, [40 x i8] c"{ v[i][j], i = {0, 1, 2}, j={3, 4, 5} }\00", ptr @compute_dep.2, ptr [[I]], ptr [[J]], ptr @v) ], !dbg [[DBG16:![0-9]+]]
// PPC64-NEXT:    call void @llvm.directive.region.exit(token [[TMP0]]), !dbg [[DBG17:![0-9]+]]
// PPC64-NEXT:    ret void, !dbg [[DBG18:![0-9]+]]
//
//
// PPC64-LABEL: define {{[^@]+}}@_Z12nonconstantsIiEvv
// PPC64-SAME: () #[[ATTR0]] comdat !dbg [[DBG19:![0-9]+]] {
// PPC64-NEXT:  entry:
// PPC64-NEXT:    [[LB1:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[UB1:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[STEP1:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[LB2:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[UB2:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[STEP2:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[I:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[J:%.*]] = alloca i32, align 4
// PPC64-NEXT:    store i32 0, ptr [[I]], align 4, !dbg [[DBG20:![0-9]+]]
// PPC64-NEXT:    store i32 0, ptr [[J]], align 4, !dbg [[DBG21:![0-9]+]]
// PPC64-NEXT:    [[TMP0:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OSS"([5 x i8] c"TASK\00"), "QUAL.OSS.SHARED"(ptr @v, [10 x [20 x i32]] undef), "QUAL.OSS.PRIVATE"(ptr [[I]], i32 undef), "QUAL.OSS.PRIVATE"(ptr [[J]], i32 undef), "QUAL.OSS.FIRSTPRIVATE"(ptr [[LB1]], i32 undef), "QUAL.OSS.FIRSTPRIVATE"(ptr [[LB2]], i32 undef), "QUAL.OSS.MULTIDEP.RANGE.IN"(ptr [[I]], ptr [[J]], ptr @compute_dep.3, ptr [[I]], ptr [[LB1]], ptr [[J]], ptr [[LB2]], ptr @v, [68 x i8] c"{ v[i][j], i = {lb1, lb1 + 1, lb1 + 2}, j={lb2, lb2 + 1, lb2 + 2} }\00", ptr @compute_dep.4, ptr [[I]], ptr [[J]], ptr [[LB1]], ptr [[LB2]], ptr @v) ], !dbg [[DBG22:![0-9]+]]
// PPC64-NEXT:    call void @llvm.directive.region.exit(token [[TMP0]]), !dbg [[DBG23:![0-9]+]]
// PPC64-NEXT:    ret void, !dbg [[DBG24:![0-9]+]]
//
//
// PPC64-LABEL: define {{[^@]+}}@_Z12nonconstantsIsEvv
// PPC64-SAME: () #[[ATTR0]] comdat !dbg [[DBG25:![0-9]+]] {
// PPC64-NEXT:  entry:
// PPC64-NEXT:    [[LB1:%.*]] = alloca i16, align 2
// PPC64-NEXT:    [[UB1:%.*]] = alloca i16, align 2
// PPC64-NEXT:    [[STEP1:%.*]] = alloca i16, align 2
// PPC64-NEXT:    [[LB2:%.*]] = alloca i16, align 2
// PPC64-NEXT:    [[UB2:%.*]] = alloca i16, align 2
// PPC64-NEXT:    [[STEP2:%.*]] = alloca i16, align 2
// PPC64-NEXT:    [[I:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[J:%.*]] = alloca i32, align 4
// PPC64-NEXT:    store i32 0, ptr [[I]], align 4, !dbg [[DBG26:![0-9]+]]
// PPC64-NEXT:    store i32 0, ptr [[J]], align 4, !dbg [[DBG27:![0-9]+]]
// PPC64-NEXT:    [[TMP0:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OSS"([5 x i8] c"TASK\00"), "QUAL.OSS.SHARED"(ptr @v, [10 x [20 x i32]] undef), "QUAL.OSS.PRIVATE"(ptr [[I]], i32 undef), "QUAL.OSS.PRIVATE"(ptr [[J]], i32 undef), "QUAL.OSS.FIRSTPRIVATE"(ptr [[LB1]], i16 undef), "QUAL.OSS.FIRSTPRIVATE"(ptr [[LB2]], i16 undef), "QUAL.OSS.MULTIDEP.RANGE.IN"(ptr [[I]], ptr [[J]], ptr @compute_dep.5, ptr [[I]], ptr [[LB1]], ptr [[J]], ptr [[LB2]], ptr @v, [68 x i8] c"{ v[i][j], i = {lb1, lb1 + 1, lb1 + 2}, j={lb2, lb2 + 1, lb2 + 2} }\00", ptr @compute_dep.6, ptr [[I]], ptr [[J]], ptr [[LB1]], ptr [[LB2]], ptr @v) ], !dbg [[DBG28:![0-9]+]]
// PPC64-NEXT:    call void @llvm.directive.region.exit(token [[TMP0]]), !dbg [[DBG29:![0-9]+]]
// PPC64-NEXT:    ret void, !dbg [[DBG30:![0-9]+]]
//
//
// PPC64-LABEL: define {{[^@]+}}@compute_dep
// PPC64-SAME: (ptr [[I:%.*]], ptr [[J:%.*]], i64 [[TMP0:%.*]]) !dbg [[DBG31:![0-9]+]] {
// PPC64-NEXT:  entry:
// PPC64-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T:%.*]], align 4
// PPC64-NEXT:    [[I_ADDR:%.*]] = alloca ptr, align 8
// PPC64-NEXT:    [[J_ADDR:%.*]] = alloca ptr, align 8
// PPC64-NEXT:    [[DOTADDR:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[DISCRETE_ARRAY:%.*]] = alloca [3 x i32], align 4
// PPC64-NEXT:    [[DISCRETE_ARRAY1:%.*]] = alloca [3 x i32], align 4
// PPC64-NEXT:    store ptr [[I]], ptr [[I_ADDR]], align 8
// PPC64-NEXT:    store ptr [[J]], ptr [[J_ADDR]], align 8
// PPC64-NEXT:    store i64 [[TMP0]], ptr [[DOTADDR]], align 8
// PPC64-NEXT:    switch i64 [[TMP0]], label [[TMP3:%.*]] [
// PPC64-NEXT:    i64 0, label [[TMP4:%.*]]
// PPC64-NEXT:    i64 1, label [[TMP11:%.*]]
// PPC64-NEXT:    ]
// PPC64:       1:
// PPC64-NEXT:    [[TMP2:%.*]] = load [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], align 4, !dbg [[DBG33:![0-9]+]]
// PPC64-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T]] [[TMP2]], !dbg [[DBG33]]
// PPC64:       3:
// PPC64-NEXT:    br label [[TMP1:%.*]]
// PPC64:       4:
// PPC64-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 4 [[DISCRETE_ARRAY]], ptr align 4 @__const._Z9constantsIiEvv.discrete.array, i64 12, i1 false), !dbg [[DBG35:![0-9]+]]
// PPC64-NEXT:    [[TMP5:%.*]] = load i32, ptr [[I]], align 4, !dbg [[DBG36:![0-9]+]]
// PPC64-NEXT:    [[DISCRETEIDX:%.*]] = getelementptr [3 x i32], ptr [[DISCRETE_ARRAY]], i32 0, i32 [[TMP5]]
// PPC64-NEXT:    [[TMP6:%.*]] = load i32, ptr [[DISCRETEIDX]], align 4
// PPC64-NEXT:    [[TMP7:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 0
// PPC64-NEXT:    store i32 0, ptr [[TMP7]], align 4
// PPC64-NEXT:    [[TMP8:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 1
// PPC64-NEXT:    store i32 [[TMP6]], ptr [[TMP8]], align 4
// PPC64-NEXT:    [[TMP9:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 2
// PPC64-NEXT:    store i32 2, ptr [[TMP9]], align 4
// PPC64-NEXT:    [[TMP10:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 3
// PPC64-NEXT:    store i32 1, ptr [[TMP10]], align 4
// PPC64-NEXT:    br label [[TMP1]]
// PPC64:       11:
// PPC64-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 4 [[DISCRETE_ARRAY1]], ptr align 4 @__const._Z9constantsIiEvv.discrete.array.1, i64 12, i1 false), !dbg [[DBG37:![0-9]+]]
// PPC64-NEXT:    [[TMP12:%.*]] = load i32, ptr [[J]], align 4, !dbg [[DBG33]]
// PPC64-NEXT:    [[DISCRETEIDX2:%.*]] = getelementptr [3 x i32], ptr [[DISCRETE_ARRAY1]], i32 0, i32 [[TMP12]]
// PPC64-NEXT:    [[TMP13:%.*]] = load i32, ptr [[DISCRETEIDX2]], align 4
// PPC64-NEXT:    [[TMP14:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 4
// PPC64-NEXT:    store i32 0, ptr [[TMP14]], align 4
// PPC64-NEXT:    [[TMP15:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 5
// PPC64-NEXT:    store i32 [[TMP13]], ptr [[TMP15]], align 4
// PPC64-NEXT:    [[TMP16:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 6
// PPC64-NEXT:    store i32 2, ptr [[TMP16]], align 4
// PPC64-NEXT:    [[TMP17:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 7
// PPC64-NEXT:    store i32 1, ptr [[TMP17]], align 4
// PPC64-NEXT:    br label [[TMP1]]
//
//
// PPC64-LABEL: define {{[^@]+}}@compute_dep.2
// PPC64-SAME: (ptr [[I:%.*]], ptr [[J:%.*]], ptr [[V:%.*]]) !dbg [[DBG38:![0-9]+]] {
// PPC64-NEXT:  entry:
// PPC64-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T_0:%.*]], align 8
// PPC64-NEXT:    [[I_ADDR:%.*]] = alloca ptr, align 8
// PPC64-NEXT:    [[J_ADDR:%.*]] = alloca ptr, align 8
// PPC64-NEXT:    [[V_ADDR:%.*]] = alloca ptr, align 8
// PPC64-NEXT:    store ptr [[I]], ptr [[I_ADDR]], align 8
// PPC64-NEXT:    store ptr [[J]], ptr [[J_ADDR]], align 8
// PPC64-NEXT:    store ptr [[V]], ptr [[V_ADDR]], align 8
// PPC64-NEXT:    [[TMP0:%.*]] = load i32, ptr [[J]], align 4, !dbg [[DBG39:![0-9]+]]
// PPC64-NEXT:    [[TMP1:%.*]] = sext i32 [[TMP0]] to i64
// PPC64-NEXT:    [[TMP2:%.*]] = add i64 [[TMP1]], 1
// PPC64-NEXT:    [[TMP3:%.*]] = load i32, ptr [[I]], align 4, !dbg [[DBG41:![0-9]+]]
// PPC64-NEXT:    [[TMP4:%.*]] = sext i32 [[TMP3]] to i64
// PPC64-NEXT:    [[TMP5:%.*]] = add i64 [[TMP4]], 1
// PPC64-NEXT:    [[ARRAYDECAY:%.*]] = getelementptr inbounds [10 x [20 x i32]], ptr [[V]], i64 0, i64 0, !dbg [[DBG42:![0-9]+]]
// PPC64-NEXT:    [[TMP6:%.*]] = mul i64 [[TMP1]], 4
// PPC64-NEXT:    [[TMP7:%.*]] = mul i64 [[TMP2]], 4
// PPC64-NEXT:    [[TMP8:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 0
// PPC64-NEXT:    store ptr [[ARRAYDECAY]], ptr [[TMP8]], align 8
// PPC64-NEXT:    [[TMP9:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 1
// PPC64-NEXT:    store i64 80, ptr [[TMP9]], align 8
// PPC64-NEXT:    [[TMP10:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 2
// PPC64-NEXT:    store i64 [[TMP6]], ptr [[TMP10]], align 8
// PPC64-NEXT:    [[TMP11:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 3
// PPC64-NEXT:    store i64 [[TMP7]], ptr [[TMP11]], align 8
// PPC64-NEXT:    [[TMP12:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 4
// PPC64-NEXT:    store i64 10, ptr [[TMP12]], align 8
// PPC64-NEXT:    [[TMP13:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 5
// PPC64-NEXT:    store i64 [[TMP4]], ptr [[TMP13]], align 8
// PPC64-NEXT:    [[TMP14:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 6
// PPC64-NEXT:    store i64 [[TMP5]], ptr [[TMP14]], align 8
// PPC64-NEXT:    [[TMP15:%.*]] = load [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], align 8, !dbg [[DBG42]]
// PPC64-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T_0]] [[TMP15]], !dbg [[DBG42]]
//
//
// PPC64-LABEL: define {{[^@]+}}@compute_dep.3
// PPC64-SAME: (ptr [[I:%.*]], ptr [[LB1:%.*]], ptr [[J:%.*]], ptr [[LB2:%.*]], i64 [[TMP0:%.*]]) !dbg [[DBG43:![0-9]+]] {
// PPC64-NEXT:  entry:
// PPC64-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T_1:%.*]], align 4
// PPC64-NEXT:    [[I_ADDR:%.*]] = alloca ptr, align 8
// PPC64-NEXT:    [[LB1_ADDR:%.*]] = alloca ptr, align 8
// PPC64-NEXT:    [[J_ADDR:%.*]] = alloca ptr, align 8
// PPC64-NEXT:    [[LB2_ADDR:%.*]] = alloca ptr, align 8
// PPC64-NEXT:    [[DOTADDR:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[DISCRETE_ARRAY:%.*]] = alloca [3 x i32], align 4
// PPC64-NEXT:    [[DISCRETE_ARRAY3:%.*]] = alloca [3 x i32], align 4
// PPC64-NEXT:    store ptr [[I]], ptr [[I_ADDR]], align 8
// PPC64-NEXT:    store ptr [[LB1]], ptr [[LB1_ADDR]], align 8
// PPC64-NEXT:    store ptr [[J]], ptr [[J_ADDR]], align 8
// PPC64-NEXT:    store ptr [[LB2]], ptr [[LB2_ADDR]], align 8
// PPC64-NEXT:    store i64 [[TMP0]], ptr [[DOTADDR]], align 8
// PPC64-NEXT:    switch i64 [[TMP0]], label [[TMP3:%.*]] [
// PPC64-NEXT:    i64 0, label [[TMP4:%.*]]
// PPC64-NEXT:    i64 1, label [[TMP14:%.*]]
// PPC64-NEXT:    ]
// PPC64:       1:
// PPC64-NEXT:    [[TMP2:%.*]] = load [[STRUCT__DEPEND_UNPACK_T_1]], ptr [[RETVAL]], align 4, !dbg [[DBG44:![0-9]+]]
// PPC64-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T_1]] [[TMP2]], !dbg [[DBG44]]
// PPC64:       3:
// PPC64-NEXT:    br label [[TMP1:%.*]]
// PPC64:       4:
// PPC64-NEXT:    [[ARRAYINIT_BEGIN:%.*]] = getelementptr inbounds [3 x i32], ptr [[DISCRETE_ARRAY]], i64 0, i64 0, !dbg [[DBG46:![0-9]+]]
// PPC64-NEXT:    [[TMP5:%.*]] = load i32, ptr [[LB1]], align 4, !dbg [[DBG47:![0-9]+]]
// PPC64-NEXT:    store i32 [[TMP5]], ptr [[ARRAYINIT_BEGIN]], align 4, !dbg [[DBG46]]
// PPC64-NEXT:    [[ARRAYINIT_ELEMENT:%.*]] = getelementptr inbounds i32, ptr [[ARRAYINIT_BEGIN]], i64 1, !dbg [[DBG46]]
// PPC64-NEXT:    [[TMP6:%.*]] = load i32, ptr [[LB1]], align 4, !dbg [[DBG48:![0-9]+]]
// PPC64-NEXT:    [[ADD:%.*]] = add nsw i32 [[TMP6]], 1, !dbg [[DBG49:![0-9]+]]
// PPC64-NEXT:    store i32 [[ADD]], ptr [[ARRAYINIT_ELEMENT]], align 4, !dbg [[DBG46]]
// PPC64-NEXT:    [[ARRAYINIT_ELEMENT1:%.*]] = getelementptr inbounds i32, ptr [[ARRAYINIT_ELEMENT]], i64 1, !dbg [[DBG46]]
// PPC64-NEXT:    [[TMP7:%.*]] = load i32, ptr [[LB1]], align 4, !dbg [[DBG50:![0-9]+]]
// PPC64-NEXT:    [[ADD2:%.*]] = add nsw i32 [[TMP7]], 2, !dbg [[DBG51:![0-9]+]]
// PPC64-NEXT:    store i32 [[ADD2]], ptr [[ARRAYINIT_ELEMENT1]], align 4, !dbg [[DBG46]]
// PPC64-NEXT:    [[TMP8:%.*]] = load i32, ptr [[I]], align 4, !dbg [[DBG52:![0-9]+]]
// PPC64-NEXT:    [[DISCRETEIDX:%.*]] = getelementptr [3 x i32], ptr [[DISCRETE_ARRAY]], i32 0, i32 [[TMP8]]
// PPC64-NEXT:    [[TMP9:%.*]] = load i32, ptr [[DISCRETEIDX]], align 4
// PPC64-NEXT:    [[TMP10:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_1]], ptr [[RETVAL]], i32 0, i32 0
// PPC64-NEXT:    store i32 0, ptr [[TMP10]], align 4
// PPC64-NEXT:    [[TMP11:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_1]], ptr [[RETVAL]], i32 0, i32 1
// PPC64-NEXT:    store i32 [[TMP9]], ptr [[TMP11]], align 4
// PPC64-NEXT:    [[TMP12:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_1]], ptr [[RETVAL]], i32 0, i32 2
// PPC64-NEXT:    store i32 2, ptr [[TMP12]], align 4
// PPC64-NEXT:    [[TMP13:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_1]], ptr [[RETVAL]], i32 0, i32 3
// PPC64-NEXT:    store i32 1, ptr [[TMP13]], align 4
// PPC64-NEXT:    br label [[TMP1]]
// PPC64:       14:
// PPC64-NEXT:    [[ARRAYINIT_BEGIN4:%.*]] = getelementptr inbounds [3 x i32], ptr [[DISCRETE_ARRAY3]], i64 0, i64 0, !dbg [[DBG53:![0-9]+]]
// PPC64-NEXT:    [[TMP15:%.*]] = load i32, ptr [[LB2]], align 4, !dbg [[DBG54:![0-9]+]]
// PPC64-NEXT:    store i32 [[TMP15]], ptr [[ARRAYINIT_BEGIN4]], align 4, !dbg [[DBG53]]
// PPC64-NEXT:    [[ARRAYINIT_ELEMENT5:%.*]] = getelementptr inbounds i32, ptr [[ARRAYINIT_BEGIN4]], i64 1, !dbg [[DBG53]]
// PPC64-NEXT:    [[TMP16:%.*]] = load i32, ptr [[LB2]], align 4, !dbg [[DBG55:![0-9]+]]
// PPC64-NEXT:    [[ADD6:%.*]] = add nsw i32 [[TMP16]], 1, !dbg [[DBG56:![0-9]+]]
// PPC64-NEXT:    store i32 [[ADD6]], ptr [[ARRAYINIT_ELEMENT5]], align 4, !dbg [[DBG53]]
// PPC64-NEXT:    [[ARRAYINIT_ELEMENT7:%.*]] = getelementptr inbounds i32, ptr [[ARRAYINIT_ELEMENT5]], i64 1, !dbg [[DBG53]]
// PPC64-NEXT:    [[TMP17:%.*]] = load i32, ptr [[LB2]], align 4, !dbg [[DBG57:![0-9]+]]
// PPC64-NEXT:    [[ADD8:%.*]] = add nsw i32 [[TMP17]], 2, !dbg [[DBG58:![0-9]+]]
// PPC64-NEXT:    store i32 [[ADD8]], ptr [[ARRAYINIT_ELEMENT7]], align 4, !dbg [[DBG53]]
// PPC64-NEXT:    [[TMP18:%.*]] = load i32, ptr [[J]], align 4, !dbg [[DBG44]]
// PPC64-NEXT:    [[DISCRETEIDX9:%.*]] = getelementptr [3 x i32], ptr [[DISCRETE_ARRAY3]], i32 0, i32 [[TMP18]]
// PPC64-NEXT:    [[TMP19:%.*]] = load i32, ptr [[DISCRETEIDX9]], align 4
// PPC64-NEXT:    [[TMP20:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_1]], ptr [[RETVAL]], i32 0, i32 4
// PPC64-NEXT:    store i32 0, ptr [[TMP20]], align 4
// PPC64-NEXT:    [[TMP21:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_1]], ptr [[RETVAL]], i32 0, i32 5
// PPC64-NEXT:    store i32 [[TMP19]], ptr [[TMP21]], align 4
// PPC64-NEXT:    [[TMP22:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_1]], ptr [[RETVAL]], i32 0, i32 6
// PPC64-NEXT:    store i32 2, ptr [[TMP22]], align 4
// PPC64-NEXT:    [[TMP23:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_1]], ptr [[RETVAL]], i32 0, i32 7
// PPC64-NEXT:    store i32 1, ptr [[TMP23]], align 4
// PPC64-NEXT:    br label [[TMP1]]
//
//
// PPC64-LABEL: define {{[^@]+}}@compute_dep.4
// PPC64-SAME: (ptr [[I:%.*]], ptr [[J:%.*]], ptr [[LB1:%.*]], ptr [[LB2:%.*]], ptr [[V:%.*]]) !dbg [[DBG59:![0-9]+]] {
// PPC64-NEXT:  entry:
// PPC64-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T_2:%.*]], align 8
// PPC64-NEXT:    [[I_ADDR:%.*]] = alloca ptr, align 8
// PPC64-NEXT:    [[J_ADDR:%.*]] = alloca ptr, align 8
// PPC64-NEXT:    [[LB1_ADDR:%.*]] = alloca ptr, align 8
// PPC64-NEXT:    [[LB2_ADDR:%.*]] = alloca ptr, align 8
// PPC64-NEXT:    [[V_ADDR:%.*]] = alloca ptr, align 8
// PPC64-NEXT:    store ptr [[I]], ptr [[I_ADDR]], align 8
// PPC64-NEXT:    store ptr [[J]], ptr [[J_ADDR]], align 8
// PPC64-NEXT:    store ptr [[LB1]], ptr [[LB1_ADDR]], align 8
// PPC64-NEXT:    store ptr [[LB2]], ptr [[LB2_ADDR]], align 8
// PPC64-NEXT:    store ptr [[V]], ptr [[V_ADDR]], align 8
// PPC64-NEXT:    [[TMP0:%.*]] = load i32, ptr [[J]], align 4, !dbg [[DBG60:![0-9]+]]
// PPC64-NEXT:    [[TMP1:%.*]] = sext i32 [[TMP0]] to i64
// PPC64-NEXT:    [[TMP2:%.*]] = add i64 [[TMP1]], 1
// PPC64-NEXT:    [[TMP3:%.*]] = load i32, ptr [[I]], align 4, !dbg [[DBG62:![0-9]+]]
// PPC64-NEXT:    [[TMP4:%.*]] = sext i32 [[TMP3]] to i64
// PPC64-NEXT:    [[TMP5:%.*]] = add i64 [[TMP4]], 1
// PPC64-NEXT:    [[ARRAYDECAY:%.*]] = getelementptr inbounds [10 x [20 x i32]], ptr [[V]], i64 0, i64 0, !dbg [[DBG63:![0-9]+]]
// PPC64-NEXT:    [[TMP6:%.*]] = mul i64 [[TMP1]], 4
// PPC64-NEXT:    [[TMP7:%.*]] = mul i64 [[TMP2]], 4
// PPC64-NEXT:    [[TMP8:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_2]], ptr [[RETVAL]], i32 0, i32 0
// PPC64-NEXT:    store ptr [[ARRAYDECAY]], ptr [[TMP8]], align 8
// PPC64-NEXT:    [[TMP9:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_2]], ptr [[RETVAL]], i32 0, i32 1
// PPC64-NEXT:    store i64 80, ptr [[TMP9]], align 8
// PPC64-NEXT:    [[TMP10:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_2]], ptr [[RETVAL]], i32 0, i32 2
// PPC64-NEXT:    store i64 [[TMP6]], ptr [[TMP10]], align 8
// PPC64-NEXT:    [[TMP11:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_2]], ptr [[RETVAL]], i32 0, i32 3
// PPC64-NEXT:    store i64 [[TMP7]], ptr [[TMP11]], align 8
// PPC64-NEXT:    [[TMP12:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_2]], ptr [[RETVAL]], i32 0, i32 4
// PPC64-NEXT:    store i64 10, ptr [[TMP12]], align 8
// PPC64-NEXT:    [[TMP13:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_2]], ptr [[RETVAL]], i32 0, i32 5
// PPC64-NEXT:    store i64 [[TMP4]], ptr [[TMP13]], align 8
// PPC64-NEXT:    [[TMP14:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_2]], ptr [[RETVAL]], i32 0, i32 6
// PPC64-NEXT:    store i64 [[TMP5]], ptr [[TMP14]], align 8
// PPC64-NEXT:    [[TMP15:%.*]] = load [[STRUCT__DEPEND_UNPACK_T_2]], ptr [[RETVAL]], align 8, !dbg [[DBG63]]
// PPC64-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T_2]] [[TMP15]], !dbg [[DBG63]]
//
//
// PPC64-LABEL: define {{[^@]+}}@compute_dep.5
// PPC64-SAME: (ptr [[I:%.*]], ptr [[LB1:%.*]], ptr [[J:%.*]], ptr [[LB2:%.*]], i64 [[TMP0:%.*]]) !dbg [[DBG64:![0-9]+]] {
// PPC64-NEXT:  entry:
// PPC64-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T_3:%.*]], align 4
// PPC64-NEXT:    [[I_ADDR:%.*]] = alloca ptr, align 8
// PPC64-NEXT:    [[LB1_ADDR:%.*]] = alloca ptr, align 8
// PPC64-NEXT:    [[J_ADDR:%.*]] = alloca ptr, align 8
// PPC64-NEXT:    [[LB2_ADDR:%.*]] = alloca ptr, align 8
// PPC64-NEXT:    [[DOTADDR:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[DISCRETE_ARRAY:%.*]] = alloca [3 x i32], align 4
// PPC64-NEXT:    [[DISCRETE_ARRAY5:%.*]] = alloca [3 x i32], align 4
// PPC64-NEXT:    store ptr [[I]], ptr [[I_ADDR]], align 8
// PPC64-NEXT:    store ptr [[LB1]], ptr [[LB1_ADDR]], align 8
// PPC64-NEXT:    store ptr [[J]], ptr [[J_ADDR]], align 8
// PPC64-NEXT:    store ptr [[LB2]], ptr [[LB2_ADDR]], align 8
// PPC64-NEXT:    store i64 [[TMP0]], ptr [[DOTADDR]], align 8
// PPC64-NEXT:    switch i64 [[TMP0]], label [[TMP3:%.*]] [
// PPC64-NEXT:    i64 0, label [[TMP4:%.*]]
// PPC64-NEXT:    i64 1, label [[TMP14:%.*]]
// PPC64-NEXT:    ]
// PPC64:       1:
// PPC64-NEXT:    [[TMP2:%.*]] = load [[STRUCT__DEPEND_UNPACK_T_3]], ptr [[RETVAL]], align 4, !dbg [[DBG65:![0-9]+]]
// PPC64-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T_3]] [[TMP2]], !dbg [[DBG65]]
// PPC64:       3:
// PPC64-NEXT:    br label [[TMP1:%.*]]
// PPC64:       4:
// PPC64-NEXT:    [[ARRAYINIT_BEGIN:%.*]] = getelementptr inbounds [3 x i32], ptr [[DISCRETE_ARRAY]], i64 0, i64 0, !dbg [[DBG67:![0-9]+]]
// PPC64-NEXT:    [[TMP5:%.*]] = load i16, ptr [[LB1]], align 2, !dbg [[DBG68:![0-9]+]]
// PPC64-NEXT:    [[CONV:%.*]] = sext i16 [[TMP5]] to i32, !dbg [[DBG68]]
// PPC64-NEXT:    store i32 [[CONV]], ptr [[ARRAYINIT_BEGIN]], align 4, !dbg [[DBG67]]
// PPC64-NEXT:    [[ARRAYINIT_ELEMENT:%.*]] = getelementptr inbounds i32, ptr [[ARRAYINIT_BEGIN]], i64 1, !dbg [[DBG67]]
// PPC64-NEXT:    [[TMP6:%.*]] = load i16, ptr [[LB1]], align 2, !dbg [[DBG69:![0-9]+]]
// PPC64-NEXT:    [[CONV1:%.*]] = sext i16 [[TMP6]] to i32, !dbg [[DBG69]]
// PPC64-NEXT:    [[ADD:%.*]] = add nsw i32 [[CONV1]], 1, !dbg [[DBG70:![0-9]+]]
// PPC64-NEXT:    store i32 [[ADD]], ptr [[ARRAYINIT_ELEMENT]], align 4, !dbg [[DBG67]]
// PPC64-NEXT:    [[ARRAYINIT_ELEMENT2:%.*]] = getelementptr inbounds i32, ptr [[ARRAYINIT_ELEMENT]], i64 1, !dbg [[DBG67]]
// PPC64-NEXT:    [[TMP7:%.*]] = load i16, ptr [[LB1]], align 2, !dbg [[DBG71:![0-9]+]]
// PPC64-NEXT:    [[CONV3:%.*]] = sext i16 [[TMP7]] to i32, !dbg [[DBG71]]
// PPC64-NEXT:    [[ADD4:%.*]] = add nsw i32 [[CONV3]], 2, !dbg [[DBG72:![0-9]+]]
// PPC64-NEXT:    store i32 [[ADD4]], ptr [[ARRAYINIT_ELEMENT2]], align 4, !dbg [[DBG67]]
// PPC64-NEXT:    [[TMP8:%.*]] = load i32, ptr [[I]], align 4, !dbg [[DBG73:![0-9]+]]
// PPC64-NEXT:    [[DISCRETEIDX:%.*]] = getelementptr [3 x i32], ptr [[DISCRETE_ARRAY]], i32 0, i32 [[TMP8]]
// PPC64-NEXT:    [[TMP9:%.*]] = load i32, ptr [[DISCRETEIDX]], align 4
// PPC64-NEXT:    [[TMP10:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_3]], ptr [[RETVAL]], i32 0, i32 0
// PPC64-NEXT:    store i32 0, ptr [[TMP10]], align 4
// PPC64-NEXT:    [[TMP11:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_3]], ptr [[RETVAL]], i32 0, i32 1
// PPC64-NEXT:    store i32 [[TMP9]], ptr [[TMP11]], align 4
// PPC64-NEXT:    [[TMP12:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_3]], ptr [[RETVAL]], i32 0, i32 2
// PPC64-NEXT:    store i32 2, ptr [[TMP12]], align 4
// PPC64-NEXT:    [[TMP13:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_3]], ptr [[RETVAL]], i32 0, i32 3
// PPC64-NEXT:    store i32 1, ptr [[TMP13]], align 4
// PPC64-NEXT:    br label [[TMP1]]
// PPC64:       14:
// PPC64-NEXT:    [[ARRAYINIT_BEGIN6:%.*]] = getelementptr inbounds [3 x i32], ptr [[DISCRETE_ARRAY5]], i64 0, i64 0, !dbg [[DBG74:![0-9]+]]
// PPC64-NEXT:    [[TMP15:%.*]] = load i16, ptr [[LB2]], align 2, !dbg [[DBG75:![0-9]+]]
// PPC64-NEXT:    [[CONV7:%.*]] = sext i16 [[TMP15]] to i32, !dbg [[DBG75]]
// PPC64-NEXT:    store i32 [[CONV7]], ptr [[ARRAYINIT_BEGIN6]], align 4, !dbg [[DBG74]]
// PPC64-NEXT:    [[ARRAYINIT_ELEMENT8:%.*]] = getelementptr inbounds i32, ptr [[ARRAYINIT_BEGIN6]], i64 1, !dbg [[DBG74]]
// PPC64-NEXT:    [[TMP16:%.*]] = load i16, ptr [[LB2]], align 2, !dbg [[DBG76:![0-9]+]]
// PPC64-NEXT:    [[CONV9:%.*]] = sext i16 [[TMP16]] to i32, !dbg [[DBG76]]
// PPC64-NEXT:    [[ADD10:%.*]] = add nsw i32 [[CONV9]], 1, !dbg [[DBG77:![0-9]+]]
// PPC64-NEXT:    store i32 [[ADD10]], ptr [[ARRAYINIT_ELEMENT8]], align 4, !dbg [[DBG74]]
// PPC64-NEXT:    [[ARRAYINIT_ELEMENT11:%.*]] = getelementptr inbounds i32, ptr [[ARRAYINIT_ELEMENT8]], i64 1, !dbg [[DBG74]]
// PPC64-NEXT:    [[TMP17:%.*]] = load i16, ptr [[LB2]], align 2, !dbg [[DBG78:![0-9]+]]
// PPC64-NEXT:    [[CONV12:%.*]] = sext i16 [[TMP17]] to i32, !dbg [[DBG78]]
// PPC64-NEXT:    [[ADD13:%.*]] = add nsw i32 [[CONV12]], 2, !dbg [[DBG79:![0-9]+]]
// PPC64-NEXT:    store i32 [[ADD13]], ptr [[ARRAYINIT_ELEMENT11]], align 4, !dbg [[DBG74]]
// PPC64-NEXT:    [[TMP18:%.*]] = load i32, ptr [[J]], align 4, !dbg [[DBG65]]
// PPC64-NEXT:    [[DISCRETEIDX14:%.*]] = getelementptr [3 x i32], ptr [[DISCRETE_ARRAY5]], i32 0, i32 [[TMP18]]
// PPC64-NEXT:    [[TMP19:%.*]] = load i32, ptr [[DISCRETEIDX14]], align 4
// PPC64-NEXT:    [[TMP20:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_3]], ptr [[RETVAL]], i32 0, i32 4
// PPC64-NEXT:    store i32 0, ptr [[TMP20]], align 4
// PPC64-NEXT:    [[TMP21:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_3]], ptr [[RETVAL]], i32 0, i32 5
// PPC64-NEXT:    store i32 [[TMP19]], ptr [[TMP21]], align 4
// PPC64-NEXT:    [[TMP22:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_3]], ptr [[RETVAL]], i32 0, i32 6
// PPC64-NEXT:    store i32 2, ptr [[TMP22]], align 4
// PPC64-NEXT:    [[TMP23:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_3]], ptr [[RETVAL]], i32 0, i32 7
// PPC64-NEXT:    store i32 1, ptr [[TMP23]], align 4
// PPC64-NEXT:    br label [[TMP1]]
//
//
// PPC64-LABEL: define {{[^@]+}}@compute_dep.6
// PPC64-SAME: (ptr [[I:%.*]], ptr [[J:%.*]], ptr [[LB1:%.*]], ptr [[LB2:%.*]], ptr [[V:%.*]]) !dbg [[DBG80:![0-9]+]] {
// PPC64-NEXT:  entry:
// PPC64-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T_4:%.*]], align 8
// PPC64-NEXT:    [[I_ADDR:%.*]] = alloca ptr, align 8
// PPC64-NEXT:    [[J_ADDR:%.*]] = alloca ptr, align 8
// PPC64-NEXT:    [[LB1_ADDR:%.*]] = alloca ptr, align 8
// PPC64-NEXT:    [[LB2_ADDR:%.*]] = alloca ptr, align 8
// PPC64-NEXT:    [[V_ADDR:%.*]] = alloca ptr, align 8
// PPC64-NEXT:    store ptr [[I]], ptr [[I_ADDR]], align 8
// PPC64-NEXT:    store ptr [[J]], ptr [[J_ADDR]], align 8
// PPC64-NEXT:    store ptr [[LB1]], ptr [[LB1_ADDR]], align 8
// PPC64-NEXT:    store ptr [[LB2]], ptr [[LB2_ADDR]], align 8
// PPC64-NEXT:    store ptr [[V]], ptr [[V_ADDR]], align 8
// PPC64-NEXT:    [[TMP0:%.*]] = load i32, ptr [[J]], align 4, !dbg [[DBG81:![0-9]+]]
// PPC64-NEXT:    [[TMP1:%.*]] = sext i32 [[TMP0]] to i64
// PPC64-NEXT:    [[TMP2:%.*]] = add i64 [[TMP1]], 1
// PPC64-NEXT:    [[TMP3:%.*]] = load i32, ptr [[I]], align 4, !dbg [[DBG83:![0-9]+]]
// PPC64-NEXT:    [[TMP4:%.*]] = sext i32 [[TMP3]] to i64
// PPC64-NEXT:    [[TMP5:%.*]] = add i64 [[TMP4]], 1
// PPC64-NEXT:    [[ARRAYDECAY:%.*]] = getelementptr inbounds [10 x [20 x i32]], ptr [[V]], i64 0, i64 0, !dbg [[DBG84:![0-9]+]]
// PPC64-NEXT:    [[TMP6:%.*]] = mul i64 [[TMP1]], 4
// PPC64-NEXT:    [[TMP7:%.*]] = mul i64 [[TMP2]], 4
// PPC64-NEXT:    [[TMP8:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_4]], ptr [[RETVAL]], i32 0, i32 0
// PPC64-NEXT:    store ptr [[ARRAYDECAY]], ptr [[TMP8]], align 8
// PPC64-NEXT:    [[TMP9:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_4]], ptr [[RETVAL]], i32 0, i32 1
// PPC64-NEXT:    store i64 80, ptr [[TMP9]], align 8
// PPC64-NEXT:    [[TMP10:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_4]], ptr [[RETVAL]], i32 0, i32 2
// PPC64-NEXT:    store i64 [[TMP6]], ptr [[TMP10]], align 8
// PPC64-NEXT:    [[TMP11:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_4]], ptr [[RETVAL]], i32 0, i32 3
// PPC64-NEXT:    store i64 [[TMP7]], ptr [[TMP11]], align 8
// PPC64-NEXT:    [[TMP12:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_4]], ptr [[RETVAL]], i32 0, i32 4
// PPC64-NEXT:    store i64 10, ptr [[TMP12]], align 8
// PPC64-NEXT:    [[TMP13:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_4]], ptr [[RETVAL]], i32 0, i32 5
// PPC64-NEXT:    store i64 [[TMP4]], ptr [[TMP13]], align 8
// PPC64-NEXT:    [[TMP14:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_4]], ptr [[RETVAL]], i32 0, i32 6
// PPC64-NEXT:    store i64 [[TMP5]], ptr [[TMP14]], align 8
// PPC64-NEXT:    [[TMP15:%.*]] = load [[STRUCT__DEPEND_UNPACK_T_4]], ptr [[RETVAL]], align 8, !dbg [[DBG84]]
// PPC64-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T_4]] [[TMP15]], !dbg [[DBG84]]
//
//
// AARCH64-LABEL: define {{[^@]+}}@_Z1fv
// AARCH64-SAME: () #[[ATTR0:[0-9]+]] !dbg [[DBG5:![0-9]+]] {
// AARCH64-NEXT:  entry:
// AARCH64-NEXT:    call void @_Z9constantsIiEvv(), !dbg [[DBG9:![0-9]+]]
// AARCH64-NEXT:    call void @_Z12nonconstantsIiEvv(), !dbg [[DBG10:![0-9]+]]
// AARCH64-NEXT:    call void @_Z12nonconstantsIsEvv(), !dbg [[DBG11:![0-9]+]]
// AARCH64-NEXT:    ret void, !dbg [[DBG12:![0-9]+]]
//
//
// AARCH64-LABEL: define {{[^@]+}}@_Z9constantsIiEvv
// AARCH64-SAME: () #[[ATTR0]] comdat !dbg [[DBG13:![0-9]+]] {
// AARCH64-NEXT:  entry:
// AARCH64-NEXT:    [[I:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[J:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    store i32 0, ptr [[I]], align 4, !dbg [[DBG14:![0-9]+]]
// AARCH64-NEXT:    store i32 0, ptr [[J]], align 4, !dbg [[DBG15:![0-9]+]]
// AARCH64-NEXT:    [[TMP0:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OSS"([5 x i8] c"TASK\00"), "QUAL.OSS.SHARED"(ptr @v, [10 x [20 x i32]] undef), "QUAL.OSS.PRIVATE"(ptr [[I]], i32 undef), "QUAL.OSS.PRIVATE"(ptr [[J]], i32 undef), "QUAL.OSS.MULTIDEP.RANGE.IN"(ptr [[I]], ptr [[J]], ptr @compute_dep, ptr [[I]], ptr [[J]], ptr @v, [40 x i8] c"{ v[i][j], i = {0, 1, 2}, j={3, 4, 5} }\00", ptr @compute_dep.2, ptr [[I]], ptr [[J]], ptr @v) ], !dbg [[DBG16:![0-9]+]]
// AARCH64-NEXT:    call void @llvm.directive.region.exit(token [[TMP0]]), !dbg [[DBG17:![0-9]+]]
// AARCH64-NEXT:    ret void, !dbg [[DBG18:![0-9]+]]
//
//
// AARCH64-LABEL: define {{[^@]+}}@_Z12nonconstantsIiEvv
// AARCH64-SAME: () #[[ATTR0]] comdat !dbg [[DBG19:![0-9]+]] {
// AARCH64-NEXT:  entry:
// AARCH64-NEXT:    [[LB1:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[UB1:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[STEP1:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[LB2:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[UB2:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[STEP2:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[I:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[J:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    store i32 0, ptr [[I]], align 4, !dbg [[DBG20:![0-9]+]]
// AARCH64-NEXT:    store i32 0, ptr [[J]], align 4, !dbg [[DBG21:![0-9]+]]
// AARCH64-NEXT:    [[TMP0:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OSS"([5 x i8] c"TASK\00"), "QUAL.OSS.SHARED"(ptr @v, [10 x [20 x i32]] undef), "QUAL.OSS.PRIVATE"(ptr [[I]], i32 undef), "QUAL.OSS.PRIVATE"(ptr [[J]], i32 undef), "QUAL.OSS.FIRSTPRIVATE"(ptr [[LB1]], i32 undef), "QUAL.OSS.FIRSTPRIVATE"(ptr [[LB2]], i32 undef), "QUAL.OSS.MULTIDEP.RANGE.IN"(ptr [[I]], ptr [[J]], ptr @compute_dep.3, ptr [[I]], ptr [[LB1]], ptr [[J]], ptr [[LB2]], ptr @v, [68 x i8] c"{ v[i][j], i = {lb1, lb1 + 1, lb1 + 2}, j={lb2, lb2 + 1, lb2 + 2} }\00", ptr @compute_dep.4, ptr [[I]], ptr [[J]], ptr [[LB1]], ptr [[LB2]], ptr @v) ], !dbg [[DBG22:![0-9]+]]
// AARCH64-NEXT:    call void @llvm.directive.region.exit(token [[TMP0]]), !dbg [[DBG23:![0-9]+]]
// AARCH64-NEXT:    ret void, !dbg [[DBG24:![0-9]+]]
//
//
// AARCH64-LABEL: define {{[^@]+}}@_Z12nonconstantsIsEvv
// AARCH64-SAME: () #[[ATTR0]] comdat !dbg [[DBG25:![0-9]+]] {
// AARCH64-NEXT:  entry:
// AARCH64-NEXT:    [[LB1:%.*]] = alloca i16, align 2
// AARCH64-NEXT:    [[UB1:%.*]] = alloca i16, align 2
// AARCH64-NEXT:    [[STEP1:%.*]] = alloca i16, align 2
// AARCH64-NEXT:    [[LB2:%.*]] = alloca i16, align 2
// AARCH64-NEXT:    [[UB2:%.*]] = alloca i16, align 2
// AARCH64-NEXT:    [[STEP2:%.*]] = alloca i16, align 2
// AARCH64-NEXT:    [[I:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[J:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    store i32 0, ptr [[I]], align 4, !dbg [[DBG26:![0-9]+]]
// AARCH64-NEXT:    store i32 0, ptr [[J]], align 4, !dbg [[DBG27:![0-9]+]]
// AARCH64-NEXT:    [[TMP0:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OSS"([5 x i8] c"TASK\00"), "QUAL.OSS.SHARED"(ptr @v, [10 x [20 x i32]] undef), "QUAL.OSS.PRIVATE"(ptr [[I]], i32 undef), "QUAL.OSS.PRIVATE"(ptr [[J]], i32 undef), "QUAL.OSS.FIRSTPRIVATE"(ptr [[LB1]], i16 undef), "QUAL.OSS.FIRSTPRIVATE"(ptr [[LB2]], i16 undef), "QUAL.OSS.MULTIDEP.RANGE.IN"(ptr [[I]], ptr [[J]], ptr @compute_dep.5, ptr [[I]], ptr [[LB1]], ptr [[J]], ptr [[LB2]], ptr @v, [68 x i8] c"{ v[i][j], i = {lb1, lb1 + 1, lb1 + 2}, j={lb2, lb2 + 1, lb2 + 2} }\00", ptr @compute_dep.6, ptr [[I]], ptr [[J]], ptr [[LB1]], ptr [[LB2]], ptr @v) ], !dbg [[DBG28:![0-9]+]]
// AARCH64-NEXT:    call void @llvm.directive.region.exit(token [[TMP0]]), !dbg [[DBG29:![0-9]+]]
// AARCH64-NEXT:    ret void, !dbg [[DBG30:![0-9]+]]
//
//
// AARCH64-LABEL: define {{[^@]+}}@compute_dep
// AARCH64-SAME: (ptr [[I:%.*]], ptr [[J:%.*]], i64 [[TMP0:%.*]]) !dbg [[DBG31:![0-9]+]] {
// AARCH64-NEXT:  entry:
// AARCH64-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T:%.*]], align 4
// AARCH64-NEXT:    [[I_ADDR:%.*]] = alloca ptr, align 8
// AARCH64-NEXT:    [[J_ADDR:%.*]] = alloca ptr, align 8
// AARCH64-NEXT:    [[DOTADDR:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[DISCRETE_ARRAY:%.*]] = alloca [3 x i32], align 4
// AARCH64-NEXT:    [[DISCRETE_ARRAY1:%.*]] = alloca [3 x i32], align 4
// AARCH64-NEXT:    store ptr [[I]], ptr [[I_ADDR]], align 8
// AARCH64-NEXT:    store ptr [[J]], ptr [[J_ADDR]], align 8
// AARCH64-NEXT:    store i64 [[TMP0]], ptr [[DOTADDR]], align 8
// AARCH64-NEXT:    switch i64 [[TMP0]], label [[TMP3:%.*]] [
// AARCH64-NEXT:    i64 0, label [[TMP4:%.*]]
// AARCH64-NEXT:    i64 1, label [[TMP11:%.*]]
// AARCH64-NEXT:    ]
// AARCH64:       1:
// AARCH64-NEXT:    [[TMP2:%.*]] = load [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], align 4, !dbg [[DBG33:![0-9]+]]
// AARCH64-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T]] [[TMP2]], !dbg [[DBG33]]
// AARCH64:       3:
// AARCH64-NEXT:    br label [[TMP1:%.*]]
// AARCH64:       4:
// AARCH64-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 4 [[DISCRETE_ARRAY]], ptr align 4 @__const._Z9constantsIiEvv.discrete.array, i64 12, i1 false), !dbg [[DBG35:![0-9]+]]
// AARCH64-NEXT:    [[TMP5:%.*]] = load i32, ptr [[I]], align 4, !dbg [[DBG36:![0-9]+]]
// AARCH64-NEXT:    [[DISCRETEIDX:%.*]] = getelementptr [3 x i32], ptr [[DISCRETE_ARRAY]], i32 0, i32 [[TMP5]]
// AARCH64-NEXT:    [[TMP6:%.*]] = load i32, ptr [[DISCRETEIDX]], align 4
// AARCH64-NEXT:    [[TMP7:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 0
// AARCH64-NEXT:    store i32 0, ptr [[TMP7]], align 4
// AARCH64-NEXT:    [[TMP8:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 1
// AARCH64-NEXT:    store i32 [[TMP6]], ptr [[TMP8]], align 4
// AARCH64-NEXT:    [[TMP9:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 2
// AARCH64-NEXT:    store i32 2, ptr [[TMP9]], align 4
// AARCH64-NEXT:    [[TMP10:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 3
// AARCH64-NEXT:    store i32 1, ptr [[TMP10]], align 4
// AARCH64-NEXT:    br label [[TMP1]]
// AARCH64:       11:
// AARCH64-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 4 [[DISCRETE_ARRAY1]], ptr align 4 @__const._Z9constantsIiEvv.discrete.array.1, i64 12, i1 false), !dbg [[DBG37:![0-9]+]]
// AARCH64-NEXT:    [[TMP12:%.*]] = load i32, ptr [[J]], align 4, !dbg [[DBG33]]
// AARCH64-NEXT:    [[DISCRETEIDX2:%.*]] = getelementptr [3 x i32], ptr [[DISCRETE_ARRAY1]], i32 0, i32 [[TMP12]]
// AARCH64-NEXT:    [[TMP13:%.*]] = load i32, ptr [[DISCRETEIDX2]], align 4
// AARCH64-NEXT:    [[TMP14:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 4
// AARCH64-NEXT:    store i32 0, ptr [[TMP14]], align 4
// AARCH64-NEXT:    [[TMP15:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 5
// AARCH64-NEXT:    store i32 [[TMP13]], ptr [[TMP15]], align 4
// AARCH64-NEXT:    [[TMP16:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 6
// AARCH64-NEXT:    store i32 2, ptr [[TMP16]], align 4
// AARCH64-NEXT:    [[TMP17:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 7
// AARCH64-NEXT:    store i32 1, ptr [[TMP17]], align 4
// AARCH64-NEXT:    br label [[TMP1]]
//
//
// AARCH64-LABEL: define {{[^@]+}}@compute_dep.2
// AARCH64-SAME: (ptr [[I:%.*]], ptr [[J:%.*]], ptr [[V:%.*]]) !dbg [[DBG38:![0-9]+]] {
// AARCH64-NEXT:  entry:
// AARCH64-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T_0:%.*]], align 8
// AARCH64-NEXT:    [[I_ADDR:%.*]] = alloca ptr, align 8
// AARCH64-NEXT:    [[J_ADDR:%.*]] = alloca ptr, align 8
// AARCH64-NEXT:    [[V_ADDR:%.*]] = alloca ptr, align 8
// AARCH64-NEXT:    store ptr [[I]], ptr [[I_ADDR]], align 8
// AARCH64-NEXT:    store ptr [[J]], ptr [[J_ADDR]], align 8
// AARCH64-NEXT:    store ptr [[V]], ptr [[V_ADDR]], align 8
// AARCH64-NEXT:    [[TMP0:%.*]] = load i32, ptr [[J]], align 4, !dbg [[DBG39:![0-9]+]]
// AARCH64-NEXT:    [[TMP1:%.*]] = sext i32 [[TMP0]] to i64
// AARCH64-NEXT:    [[TMP2:%.*]] = add i64 [[TMP1]], 1
// AARCH64-NEXT:    [[TMP3:%.*]] = load i32, ptr [[I]], align 4, !dbg [[DBG41:![0-9]+]]
// AARCH64-NEXT:    [[TMP4:%.*]] = sext i32 [[TMP3]] to i64
// AARCH64-NEXT:    [[TMP5:%.*]] = add i64 [[TMP4]], 1
// AARCH64-NEXT:    [[ARRAYDECAY:%.*]] = getelementptr inbounds [10 x [20 x i32]], ptr [[V]], i64 0, i64 0, !dbg [[DBG42:![0-9]+]]
// AARCH64-NEXT:    [[TMP6:%.*]] = mul i64 [[TMP1]], 4
// AARCH64-NEXT:    [[TMP7:%.*]] = mul i64 [[TMP2]], 4
// AARCH64-NEXT:    [[TMP8:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 0
// AARCH64-NEXT:    store ptr [[ARRAYDECAY]], ptr [[TMP8]], align 8
// AARCH64-NEXT:    [[TMP9:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 1
// AARCH64-NEXT:    store i64 80, ptr [[TMP9]], align 8
// AARCH64-NEXT:    [[TMP10:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 2
// AARCH64-NEXT:    store i64 [[TMP6]], ptr [[TMP10]], align 8
// AARCH64-NEXT:    [[TMP11:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 3
// AARCH64-NEXT:    store i64 [[TMP7]], ptr [[TMP11]], align 8
// AARCH64-NEXT:    [[TMP12:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 4
// AARCH64-NEXT:    store i64 10, ptr [[TMP12]], align 8
// AARCH64-NEXT:    [[TMP13:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 5
// AARCH64-NEXT:    store i64 [[TMP4]], ptr [[TMP13]], align 8
// AARCH64-NEXT:    [[TMP14:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], i32 0, i32 6
// AARCH64-NEXT:    store i64 [[TMP5]], ptr [[TMP14]], align 8
// AARCH64-NEXT:    [[TMP15:%.*]] = load [[STRUCT__DEPEND_UNPACK_T_0]], ptr [[RETVAL]], align 8, !dbg [[DBG42]]
// AARCH64-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T_0]] [[TMP15]], !dbg [[DBG42]]
//
//
// AARCH64-LABEL: define {{[^@]+}}@compute_dep.3
// AARCH64-SAME: (ptr [[I:%.*]], ptr [[LB1:%.*]], ptr [[J:%.*]], ptr [[LB2:%.*]], i64 [[TMP0:%.*]]) !dbg [[DBG43:![0-9]+]] {
// AARCH64-NEXT:  entry:
// AARCH64-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T_1:%.*]], align 4
// AARCH64-NEXT:    [[I_ADDR:%.*]] = alloca ptr, align 8
// AARCH64-NEXT:    [[LB1_ADDR:%.*]] = alloca ptr, align 8
// AARCH64-NEXT:    [[J_ADDR:%.*]] = alloca ptr, align 8
// AARCH64-NEXT:    [[LB2_ADDR:%.*]] = alloca ptr, align 8
// AARCH64-NEXT:    [[DOTADDR:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[DISCRETE_ARRAY:%.*]] = alloca [3 x i32], align 4
// AARCH64-NEXT:    [[DISCRETE_ARRAY3:%.*]] = alloca [3 x i32], align 4
// AARCH64-NEXT:    store ptr [[I]], ptr [[I_ADDR]], align 8
// AARCH64-NEXT:    store ptr [[LB1]], ptr [[LB1_ADDR]], align 8
// AARCH64-NEXT:    store ptr [[J]], ptr [[J_ADDR]], align 8
// AARCH64-NEXT:    store ptr [[LB2]], ptr [[LB2_ADDR]], align 8
// AARCH64-NEXT:    store i64 [[TMP0]], ptr [[DOTADDR]], align 8
// AARCH64-NEXT:    switch i64 [[TMP0]], label [[TMP3:%.*]] [
// AARCH64-NEXT:    i64 0, label [[TMP4:%.*]]
// AARCH64-NEXT:    i64 1, label [[TMP14:%.*]]
// AARCH64-NEXT:    ]
// AARCH64:       1:
// AARCH64-NEXT:    [[TMP2:%.*]] = load [[STRUCT__DEPEND_UNPACK_T_1]], ptr [[RETVAL]], align 4, !dbg [[DBG44:![0-9]+]]
// AARCH64-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T_1]] [[TMP2]], !dbg [[DBG44]]
// AARCH64:       3:
// AARCH64-NEXT:    br label [[TMP1:%.*]]
// AARCH64:       4:
// AARCH64-NEXT:    [[ARRAYINIT_BEGIN:%.*]] = getelementptr inbounds [3 x i32], ptr [[DISCRETE_ARRAY]], i64 0, i64 0, !dbg [[DBG46:![0-9]+]]
// AARCH64-NEXT:    [[TMP5:%.*]] = load i32, ptr [[LB1]], align 4, !dbg [[DBG47:![0-9]+]]
// AARCH64-NEXT:    store i32 [[TMP5]], ptr [[ARRAYINIT_BEGIN]], align 4, !dbg [[DBG46]]
// AARCH64-NEXT:    [[ARRAYINIT_ELEMENT:%.*]] = getelementptr inbounds i32, ptr [[ARRAYINIT_BEGIN]], i64 1, !dbg [[DBG46]]
// AARCH64-NEXT:    [[TMP6:%.*]] = load i32, ptr [[LB1]], align 4, !dbg [[DBG48:![0-9]+]]
// AARCH64-NEXT:    [[ADD:%.*]] = add nsw i32 [[TMP6]], 1, !dbg [[DBG49:![0-9]+]]
// AARCH64-NEXT:    store i32 [[ADD]], ptr [[ARRAYINIT_ELEMENT]], align 4, !dbg [[DBG46]]
// AARCH64-NEXT:    [[ARRAYINIT_ELEMENT1:%.*]] = getelementptr inbounds i32, ptr [[ARRAYINIT_ELEMENT]], i64 1, !dbg [[DBG46]]
// AARCH64-NEXT:    [[TMP7:%.*]] = load i32, ptr [[LB1]], align 4, !dbg [[DBG50:![0-9]+]]
// AARCH64-NEXT:    [[ADD2:%.*]] = add nsw i32 [[TMP7]], 2, !dbg [[DBG51:![0-9]+]]
// AARCH64-NEXT:    store i32 [[ADD2]], ptr [[ARRAYINIT_ELEMENT1]], align 4, !dbg [[DBG46]]
// AARCH64-NEXT:    [[TMP8:%.*]] = load i32, ptr [[I]], align 4, !dbg [[DBG52:![0-9]+]]
// AARCH64-NEXT:    [[DISCRETEIDX:%.*]] = getelementptr [3 x i32], ptr [[DISCRETE_ARRAY]], i32 0, i32 [[TMP8]]
// AARCH64-NEXT:    [[TMP9:%.*]] = load i32, ptr [[DISCRETEIDX]], align 4
// AARCH64-NEXT:    [[TMP10:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_1]], ptr [[RETVAL]], i32 0, i32 0
// AARCH64-NEXT:    store i32 0, ptr [[TMP10]], align 4
// AARCH64-NEXT:    [[TMP11:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_1]], ptr [[RETVAL]], i32 0, i32 1
// AARCH64-NEXT:    store i32 [[TMP9]], ptr [[TMP11]], align 4
// AARCH64-NEXT:    [[TMP12:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_1]], ptr [[RETVAL]], i32 0, i32 2
// AARCH64-NEXT:    store i32 2, ptr [[TMP12]], align 4
// AARCH64-NEXT:    [[TMP13:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_1]], ptr [[RETVAL]], i32 0, i32 3
// AARCH64-NEXT:    store i32 1, ptr [[TMP13]], align 4
// AARCH64-NEXT:    br label [[TMP1]]
// AARCH64:       14:
// AARCH64-NEXT:    [[ARRAYINIT_BEGIN4:%.*]] = getelementptr inbounds [3 x i32], ptr [[DISCRETE_ARRAY3]], i64 0, i64 0, !dbg [[DBG53:![0-9]+]]
// AARCH64-NEXT:    [[TMP15:%.*]] = load i32, ptr [[LB2]], align 4, !dbg [[DBG54:![0-9]+]]
// AARCH64-NEXT:    store i32 [[TMP15]], ptr [[ARRAYINIT_BEGIN4]], align 4, !dbg [[DBG53]]
// AARCH64-NEXT:    [[ARRAYINIT_ELEMENT5:%.*]] = getelementptr inbounds i32, ptr [[ARRAYINIT_BEGIN4]], i64 1, !dbg [[DBG53]]
// AARCH64-NEXT:    [[TMP16:%.*]] = load i32, ptr [[LB2]], align 4, !dbg [[DBG55:![0-9]+]]
// AARCH64-NEXT:    [[ADD6:%.*]] = add nsw i32 [[TMP16]], 1, !dbg [[DBG56:![0-9]+]]
// AARCH64-NEXT:    store i32 [[ADD6]], ptr [[ARRAYINIT_ELEMENT5]], align 4, !dbg [[DBG53]]
// AARCH64-NEXT:    [[ARRAYINIT_ELEMENT7:%.*]] = getelementptr inbounds i32, ptr [[ARRAYINIT_ELEMENT5]], i64 1, !dbg [[DBG53]]
// AARCH64-NEXT:    [[TMP17:%.*]] = load i32, ptr [[LB2]], align 4, !dbg [[DBG57:![0-9]+]]
// AARCH64-NEXT:    [[ADD8:%.*]] = add nsw i32 [[TMP17]], 2, !dbg [[DBG58:![0-9]+]]
// AARCH64-NEXT:    store i32 [[ADD8]], ptr [[ARRAYINIT_ELEMENT7]], align 4, !dbg [[DBG53]]
// AARCH64-NEXT:    [[TMP18:%.*]] = load i32, ptr [[J]], align 4, !dbg [[DBG44]]
// AARCH64-NEXT:    [[DISCRETEIDX9:%.*]] = getelementptr [3 x i32], ptr [[DISCRETE_ARRAY3]], i32 0, i32 [[TMP18]]
// AARCH64-NEXT:    [[TMP19:%.*]] = load i32, ptr [[DISCRETEIDX9]], align 4
// AARCH64-NEXT:    [[TMP20:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_1]], ptr [[RETVAL]], i32 0, i32 4
// AARCH64-NEXT:    store i32 0, ptr [[TMP20]], align 4
// AARCH64-NEXT:    [[TMP21:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_1]], ptr [[RETVAL]], i32 0, i32 5
// AARCH64-NEXT:    store i32 [[TMP19]], ptr [[TMP21]], align 4
// AARCH64-NEXT:    [[TMP22:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_1]], ptr [[RETVAL]], i32 0, i32 6
// AARCH64-NEXT:    store i32 2, ptr [[TMP22]], align 4
// AARCH64-NEXT:    [[TMP23:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_1]], ptr [[RETVAL]], i32 0, i32 7
// AARCH64-NEXT:    store i32 1, ptr [[TMP23]], align 4
// AARCH64-NEXT:    br label [[TMP1]]
//
//
// AARCH64-LABEL: define {{[^@]+}}@compute_dep.4
// AARCH64-SAME: (ptr [[I:%.*]], ptr [[J:%.*]], ptr [[LB1:%.*]], ptr [[LB2:%.*]], ptr [[V:%.*]]) !dbg [[DBG59:![0-9]+]] {
// AARCH64-NEXT:  entry:
// AARCH64-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T_2:%.*]], align 8
// AARCH64-NEXT:    [[I_ADDR:%.*]] = alloca ptr, align 8
// AARCH64-NEXT:    [[J_ADDR:%.*]] = alloca ptr, align 8
// AARCH64-NEXT:    [[LB1_ADDR:%.*]] = alloca ptr, align 8
// AARCH64-NEXT:    [[LB2_ADDR:%.*]] = alloca ptr, align 8
// AARCH64-NEXT:    [[V_ADDR:%.*]] = alloca ptr, align 8
// AARCH64-NEXT:    store ptr [[I]], ptr [[I_ADDR]], align 8
// AARCH64-NEXT:    store ptr [[J]], ptr [[J_ADDR]], align 8
// AARCH64-NEXT:    store ptr [[LB1]], ptr [[LB1_ADDR]], align 8
// AARCH64-NEXT:    store ptr [[LB2]], ptr [[LB2_ADDR]], align 8
// AARCH64-NEXT:    store ptr [[V]], ptr [[V_ADDR]], align 8
// AARCH64-NEXT:    [[TMP0:%.*]] = load i32, ptr [[J]], align 4, !dbg [[DBG60:![0-9]+]]
// AARCH64-NEXT:    [[TMP1:%.*]] = sext i32 [[TMP0]] to i64
// AARCH64-NEXT:    [[TMP2:%.*]] = add i64 [[TMP1]], 1
// AARCH64-NEXT:    [[TMP3:%.*]] = load i32, ptr [[I]], align 4, !dbg [[DBG62:![0-9]+]]
// AARCH64-NEXT:    [[TMP4:%.*]] = sext i32 [[TMP3]] to i64
// AARCH64-NEXT:    [[TMP5:%.*]] = add i64 [[TMP4]], 1
// AARCH64-NEXT:    [[ARRAYDECAY:%.*]] = getelementptr inbounds [10 x [20 x i32]], ptr [[V]], i64 0, i64 0, !dbg [[DBG63:![0-9]+]]
// AARCH64-NEXT:    [[TMP6:%.*]] = mul i64 [[TMP1]], 4
// AARCH64-NEXT:    [[TMP7:%.*]] = mul i64 [[TMP2]], 4
// AARCH64-NEXT:    [[TMP8:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_2]], ptr [[RETVAL]], i32 0, i32 0
// AARCH64-NEXT:    store ptr [[ARRAYDECAY]], ptr [[TMP8]], align 8
// AARCH64-NEXT:    [[TMP9:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_2]], ptr [[RETVAL]], i32 0, i32 1
// AARCH64-NEXT:    store i64 80, ptr [[TMP9]], align 8
// AARCH64-NEXT:    [[TMP10:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_2]], ptr [[RETVAL]], i32 0, i32 2
// AARCH64-NEXT:    store i64 [[TMP6]], ptr [[TMP10]], align 8
// AARCH64-NEXT:    [[TMP11:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_2]], ptr [[RETVAL]], i32 0, i32 3
// AARCH64-NEXT:    store i64 [[TMP7]], ptr [[TMP11]], align 8
// AARCH64-NEXT:    [[TMP12:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_2]], ptr [[RETVAL]], i32 0, i32 4
// AARCH64-NEXT:    store i64 10, ptr [[TMP12]], align 8
// AARCH64-NEXT:    [[TMP13:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_2]], ptr [[RETVAL]], i32 0, i32 5
// AARCH64-NEXT:    store i64 [[TMP4]], ptr [[TMP13]], align 8
// AARCH64-NEXT:    [[TMP14:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_2]], ptr [[RETVAL]], i32 0, i32 6
// AARCH64-NEXT:    store i64 [[TMP5]], ptr [[TMP14]], align 8
// AARCH64-NEXT:    [[TMP15:%.*]] = load [[STRUCT__DEPEND_UNPACK_T_2]], ptr [[RETVAL]], align 8, !dbg [[DBG63]]
// AARCH64-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T_2]] [[TMP15]], !dbg [[DBG63]]
//
//
// AARCH64-LABEL: define {{[^@]+}}@compute_dep.5
// AARCH64-SAME: (ptr [[I:%.*]], ptr [[LB1:%.*]], ptr [[J:%.*]], ptr [[LB2:%.*]], i64 [[TMP0:%.*]]) !dbg [[DBG64:![0-9]+]] {
// AARCH64-NEXT:  entry:
// AARCH64-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T_3:%.*]], align 4
// AARCH64-NEXT:    [[I_ADDR:%.*]] = alloca ptr, align 8
// AARCH64-NEXT:    [[LB1_ADDR:%.*]] = alloca ptr, align 8
// AARCH64-NEXT:    [[J_ADDR:%.*]] = alloca ptr, align 8
// AARCH64-NEXT:    [[LB2_ADDR:%.*]] = alloca ptr, align 8
// AARCH64-NEXT:    [[DOTADDR:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[DISCRETE_ARRAY:%.*]] = alloca [3 x i32], align 4
// AARCH64-NEXT:    [[DISCRETE_ARRAY5:%.*]] = alloca [3 x i32], align 4
// AARCH64-NEXT:    store ptr [[I]], ptr [[I_ADDR]], align 8
// AARCH64-NEXT:    store ptr [[LB1]], ptr [[LB1_ADDR]], align 8
// AARCH64-NEXT:    store ptr [[J]], ptr [[J_ADDR]], align 8
// AARCH64-NEXT:    store ptr [[LB2]], ptr [[LB2_ADDR]], align 8
// AARCH64-NEXT:    store i64 [[TMP0]], ptr [[DOTADDR]], align 8
// AARCH64-NEXT:    switch i64 [[TMP0]], label [[TMP3:%.*]] [
// AARCH64-NEXT:    i64 0, label [[TMP4:%.*]]
// AARCH64-NEXT:    i64 1, label [[TMP14:%.*]]
// AARCH64-NEXT:    ]
// AARCH64:       1:
// AARCH64-NEXT:    [[TMP2:%.*]] = load [[STRUCT__DEPEND_UNPACK_T_3]], ptr [[RETVAL]], align 4, !dbg [[DBG65:![0-9]+]]
// AARCH64-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T_3]] [[TMP2]], !dbg [[DBG65]]
// AARCH64:       3:
// AARCH64-NEXT:    br label [[TMP1:%.*]]
// AARCH64:       4:
// AARCH64-NEXT:    [[ARRAYINIT_BEGIN:%.*]] = getelementptr inbounds [3 x i32], ptr [[DISCRETE_ARRAY]], i64 0, i64 0, !dbg [[DBG67:![0-9]+]]
// AARCH64-NEXT:    [[TMP5:%.*]] = load i16, ptr [[LB1]], align 2, !dbg [[DBG68:![0-9]+]]
// AARCH64-NEXT:    [[CONV:%.*]] = sext i16 [[TMP5]] to i32, !dbg [[DBG68]]
// AARCH64-NEXT:    store i32 [[CONV]], ptr [[ARRAYINIT_BEGIN]], align 4, !dbg [[DBG67]]
// AARCH64-NEXT:    [[ARRAYINIT_ELEMENT:%.*]] = getelementptr inbounds i32, ptr [[ARRAYINIT_BEGIN]], i64 1, !dbg [[DBG67]]
// AARCH64-NEXT:    [[TMP6:%.*]] = load i16, ptr [[LB1]], align 2, !dbg [[DBG69:![0-9]+]]
// AARCH64-NEXT:    [[CONV1:%.*]] = sext i16 [[TMP6]] to i32, !dbg [[DBG69]]
// AARCH64-NEXT:    [[ADD:%.*]] = add nsw i32 [[CONV1]], 1, !dbg [[DBG70:![0-9]+]]
// AARCH64-NEXT:    store i32 [[ADD]], ptr [[ARRAYINIT_ELEMENT]], align 4, !dbg [[DBG67]]
// AARCH64-NEXT:    [[ARRAYINIT_ELEMENT2:%.*]] = getelementptr inbounds i32, ptr [[ARRAYINIT_ELEMENT]], i64 1, !dbg [[DBG67]]
// AARCH64-NEXT:    [[TMP7:%.*]] = load i16, ptr [[LB1]], align 2, !dbg [[DBG71:![0-9]+]]
// AARCH64-NEXT:    [[CONV3:%.*]] = sext i16 [[TMP7]] to i32, !dbg [[DBG71]]
// AARCH64-NEXT:    [[ADD4:%.*]] = add nsw i32 [[CONV3]], 2, !dbg [[DBG72:![0-9]+]]
// AARCH64-NEXT:    store i32 [[ADD4]], ptr [[ARRAYINIT_ELEMENT2]], align 4, !dbg [[DBG67]]
// AARCH64-NEXT:    [[TMP8:%.*]] = load i32, ptr [[I]], align 4, !dbg [[DBG73:![0-9]+]]
// AARCH64-NEXT:    [[DISCRETEIDX:%.*]] = getelementptr [3 x i32], ptr [[DISCRETE_ARRAY]], i32 0, i32 [[TMP8]]
// AARCH64-NEXT:    [[TMP9:%.*]] = load i32, ptr [[DISCRETEIDX]], align 4
// AARCH64-NEXT:    [[TMP10:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_3]], ptr [[RETVAL]], i32 0, i32 0
// AARCH64-NEXT:    store i32 0, ptr [[TMP10]], align 4
// AARCH64-NEXT:    [[TMP11:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_3]], ptr [[RETVAL]], i32 0, i32 1
// AARCH64-NEXT:    store i32 [[TMP9]], ptr [[TMP11]], align 4
// AARCH64-NEXT:    [[TMP12:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_3]], ptr [[RETVAL]], i32 0, i32 2
// AARCH64-NEXT:    store i32 2, ptr [[TMP12]], align 4
// AARCH64-NEXT:    [[TMP13:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_3]], ptr [[RETVAL]], i32 0, i32 3
// AARCH64-NEXT:    store i32 1, ptr [[TMP13]], align 4
// AARCH64-NEXT:    br label [[TMP1]]
// AARCH64:       14:
// AARCH64-NEXT:    [[ARRAYINIT_BEGIN6:%.*]] = getelementptr inbounds [3 x i32], ptr [[DISCRETE_ARRAY5]], i64 0, i64 0, !dbg [[DBG74:![0-9]+]]
// AARCH64-NEXT:    [[TMP15:%.*]] = load i16, ptr [[LB2]], align 2, !dbg [[DBG75:![0-9]+]]
// AARCH64-NEXT:    [[CONV7:%.*]] = sext i16 [[TMP15]] to i32, !dbg [[DBG75]]
// AARCH64-NEXT:    store i32 [[CONV7]], ptr [[ARRAYINIT_BEGIN6]], align 4, !dbg [[DBG74]]
// AARCH64-NEXT:    [[ARRAYINIT_ELEMENT8:%.*]] = getelementptr inbounds i32, ptr [[ARRAYINIT_BEGIN6]], i64 1, !dbg [[DBG74]]
// AARCH64-NEXT:    [[TMP16:%.*]] = load i16, ptr [[LB2]], align 2, !dbg [[DBG76:![0-9]+]]
// AARCH64-NEXT:    [[CONV9:%.*]] = sext i16 [[TMP16]] to i32, !dbg [[DBG76]]
// AARCH64-NEXT:    [[ADD10:%.*]] = add nsw i32 [[CONV9]], 1, !dbg [[DBG77:![0-9]+]]
// AARCH64-NEXT:    store i32 [[ADD10]], ptr [[ARRAYINIT_ELEMENT8]], align 4, !dbg [[DBG74]]
// AARCH64-NEXT:    [[ARRAYINIT_ELEMENT11:%.*]] = getelementptr inbounds i32, ptr [[ARRAYINIT_ELEMENT8]], i64 1, !dbg [[DBG74]]
// AARCH64-NEXT:    [[TMP17:%.*]] = load i16, ptr [[LB2]], align 2, !dbg [[DBG78:![0-9]+]]
// AARCH64-NEXT:    [[CONV12:%.*]] = sext i16 [[TMP17]] to i32, !dbg [[DBG78]]
// AARCH64-NEXT:    [[ADD13:%.*]] = add nsw i32 [[CONV12]], 2, !dbg [[DBG79:![0-9]+]]
// AARCH64-NEXT:    store i32 [[ADD13]], ptr [[ARRAYINIT_ELEMENT11]], align 4, !dbg [[DBG74]]
// AARCH64-NEXT:    [[TMP18:%.*]] = load i32, ptr [[J]], align 4, !dbg [[DBG65]]
// AARCH64-NEXT:    [[DISCRETEIDX14:%.*]] = getelementptr [3 x i32], ptr [[DISCRETE_ARRAY5]], i32 0, i32 [[TMP18]]
// AARCH64-NEXT:    [[TMP19:%.*]] = load i32, ptr [[DISCRETEIDX14]], align 4
// AARCH64-NEXT:    [[TMP20:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_3]], ptr [[RETVAL]], i32 0, i32 4
// AARCH64-NEXT:    store i32 0, ptr [[TMP20]], align 4
// AARCH64-NEXT:    [[TMP21:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_3]], ptr [[RETVAL]], i32 0, i32 5
// AARCH64-NEXT:    store i32 [[TMP19]], ptr [[TMP21]], align 4
// AARCH64-NEXT:    [[TMP22:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_3]], ptr [[RETVAL]], i32 0, i32 6
// AARCH64-NEXT:    store i32 2, ptr [[TMP22]], align 4
// AARCH64-NEXT:    [[TMP23:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_3]], ptr [[RETVAL]], i32 0, i32 7
// AARCH64-NEXT:    store i32 1, ptr [[TMP23]], align 4
// AARCH64-NEXT:    br label [[TMP1]]
//
//
// AARCH64-LABEL: define {{[^@]+}}@compute_dep.6
// AARCH64-SAME: (ptr [[I:%.*]], ptr [[J:%.*]], ptr [[LB1:%.*]], ptr [[LB2:%.*]], ptr [[V:%.*]]) !dbg [[DBG80:![0-9]+]] {
// AARCH64-NEXT:  entry:
// AARCH64-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T_4:%.*]], align 8
// AARCH64-NEXT:    [[I_ADDR:%.*]] = alloca ptr, align 8
// AARCH64-NEXT:    [[J_ADDR:%.*]] = alloca ptr, align 8
// AARCH64-NEXT:    [[LB1_ADDR:%.*]] = alloca ptr, align 8
// AARCH64-NEXT:    [[LB2_ADDR:%.*]] = alloca ptr, align 8
// AARCH64-NEXT:    [[V_ADDR:%.*]] = alloca ptr, align 8
// AARCH64-NEXT:    store ptr [[I]], ptr [[I_ADDR]], align 8
// AARCH64-NEXT:    store ptr [[J]], ptr [[J_ADDR]], align 8
// AARCH64-NEXT:    store ptr [[LB1]], ptr [[LB1_ADDR]], align 8
// AARCH64-NEXT:    store ptr [[LB2]], ptr [[LB2_ADDR]], align 8
// AARCH64-NEXT:    store ptr [[V]], ptr [[V_ADDR]], align 8
// AARCH64-NEXT:    [[TMP0:%.*]] = load i32, ptr [[J]], align 4, !dbg [[DBG81:![0-9]+]]
// AARCH64-NEXT:    [[TMP1:%.*]] = sext i32 [[TMP0]] to i64
// AARCH64-NEXT:    [[TMP2:%.*]] = add i64 [[TMP1]], 1
// AARCH64-NEXT:    [[TMP3:%.*]] = load i32, ptr [[I]], align 4, !dbg [[DBG83:![0-9]+]]
// AARCH64-NEXT:    [[TMP4:%.*]] = sext i32 [[TMP3]] to i64
// AARCH64-NEXT:    [[TMP5:%.*]] = add i64 [[TMP4]], 1
// AARCH64-NEXT:    [[ARRAYDECAY:%.*]] = getelementptr inbounds [10 x [20 x i32]], ptr [[V]], i64 0, i64 0, !dbg [[DBG84:![0-9]+]]
// AARCH64-NEXT:    [[TMP6:%.*]] = mul i64 [[TMP1]], 4
// AARCH64-NEXT:    [[TMP7:%.*]] = mul i64 [[TMP2]], 4
// AARCH64-NEXT:    [[TMP8:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_4]], ptr [[RETVAL]], i32 0, i32 0
// AARCH64-NEXT:    store ptr [[ARRAYDECAY]], ptr [[TMP8]], align 8
// AARCH64-NEXT:    [[TMP9:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_4]], ptr [[RETVAL]], i32 0, i32 1
// AARCH64-NEXT:    store i64 80, ptr [[TMP9]], align 8
// AARCH64-NEXT:    [[TMP10:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_4]], ptr [[RETVAL]], i32 0, i32 2
// AARCH64-NEXT:    store i64 [[TMP6]], ptr [[TMP10]], align 8
// AARCH64-NEXT:    [[TMP11:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_4]], ptr [[RETVAL]], i32 0, i32 3
// AARCH64-NEXT:    store i64 [[TMP7]], ptr [[TMP11]], align 8
// AARCH64-NEXT:    [[TMP12:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_4]], ptr [[RETVAL]], i32 0, i32 4
// AARCH64-NEXT:    store i64 10, ptr [[TMP12]], align 8
// AARCH64-NEXT:    [[TMP13:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_4]], ptr [[RETVAL]], i32 0, i32 5
// AARCH64-NEXT:    store i64 [[TMP4]], ptr [[TMP13]], align 8
// AARCH64-NEXT:    [[TMP14:%.*]] = getelementptr inbounds [[STRUCT__DEPEND_UNPACK_T_4]], ptr [[RETVAL]], i32 0, i32 6
// AARCH64-NEXT:    store i64 [[TMP5]], ptr [[TMP14]], align 8
// AARCH64-NEXT:    [[TMP15:%.*]] = load [[STRUCT__DEPEND_UNPACK_T_4]], ptr [[RETVAL]], align 8, !dbg [[DBG84]]
// AARCH64-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T_4]] [[TMP15]], !dbg [[DBG84]]
//
