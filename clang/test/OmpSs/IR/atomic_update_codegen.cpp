// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --function-signature --include-generated-funcs
// RUN: %clang_cc1 -x c -no-opaque-pointers -triple x86_64-gnu-linux -verify -fompss-2 -disable-llvm-passes -ferror-limit 100 %s -S -emit-llvm -o - | FileCheck %s --check-prefixes=LIN64
// RUN: %clang_cc1 -x c -no-opaque-pointers -triple ppc64 -verify -fompss-2 -disable-llvm-passes -ferror-limit 100 %s -S -emit-llvm -o - | FileCheck %s --check-prefixes=PPC64
// RUN: %clang_cc1 -x c -no-opaque-pointers -triple aarch64 -verify -fompss-2 -disable-llvm-passes -ferror-limit 100 %s -S -emit-llvm -o - | FileCheck %s --check-prefixes=AARCH64
// expected-no-diagnostics
#ifndef HEADER
#define HEADER

_Bool bv, bx;
char cv, cx;
unsigned char ucv, ucx;
short sv, sx;
unsigned short usv, usx;
int iv, ix;
unsigned int uiv, uix;
long lv, lx;
unsigned long ulv, ulx;
long long llv, llx;
unsigned long long ullv, ullx;
float fv, fx;
double dv, dx;
long double ldv, ldx;
_Complex int civ, cix;
_Complex float cfv, cfx;
_Complex double cdv, cdx;

typedef int int4 __attribute__((__vector_size__(16)));
int4 int4x;

struct BitFields {
  int : 32;
  int a : 31;
} bfx;

struct BitFields_packed {
  int : 32;
  int a : 31;
} __attribute__ ((__packed__)) bfx_packed;

struct BitFields2 {
  int : 31;
  int a : 1;
} bfx2;

struct BitFields2_packed {
  int : 31;
  int a : 1;
} __attribute__ ((__packed__)) bfx2_packed;

struct BitFields3 {
  int : 11;
  int a : 14;
} bfx3;

struct BitFields3_packed {
  int : 11;
  int a : 14;
} __attribute__ ((__packed__)) bfx3_packed;

struct BitFields4 {
  short : 16;
  int a: 1;
  long b : 7;
} bfx4;

struct BitFields4_packed {
  short : 16;
  int a: 1;
  long b : 7;
} __attribute__ ((__packed__)) bfx4_packed;

typedef float float2 __attribute__((ext_vector_type(2)));
float2 float2x;

#if defined(__x86_64__)
// Register "0" is currently an invalid register for global register variables.
// Use "esp" instead of "0".
// register int rix __asm__("0");
register int rix __asm__("esp");
#endif

int main(void) {
#pragma oss atomic
  ++dv;
#pragma oss atomic
  bx++;
#pragma oss atomic update
  ++cx;
#pragma oss atomic
  ucx--;
#pragma oss atomic update
  --sx;
#pragma oss atomic
  usx += usv;
#pragma oss atomic update
  ix *= iv;
#pragma oss atomic
  uix -= uiv;
#pragma oss atomic update
  ix <<= iv;
#pragma oss atomic
  uix >>= uiv;
#pragma oss atomic update
  lx /= lv;
#pragma oss atomic
  ulx &= ulv;
#pragma oss atomic update
  llx ^= llv;
#pragma oss atomic
  ullx |= ullv;
#pragma oss atomic update
  fx = fx + fv;
#pragma oss atomic
  dx = dv - dx;
#pragma oss atomic update
  ldx = ldx * ldv;
// <Skip checks for complex calculations>
#pragma oss atomic
  cix = civ / cix;
// <Skip checks for complex calculations>
#pragma oss atomic update
  cfx = cfv + cfx;
// <Skip checks for complex calculations>
#pragma oss atomic seq_cst
  cdx = cdx - cdv;
#pragma oss atomic update
  ulx = ulx & bv;
#pragma oss atomic
  bx = cv & bx;
#pragma oss atomic update, seq_cst
  cx = cx >> ucv;
#pragma oss atomic update
  ulx = sv << ulx;
#pragma oss atomic
  lx = lx % usv;
#pragma oss atomic seq_cst, update
  uix = iv | uix;
#pragma oss atomic
  ix = ix & uiv;
// <Skip checks for complex calculations>
#pragma oss atomic update
  cix = lv + cix;
#pragma oss atomic
  fx = fx * ulv;
#pragma oss atomic update
  dx /= llv;
#pragma oss atomic
  ldx -= ullv;
// <Skip checks for complex calculations>
#pragma oss atomic update
  cix = fv / cix;
#pragma oss atomic
  sx = sx + dv;
#pragma oss atomic update release
  bx = ldv * bx;
#pragma oss atomic
  bx = civ - bx;
#pragma oss atomic update
  int4x[sv] |= bv;
#pragma oss atomic
  bfx.a = bfx.a - ldv;
#pragma oss atomic update
  bfx_packed.a *= ldv;
#pragma oss atomic
  bfx2.a -= ldv;
#pragma oss atomic update
  bfx2_packed.a = ldv / bfx2_packed.a;
#pragma oss atomic
  bfx3.a /= ldv;
#pragma oss atomic update
  bfx3_packed.a += ldv;
#pragma oss atomic
  bfx4.a = bfx4.a * ldv;
#pragma oss atomic relaxed update
  bfx4_packed.a -= ldv;
#pragma oss atomic
  bfx4.b /= ldv;
#pragma oss atomic update relaxed
  bfx4_packed.b += ldv;
#pragma oss atomic relaxed
  float2x.x = ulv - float2x.x;
#if defined(__x86_64__)
#pragma oss atomic seq_cst
  rix = dv / rix;
#endif
  return 0;
}

#endif
// LIN64-LABEL: define {{[^@]+}}@main
// LIN64-SAME: () #[[ATTR0:[0-9]+]] !dbg [[DBG6:![0-9]+]] {
// LIN64-NEXT:  entry:
// LIN64-NEXT:    [[RETVAL:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca i16, align 2
// LIN64-NEXT:    [[ATOMIC_TEMP5:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP9:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP13:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP17:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP21:%.*]] = alloca double, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP23:%.*]] = alloca x86_fp80, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP25:%.*]] = alloca x86_fp80, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP28:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP30:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP33:%.*]] = alloca { float, float }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP35:%.*]] = alloca { float, float }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP38:%.*]] = alloca { double, double }, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP40:%.*]] = alloca { double, double }, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP47:%.*]] = alloca i8, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP55:%.*]] = alloca i8, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP63:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP70:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP72:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP74:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP86:%.*]] = alloca float, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP92:%.*]] = alloca double, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP96:%.*]] = alloca x86_fp80, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP98:%.*]] = alloca x86_fp80, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP102:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP104:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[COERCE:%.*]] = alloca { float, float }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP114:%.*]] = alloca i16, align 2
// LIN64-NEXT:    [[ATOMIC_TEMP122:%.*]] = alloca i8, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP134:%.*]] = alloca i8, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP146:%.*]] = alloca <4 x i32>, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP148:%.*]] = alloca <4 x i32>, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP149:%.*]] = alloca <4 x i32>, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP154:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP155:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP161:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP163:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP164:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP179:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP180:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP194:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP195:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP209:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP210:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP223:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP225:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP226:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP243:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP244:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP260:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP261:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP276:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP277:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP292:%.*]] = alloca i64, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP293:%.*]] = alloca i64, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP309:%.*]] = alloca <2 x float>, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP310:%.*]] = alloca <2 x float>, align 8
// LIN64-NEXT:    store i32 0, i32* [[RETVAL]], align 4
// LIN64-NEXT:    [[TMP0:%.*]] = atomicrmw fadd double* @dv, double 1.000000e+00 monotonic, align 8, !dbg [[DBG10:![0-9]+]]
// LIN64-NEXT:    [[TMP1:%.*]] = atomicrmw add i8* @bx, i8 1 monotonic, align 1, !dbg [[DBG11:![0-9]+]]
// LIN64-NEXT:    [[TMP2:%.*]] = atomicrmw add i8* @cx, i8 1 monotonic, align 1, !dbg [[DBG12:![0-9]+]]
// LIN64-NEXT:    [[TMP3:%.*]] = atomicrmw sub i8* @ucx, i8 1 monotonic, align 1, !dbg [[DBG13:![0-9]+]]
// LIN64-NEXT:    [[TMP4:%.*]] = atomicrmw sub i16* @sx, i16 1 monotonic, align 2, !dbg [[DBG14:![0-9]+]]
// LIN64-NEXT:    [[TMP5:%.*]] = load i16, i16* @usv, align 2, !dbg [[DBG15:![0-9]+]]
// LIN64-NEXT:    [[CONV:%.*]] = zext i16 [[TMP5]] to i32, !dbg [[DBG15]]
// LIN64-NEXT:    [[ATOMIC_LOAD:%.*]] = load atomic i16, i16* @usx monotonic, align 2, !dbg [[DBG16:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT:%.*]], !dbg [[DBG16]]
// LIN64:       atomic_cont:
// LIN64-NEXT:    [[TMP6:%.*]] = phi i16 [ [[ATOMIC_LOAD]], [[ENTRY:%.*]] ], [ [[TMP9:%.*]], [[ATOMIC_CONT]] ], !dbg [[DBG16]]
// LIN64-NEXT:    [[CONV1:%.*]] = zext i16 [[TMP6]] to i32, !dbg [[DBG16]]
// LIN64-NEXT:    [[ADD:%.*]] = add nsw i32 [[CONV1]], [[CONV]], !dbg [[DBG17:![0-9]+]]
// LIN64-NEXT:    [[CONV2:%.*]] = trunc i32 [[ADD]] to i16, !dbg [[DBG16]]
// LIN64-NEXT:    store i16 [[CONV2]], i16* [[ATOMIC_TEMP]], align 2, !dbg [[DBG16]]
// LIN64-NEXT:    [[TMP7:%.*]] = load i16, i16* [[ATOMIC_TEMP]], align 2, !dbg [[DBG16]]
// LIN64-NEXT:    [[TMP8:%.*]] = cmpxchg i16* @usx, i16 [[TMP6]], i16 [[TMP7]] monotonic monotonic, align 2, !dbg [[DBG16]]
// LIN64-NEXT:    [[TMP9]] = extractvalue { i16, i1 } [[TMP8]], 0, !dbg [[DBG16]]
// LIN64-NEXT:    [[TMP10:%.*]] = extractvalue { i16, i1 } [[TMP8]], 1, !dbg [[DBG16]]
// LIN64-NEXT:    br i1 [[TMP10]], label [[ATOMIC_EXIT:%.*]], label [[ATOMIC_CONT]], !dbg [[DBG16]]
// LIN64:       atomic_exit:
// LIN64-NEXT:    [[TMP11:%.*]] = load i32, i32* @iv, align 4, !dbg [[DBG18:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD3:%.*]] = load atomic i32, i32* @ix monotonic, align 4, !dbg [[DBG19:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT4:%.*]], !dbg [[DBG19]]
// LIN64:       atomic_cont4:
// LIN64-NEXT:    [[TMP12:%.*]] = phi i32 [ [[ATOMIC_LOAD3]], [[ATOMIC_EXIT]] ], [ [[TMP15:%.*]], [[ATOMIC_CONT4]] ], !dbg [[DBG19]]
// LIN64-NEXT:    [[MUL:%.*]] = mul nsw i32 [[TMP12]], [[TMP11]], !dbg [[DBG20:![0-9]+]]
// LIN64-NEXT:    store i32 [[MUL]], i32* [[ATOMIC_TEMP5]], align 4, !dbg [[DBG19]]
// LIN64-NEXT:    [[TMP13:%.*]] = load i32, i32* [[ATOMIC_TEMP5]], align 4, !dbg [[DBG19]]
// LIN64-NEXT:    [[TMP14:%.*]] = cmpxchg i32* @ix, i32 [[TMP12]], i32 [[TMP13]] monotonic monotonic, align 4, !dbg [[DBG19]]
// LIN64-NEXT:    [[TMP15]] = extractvalue { i32, i1 } [[TMP14]], 0, !dbg [[DBG19]]
// LIN64-NEXT:    [[TMP16:%.*]] = extractvalue { i32, i1 } [[TMP14]], 1, !dbg [[DBG19]]
// LIN64-NEXT:    br i1 [[TMP16]], label [[ATOMIC_EXIT6:%.*]], label [[ATOMIC_CONT4]], !dbg [[DBG19]]
// LIN64:       atomic_exit6:
// LIN64-NEXT:    [[TMP17:%.*]] = load i32, i32* @uiv, align 4, !dbg [[DBG21:![0-9]+]]
// LIN64-NEXT:    [[TMP18:%.*]] = atomicrmw sub i32* @uix, i32 [[TMP17]] monotonic, align 4, !dbg [[DBG22:![0-9]+]]
// LIN64-NEXT:    [[TMP19:%.*]] = load i32, i32* @iv, align 4, !dbg [[DBG23:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD7:%.*]] = load atomic i32, i32* @ix monotonic, align 4, !dbg [[DBG24:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT8:%.*]], !dbg [[DBG24]]
// LIN64:       atomic_cont8:
// LIN64-NEXT:    [[TMP20:%.*]] = phi i32 [ [[ATOMIC_LOAD7]], [[ATOMIC_EXIT6]] ], [ [[TMP23:%.*]], [[ATOMIC_CONT8]] ], !dbg [[DBG24]]
// LIN64-NEXT:    [[SHL:%.*]] = shl i32 [[TMP20]], [[TMP19]], !dbg [[DBG25:![0-9]+]]
// LIN64-NEXT:    store i32 [[SHL]], i32* [[ATOMIC_TEMP9]], align 4, !dbg [[DBG24]]
// LIN64-NEXT:    [[TMP21:%.*]] = load i32, i32* [[ATOMIC_TEMP9]], align 4, !dbg [[DBG24]]
// LIN64-NEXT:    [[TMP22:%.*]] = cmpxchg i32* @ix, i32 [[TMP20]], i32 [[TMP21]] monotonic monotonic, align 4, !dbg [[DBG24]]
// LIN64-NEXT:    [[TMP23]] = extractvalue { i32, i1 } [[TMP22]], 0, !dbg [[DBG24]]
// LIN64-NEXT:    [[TMP24:%.*]] = extractvalue { i32, i1 } [[TMP22]], 1, !dbg [[DBG24]]
// LIN64-NEXT:    br i1 [[TMP24]], label [[ATOMIC_EXIT10:%.*]], label [[ATOMIC_CONT8]], !dbg [[DBG24]]
// LIN64:       atomic_exit10:
// LIN64-NEXT:    [[TMP25:%.*]] = load i32, i32* @uiv, align 4, !dbg [[DBG26:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD11:%.*]] = load atomic i32, i32* @uix monotonic, align 4, !dbg [[DBG27:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT12:%.*]], !dbg [[DBG27]]
// LIN64:       atomic_cont12:
// LIN64-NEXT:    [[TMP26:%.*]] = phi i32 [ [[ATOMIC_LOAD11]], [[ATOMIC_EXIT10]] ], [ [[TMP29:%.*]], [[ATOMIC_CONT12]] ], !dbg [[DBG27]]
// LIN64-NEXT:    [[SHR:%.*]] = lshr i32 [[TMP26]], [[TMP25]], !dbg [[DBG28:![0-9]+]]
// LIN64-NEXT:    store i32 [[SHR]], i32* [[ATOMIC_TEMP13]], align 4, !dbg [[DBG27]]
// LIN64-NEXT:    [[TMP27:%.*]] = load i32, i32* [[ATOMIC_TEMP13]], align 4, !dbg [[DBG27]]
// LIN64-NEXT:    [[TMP28:%.*]] = cmpxchg i32* @uix, i32 [[TMP26]], i32 [[TMP27]] monotonic monotonic, align 4, !dbg [[DBG27]]
// LIN64-NEXT:    [[TMP29]] = extractvalue { i32, i1 } [[TMP28]], 0, !dbg [[DBG27]]
// LIN64-NEXT:    [[TMP30:%.*]] = extractvalue { i32, i1 } [[TMP28]], 1, !dbg [[DBG27]]
// LIN64-NEXT:    br i1 [[TMP30]], label [[ATOMIC_EXIT14:%.*]], label [[ATOMIC_CONT12]], !dbg [[DBG27]]
// LIN64:       atomic_exit14:
// LIN64-NEXT:    [[TMP31:%.*]] = load i64, i64* @lv, align 8, !dbg [[DBG29:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD15:%.*]] = load atomic i64, i64* @lx monotonic, align 8, !dbg [[DBG30:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT16:%.*]], !dbg [[DBG30]]
// LIN64:       atomic_cont16:
// LIN64-NEXT:    [[TMP32:%.*]] = phi i64 [ [[ATOMIC_LOAD15]], [[ATOMIC_EXIT14]] ], [ [[TMP35:%.*]], [[ATOMIC_CONT16]] ], !dbg [[DBG30]]
// LIN64-NEXT:    [[DIV:%.*]] = sdiv i64 [[TMP32]], [[TMP31]], !dbg [[DBG31:![0-9]+]]
// LIN64-NEXT:    store i64 [[DIV]], i64* [[ATOMIC_TEMP17]], align 8, !dbg [[DBG30]]
// LIN64-NEXT:    [[TMP33:%.*]] = load i64, i64* [[ATOMIC_TEMP17]], align 8, !dbg [[DBG30]]
// LIN64-NEXT:    [[TMP34:%.*]] = cmpxchg i64* @lx, i64 [[TMP32]], i64 [[TMP33]] monotonic monotonic, align 8, !dbg [[DBG30]]
// LIN64-NEXT:    [[TMP35]] = extractvalue { i64, i1 } [[TMP34]], 0, !dbg [[DBG30]]
// LIN64-NEXT:    [[TMP36:%.*]] = extractvalue { i64, i1 } [[TMP34]], 1, !dbg [[DBG30]]
// LIN64-NEXT:    br i1 [[TMP36]], label [[ATOMIC_EXIT18:%.*]], label [[ATOMIC_CONT16]], !dbg [[DBG30]]
// LIN64:       atomic_exit18:
// LIN64-NEXT:    [[TMP37:%.*]] = load i64, i64* @ulv, align 8, !dbg [[DBG32:![0-9]+]]
// LIN64-NEXT:    [[TMP38:%.*]] = atomicrmw and i64* @ulx, i64 [[TMP37]] monotonic, align 8, !dbg [[DBG33:![0-9]+]]
// LIN64-NEXT:    [[TMP39:%.*]] = load i64, i64* @llv, align 8, !dbg [[DBG34:![0-9]+]]
// LIN64-NEXT:    [[TMP40:%.*]] = atomicrmw xor i64* @llx, i64 [[TMP39]] monotonic, align 8, !dbg [[DBG35:![0-9]+]]
// LIN64-NEXT:    [[TMP41:%.*]] = load i64, i64* @ullv, align 8, !dbg [[DBG36:![0-9]+]]
// LIN64-NEXT:    [[TMP42:%.*]] = atomicrmw or i64* @ullx, i64 [[TMP41]] monotonic, align 8, !dbg [[DBG37:![0-9]+]]
// LIN64-NEXT:    [[TMP43:%.*]] = load float, float* @fv, align 4, !dbg [[DBG38:![0-9]+]]
// LIN64-NEXT:    [[TMP44:%.*]] = atomicrmw fadd float* @fx, float [[TMP43]] monotonic, align 4, !dbg [[DBG39:![0-9]+]]
// LIN64-NEXT:    [[TMP45:%.*]] = load double, double* @dv, align 8, !dbg [[DBG40:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD19:%.*]] = load atomic i64, i64* bitcast (double* @dx to i64*) monotonic, align 8, !dbg [[DBG41:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT20:%.*]], !dbg [[DBG41]]
// LIN64:       atomic_cont20:
// LIN64-NEXT:    [[TMP46:%.*]] = phi i64 [ [[ATOMIC_LOAD19]], [[ATOMIC_EXIT18]] ], [ [[TMP51:%.*]], [[ATOMIC_CONT20]] ], !dbg [[DBG41]]
// LIN64-NEXT:    [[TMP47:%.*]] = bitcast double* [[ATOMIC_TEMP21]] to i64*, !dbg [[DBG41]]
// LIN64-NEXT:    [[TMP48:%.*]] = bitcast i64 [[TMP46]] to double, !dbg [[DBG41]]
// LIN64-NEXT:    [[SUB:%.*]] = fsub double [[TMP45]], [[TMP48]], !dbg [[DBG42:![0-9]+]]
// LIN64-NEXT:    store double [[SUB]], double* [[ATOMIC_TEMP21]], align 8, !dbg [[DBG41]]
// LIN64-NEXT:    [[TMP49:%.*]] = load i64, i64* [[TMP47]], align 8, !dbg [[DBG41]]
// LIN64-NEXT:    [[TMP50:%.*]] = cmpxchg i64* bitcast (double* @dx to i64*), i64 [[TMP46]], i64 [[TMP49]] monotonic monotonic, align 8, !dbg [[DBG41]]
// LIN64-NEXT:    [[TMP51]] = extractvalue { i64, i1 } [[TMP50]], 0, !dbg [[DBG41]]
// LIN64-NEXT:    [[TMP52:%.*]] = extractvalue { i64, i1 } [[TMP50]], 1, !dbg [[DBG41]]
// LIN64-NEXT:    br i1 [[TMP52]], label [[ATOMIC_EXIT22:%.*]], label [[ATOMIC_CONT20]], !dbg [[DBG41]]
// LIN64:       atomic_exit22:
// LIN64-NEXT:    [[TMP53:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG43:![0-9]+]]
// LIN64-NEXT:    [[TMP54:%.*]] = bitcast x86_fp80* [[ATOMIC_TEMP23]] to i8*, !dbg [[DBG44:![0-9]+]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 16, i8* noundef bitcast (x86_fp80* @ldx to i8*), i8* noundef [[TMP54]], i32 noundef 0), !dbg [[DBG44]]
// LIN64-NEXT:    br label [[ATOMIC_CONT24:%.*]], !dbg [[DBG44]]
// LIN64:       atomic_cont24:
// LIN64-NEXT:    [[TMP55:%.*]] = load x86_fp80, x86_fp80* [[ATOMIC_TEMP23]], align 16, !dbg [[DBG44]]
// LIN64-NEXT:    store x86_fp80 [[TMP55]], x86_fp80* [[ATOMIC_TEMP25]], align 16, !dbg [[DBG44]]
// LIN64-NEXT:    [[TMP56:%.*]] = load x86_fp80, x86_fp80* [[ATOMIC_TEMP23]], align 16, !dbg [[DBG44]]
// LIN64-NEXT:    [[MUL26:%.*]] = fmul x86_fp80 [[TMP56]], [[TMP53]], !dbg [[DBG45:![0-9]+]]
// LIN64-NEXT:    store x86_fp80 [[MUL26]], x86_fp80* [[ATOMIC_TEMP25]], align 16, !dbg [[DBG44]]
// LIN64-NEXT:    [[TMP57:%.*]] = bitcast x86_fp80* [[ATOMIC_TEMP23]] to i8*, !dbg [[DBG44]]
// LIN64-NEXT:    [[TMP58:%.*]] = bitcast x86_fp80* [[ATOMIC_TEMP25]] to i8*, !dbg [[DBG44]]
// LIN64-NEXT:    [[CALL:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, i8* noundef bitcast (x86_fp80* @ldx to i8*), i8* noundef [[TMP57]], i8* noundef [[TMP58]], i32 noundef 0, i32 noundef 0), !dbg [[DBG44]]
// LIN64-NEXT:    br i1 [[CALL]], label [[ATOMIC_EXIT27:%.*]], label [[ATOMIC_CONT24]], !dbg [[DBG44]]
// LIN64:       atomic_exit27:
// LIN64-NEXT:    [[CIV_REAL:%.*]] = load i32, i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 0), align 4, !dbg [[DBG46:![0-9]+]]
// LIN64-NEXT:    [[CIV_IMAG:%.*]] = load i32, i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 1), align 4, !dbg [[DBG46]]
// LIN64-NEXT:    [[TMP59:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP28]] to i8*, !dbg [[DBG47:![0-9]+]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP59]], i32 noundef 0), !dbg [[DBG47]]
// LIN64-NEXT:    br label [[ATOMIC_CONT29:%.*]], !dbg [[DBG47]]
// LIN64:       atomic_cont29:
// LIN64-NEXT:    [[ATOMIC_TEMP28_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP28]], i32 0, i32 0, !dbg [[DBG47]]
// LIN64-NEXT:    [[ATOMIC_TEMP28_REAL:%.*]] = load i32, i32* [[ATOMIC_TEMP28_REALP]], align 4, !dbg [[DBG47]]
// LIN64-NEXT:    [[ATOMIC_TEMP28_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP28]], i32 0, i32 1, !dbg [[DBG47]]
// LIN64-NEXT:    [[ATOMIC_TEMP28_IMAG:%.*]] = load i32, i32* [[ATOMIC_TEMP28_IMAGP]], align 4, !dbg [[DBG47]]
// LIN64-NEXT:    [[TMP60:%.*]] = mul i32 [[CIV_REAL]], [[ATOMIC_TEMP28_REAL]], !dbg [[DBG48:![0-9]+]]
// LIN64-NEXT:    [[TMP61:%.*]] = mul i32 [[CIV_IMAG]], [[ATOMIC_TEMP28_IMAG]], !dbg [[DBG48]]
// LIN64-NEXT:    [[TMP62:%.*]] = add i32 [[TMP60]], [[TMP61]], !dbg [[DBG48]]
// LIN64-NEXT:    [[TMP63:%.*]] = mul i32 [[ATOMIC_TEMP28_REAL]], [[ATOMIC_TEMP28_REAL]], !dbg [[DBG48]]
// LIN64-NEXT:    [[TMP64:%.*]] = mul i32 [[ATOMIC_TEMP28_IMAG]], [[ATOMIC_TEMP28_IMAG]], !dbg [[DBG48]]
// LIN64-NEXT:    [[TMP65:%.*]] = add i32 [[TMP63]], [[TMP64]], !dbg [[DBG48]]
// LIN64-NEXT:    [[TMP66:%.*]] = mul i32 [[CIV_IMAG]], [[ATOMIC_TEMP28_REAL]], !dbg [[DBG48]]
// LIN64-NEXT:    [[TMP67:%.*]] = mul i32 [[CIV_REAL]], [[ATOMIC_TEMP28_IMAG]], !dbg [[DBG48]]
// LIN64-NEXT:    [[TMP68:%.*]] = sub i32 [[TMP66]], [[TMP67]], !dbg [[DBG48]]
// LIN64-NEXT:    [[TMP69:%.*]] = sdiv i32 [[TMP62]], [[TMP65]], !dbg [[DBG48]]
// LIN64-NEXT:    [[TMP70:%.*]] = sdiv i32 [[TMP68]], [[TMP65]], !dbg [[DBG48]]
// LIN64-NEXT:    [[ATOMIC_TEMP30_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP30]], i32 0, i32 0, !dbg [[DBG47]]
// LIN64-NEXT:    [[ATOMIC_TEMP30_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP30]], i32 0, i32 1, !dbg [[DBG47]]
// LIN64-NEXT:    store i32 [[TMP69]], i32* [[ATOMIC_TEMP30_REALP]], align 4, !dbg [[DBG47]]
// LIN64-NEXT:    store i32 [[TMP70]], i32* [[ATOMIC_TEMP30_IMAGP]], align 4, !dbg [[DBG47]]
// LIN64-NEXT:    [[TMP71:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP28]] to i8*, !dbg [[DBG47]]
// LIN64-NEXT:    [[TMP72:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP30]] to i8*, !dbg [[DBG47]]
// LIN64-NEXT:    [[CALL31:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP71]], i8* noundef [[TMP72]], i32 noundef 0, i32 noundef 0), !dbg [[DBG47]]
// LIN64-NEXT:    br i1 [[CALL31]], label [[ATOMIC_EXIT32:%.*]], label [[ATOMIC_CONT29]], !dbg [[DBG47]]
// LIN64:       atomic_exit32:
// LIN64-NEXT:    [[CFV_REAL:%.*]] = load float, float* getelementptr inbounds ({ float, float }, { float, float }* @cfv, i32 0, i32 0), align 4, !dbg [[DBG49:![0-9]+]]
// LIN64-NEXT:    [[CFV_IMAG:%.*]] = load float, float* getelementptr inbounds ({ float, float }, { float, float }* @cfv, i32 0, i32 1), align 4, !dbg [[DBG49]]
// LIN64-NEXT:    [[TMP73:%.*]] = bitcast { float, float }* [[ATOMIC_TEMP33]] to i8*, !dbg [[DBG50:![0-9]+]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 8, i8* noundef bitcast ({ float, float }* @cfx to i8*), i8* noundef [[TMP73]], i32 noundef 0), !dbg [[DBG50]]
// LIN64-NEXT:    br label [[ATOMIC_CONT34:%.*]], !dbg [[DBG50]]
// LIN64:       atomic_cont34:
// LIN64-NEXT:    [[ATOMIC_TEMP33_REALP:%.*]] = getelementptr inbounds { float, float }, { float, float }* [[ATOMIC_TEMP33]], i32 0, i32 0, !dbg [[DBG50]]
// LIN64-NEXT:    [[ATOMIC_TEMP33_REAL:%.*]] = load float, float* [[ATOMIC_TEMP33_REALP]], align 4, !dbg [[DBG50]]
// LIN64-NEXT:    [[ATOMIC_TEMP33_IMAGP:%.*]] = getelementptr inbounds { float, float }, { float, float }* [[ATOMIC_TEMP33]], i32 0, i32 1, !dbg [[DBG50]]
// LIN64-NEXT:    [[ATOMIC_TEMP33_IMAG:%.*]] = load float, float* [[ATOMIC_TEMP33_IMAGP]], align 4, !dbg [[DBG50]]
// LIN64-NEXT:    [[ADD_R:%.*]] = fadd float [[CFV_REAL]], [[ATOMIC_TEMP33_REAL]], !dbg [[DBG51:![0-9]+]]
// LIN64-NEXT:    [[ADD_I:%.*]] = fadd float [[CFV_IMAG]], [[ATOMIC_TEMP33_IMAG]], !dbg [[DBG51]]
// LIN64-NEXT:    [[ATOMIC_TEMP35_REALP:%.*]] = getelementptr inbounds { float, float }, { float, float }* [[ATOMIC_TEMP35]], i32 0, i32 0, !dbg [[DBG50]]
// LIN64-NEXT:    [[ATOMIC_TEMP35_IMAGP:%.*]] = getelementptr inbounds { float, float }, { float, float }* [[ATOMIC_TEMP35]], i32 0, i32 1, !dbg [[DBG50]]
// LIN64-NEXT:    store float [[ADD_R]], float* [[ATOMIC_TEMP35_REALP]], align 4, !dbg [[DBG50]]
// LIN64-NEXT:    store float [[ADD_I]], float* [[ATOMIC_TEMP35_IMAGP]], align 4, !dbg [[DBG50]]
// LIN64-NEXT:    [[TMP74:%.*]] = bitcast { float, float }* [[ATOMIC_TEMP33]] to i8*, !dbg [[DBG50]]
// LIN64-NEXT:    [[TMP75:%.*]] = bitcast { float, float }* [[ATOMIC_TEMP35]] to i8*, !dbg [[DBG50]]
// LIN64-NEXT:    [[CALL36:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, i8* noundef bitcast ({ float, float }* @cfx to i8*), i8* noundef [[TMP74]], i8* noundef [[TMP75]], i32 noundef 0, i32 noundef 0), !dbg [[DBG50]]
// LIN64-NEXT:    br i1 [[CALL36]], label [[ATOMIC_EXIT37:%.*]], label [[ATOMIC_CONT34]], !dbg [[DBG50]]
// LIN64:       atomic_exit37:
// LIN64-NEXT:    [[CDV_REAL:%.*]] = load double, double* getelementptr inbounds ({ double, double }, { double, double }* @cdv, i32 0, i32 0), align 8, !dbg [[DBG52:![0-9]+]]
// LIN64-NEXT:    [[CDV_IMAG:%.*]] = load double, double* getelementptr inbounds ({ double, double }, { double, double }* @cdv, i32 0, i32 1), align 8, !dbg [[DBG52]]
// LIN64-NEXT:    [[TMP76:%.*]] = bitcast { double, double }* [[ATOMIC_TEMP38]] to i8*, !dbg [[DBG53:![0-9]+]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 16, i8* noundef bitcast ({ double, double }* @cdx to i8*), i8* noundef [[TMP76]], i32 noundef 5), !dbg [[DBG53]]
// LIN64-NEXT:    br label [[ATOMIC_CONT39:%.*]], !dbg [[DBG53]]
// LIN64:       atomic_cont39:
// LIN64-NEXT:    [[ATOMIC_TEMP38_REALP:%.*]] = getelementptr inbounds { double, double }, { double, double }* [[ATOMIC_TEMP38]], i32 0, i32 0, !dbg [[DBG53]]
// LIN64-NEXT:    [[ATOMIC_TEMP38_REAL:%.*]] = load double, double* [[ATOMIC_TEMP38_REALP]], align 8, !dbg [[DBG53]]
// LIN64-NEXT:    [[ATOMIC_TEMP38_IMAGP:%.*]] = getelementptr inbounds { double, double }, { double, double }* [[ATOMIC_TEMP38]], i32 0, i32 1, !dbg [[DBG53]]
// LIN64-NEXT:    [[ATOMIC_TEMP38_IMAG:%.*]] = load double, double* [[ATOMIC_TEMP38_IMAGP]], align 8, !dbg [[DBG53]]
// LIN64-NEXT:    [[SUB_R:%.*]] = fsub double [[ATOMIC_TEMP38_REAL]], [[CDV_REAL]], !dbg [[DBG54:![0-9]+]]
// LIN64-NEXT:    [[SUB_I:%.*]] = fsub double [[ATOMIC_TEMP38_IMAG]], [[CDV_IMAG]], !dbg [[DBG54]]
// LIN64-NEXT:    [[ATOMIC_TEMP40_REALP:%.*]] = getelementptr inbounds { double, double }, { double, double }* [[ATOMIC_TEMP40]], i32 0, i32 0, !dbg [[DBG53]]
// LIN64-NEXT:    [[ATOMIC_TEMP40_IMAGP:%.*]] = getelementptr inbounds { double, double }, { double, double }* [[ATOMIC_TEMP40]], i32 0, i32 1, !dbg [[DBG53]]
// LIN64-NEXT:    store double [[SUB_R]], double* [[ATOMIC_TEMP40_REALP]], align 8, !dbg [[DBG53]]
// LIN64-NEXT:    store double [[SUB_I]], double* [[ATOMIC_TEMP40_IMAGP]], align 8, !dbg [[DBG53]]
// LIN64-NEXT:    [[TMP77:%.*]] = bitcast { double, double }* [[ATOMIC_TEMP38]] to i8*, !dbg [[DBG53]]
// LIN64-NEXT:    [[TMP78:%.*]] = bitcast { double, double }* [[ATOMIC_TEMP40]] to i8*, !dbg [[DBG53]]
// LIN64-NEXT:    [[CALL41:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, i8* noundef bitcast ({ double, double }* @cdx to i8*), i8* noundef [[TMP77]], i8* noundef [[TMP78]], i32 noundef 5, i32 noundef 5), !dbg [[DBG53]]
// LIN64-NEXT:    br i1 [[CALL41]], label [[ATOMIC_EXIT42:%.*]], label [[ATOMIC_CONT39]], !dbg [[DBG53]]
// LIN64:       atomic_exit42:
// LIN64-NEXT:    fence release
// LIN64-NEXT:    [[TMP79:%.*]] = load i8, i8* @bv, align 1, !dbg [[DBG55:![0-9]+]]
// LIN64-NEXT:    [[TOBOOL:%.*]] = trunc i8 [[TMP79]] to i1, !dbg [[DBG55]]
// LIN64-NEXT:    [[CONV43:%.*]] = zext i1 [[TOBOOL]] to i64, !dbg [[DBG55]]
// LIN64-NEXT:    [[TMP80:%.*]] = atomicrmw and i64* @ulx, i64 [[CONV43]] monotonic, align 8, !dbg [[DBG56:![0-9]+]]
// LIN64-NEXT:    [[TMP81:%.*]] = load i8, i8* @cv, align 1, !dbg [[DBG57:![0-9]+]]
// LIN64-NEXT:    [[CONV44:%.*]] = sext i8 [[TMP81]] to i32, !dbg [[DBG57]]
// LIN64-NEXT:    [[ATOMIC_LOAD45:%.*]] = load atomic i8, i8* @bx monotonic, align 1, !dbg [[DBG58:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT46:%.*]], !dbg [[DBG58]]
// LIN64:       atomic_cont46:
// LIN64-NEXT:    [[TMP82:%.*]] = phi i8 [ [[ATOMIC_LOAD45]], [[ATOMIC_EXIT42]] ], [ [[TMP85:%.*]], [[ATOMIC_CONT46]] ], !dbg [[DBG58]]
// LIN64-NEXT:    [[TOBOOL48:%.*]] = trunc i8 [[TMP82]] to i1, !dbg [[DBG58]]
// LIN64-NEXT:    [[CONV49:%.*]] = zext i1 [[TOBOOL48]] to i32, !dbg [[DBG58]]
// LIN64-NEXT:    [[AND:%.*]] = and i32 [[CONV44]], [[CONV49]], !dbg [[DBG59:![0-9]+]]
// LIN64-NEXT:    [[TOBOOL50:%.*]] = icmp ne i32 [[AND]], 0, !dbg [[DBG57]]
// LIN64-NEXT:    [[FROMBOOL:%.*]] = zext i1 [[TOBOOL50]] to i8, !dbg [[DBG58]]
// LIN64-NEXT:    store i8 [[FROMBOOL]], i8* [[ATOMIC_TEMP47]], align 1, !dbg [[DBG58]]
// LIN64-NEXT:    [[TMP83:%.*]] = load i8, i8* [[ATOMIC_TEMP47]], align 1, !dbg [[DBG58]]
// LIN64-NEXT:    [[TMP84:%.*]] = cmpxchg i8* @bx, i8 [[TMP82]], i8 [[TMP83]] monotonic monotonic, align 1, !dbg [[DBG58]]
// LIN64-NEXT:    [[TMP85]] = extractvalue { i8, i1 } [[TMP84]], 0, !dbg [[DBG58]]
// LIN64-NEXT:    [[TMP86:%.*]] = extractvalue { i8, i1 } [[TMP84]], 1, !dbg [[DBG58]]
// LIN64-NEXT:    br i1 [[TMP86]], label [[ATOMIC_EXIT51:%.*]], label [[ATOMIC_CONT46]], !dbg [[DBG58]]
// LIN64:       atomic_exit51:
// LIN64-NEXT:    [[TMP87:%.*]] = load i8, i8* @ucv, align 1, !dbg [[DBG60:![0-9]+]]
// LIN64-NEXT:    [[CONV52:%.*]] = zext i8 [[TMP87]] to i32, !dbg [[DBG60]]
// LIN64-NEXT:    [[ATOMIC_LOAD53:%.*]] = load atomic i8, i8* @cx seq_cst, align 1, !dbg [[DBG61:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT54:%.*]], !dbg [[DBG61]]
// LIN64:       atomic_cont54:
// LIN64-NEXT:    [[TMP88:%.*]] = phi i8 [ [[ATOMIC_LOAD53]], [[ATOMIC_EXIT51]] ], [ [[TMP91:%.*]], [[ATOMIC_CONT54]] ], !dbg [[DBG61]]
// LIN64-NEXT:    [[CONV56:%.*]] = sext i8 [[TMP88]] to i32, !dbg [[DBG61]]
// LIN64-NEXT:    [[SHR57:%.*]] = ashr i32 [[CONV56]], [[CONV52]], !dbg [[DBG62:![0-9]+]]
// LIN64-NEXT:    [[CONV58:%.*]] = trunc i32 [[SHR57]] to i8, !dbg [[DBG61]]
// LIN64-NEXT:    store i8 [[CONV58]], i8* [[ATOMIC_TEMP55]], align 1, !dbg [[DBG61]]
// LIN64-NEXT:    [[TMP89:%.*]] = load i8, i8* [[ATOMIC_TEMP55]], align 1, !dbg [[DBG61]]
// LIN64-NEXT:    [[TMP90:%.*]] = cmpxchg i8* @cx, i8 [[TMP88]], i8 [[TMP89]] seq_cst seq_cst, align 1, !dbg [[DBG61]]
// LIN64-NEXT:    [[TMP91]] = extractvalue { i8, i1 } [[TMP90]], 0, !dbg [[DBG61]]
// LIN64-NEXT:    [[TMP92:%.*]] = extractvalue { i8, i1 } [[TMP90]], 1, !dbg [[DBG61]]
// LIN64-NEXT:    br i1 [[TMP92]], label [[ATOMIC_EXIT59:%.*]], label [[ATOMIC_CONT54]], !dbg [[DBG61]]
// LIN64:       atomic_exit59:
// LIN64-NEXT:    fence release
// LIN64-NEXT:    [[TMP93:%.*]] = load i16, i16* @sv, align 2, !dbg [[DBG63:![0-9]+]]
// LIN64-NEXT:    [[CONV60:%.*]] = sext i16 [[TMP93]] to i32, !dbg [[DBG63]]
// LIN64-NEXT:    [[ATOMIC_LOAD61:%.*]] = load atomic i64, i64* @ulx monotonic, align 8, !dbg [[DBG64:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT62:%.*]], !dbg [[DBG64]]
// LIN64:       atomic_cont62:
// LIN64-NEXT:    [[TMP94:%.*]] = phi i64 [ [[ATOMIC_LOAD61]], [[ATOMIC_EXIT59]] ], [ [[TMP97:%.*]], [[ATOMIC_CONT62]] ], !dbg [[DBG64]]
// LIN64-NEXT:    [[SH_PROM:%.*]] = trunc i64 [[TMP94]] to i32, !dbg [[DBG65:![0-9]+]]
// LIN64-NEXT:    [[SHL64:%.*]] = shl i32 [[CONV60]], [[SH_PROM]], !dbg [[DBG65]]
// LIN64-NEXT:    [[CONV65:%.*]] = sext i32 [[SHL64]] to i64, !dbg [[DBG63]]
// LIN64-NEXT:    store i64 [[CONV65]], i64* [[ATOMIC_TEMP63]], align 8, !dbg [[DBG64]]
// LIN64-NEXT:    [[TMP95:%.*]] = load i64, i64* [[ATOMIC_TEMP63]], align 8, !dbg [[DBG64]]
// LIN64-NEXT:    [[TMP96:%.*]] = cmpxchg i64* @ulx, i64 [[TMP94]], i64 [[TMP95]] monotonic monotonic, align 8, !dbg [[DBG64]]
// LIN64-NEXT:    [[TMP97]] = extractvalue { i64, i1 } [[TMP96]], 0, !dbg [[DBG64]]
// LIN64-NEXT:    [[TMP98:%.*]] = extractvalue { i64, i1 } [[TMP96]], 1, !dbg [[DBG64]]
// LIN64-NEXT:    br i1 [[TMP98]], label [[ATOMIC_EXIT66:%.*]], label [[ATOMIC_CONT62]], !dbg [[DBG64]]
// LIN64:       atomic_exit66:
// LIN64-NEXT:    [[TMP99:%.*]] = load i16, i16* @usv, align 2, !dbg [[DBG66:![0-9]+]]
// LIN64-NEXT:    [[CONV67:%.*]] = zext i16 [[TMP99]] to i64, !dbg [[DBG66]]
// LIN64-NEXT:    [[ATOMIC_LOAD68:%.*]] = load atomic i64, i64* @lx monotonic, align 8, !dbg [[DBG67:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT69:%.*]], !dbg [[DBG67]]
// LIN64:       atomic_cont69:
// LIN64-NEXT:    [[TMP100:%.*]] = phi i64 [ [[ATOMIC_LOAD68]], [[ATOMIC_EXIT66]] ], [ [[TMP103:%.*]], [[ATOMIC_CONT69]] ], !dbg [[DBG67]]
// LIN64-NEXT:    [[REM:%.*]] = srem i64 [[TMP100]], [[CONV67]], !dbg [[DBG68:![0-9]+]]
// LIN64-NEXT:    store i64 [[REM]], i64* [[ATOMIC_TEMP70]], align 8, !dbg [[DBG67]]
// LIN64-NEXT:    [[TMP101:%.*]] = load i64, i64* [[ATOMIC_TEMP70]], align 8, !dbg [[DBG67]]
// LIN64-NEXT:    [[TMP102:%.*]] = cmpxchg i64* @lx, i64 [[TMP100]], i64 [[TMP101]] monotonic monotonic, align 8, !dbg [[DBG67]]
// LIN64-NEXT:    [[TMP103]] = extractvalue { i64, i1 } [[TMP102]], 0, !dbg [[DBG67]]
// LIN64-NEXT:    [[TMP104:%.*]] = extractvalue { i64, i1 } [[TMP102]], 1, !dbg [[DBG67]]
// LIN64-NEXT:    br i1 [[TMP104]], label [[ATOMIC_EXIT71:%.*]], label [[ATOMIC_CONT69]], !dbg [[DBG67]]
// LIN64:       atomic_exit71:
// LIN64-NEXT:    [[TMP105:%.*]] = load i32, i32* @iv, align 4, !dbg [[DBG69:![0-9]+]]
// LIN64-NEXT:    [[TMP106:%.*]] = atomicrmw or i32* @uix, i32 [[TMP105]] seq_cst, align 4, !dbg [[DBG70:![0-9]+]]
// LIN64-NEXT:    fence release
// LIN64-NEXT:    [[TMP107:%.*]] = load i32, i32* @uiv, align 4, !dbg [[DBG71:![0-9]+]]
// LIN64-NEXT:    [[TMP108:%.*]] = atomicrmw and i32* @ix, i32 [[TMP107]] monotonic, align 4, !dbg [[DBG72:![0-9]+]]
// LIN64-NEXT:    [[TMP109:%.*]] = load i64, i64* @lv, align 8, !dbg [[DBG73:![0-9]+]]
// LIN64-NEXT:    [[TMP110:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP72]] to i8*, !dbg [[DBG74:![0-9]+]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP110]], i32 noundef 0), !dbg [[DBG74]]
// LIN64-NEXT:    br label [[ATOMIC_CONT73:%.*]], !dbg [[DBG74]]
// LIN64:       atomic_cont73:
// LIN64-NEXT:    [[ATOMIC_TEMP72_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP72]], i32 0, i32 0, !dbg [[DBG74]]
// LIN64-NEXT:    [[ATOMIC_TEMP72_REAL:%.*]] = load i32, i32* [[ATOMIC_TEMP72_REALP]], align 4, !dbg [[DBG74]]
// LIN64-NEXT:    [[ATOMIC_TEMP72_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP72]], i32 0, i32 1, !dbg [[DBG74]]
// LIN64-NEXT:    [[ATOMIC_TEMP72_IMAG:%.*]] = load i32, i32* [[ATOMIC_TEMP72_IMAGP]], align 4, !dbg [[DBG74]]
// LIN64-NEXT:    [[CONV75:%.*]] = sext i32 [[ATOMIC_TEMP72_REAL]] to i64, !dbg [[DBG74]]
// LIN64-NEXT:    [[CONV76:%.*]] = sext i32 [[ATOMIC_TEMP72_IMAG]] to i64, !dbg [[DBG74]]
// LIN64-NEXT:    [[ADD_R77:%.*]] = add i64 [[TMP109]], [[CONV75]], !dbg [[DBG75:![0-9]+]]
// LIN64-NEXT:    [[ADD_I78:%.*]] = add i64 0, [[CONV76]], !dbg [[DBG75]]
// LIN64-NEXT:    [[CONV79:%.*]] = trunc i64 [[ADD_R77]] to i32, !dbg [[DBG73]]
// LIN64-NEXT:    [[CONV80:%.*]] = trunc i64 [[ADD_I78]] to i32, !dbg [[DBG73]]
// LIN64-NEXT:    [[ATOMIC_TEMP74_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP74]], i32 0, i32 0, !dbg [[DBG74]]
// LIN64-NEXT:    [[ATOMIC_TEMP74_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP74]], i32 0, i32 1, !dbg [[DBG74]]
// LIN64-NEXT:    store i32 [[CONV79]], i32* [[ATOMIC_TEMP74_REALP]], align 4, !dbg [[DBG74]]
// LIN64-NEXT:    store i32 [[CONV80]], i32* [[ATOMIC_TEMP74_IMAGP]], align 4, !dbg [[DBG74]]
// LIN64-NEXT:    [[TMP111:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP72]] to i8*, !dbg [[DBG74]]
// LIN64-NEXT:    [[TMP112:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP74]] to i8*, !dbg [[DBG74]]
// LIN64-NEXT:    [[CALL81:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP111]], i8* noundef [[TMP112]], i32 noundef 0, i32 noundef 0), !dbg [[DBG74]]
// LIN64-NEXT:    br i1 [[CALL81]], label [[ATOMIC_EXIT82:%.*]], label [[ATOMIC_CONT73]], !dbg [[DBG74]]
// LIN64:       atomic_exit82:
// LIN64-NEXT:    [[TMP113:%.*]] = load i64, i64* @ulv, align 8, !dbg [[DBG76:![0-9]+]]
// LIN64-NEXT:    [[CONV83:%.*]] = uitofp i64 [[TMP113]] to float, !dbg [[DBG76]]
// LIN64-NEXT:    [[ATOMIC_LOAD84:%.*]] = load atomic i32, i32* bitcast (float* @fx to i32*) monotonic, align 4, !dbg [[DBG77:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT85:%.*]], !dbg [[DBG77]]
// LIN64:       atomic_cont85:
// LIN64-NEXT:    [[TMP114:%.*]] = phi i32 [ [[ATOMIC_LOAD84]], [[ATOMIC_EXIT82]] ], [ [[TMP119:%.*]], [[ATOMIC_CONT85]] ], !dbg [[DBG77]]
// LIN64-NEXT:    [[TMP115:%.*]] = bitcast float* [[ATOMIC_TEMP86]] to i32*, !dbg [[DBG77]]
// LIN64-NEXT:    [[TMP116:%.*]] = bitcast i32 [[TMP114]] to float, !dbg [[DBG77]]
// LIN64-NEXT:    [[MUL87:%.*]] = fmul float [[TMP116]], [[CONV83]], !dbg [[DBG78:![0-9]+]]
// LIN64-NEXT:    store float [[MUL87]], float* [[ATOMIC_TEMP86]], align 4, !dbg [[DBG77]]
// LIN64-NEXT:    [[TMP117:%.*]] = load i32, i32* [[TMP115]], align 4, !dbg [[DBG77]]
// LIN64-NEXT:    [[TMP118:%.*]] = cmpxchg i32* bitcast (float* @fx to i32*), i32 [[TMP114]], i32 [[TMP117]] monotonic monotonic, align 4, !dbg [[DBG77]]
// LIN64-NEXT:    [[TMP119]] = extractvalue { i32, i1 } [[TMP118]], 0, !dbg [[DBG77]]
// LIN64-NEXT:    [[TMP120:%.*]] = extractvalue { i32, i1 } [[TMP118]], 1, !dbg [[DBG77]]
// LIN64-NEXT:    br i1 [[TMP120]], label [[ATOMIC_EXIT88:%.*]], label [[ATOMIC_CONT85]], !dbg [[DBG77]]
// LIN64:       atomic_exit88:
// LIN64-NEXT:    [[TMP121:%.*]] = load i64, i64* @llv, align 8, !dbg [[DBG79:![0-9]+]]
// LIN64-NEXT:    [[CONV89:%.*]] = sitofp i64 [[TMP121]] to double, !dbg [[DBG79]]
// LIN64-NEXT:    [[ATOMIC_LOAD90:%.*]] = load atomic i64, i64* bitcast (double* @dx to i64*) monotonic, align 8, !dbg [[DBG80:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT91:%.*]], !dbg [[DBG80]]
// LIN64:       atomic_cont91:
// LIN64-NEXT:    [[TMP122:%.*]] = phi i64 [ [[ATOMIC_LOAD90]], [[ATOMIC_EXIT88]] ], [ [[TMP127:%.*]], [[ATOMIC_CONT91]] ], !dbg [[DBG80]]
// LIN64-NEXT:    [[TMP123:%.*]] = bitcast double* [[ATOMIC_TEMP92]] to i64*, !dbg [[DBG80]]
// LIN64-NEXT:    [[TMP124:%.*]] = bitcast i64 [[TMP122]] to double, !dbg [[DBG80]]
// LIN64-NEXT:    [[DIV93:%.*]] = fdiv double [[TMP124]], [[CONV89]], !dbg [[DBG81:![0-9]+]]
// LIN64-NEXT:    store double [[DIV93]], double* [[ATOMIC_TEMP92]], align 8, !dbg [[DBG80]]
// LIN64-NEXT:    [[TMP125:%.*]] = load i64, i64* [[TMP123]], align 8, !dbg [[DBG80]]
// LIN64-NEXT:    [[TMP126:%.*]] = cmpxchg i64* bitcast (double* @dx to i64*), i64 [[TMP122]], i64 [[TMP125]] monotonic monotonic, align 8, !dbg [[DBG80]]
// LIN64-NEXT:    [[TMP127]] = extractvalue { i64, i1 } [[TMP126]], 0, !dbg [[DBG80]]
// LIN64-NEXT:    [[TMP128:%.*]] = extractvalue { i64, i1 } [[TMP126]], 1, !dbg [[DBG80]]
// LIN64-NEXT:    br i1 [[TMP128]], label [[ATOMIC_EXIT94:%.*]], label [[ATOMIC_CONT91]], !dbg [[DBG80]]
// LIN64:       atomic_exit94:
// LIN64-NEXT:    [[TMP129:%.*]] = load i64, i64* @ullv, align 8, !dbg [[DBG82:![0-9]+]]
// LIN64-NEXT:    [[CONV95:%.*]] = uitofp i64 [[TMP129]] to x86_fp80, !dbg [[DBG82]]
// LIN64-NEXT:    [[TMP130:%.*]] = bitcast x86_fp80* [[ATOMIC_TEMP96]] to i8*, !dbg [[DBG83:![0-9]+]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 16, i8* noundef bitcast (x86_fp80* @ldx to i8*), i8* noundef [[TMP130]], i32 noundef 0), !dbg [[DBG83]]
// LIN64-NEXT:    br label [[ATOMIC_CONT97:%.*]], !dbg [[DBG83]]
// LIN64:       atomic_cont97:
// LIN64-NEXT:    [[TMP131:%.*]] = load x86_fp80, x86_fp80* [[ATOMIC_TEMP96]], align 16, !dbg [[DBG83]]
// LIN64-NEXT:    store x86_fp80 [[TMP131]], x86_fp80* [[ATOMIC_TEMP98]], align 16, !dbg [[DBG83]]
// LIN64-NEXT:    [[TMP132:%.*]] = load x86_fp80, x86_fp80* [[ATOMIC_TEMP96]], align 16, !dbg [[DBG83]]
// LIN64-NEXT:    [[SUB99:%.*]] = fsub x86_fp80 [[TMP132]], [[CONV95]], !dbg [[DBG84:![0-9]+]]
// LIN64-NEXT:    store x86_fp80 [[SUB99]], x86_fp80* [[ATOMIC_TEMP98]], align 16, !dbg [[DBG83]]
// LIN64-NEXT:    [[TMP133:%.*]] = bitcast x86_fp80* [[ATOMIC_TEMP96]] to i8*, !dbg [[DBG83]]
// LIN64-NEXT:    [[TMP134:%.*]] = bitcast x86_fp80* [[ATOMIC_TEMP98]] to i8*, !dbg [[DBG83]]
// LIN64-NEXT:    [[CALL100:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, i8* noundef bitcast (x86_fp80* @ldx to i8*), i8* noundef [[TMP133]], i8* noundef [[TMP134]], i32 noundef 0, i32 noundef 0), !dbg [[DBG83]]
// LIN64-NEXT:    br i1 [[CALL100]], label [[ATOMIC_EXIT101:%.*]], label [[ATOMIC_CONT97]], !dbg [[DBG83]]
// LIN64:       atomic_exit101:
// LIN64-NEXT:    [[TMP135:%.*]] = load float, float* @fv, align 4, !dbg [[DBG85:![0-9]+]]
// LIN64-NEXT:    [[TMP136:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP102]] to i8*, !dbg [[DBG86:![0-9]+]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP136]], i32 noundef 0), !dbg [[DBG86]]
// LIN64-NEXT:    br label [[ATOMIC_CONT103:%.*]], !dbg [[DBG86]]
// LIN64:       atomic_cont103:
// LIN64-NEXT:    [[ATOMIC_TEMP102_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP102]], i32 0, i32 0, !dbg [[DBG86]]
// LIN64-NEXT:    [[ATOMIC_TEMP102_REAL:%.*]] = load i32, i32* [[ATOMIC_TEMP102_REALP]], align 4, !dbg [[DBG86]]
// LIN64-NEXT:    [[ATOMIC_TEMP102_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP102]], i32 0, i32 1, !dbg [[DBG86]]
// LIN64-NEXT:    [[ATOMIC_TEMP102_IMAG:%.*]] = load i32, i32* [[ATOMIC_TEMP102_IMAGP]], align 4, !dbg [[DBG86]]
// LIN64-NEXT:    [[CONV105:%.*]] = sitofp i32 [[ATOMIC_TEMP102_REAL]] to float, !dbg [[DBG86]]
// LIN64-NEXT:    [[CONV106:%.*]] = sitofp i32 [[ATOMIC_TEMP102_IMAG]] to float, !dbg [[DBG86]]
// LIN64-NEXT:    [[CALL107:%.*]] = call <2 x float> @__divsc3(float noundef [[TMP135]], float noundef 0.000000e+00, float noundef [[CONV105]], float noundef [[CONV106]]) #[[ATTR2:[0-9]+]], !dbg [[DBG87:![0-9]+]]
// LIN64-NEXT:    [[TMP137:%.*]] = bitcast { float, float }* [[COERCE]] to <2 x float>*, !dbg [[DBG87]]
// LIN64-NEXT:    store <2 x float> [[CALL107]], <2 x float>* [[TMP137]], align 4, !dbg [[DBG87]]
// LIN64-NEXT:    [[COERCE_REALP:%.*]] = getelementptr inbounds { float, float }, { float, float }* [[COERCE]], i32 0, i32 0, !dbg [[DBG87]]
// LIN64-NEXT:    [[COERCE_REAL:%.*]] = load float, float* [[COERCE_REALP]], align 4, !dbg [[DBG87]]
// LIN64-NEXT:    [[COERCE_IMAGP:%.*]] = getelementptr inbounds { float, float }, { float, float }* [[COERCE]], i32 0, i32 1, !dbg [[DBG87]]
// LIN64-NEXT:    [[COERCE_IMAG:%.*]] = load float, float* [[COERCE_IMAGP]], align 4, !dbg [[DBG87]]
// LIN64-NEXT:    [[CONV108:%.*]] = fptosi float [[COERCE_REAL]] to i32, !dbg [[DBG85]]
// LIN64-NEXT:    [[CONV109:%.*]] = fptosi float [[COERCE_IMAG]] to i32, !dbg [[DBG85]]
// LIN64-NEXT:    [[ATOMIC_TEMP104_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP104]], i32 0, i32 0, !dbg [[DBG86]]
// LIN64-NEXT:    [[ATOMIC_TEMP104_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP104]], i32 0, i32 1, !dbg [[DBG86]]
// LIN64-NEXT:    store i32 [[CONV108]], i32* [[ATOMIC_TEMP104_REALP]], align 4, !dbg [[DBG86]]
// LIN64-NEXT:    store i32 [[CONV109]], i32* [[ATOMIC_TEMP104_IMAGP]], align 4, !dbg [[DBG86]]
// LIN64-NEXT:    [[TMP138:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP102]] to i8*, !dbg [[DBG86]]
// LIN64-NEXT:    [[TMP139:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP104]] to i8*, !dbg [[DBG86]]
// LIN64-NEXT:    [[CALL110:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP138]], i8* noundef [[TMP139]], i32 noundef 0, i32 noundef 0), !dbg [[DBG86]]
// LIN64-NEXT:    br i1 [[CALL110]], label [[ATOMIC_EXIT111:%.*]], label [[ATOMIC_CONT103]], !dbg [[DBG86]]
// LIN64:       atomic_exit111:
// LIN64-NEXT:    [[TMP140:%.*]] = load double, double* @dv, align 8, !dbg [[DBG88:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD112:%.*]] = load atomic i16, i16* @sx monotonic, align 2, !dbg [[DBG89:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT113:%.*]], !dbg [[DBG89]]
// LIN64:       atomic_cont113:
// LIN64-NEXT:    [[TMP141:%.*]] = phi i16 [ [[ATOMIC_LOAD112]], [[ATOMIC_EXIT111]] ], [ [[TMP144:%.*]], [[ATOMIC_CONT113]] ], !dbg [[DBG89]]
// LIN64-NEXT:    [[CONV115:%.*]] = sext i16 [[TMP141]] to i32, !dbg [[DBG89]]
// LIN64-NEXT:    [[CONV116:%.*]] = sitofp i32 [[CONV115]] to double, !dbg [[DBG89]]
// LIN64-NEXT:    [[ADD117:%.*]] = fadd double [[CONV116]], [[TMP140]], !dbg [[DBG90:![0-9]+]]
// LIN64-NEXT:    [[CONV118:%.*]] = fptosi double [[ADD117]] to i16, !dbg [[DBG89]]
// LIN64-NEXT:    store i16 [[CONV118]], i16* [[ATOMIC_TEMP114]], align 2, !dbg [[DBG89]]
// LIN64-NEXT:    [[TMP142:%.*]] = load i16, i16* [[ATOMIC_TEMP114]], align 2, !dbg [[DBG89]]
// LIN64-NEXT:    [[TMP143:%.*]] = cmpxchg i16* @sx, i16 [[TMP141]], i16 [[TMP142]] monotonic monotonic, align 2, !dbg [[DBG89]]
// LIN64-NEXT:    [[TMP144]] = extractvalue { i16, i1 } [[TMP143]], 0, !dbg [[DBG89]]
// LIN64-NEXT:    [[TMP145:%.*]] = extractvalue { i16, i1 } [[TMP143]], 1, !dbg [[DBG89]]
// LIN64-NEXT:    br i1 [[TMP145]], label [[ATOMIC_EXIT119:%.*]], label [[ATOMIC_CONT113]], !dbg [[DBG89]]
// LIN64:       atomic_exit119:
// LIN64-NEXT:    [[TMP146:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG91:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD120:%.*]] = load atomic i8, i8* @bx monotonic, align 1, !dbg [[DBG92:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT121:%.*]], !dbg [[DBG92]]
// LIN64:       atomic_cont121:
// LIN64-NEXT:    [[TMP147:%.*]] = phi i8 [ [[ATOMIC_LOAD120]], [[ATOMIC_EXIT119]] ], [ [[TMP150:%.*]], [[ATOMIC_CONT121]] ], !dbg [[DBG92]]
// LIN64-NEXT:    [[TOBOOL123:%.*]] = trunc i8 [[TMP147]] to i1, !dbg [[DBG92]]
// LIN64-NEXT:    [[CONV124:%.*]] = zext i1 [[TOBOOL123]] to i32, !dbg [[DBG92]]
// LIN64-NEXT:    [[CONV125:%.*]] = sitofp i32 [[CONV124]] to x86_fp80, !dbg [[DBG92]]
// LIN64-NEXT:    [[MUL126:%.*]] = fmul x86_fp80 [[TMP146]], [[CONV125]], !dbg [[DBG93:![0-9]+]]
// LIN64-NEXT:    [[TOBOOL127:%.*]] = fcmp une x86_fp80 [[MUL126]], 0xK00000000000000000000, !dbg [[DBG91]]
// LIN64-NEXT:    [[FROMBOOL128:%.*]] = zext i1 [[TOBOOL127]] to i8, !dbg [[DBG92]]
// LIN64-NEXT:    store i8 [[FROMBOOL128]], i8* [[ATOMIC_TEMP122]], align 1, !dbg [[DBG92]]
// LIN64-NEXT:    [[TMP148:%.*]] = load i8, i8* [[ATOMIC_TEMP122]], align 1, !dbg [[DBG92]]
// LIN64-NEXT:    [[TMP149:%.*]] = cmpxchg i8* @bx, i8 [[TMP147]], i8 [[TMP148]] release monotonic, align 1, !dbg [[DBG92]]
// LIN64-NEXT:    [[TMP150]] = extractvalue { i8, i1 } [[TMP149]], 0, !dbg [[DBG92]]
// LIN64-NEXT:    [[TMP151:%.*]] = extractvalue { i8, i1 } [[TMP149]], 1, !dbg [[DBG92]]
// LIN64-NEXT:    br i1 [[TMP151]], label [[ATOMIC_EXIT129:%.*]], label [[ATOMIC_CONT121]], !dbg [[DBG92]]
// LIN64:       atomic_exit129:
// LIN64-NEXT:    fence release
// LIN64-NEXT:    [[CIV_REAL130:%.*]] = load i32, i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 0), align 4, !dbg [[DBG94:![0-9]+]]
// LIN64-NEXT:    [[CIV_IMAG131:%.*]] = load i32, i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 1), align 4, !dbg [[DBG94]]
// LIN64-NEXT:    [[ATOMIC_LOAD132:%.*]] = load atomic i8, i8* @bx monotonic, align 1, !dbg [[DBG95:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT133:%.*]], !dbg [[DBG95]]
// LIN64:       atomic_cont133:
// LIN64-NEXT:    [[TMP152:%.*]] = phi i8 [ [[ATOMIC_LOAD132]], [[ATOMIC_EXIT129]] ], [ [[TMP155:%.*]], [[ATOMIC_CONT133]] ], !dbg [[DBG95]]
// LIN64-NEXT:    [[TOBOOL135:%.*]] = trunc i8 [[TMP152]] to i1, !dbg [[DBG95]]
// LIN64-NEXT:    [[CONV136:%.*]] = zext i1 [[TOBOOL135]] to i32, !dbg [[DBG95]]
// LIN64-NEXT:    [[SUB_R137:%.*]] = sub i32 [[CIV_REAL130]], [[CONV136]], !dbg [[DBG96:![0-9]+]]
// LIN64-NEXT:    [[SUB_I138:%.*]] = sub i32 [[CIV_IMAG131]], 0, !dbg [[DBG96]]
// LIN64-NEXT:    [[TOBOOL139:%.*]] = icmp ne i32 [[SUB_R137]], 0, !dbg [[DBG94]]
// LIN64-NEXT:    [[TOBOOL140:%.*]] = icmp ne i32 [[SUB_I138]], 0, !dbg [[DBG94]]
// LIN64-NEXT:    [[TOBOOL141:%.*]] = or i1 [[TOBOOL139]], [[TOBOOL140]], !dbg [[DBG94]]
// LIN64-NEXT:    [[FROMBOOL142:%.*]] = zext i1 [[TOBOOL141]] to i8, !dbg [[DBG95]]
// LIN64-NEXT:    store i8 [[FROMBOOL142]], i8* [[ATOMIC_TEMP134]], align 1, !dbg [[DBG95]]
// LIN64-NEXT:    [[TMP153:%.*]] = load i8, i8* [[ATOMIC_TEMP134]], align 1, !dbg [[DBG95]]
// LIN64-NEXT:    [[TMP154:%.*]] = cmpxchg i8* @bx, i8 [[TMP152]], i8 [[TMP153]] monotonic monotonic, align 1, !dbg [[DBG95]]
// LIN64-NEXT:    [[TMP155]] = extractvalue { i8, i1 } [[TMP154]], 0, !dbg [[DBG95]]
// LIN64-NEXT:    [[TMP156:%.*]] = extractvalue { i8, i1 } [[TMP154]], 1, !dbg [[DBG95]]
// LIN64-NEXT:    br i1 [[TMP156]], label [[ATOMIC_EXIT143:%.*]], label [[ATOMIC_CONT133]], !dbg [[DBG95]]
// LIN64:       atomic_exit143:
// LIN64-NEXT:    [[TMP157:%.*]] = load i16, i16* @sv, align 2, !dbg [[DBG97:![0-9]+]]
// LIN64-NEXT:    [[TMP158:%.*]] = load i8, i8* @bv, align 1, !dbg [[DBG98:![0-9]+]]
// LIN64-NEXT:    [[TOBOOL144:%.*]] = trunc i8 [[TMP158]] to i1, !dbg [[DBG98]]
// LIN64-NEXT:    [[CONV145:%.*]] = zext i1 [[TOBOOL144]] to i32, !dbg [[DBG98]]
// LIN64-NEXT:    [[TMP159:%.*]] = bitcast <4 x i32>* [[ATOMIC_TEMP146]] to i8*, !dbg [[DBG99:![0-9]+]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 16, i8* noundef bitcast (<4 x i32>* @int4x to i8*), i8* noundef [[TMP159]], i32 noundef 0), !dbg [[DBG99]]
// LIN64-NEXT:    br label [[ATOMIC_CONT147:%.*]], !dbg [[DBG99]]
// LIN64:       atomic_cont147:
// LIN64-NEXT:    [[TMP160:%.*]] = load <4 x i32>, <4 x i32>* [[ATOMIC_TEMP146]], align 16, !dbg [[DBG99]]
// LIN64-NEXT:    store <4 x i32> [[TMP160]], <4 x i32>* [[ATOMIC_TEMP148]], align 16, !dbg [[DBG99]]
// LIN64-NEXT:    [[TMP161:%.*]] = load <4 x i32>, <4 x i32>* [[ATOMIC_TEMP146]], align 16, !dbg [[DBG99]]
// LIN64-NEXT:    store <4 x i32> [[TMP161]], <4 x i32>* [[ATOMIC_TEMP149]], align 16, !dbg [[DBG99]]
// LIN64-NEXT:    [[TMP162:%.*]] = load <4 x i32>, <4 x i32>* [[ATOMIC_TEMP149]], align 16, !dbg [[DBG99]]
// LIN64-NEXT:    [[VECEXT:%.*]] = extractelement <4 x i32> [[TMP162]], i16 [[TMP157]], !dbg [[DBG99]]
// LIN64-NEXT:    [[OR:%.*]] = or i32 [[VECEXT]], [[CONV145]], !dbg [[DBG100:![0-9]+]]
// LIN64-NEXT:    [[TMP163:%.*]] = load <4 x i32>, <4 x i32>* [[ATOMIC_TEMP148]], align 16, !dbg [[DBG99]]
// LIN64-NEXT:    [[VECINS:%.*]] = insertelement <4 x i32> [[TMP163]], i32 [[OR]], i16 [[TMP157]], !dbg [[DBG99]]
// LIN64-NEXT:    store <4 x i32> [[VECINS]], <4 x i32>* [[ATOMIC_TEMP148]], align 16, !dbg [[DBG99]]
// LIN64-NEXT:    [[TMP164:%.*]] = bitcast <4 x i32>* [[ATOMIC_TEMP146]] to i8*, !dbg [[DBG99]]
// LIN64-NEXT:    [[TMP165:%.*]] = bitcast <4 x i32>* [[ATOMIC_TEMP148]] to i8*, !dbg [[DBG99]]
// LIN64-NEXT:    [[CALL150:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, i8* noundef bitcast (<4 x i32>* @int4x to i8*), i8* noundef [[TMP164]], i8* noundef [[TMP165]], i32 noundef 0, i32 noundef 0), !dbg [[DBG99]]
// LIN64-NEXT:    br i1 [[CALL150]], label [[ATOMIC_EXIT151:%.*]], label [[ATOMIC_CONT147]], !dbg [[DBG99]]
// LIN64:       atomic_exit151:
// LIN64-NEXT:    [[TMP166:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG101:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD152:%.*]] = load atomic i32, i32* bitcast (i8* getelementptr (i8, i8* bitcast (%struct.BitFields* @bfx to i8*), i64 4) to i32*) monotonic, align 4, !dbg [[DBG102:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT153:%.*]], !dbg [[DBG102]]
// LIN64:       atomic_cont153:
// LIN64-NEXT:    [[TMP167:%.*]] = phi i32 [ [[ATOMIC_LOAD152]], [[ATOMIC_EXIT151]] ], [ [[TMP170:%.*]], [[ATOMIC_CONT153]] ], !dbg [[DBG102]]
// LIN64-NEXT:    store i32 [[TMP167]], i32* [[ATOMIC_TEMP154]], align 4, !dbg [[DBG102]]
// LIN64-NEXT:    store i32 [[TMP167]], i32* [[ATOMIC_TEMP155]], align 4, !dbg [[DBG102]]
// LIN64-NEXT:    [[BF_LOAD:%.*]] = load i32, i32* [[ATOMIC_TEMP155]], align 4, !dbg [[DBG102]]
// LIN64-NEXT:    [[BF_SHL:%.*]] = shl i32 [[BF_LOAD]], 1, !dbg [[DBG102]]
// LIN64-NEXT:    [[BF_ASHR:%.*]] = ashr i32 [[BF_SHL]], 1, !dbg [[DBG102]]
// LIN64-NEXT:    [[CONV156:%.*]] = sitofp i32 [[BF_ASHR]] to x86_fp80, !dbg [[DBG103:![0-9]+]]
// LIN64-NEXT:    [[SUB157:%.*]] = fsub x86_fp80 [[CONV156]], [[TMP166]], !dbg [[DBG104:![0-9]+]]
// LIN64-NEXT:    [[CONV158:%.*]] = fptosi x86_fp80 [[SUB157]] to i32, !dbg [[DBG103]]
// LIN64-NEXT:    [[BF_LOAD159:%.*]] = load i32, i32* [[ATOMIC_TEMP154]], align 4, !dbg [[DBG102]]
// LIN64-NEXT:    [[BF_VALUE:%.*]] = and i32 [[CONV158]], 2147483647, !dbg [[DBG102]]
// LIN64-NEXT:    [[BF_CLEAR:%.*]] = and i32 [[BF_LOAD159]], -2147483648, !dbg [[DBG102]]
// LIN64-NEXT:    [[BF_SET:%.*]] = or i32 [[BF_CLEAR]], [[BF_VALUE]], !dbg [[DBG102]]
// LIN64-NEXT:    store i32 [[BF_SET]], i32* [[ATOMIC_TEMP154]], align 4, !dbg [[DBG102]]
// LIN64-NEXT:    [[TMP168:%.*]] = load i32, i32* [[ATOMIC_TEMP154]], align 4, !dbg [[DBG102]]
// LIN64-NEXT:    [[TMP169:%.*]] = cmpxchg i32* bitcast (i8* getelementptr (i8, i8* bitcast (%struct.BitFields* @bfx to i8*), i64 4) to i32*), i32 [[TMP167]], i32 [[TMP168]] monotonic monotonic, align 4, !dbg [[DBG102]]
// LIN64-NEXT:    [[TMP170]] = extractvalue { i32, i1 } [[TMP169]], 0, !dbg [[DBG102]]
// LIN64-NEXT:    [[TMP171:%.*]] = extractvalue { i32, i1 } [[TMP169]], 1, !dbg [[DBG102]]
// LIN64-NEXT:    br i1 [[TMP171]], label [[ATOMIC_EXIT160:%.*]], label [[ATOMIC_CONT153]], !dbg [[DBG102]]
// LIN64:       atomic_exit160:
// LIN64-NEXT:    [[TMP172:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG105:![0-9]+]]
// LIN64-NEXT:    [[TMP173:%.*]] = bitcast i32* [[ATOMIC_TEMP161]] to i8*, !dbg [[DBG106:![0-9]+]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 4, i8* noundef getelementptr (i8, i8* bitcast (%struct.BitFields_packed* @bfx_packed to i8*), i64 4), i8* noundef [[TMP173]], i32 noundef 0), !dbg [[DBG106]]
// LIN64-NEXT:    br label [[ATOMIC_CONT162:%.*]], !dbg [[DBG106]]
// LIN64:       atomic_cont162:
// LIN64-NEXT:    [[TMP174:%.*]] = load i32, i32* [[ATOMIC_TEMP161]], align 1, !dbg [[DBG106]]
// LIN64-NEXT:    store i32 [[TMP174]], i32* [[ATOMIC_TEMP163]], align 1, !dbg [[DBG106]]
// LIN64-NEXT:    [[TMP175:%.*]] = load i32, i32* [[ATOMIC_TEMP161]], align 1, !dbg [[DBG106]]
// LIN64-NEXT:    store i32 [[TMP175]], i32* [[ATOMIC_TEMP164]], align 4, !dbg [[DBG106]]
// LIN64-NEXT:    [[BF_LOAD165:%.*]] = load i32, i32* [[ATOMIC_TEMP164]], align 1, !dbg [[DBG106]]
// LIN64-NEXT:    [[BF_SHL166:%.*]] = shl i32 [[BF_LOAD165]], 1, !dbg [[DBG106]]
// LIN64-NEXT:    [[BF_ASHR167:%.*]] = ashr i32 [[BF_SHL166]], 1, !dbg [[DBG106]]
// LIN64-NEXT:    [[CONV168:%.*]] = sitofp i32 [[BF_ASHR167]] to x86_fp80, !dbg [[DBG107:![0-9]+]]
// LIN64-NEXT:    [[MUL169:%.*]] = fmul x86_fp80 [[CONV168]], [[TMP172]], !dbg [[DBG108:![0-9]+]]
// LIN64-NEXT:    [[CONV170:%.*]] = fptosi x86_fp80 [[MUL169]] to i32, !dbg [[DBG107]]
// LIN64-NEXT:    [[BF_LOAD171:%.*]] = load i32, i32* [[ATOMIC_TEMP163]], align 1, !dbg [[DBG106]]
// LIN64-NEXT:    [[BF_VALUE172:%.*]] = and i32 [[CONV170]], 2147483647, !dbg [[DBG106]]
// LIN64-NEXT:    [[BF_CLEAR173:%.*]] = and i32 [[BF_LOAD171]], -2147483648, !dbg [[DBG106]]
// LIN64-NEXT:    [[BF_SET174:%.*]] = or i32 [[BF_CLEAR173]], [[BF_VALUE172]], !dbg [[DBG106]]
// LIN64-NEXT:    store i32 [[BF_SET174]], i32* [[ATOMIC_TEMP163]], align 1, !dbg [[DBG106]]
// LIN64-NEXT:    [[TMP176:%.*]] = bitcast i32* [[ATOMIC_TEMP161]] to i8*, !dbg [[DBG106]]
// LIN64-NEXT:    [[TMP177:%.*]] = bitcast i32* [[ATOMIC_TEMP163]] to i8*, !dbg [[DBG106]]
// LIN64-NEXT:    [[CALL175:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 4, i8* noundef getelementptr (i8, i8* bitcast (%struct.BitFields_packed* @bfx_packed to i8*), i64 4), i8* noundef [[TMP176]], i8* noundef [[TMP177]], i32 noundef 0, i32 noundef 0), !dbg [[DBG106]]
// LIN64-NEXT:    br i1 [[CALL175]], label [[ATOMIC_EXIT176:%.*]], label [[ATOMIC_CONT162]], !dbg [[DBG106]]
// LIN64:       atomic_exit176:
// LIN64-NEXT:    [[TMP178:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG109:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD177:%.*]] = load atomic i32, i32* getelementptr inbounds ([[STRUCT_BITFIELDS2:%.*]], %struct.BitFields2* @bfx2, i32 0, i32 0) monotonic, align 4, !dbg [[DBG110:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT178:%.*]], !dbg [[DBG110]]
// LIN64:       atomic_cont178:
// LIN64-NEXT:    [[TMP179:%.*]] = phi i32 [ [[ATOMIC_LOAD177]], [[ATOMIC_EXIT176]] ], [ [[TMP182:%.*]], [[ATOMIC_CONT178]] ], !dbg [[DBG110]]
// LIN64-NEXT:    store i32 [[TMP179]], i32* [[ATOMIC_TEMP179]], align 4, !dbg [[DBG110]]
// LIN64-NEXT:    store i32 [[TMP179]], i32* [[ATOMIC_TEMP180]], align 4, !dbg [[DBG110]]
// LIN64-NEXT:    [[BF_LOAD181:%.*]] = load i32, i32* [[ATOMIC_TEMP180]], align 4, !dbg [[DBG110]]
// LIN64-NEXT:    [[BF_ASHR182:%.*]] = ashr i32 [[BF_LOAD181]], 31, !dbg [[DBG110]]
// LIN64-NEXT:    [[CONV183:%.*]] = sitofp i32 [[BF_ASHR182]] to x86_fp80, !dbg [[DBG111:![0-9]+]]
// LIN64-NEXT:    [[SUB184:%.*]] = fsub x86_fp80 [[CONV183]], [[TMP178]], !dbg [[DBG112:![0-9]+]]
// LIN64-NEXT:    [[CONV185:%.*]] = fptosi x86_fp80 [[SUB184]] to i32, !dbg [[DBG111]]
// LIN64-NEXT:    [[BF_LOAD186:%.*]] = load i32, i32* [[ATOMIC_TEMP179]], align 4, !dbg [[DBG110]]
// LIN64-NEXT:    [[BF_VALUE187:%.*]] = and i32 [[CONV185]], 1, !dbg [[DBG110]]
// LIN64-NEXT:    [[BF_SHL188:%.*]] = shl i32 [[BF_VALUE187]], 31, !dbg [[DBG110]]
// LIN64-NEXT:    [[BF_CLEAR189:%.*]] = and i32 [[BF_LOAD186]], 2147483647, !dbg [[DBG110]]
// LIN64-NEXT:    [[BF_SET190:%.*]] = or i32 [[BF_CLEAR189]], [[BF_SHL188]], !dbg [[DBG110]]
// LIN64-NEXT:    store i32 [[BF_SET190]], i32* [[ATOMIC_TEMP179]], align 4, !dbg [[DBG110]]
// LIN64-NEXT:    [[TMP180:%.*]] = load i32, i32* [[ATOMIC_TEMP179]], align 4, !dbg [[DBG110]]
// LIN64-NEXT:    [[TMP181:%.*]] = cmpxchg i32* getelementptr inbounds ([[STRUCT_BITFIELDS2]], %struct.BitFields2* @bfx2, i32 0, i32 0), i32 [[TMP179]], i32 [[TMP180]] monotonic monotonic, align 4, !dbg [[DBG110]]
// LIN64-NEXT:    [[TMP182]] = extractvalue { i32, i1 } [[TMP181]], 0, !dbg [[DBG110]]
// LIN64-NEXT:    [[TMP183:%.*]] = extractvalue { i32, i1 } [[TMP181]], 1, !dbg [[DBG110]]
// LIN64-NEXT:    br i1 [[TMP183]], label [[ATOMIC_EXIT191:%.*]], label [[ATOMIC_CONT178]], !dbg [[DBG110]]
// LIN64:       atomic_exit191:
// LIN64-NEXT:    [[TMP184:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG113:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD192:%.*]] = load atomic i8, i8* getelementptr (i8, i8* bitcast (%struct.BitFields2_packed* @bfx2_packed to i8*), i64 3) monotonic, align 1, !dbg [[DBG114:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT193:%.*]], !dbg [[DBG114]]
// LIN64:       atomic_cont193:
// LIN64-NEXT:    [[TMP185:%.*]] = phi i8 [ [[ATOMIC_LOAD192]], [[ATOMIC_EXIT191]] ], [ [[TMP191:%.*]], [[ATOMIC_CONT193]] ], !dbg [[DBG114]]
// LIN64-NEXT:    [[TMP186:%.*]] = bitcast i32* [[ATOMIC_TEMP194]] to i8*, !dbg [[DBG114]]
// LIN64-NEXT:    store i8 [[TMP185]], i8* [[TMP186]], align 1, !dbg [[DBG114]]
// LIN64-NEXT:    [[TMP187:%.*]] = bitcast i32* [[ATOMIC_TEMP195]] to i8*, !dbg [[DBG114]]
// LIN64-NEXT:    store i8 [[TMP185]], i8* [[TMP187]], align 1, !dbg [[DBG114]]
// LIN64-NEXT:    [[BF_LOAD196:%.*]] = load i8, i8* [[TMP187]], align 1, !dbg [[DBG114]]
// LIN64-NEXT:    [[BF_ASHR197:%.*]] = ashr i8 [[BF_LOAD196]], 7, !dbg [[DBG114]]
// LIN64-NEXT:    [[BF_CAST:%.*]] = sext i8 [[BF_ASHR197]] to i32, !dbg [[DBG114]]
// LIN64-NEXT:    [[CONV198:%.*]] = sitofp i32 [[BF_CAST]] to x86_fp80, !dbg [[DBG115:![0-9]+]]
// LIN64-NEXT:    [[DIV199:%.*]] = fdiv x86_fp80 [[TMP184]], [[CONV198]], !dbg [[DBG116:![0-9]+]]
// LIN64-NEXT:    [[CONV200:%.*]] = fptosi x86_fp80 [[DIV199]] to i32, !dbg [[DBG113]]
// LIN64-NEXT:    [[TMP188:%.*]] = trunc i32 [[CONV200]] to i8, !dbg [[DBG114]]
// LIN64-NEXT:    [[BF_LOAD201:%.*]] = load i8, i8* [[TMP186]], align 1, !dbg [[DBG114]]
// LIN64-NEXT:    [[BF_VALUE202:%.*]] = and i8 [[TMP188]], 1, !dbg [[DBG114]]
// LIN64-NEXT:    [[BF_SHL203:%.*]] = shl i8 [[BF_VALUE202]], 7, !dbg [[DBG114]]
// LIN64-NEXT:    [[BF_CLEAR204:%.*]] = and i8 [[BF_LOAD201]], 127, !dbg [[DBG114]]
// LIN64-NEXT:    [[BF_SET205:%.*]] = or i8 [[BF_CLEAR204]], [[BF_SHL203]], !dbg [[DBG114]]
// LIN64-NEXT:    store i8 [[BF_SET205]], i8* [[TMP186]], align 1, !dbg [[DBG114]]
// LIN64-NEXT:    [[TMP189:%.*]] = load i8, i8* [[TMP186]], align 1, !dbg [[DBG114]]
// LIN64-NEXT:    [[TMP190:%.*]] = cmpxchg i8* getelementptr (i8, i8* bitcast (%struct.BitFields2_packed* @bfx2_packed to i8*), i64 3), i8 [[TMP185]], i8 [[TMP189]] monotonic monotonic, align 1, !dbg [[DBG114]]
// LIN64-NEXT:    [[TMP191]] = extractvalue { i8, i1 } [[TMP190]], 0, !dbg [[DBG114]]
// LIN64-NEXT:    [[TMP192:%.*]] = extractvalue { i8, i1 } [[TMP190]], 1, !dbg [[DBG114]]
// LIN64-NEXT:    br i1 [[TMP192]], label [[ATOMIC_EXIT206:%.*]], label [[ATOMIC_CONT193]], !dbg [[DBG114]]
// LIN64:       atomic_exit206:
// LIN64-NEXT:    [[TMP193:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG117:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD207:%.*]] = load atomic i32, i32* getelementptr inbounds ([[STRUCT_BITFIELDS3:%.*]], %struct.BitFields3* @bfx3, i32 0, i32 0) monotonic, align 4, !dbg [[DBG118:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT208:%.*]], !dbg [[DBG118]]
// LIN64:       atomic_cont208:
// LIN64-NEXT:    [[TMP194:%.*]] = phi i32 [ [[ATOMIC_LOAD207]], [[ATOMIC_EXIT206]] ], [ [[TMP197:%.*]], [[ATOMIC_CONT208]] ], !dbg [[DBG118]]
// LIN64-NEXT:    store i32 [[TMP194]], i32* [[ATOMIC_TEMP209]], align 4, !dbg [[DBG118]]
// LIN64-NEXT:    store i32 [[TMP194]], i32* [[ATOMIC_TEMP210]], align 4, !dbg [[DBG118]]
// LIN64-NEXT:    [[BF_LOAD211:%.*]] = load i32, i32* [[ATOMIC_TEMP210]], align 4, !dbg [[DBG118]]
// LIN64-NEXT:    [[BF_SHL212:%.*]] = shl i32 [[BF_LOAD211]], 7, !dbg [[DBG118]]
// LIN64-NEXT:    [[BF_ASHR213:%.*]] = ashr i32 [[BF_SHL212]], 18, !dbg [[DBG118]]
// LIN64-NEXT:    [[CONV214:%.*]] = sitofp i32 [[BF_ASHR213]] to x86_fp80, !dbg [[DBG119:![0-9]+]]
// LIN64-NEXT:    [[DIV215:%.*]] = fdiv x86_fp80 [[CONV214]], [[TMP193]], !dbg [[DBG120:![0-9]+]]
// LIN64-NEXT:    [[CONV216:%.*]] = fptosi x86_fp80 [[DIV215]] to i32, !dbg [[DBG119]]
// LIN64-NEXT:    [[BF_LOAD217:%.*]] = load i32, i32* [[ATOMIC_TEMP209]], align 4, !dbg [[DBG118]]
// LIN64-NEXT:    [[BF_VALUE218:%.*]] = and i32 [[CONV216]], 16383, !dbg [[DBG118]]
// LIN64-NEXT:    [[BF_SHL219:%.*]] = shl i32 [[BF_VALUE218]], 11, !dbg [[DBG118]]
// LIN64-NEXT:    [[BF_CLEAR220:%.*]] = and i32 [[BF_LOAD217]], -33552385, !dbg [[DBG118]]
// LIN64-NEXT:    [[BF_SET221:%.*]] = or i32 [[BF_CLEAR220]], [[BF_SHL219]], !dbg [[DBG118]]
// LIN64-NEXT:    store i32 [[BF_SET221]], i32* [[ATOMIC_TEMP209]], align 4, !dbg [[DBG118]]
// LIN64-NEXT:    [[TMP195:%.*]] = load i32, i32* [[ATOMIC_TEMP209]], align 4, !dbg [[DBG118]]
// LIN64-NEXT:    [[TMP196:%.*]] = cmpxchg i32* getelementptr inbounds ([[STRUCT_BITFIELDS3]], %struct.BitFields3* @bfx3, i32 0, i32 0), i32 [[TMP194]], i32 [[TMP195]] monotonic monotonic, align 4, !dbg [[DBG118]]
// LIN64-NEXT:    [[TMP197]] = extractvalue { i32, i1 } [[TMP196]], 0, !dbg [[DBG118]]
// LIN64-NEXT:    [[TMP198:%.*]] = extractvalue { i32, i1 } [[TMP196]], 1, !dbg [[DBG118]]
// LIN64-NEXT:    br i1 [[TMP198]], label [[ATOMIC_EXIT222:%.*]], label [[ATOMIC_CONT208]], !dbg [[DBG118]]
// LIN64:       atomic_exit222:
// LIN64-NEXT:    [[TMP199:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG121:![0-9]+]]
// LIN64-NEXT:    [[TMP200:%.*]] = bitcast i32* [[ATOMIC_TEMP223]] to i24*, !dbg [[DBG122:![0-9]+]]
// LIN64-NEXT:    [[TMP201:%.*]] = bitcast i24* [[TMP200]] to i8*, !dbg [[DBG122]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 3, i8* noundef getelementptr (i8, i8* bitcast (%struct.BitFields3_packed* @bfx3_packed to i8*), i64 1), i8* noundef [[TMP201]], i32 noundef 0), !dbg [[DBG122]]
// LIN64-NEXT:    br label [[ATOMIC_CONT224:%.*]], !dbg [[DBG122]]
// LIN64:       atomic_cont224:
// LIN64-NEXT:    [[TMP202:%.*]] = bitcast i32* [[ATOMIC_TEMP225]] to i24*, !dbg [[DBG122]]
// LIN64-NEXT:    [[TMP203:%.*]] = load i24, i24* [[TMP200]], align 1, !dbg [[DBG122]]
// LIN64-NEXT:    store i24 [[TMP203]], i24* [[TMP202]], align 1, !dbg [[DBG122]]
// LIN64-NEXT:    [[TMP204:%.*]] = load i24, i24* [[TMP200]], align 1, !dbg [[DBG122]]
// LIN64-NEXT:    [[TMP205:%.*]] = bitcast i32* [[ATOMIC_TEMP226]] to i24*, !dbg [[DBG122]]
// LIN64-NEXT:    store i24 [[TMP204]], i24* [[TMP205]], align 1, !dbg [[DBG122]]
// LIN64-NEXT:    [[BF_LOAD227:%.*]] = load i24, i24* [[TMP205]], align 1, !dbg [[DBG122]]
// LIN64-NEXT:    [[BF_SHL228:%.*]] = shl i24 [[BF_LOAD227]], 7, !dbg [[DBG122]]
// LIN64-NEXT:    [[BF_ASHR229:%.*]] = ashr i24 [[BF_SHL228]], 10, !dbg [[DBG122]]
// LIN64-NEXT:    [[BF_CAST230:%.*]] = sext i24 [[BF_ASHR229]] to i32, !dbg [[DBG122]]
// LIN64-NEXT:    [[CONV231:%.*]] = sitofp i32 [[BF_CAST230]] to x86_fp80, !dbg [[DBG123:![0-9]+]]
// LIN64-NEXT:    [[ADD232:%.*]] = fadd x86_fp80 [[CONV231]], [[TMP199]], !dbg [[DBG124:![0-9]+]]
// LIN64-NEXT:    [[CONV233:%.*]] = fptosi x86_fp80 [[ADD232]] to i32, !dbg [[DBG123]]
// LIN64-NEXT:    [[TMP206:%.*]] = trunc i32 [[CONV233]] to i24, !dbg [[DBG122]]
// LIN64-NEXT:    [[BF_LOAD234:%.*]] = load i24, i24* [[TMP202]], align 1, !dbg [[DBG122]]
// LIN64-NEXT:    [[BF_VALUE235:%.*]] = and i24 [[TMP206]], 16383, !dbg [[DBG122]]
// LIN64-NEXT:    [[BF_SHL236:%.*]] = shl i24 [[BF_VALUE235]], 3, !dbg [[DBG122]]
// LIN64-NEXT:    [[BF_CLEAR237:%.*]] = and i24 [[BF_LOAD234]], -131065, !dbg [[DBG122]]
// LIN64-NEXT:    [[BF_SET238:%.*]] = or i24 [[BF_CLEAR237]], [[BF_SHL236]], !dbg [[DBG122]]
// LIN64-NEXT:    store i24 [[BF_SET238]], i24* [[TMP202]], align 1, !dbg [[DBG122]]
// LIN64-NEXT:    [[TMP207:%.*]] = bitcast i24* [[TMP200]] to i8*, !dbg [[DBG122]]
// LIN64-NEXT:    [[TMP208:%.*]] = bitcast i24* [[TMP202]] to i8*, !dbg [[DBG122]]
// LIN64-NEXT:    [[CALL239:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 3, i8* noundef getelementptr (i8, i8* bitcast (%struct.BitFields3_packed* @bfx3_packed to i8*), i64 1), i8* noundef [[TMP207]], i8* noundef [[TMP208]], i32 noundef 0, i32 noundef 0), !dbg [[DBG122]]
// LIN64-NEXT:    br i1 [[CALL239]], label [[ATOMIC_EXIT240:%.*]], label [[ATOMIC_CONT224]], !dbg [[DBG122]]
// LIN64:       atomic_exit240:
// LIN64-NEXT:    [[TMP209:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG125:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD241:%.*]] = load atomic i64, i64* bitcast (%struct.BitFields4* @bfx4 to i64*) monotonic, align 8, !dbg [[DBG126:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT242:%.*]], !dbg [[DBG126]]
// LIN64:       atomic_cont242:
// LIN64-NEXT:    [[TMP210:%.*]] = phi i64 [ [[ATOMIC_LOAD241]], [[ATOMIC_EXIT240]] ], [ [[TMP214:%.*]], [[ATOMIC_CONT242]] ], !dbg [[DBG126]]
// LIN64-NEXT:    store i64 [[TMP210]], i64* [[ATOMIC_TEMP243]], align 8, !dbg [[DBG126]]
// LIN64-NEXT:    store i64 [[TMP210]], i64* [[ATOMIC_TEMP244]], align 8, !dbg [[DBG126]]
// LIN64-NEXT:    [[BF_LOAD245:%.*]] = load i64, i64* [[ATOMIC_TEMP244]], align 8, !dbg [[DBG126]]
// LIN64-NEXT:    [[BF_SHL246:%.*]] = shl i64 [[BF_LOAD245]], 47, !dbg [[DBG126]]
// LIN64-NEXT:    [[BF_ASHR247:%.*]] = ashr i64 [[BF_SHL246]], 63, !dbg [[DBG126]]
// LIN64-NEXT:    [[BF_CAST248:%.*]] = trunc i64 [[BF_ASHR247]] to i32, !dbg [[DBG126]]
// LIN64-NEXT:    [[CONV249:%.*]] = sitofp i32 [[BF_CAST248]] to x86_fp80, !dbg [[DBG127:![0-9]+]]
// LIN64-NEXT:    [[MUL250:%.*]] = fmul x86_fp80 [[CONV249]], [[TMP209]], !dbg [[DBG128:![0-9]+]]
// LIN64-NEXT:    [[CONV251:%.*]] = fptosi x86_fp80 [[MUL250]] to i32, !dbg [[DBG127]]
// LIN64-NEXT:    [[TMP211:%.*]] = zext i32 [[CONV251]] to i64, !dbg [[DBG126]]
// LIN64-NEXT:    [[BF_LOAD252:%.*]] = load i64, i64* [[ATOMIC_TEMP243]], align 8, !dbg [[DBG126]]
// LIN64-NEXT:    [[BF_VALUE253:%.*]] = and i64 [[TMP211]], 1, !dbg [[DBG126]]
// LIN64-NEXT:    [[BF_SHL254:%.*]] = shl i64 [[BF_VALUE253]], 16, !dbg [[DBG126]]
// LIN64-NEXT:    [[BF_CLEAR255:%.*]] = and i64 [[BF_LOAD252]], -65537, !dbg [[DBG126]]
// LIN64-NEXT:    [[BF_SET256:%.*]] = or i64 [[BF_CLEAR255]], [[BF_SHL254]], !dbg [[DBG126]]
// LIN64-NEXT:    store i64 [[BF_SET256]], i64* [[ATOMIC_TEMP243]], align 8, !dbg [[DBG126]]
// LIN64-NEXT:    [[TMP212:%.*]] = load i64, i64* [[ATOMIC_TEMP243]], align 8, !dbg [[DBG126]]
// LIN64-NEXT:    [[TMP213:%.*]] = cmpxchg i64* bitcast (%struct.BitFields4* @bfx4 to i64*), i64 [[TMP210]], i64 [[TMP212]] monotonic monotonic, align 8, !dbg [[DBG126]]
// LIN64-NEXT:    [[TMP214]] = extractvalue { i64, i1 } [[TMP213]], 0, !dbg [[DBG126]]
// LIN64-NEXT:    [[TMP215:%.*]] = extractvalue { i64, i1 } [[TMP213]], 1, !dbg [[DBG126]]
// LIN64-NEXT:    br i1 [[TMP215]], label [[ATOMIC_EXIT257:%.*]], label [[ATOMIC_CONT242]], !dbg [[DBG126]]
// LIN64:       atomic_exit257:
// LIN64-NEXT:    [[TMP216:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG129:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD258:%.*]] = load atomic i8, i8* getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED:%.*]], %struct.BitFields4_packed* @bfx4_packed, i32 0, i32 0, i64 2) monotonic, align 1, !dbg [[DBG130:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT259:%.*]], !dbg [[DBG130]]
// LIN64:       atomic_cont259:
// LIN64-NEXT:    [[TMP217:%.*]] = phi i8 [ [[ATOMIC_LOAD258]], [[ATOMIC_EXIT257]] ], [ [[TMP223:%.*]], [[ATOMIC_CONT259]] ], !dbg [[DBG130]]
// LIN64-NEXT:    [[TMP218:%.*]] = bitcast i32* [[ATOMIC_TEMP260]] to i8*, !dbg [[DBG130]]
// LIN64-NEXT:    store i8 [[TMP217]], i8* [[TMP218]], align 1, !dbg [[DBG130]]
// LIN64-NEXT:    [[TMP219:%.*]] = bitcast i32* [[ATOMIC_TEMP261]] to i8*, !dbg [[DBG130]]
// LIN64-NEXT:    store i8 [[TMP217]], i8* [[TMP219]], align 1, !dbg [[DBG130]]
// LIN64-NEXT:    [[BF_LOAD262:%.*]] = load i8, i8* [[TMP219]], align 1, !dbg [[DBG130]]
// LIN64-NEXT:    [[BF_SHL263:%.*]] = shl i8 [[BF_LOAD262]], 7, !dbg [[DBG130]]
// LIN64-NEXT:    [[BF_ASHR264:%.*]] = ashr i8 [[BF_SHL263]], 7, !dbg [[DBG130]]
// LIN64-NEXT:    [[BF_CAST265:%.*]] = sext i8 [[BF_ASHR264]] to i32, !dbg [[DBG130]]
// LIN64-NEXT:    [[CONV266:%.*]] = sitofp i32 [[BF_CAST265]] to x86_fp80, !dbg [[DBG131:![0-9]+]]
// LIN64-NEXT:    [[SUB267:%.*]] = fsub x86_fp80 [[CONV266]], [[TMP216]], !dbg [[DBG132:![0-9]+]]
// LIN64-NEXT:    [[CONV268:%.*]] = fptosi x86_fp80 [[SUB267]] to i32, !dbg [[DBG131]]
// LIN64-NEXT:    [[TMP220:%.*]] = trunc i32 [[CONV268]] to i8, !dbg [[DBG130]]
// LIN64-NEXT:    [[BF_LOAD269:%.*]] = load i8, i8* [[TMP218]], align 1, !dbg [[DBG130]]
// LIN64-NEXT:    [[BF_VALUE270:%.*]] = and i8 [[TMP220]], 1, !dbg [[DBG130]]
// LIN64-NEXT:    [[BF_CLEAR271:%.*]] = and i8 [[BF_LOAD269]], -2, !dbg [[DBG130]]
// LIN64-NEXT:    [[BF_SET272:%.*]] = or i8 [[BF_CLEAR271]], [[BF_VALUE270]], !dbg [[DBG130]]
// LIN64-NEXT:    store i8 [[BF_SET272]], i8* [[TMP218]], align 1, !dbg [[DBG130]]
// LIN64-NEXT:    [[TMP221:%.*]] = load i8, i8* [[TMP218]], align 1, !dbg [[DBG130]]
// LIN64-NEXT:    [[TMP222:%.*]] = cmpxchg i8* getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED]], %struct.BitFields4_packed* @bfx4_packed, i32 0, i32 0, i64 2), i8 [[TMP217]], i8 [[TMP221]] monotonic monotonic, align 1, !dbg [[DBG130]]
// LIN64-NEXT:    [[TMP223]] = extractvalue { i8, i1 } [[TMP222]], 0, !dbg [[DBG130]]
// LIN64-NEXT:    [[TMP224:%.*]] = extractvalue { i8, i1 } [[TMP222]], 1, !dbg [[DBG130]]
// LIN64-NEXT:    br i1 [[TMP224]], label [[ATOMIC_EXIT273:%.*]], label [[ATOMIC_CONT259]], !dbg [[DBG130]]
// LIN64:       atomic_exit273:
// LIN64-NEXT:    [[TMP225:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG133:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD274:%.*]] = load atomic i64, i64* bitcast (%struct.BitFields4* @bfx4 to i64*) monotonic, align 8, !dbg [[DBG134:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT275:%.*]], !dbg [[DBG134]]
// LIN64:       atomic_cont275:
// LIN64-NEXT:    [[TMP226:%.*]] = phi i64 [ [[ATOMIC_LOAD274]], [[ATOMIC_EXIT273]] ], [ [[TMP229:%.*]], [[ATOMIC_CONT275]] ], !dbg [[DBG134]]
// LIN64-NEXT:    store i64 [[TMP226]], i64* [[ATOMIC_TEMP276]], align 8, !dbg [[DBG134]]
// LIN64-NEXT:    store i64 [[TMP226]], i64* [[ATOMIC_TEMP277]], align 8, !dbg [[DBG134]]
// LIN64-NEXT:    [[BF_LOAD278:%.*]] = load i64, i64* [[ATOMIC_TEMP277]], align 8, !dbg [[DBG134]]
// LIN64-NEXT:    [[BF_SHL279:%.*]] = shl i64 [[BF_LOAD278]], 40, !dbg [[DBG134]]
// LIN64-NEXT:    [[BF_ASHR280:%.*]] = ashr i64 [[BF_SHL279]], 57, !dbg [[DBG134]]
// LIN64-NEXT:    [[CONV281:%.*]] = sitofp i64 [[BF_ASHR280]] to x86_fp80, !dbg [[DBG135:![0-9]+]]
// LIN64-NEXT:    [[DIV282:%.*]] = fdiv x86_fp80 [[CONV281]], [[TMP225]], !dbg [[DBG136:![0-9]+]]
// LIN64-NEXT:    [[CONV283:%.*]] = fptosi x86_fp80 [[DIV282]] to i64, !dbg [[DBG135]]
// LIN64-NEXT:    [[BF_LOAD284:%.*]] = load i64, i64* [[ATOMIC_TEMP276]], align 8, !dbg [[DBG134]]
// LIN64-NEXT:    [[BF_VALUE285:%.*]] = and i64 [[CONV283]], 127, !dbg [[DBG134]]
// LIN64-NEXT:    [[BF_SHL286:%.*]] = shl i64 [[BF_VALUE285]], 17, !dbg [[DBG134]]
// LIN64-NEXT:    [[BF_CLEAR287:%.*]] = and i64 [[BF_LOAD284]], -16646145, !dbg [[DBG134]]
// LIN64-NEXT:    [[BF_SET288:%.*]] = or i64 [[BF_CLEAR287]], [[BF_SHL286]], !dbg [[DBG134]]
// LIN64-NEXT:    store i64 [[BF_SET288]], i64* [[ATOMIC_TEMP276]], align 8, !dbg [[DBG134]]
// LIN64-NEXT:    [[TMP227:%.*]] = load i64, i64* [[ATOMIC_TEMP276]], align 8, !dbg [[DBG134]]
// LIN64-NEXT:    [[TMP228:%.*]] = cmpxchg i64* bitcast (%struct.BitFields4* @bfx4 to i64*), i64 [[TMP226]], i64 [[TMP227]] monotonic monotonic, align 8, !dbg [[DBG134]]
// LIN64-NEXT:    [[TMP229]] = extractvalue { i64, i1 } [[TMP228]], 0, !dbg [[DBG134]]
// LIN64-NEXT:    [[TMP230:%.*]] = extractvalue { i64, i1 } [[TMP228]], 1, !dbg [[DBG134]]
// LIN64-NEXT:    br i1 [[TMP230]], label [[ATOMIC_EXIT289:%.*]], label [[ATOMIC_CONT275]], !dbg [[DBG134]]
// LIN64:       atomic_exit289:
// LIN64-NEXT:    [[TMP231:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG137:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD290:%.*]] = load atomic i8, i8* getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED]], %struct.BitFields4_packed* @bfx4_packed, i32 0, i32 0, i64 2) monotonic, align 1, !dbg [[DBG138:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT291:%.*]], !dbg [[DBG138]]
// LIN64:       atomic_cont291:
// LIN64-NEXT:    [[TMP232:%.*]] = phi i8 [ [[ATOMIC_LOAD290]], [[ATOMIC_EXIT289]] ], [ [[TMP238:%.*]], [[ATOMIC_CONT291]] ], !dbg [[DBG138]]
// LIN64-NEXT:    [[TMP233:%.*]] = bitcast i64* [[ATOMIC_TEMP292]] to i8*, !dbg [[DBG138]]
// LIN64-NEXT:    store i8 [[TMP232]], i8* [[TMP233]], align 1, !dbg [[DBG138]]
// LIN64-NEXT:    [[TMP234:%.*]] = bitcast i64* [[ATOMIC_TEMP293]] to i8*, !dbg [[DBG138]]
// LIN64-NEXT:    store i8 [[TMP232]], i8* [[TMP234]], align 1, !dbg [[DBG138]]
// LIN64-NEXT:    [[BF_LOAD294:%.*]] = load i8, i8* [[TMP234]], align 1, !dbg [[DBG138]]
// LIN64-NEXT:    [[BF_ASHR295:%.*]] = ashr i8 [[BF_LOAD294]], 1, !dbg [[DBG138]]
// LIN64-NEXT:    [[BF_CAST296:%.*]] = sext i8 [[BF_ASHR295]] to i64, !dbg [[DBG138]]
// LIN64-NEXT:    [[CONV297:%.*]] = sitofp i64 [[BF_CAST296]] to x86_fp80, !dbg [[DBG139:![0-9]+]]
// LIN64-NEXT:    [[ADD298:%.*]] = fadd x86_fp80 [[CONV297]], [[TMP231]], !dbg [[DBG140:![0-9]+]]
// LIN64-NEXT:    [[CONV299:%.*]] = fptosi x86_fp80 [[ADD298]] to i64, !dbg [[DBG139]]
// LIN64-NEXT:    [[TMP235:%.*]] = trunc i64 [[CONV299]] to i8, !dbg [[DBG138]]
// LIN64-NEXT:    [[BF_LOAD300:%.*]] = load i8, i8* [[TMP233]], align 1, !dbg [[DBG138]]
// LIN64-NEXT:    [[BF_VALUE301:%.*]] = and i8 [[TMP235]], 127, !dbg [[DBG138]]
// LIN64-NEXT:    [[BF_SHL302:%.*]] = shl i8 [[BF_VALUE301]], 1, !dbg [[DBG138]]
// LIN64-NEXT:    [[BF_CLEAR303:%.*]] = and i8 [[BF_LOAD300]], 1, !dbg [[DBG138]]
// LIN64-NEXT:    [[BF_SET304:%.*]] = or i8 [[BF_CLEAR303]], [[BF_SHL302]], !dbg [[DBG138]]
// LIN64-NEXT:    store i8 [[BF_SET304]], i8* [[TMP233]], align 1, !dbg [[DBG138]]
// LIN64-NEXT:    [[TMP236:%.*]] = load i8, i8* [[TMP233]], align 1, !dbg [[DBG138]]
// LIN64-NEXT:    [[TMP237:%.*]] = cmpxchg i8* getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED]], %struct.BitFields4_packed* @bfx4_packed, i32 0, i32 0, i64 2), i8 [[TMP232]], i8 [[TMP236]] monotonic monotonic, align 1, !dbg [[DBG138]]
// LIN64-NEXT:    [[TMP238]] = extractvalue { i8, i1 } [[TMP237]], 0, !dbg [[DBG138]]
// LIN64-NEXT:    [[TMP239:%.*]] = extractvalue { i8, i1 } [[TMP237]], 1, !dbg [[DBG138]]
// LIN64-NEXT:    br i1 [[TMP239]], label [[ATOMIC_EXIT305:%.*]], label [[ATOMIC_CONT291]], !dbg [[DBG138]]
// LIN64:       atomic_exit305:
// LIN64-NEXT:    [[TMP240:%.*]] = load i64, i64* @ulv, align 8, !dbg [[DBG141:![0-9]+]]
// LIN64-NEXT:    [[CONV306:%.*]] = uitofp i64 [[TMP240]] to float, !dbg [[DBG141]]
// LIN64-NEXT:    [[ATOMIC_LOAD307:%.*]] = load atomic i64, i64* bitcast (<2 x float>* @float2x to i64*) monotonic, align 8, !dbg [[DBG142:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT308:%.*]], !dbg [[DBG142]]
// LIN64:       atomic_cont308:
// LIN64-NEXT:    [[TMP241:%.*]] = phi i64 [ [[ATOMIC_LOAD307]], [[ATOMIC_EXIT305]] ], [ [[TMP250:%.*]], [[ATOMIC_CONT308]] ], !dbg [[DBG142]]
// LIN64-NEXT:    [[TMP242:%.*]] = bitcast <2 x float>* [[ATOMIC_TEMP309]] to i64*, !dbg [[DBG142]]
// LIN64-NEXT:    store i64 [[TMP241]], i64* [[TMP242]], align 8, !dbg [[DBG142]]
// LIN64-NEXT:    [[TMP243:%.*]] = bitcast i64 [[TMP241]] to <2 x float>, !dbg [[DBG142]]
// LIN64-NEXT:    store <2 x float> [[TMP243]], <2 x float>* [[ATOMIC_TEMP310]], align 8, !dbg [[DBG142]]
// LIN64-NEXT:    [[TMP244:%.*]] = load <2 x float>, <2 x float>* [[ATOMIC_TEMP310]], align 8, !dbg [[DBG142]]
// LIN64-NEXT:    [[TMP245:%.*]] = extractelement <2 x float> [[TMP244]], i64 0, !dbg [[DBG142]]
// LIN64-NEXT:    [[SUB311:%.*]] = fsub float [[CONV306]], [[TMP245]], !dbg [[DBG143:![0-9]+]]
// LIN64-NEXT:    [[TMP246:%.*]] = load <2 x float>, <2 x float>* [[ATOMIC_TEMP309]], align 8, !dbg [[DBG142]]
// LIN64-NEXT:    [[TMP247:%.*]] = insertelement <2 x float> [[TMP246]], float [[SUB311]], i64 0, !dbg [[DBG142]]
// LIN64-NEXT:    store <2 x float> [[TMP247]], <2 x float>* [[ATOMIC_TEMP309]], align 8, !dbg [[DBG142]]
// LIN64-NEXT:    [[TMP248:%.*]] = load i64, i64* [[TMP242]], align 8, !dbg [[DBG142]]
// LIN64-NEXT:    [[TMP249:%.*]] = cmpxchg i64* bitcast (<2 x float>* @float2x to i64*), i64 [[TMP241]], i64 [[TMP248]] monotonic monotonic, align 8, !dbg [[DBG142]]
// LIN64-NEXT:    [[TMP250]] = extractvalue { i64, i1 } [[TMP249]], 0, !dbg [[DBG142]]
// LIN64-NEXT:    [[TMP251:%.*]] = extractvalue { i64, i1 } [[TMP249]], 1, !dbg [[DBG142]]
// LIN64-NEXT:    br i1 [[TMP251]], label [[ATOMIC_EXIT312:%.*]], label [[ATOMIC_CONT308]], !dbg [[DBG142]]
// LIN64:       atomic_exit312:
// LIN64-NEXT:    [[TMP252:%.*]] = load double, double* @dv, align 8, !dbg [[DBG144:![0-9]+]]
// LIN64-NEXT:    [[TMP253:%.*]] = call i32 @llvm.read_register.i32(metadata [[META2:![0-9]+]]), !dbg [[DBG145:![0-9]+]]
// LIN64-NEXT:    [[CONV313:%.*]] = sitofp i32 [[TMP253]] to double, !dbg [[DBG145]]
// LIN64-NEXT:    [[DIV314:%.*]] = fdiv double [[TMP252]], [[CONV313]], !dbg [[DBG146:![0-9]+]]
// LIN64-NEXT:    [[CONV315:%.*]] = fptosi double [[DIV314]] to i32, !dbg [[DBG144]]
// LIN64-NEXT:    call void @llvm.write_register.i32(metadata [[META2]], i32 [[CONV315]]), !dbg [[DBG145]]
// LIN64-NEXT:    fence release
// LIN64-NEXT:    ret i32 0, !dbg [[DBG147:![0-9]+]]
//
//
// PPC64-LABEL: define {{[^@]+}}@main
// PPC64-SAME: () #[[ATTR0:[0-9]+]] !dbg [[DBG5:![0-9]+]] {
// PPC64-NEXT:  entry:
// PPC64-NEXT:    [[RETVAL:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca i16, align 2
// PPC64-NEXT:    [[ATOMIC_TEMP5:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP9:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP13:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP17:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP21:%.*]] = alloca double, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP23:%.*]] = alloca ppc_fp128, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP25:%.*]] = alloca ppc_fp128, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP28:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP30:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP33:%.*]] = alloca { float, float }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP35:%.*]] = alloca { float, float }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP38:%.*]] = alloca { double, double }, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP40:%.*]] = alloca { double, double }, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP47:%.*]] = alloca i8, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP55:%.*]] = alloca i8, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP63:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP70:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP72:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP74:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP86:%.*]] = alloca float, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP92:%.*]] = alloca double, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP96:%.*]] = alloca ppc_fp128, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP98:%.*]] = alloca ppc_fp128, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP102:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP104:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP114:%.*]] = alloca i16, align 2
// PPC64-NEXT:    [[ATOMIC_TEMP122:%.*]] = alloca i8, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP134:%.*]] = alloca i8, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP146:%.*]] = alloca <4 x i32>, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP148:%.*]] = alloca <4 x i32>, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP149:%.*]] = alloca <4 x i32>, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP154:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP155:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP161:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP163:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP164:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP179:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP180:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP194:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP195:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP209:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP210:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP223:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP225:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP226:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP243:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP244:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP260:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP261:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP276:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP277:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP292:%.*]] = alloca i64, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP293:%.*]] = alloca i64, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP309:%.*]] = alloca <2 x float>, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP310:%.*]] = alloca <2 x float>, align 8
// PPC64-NEXT:    store i32 0, i32* [[RETVAL]], align 4
// PPC64-NEXT:    [[TMP0:%.*]] = atomicrmw fadd double* @dv, double 1.000000e+00 monotonic, align 8, !dbg [[DBG9:![0-9]+]]
// PPC64-NEXT:    [[TMP1:%.*]] = atomicrmw add i8* @bx, i8 1 monotonic, align 1, !dbg [[DBG10:![0-9]+]]
// PPC64-NEXT:    [[TMP2:%.*]] = atomicrmw add i8* @cx, i8 1 monotonic, align 1, !dbg [[DBG11:![0-9]+]]
// PPC64-NEXT:    [[TMP3:%.*]] = atomicrmw sub i8* @ucx, i8 1 monotonic, align 1, !dbg [[DBG12:![0-9]+]]
// PPC64-NEXT:    [[TMP4:%.*]] = atomicrmw sub i16* @sx, i16 1 monotonic, align 2, !dbg [[DBG13:![0-9]+]]
// PPC64-NEXT:    [[TMP5:%.*]] = load i16, i16* @usv, align 2, !dbg [[DBG14:![0-9]+]]
// PPC64-NEXT:    [[CONV:%.*]] = zext i16 [[TMP5]] to i32, !dbg [[DBG14]]
// PPC64-NEXT:    [[ATOMIC_LOAD:%.*]] = load atomic i16, i16* @usx monotonic, align 2, !dbg [[DBG15:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT:%.*]], !dbg [[DBG15]]
// PPC64:       atomic_cont:
// PPC64-NEXT:    [[TMP6:%.*]] = phi i16 [ [[ATOMIC_LOAD]], [[ENTRY:%.*]] ], [ [[TMP9:%.*]], [[ATOMIC_CONT]] ], !dbg [[DBG15]]
// PPC64-NEXT:    [[CONV1:%.*]] = zext i16 [[TMP6]] to i32, !dbg [[DBG15]]
// PPC64-NEXT:    [[ADD:%.*]] = add nsw i32 [[CONV1]], [[CONV]], !dbg [[DBG16:![0-9]+]]
// PPC64-NEXT:    [[CONV2:%.*]] = trunc i32 [[ADD]] to i16, !dbg [[DBG15]]
// PPC64-NEXT:    store i16 [[CONV2]], i16* [[ATOMIC_TEMP]], align 2, !dbg [[DBG15]]
// PPC64-NEXT:    [[TMP7:%.*]] = load i16, i16* [[ATOMIC_TEMP]], align 2, !dbg [[DBG15]]
// PPC64-NEXT:    [[TMP8:%.*]] = cmpxchg i16* @usx, i16 [[TMP6]], i16 [[TMP7]] monotonic monotonic, align 2, !dbg [[DBG15]]
// PPC64-NEXT:    [[TMP9]] = extractvalue { i16, i1 } [[TMP8]], 0, !dbg [[DBG15]]
// PPC64-NEXT:    [[TMP10:%.*]] = extractvalue { i16, i1 } [[TMP8]], 1, !dbg [[DBG15]]
// PPC64-NEXT:    br i1 [[TMP10]], label [[ATOMIC_EXIT:%.*]], label [[ATOMIC_CONT]], !dbg [[DBG15]]
// PPC64:       atomic_exit:
// PPC64-NEXT:    [[TMP11:%.*]] = load i32, i32* @iv, align 4, !dbg [[DBG17:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD3:%.*]] = load atomic i32, i32* @ix monotonic, align 4, !dbg [[DBG18:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT4:%.*]], !dbg [[DBG18]]
// PPC64:       atomic_cont4:
// PPC64-NEXT:    [[TMP12:%.*]] = phi i32 [ [[ATOMIC_LOAD3]], [[ATOMIC_EXIT]] ], [ [[TMP15:%.*]], [[ATOMIC_CONT4]] ], !dbg [[DBG18]]
// PPC64-NEXT:    [[MUL:%.*]] = mul nsw i32 [[TMP12]], [[TMP11]], !dbg [[DBG19:![0-9]+]]
// PPC64-NEXT:    store i32 [[MUL]], i32* [[ATOMIC_TEMP5]], align 4, !dbg [[DBG18]]
// PPC64-NEXT:    [[TMP13:%.*]] = load i32, i32* [[ATOMIC_TEMP5]], align 4, !dbg [[DBG18]]
// PPC64-NEXT:    [[TMP14:%.*]] = cmpxchg i32* @ix, i32 [[TMP12]], i32 [[TMP13]] monotonic monotonic, align 4, !dbg [[DBG18]]
// PPC64-NEXT:    [[TMP15]] = extractvalue { i32, i1 } [[TMP14]], 0, !dbg [[DBG18]]
// PPC64-NEXT:    [[TMP16:%.*]] = extractvalue { i32, i1 } [[TMP14]], 1, !dbg [[DBG18]]
// PPC64-NEXT:    br i1 [[TMP16]], label [[ATOMIC_EXIT6:%.*]], label [[ATOMIC_CONT4]], !dbg [[DBG18]]
// PPC64:       atomic_exit6:
// PPC64-NEXT:    [[TMP17:%.*]] = load i32, i32* @uiv, align 4, !dbg [[DBG20:![0-9]+]]
// PPC64-NEXT:    [[TMP18:%.*]] = atomicrmw sub i32* @uix, i32 [[TMP17]] monotonic, align 4, !dbg [[DBG21:![0-9]+]]
// PPC64-NEXT:    [[TMP19:%.*]] = load i32, i32* @iv, align 4, !dbg [[DBG22:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD7:%.*]] = load atomic i32, i32* @ix monotonic, align 4, !dbg [[DBG23:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT8:%.*]], !dbg [[DBG23]]
// PPC64:       atomic_cont8:
// PPC64-NEXT:    [[TMP20:%.*]] = phi i32 [ [[ATOMIC_LOAD7]], [[ATOMIC_EXIT6]] ], [ [[TMP23:%.*]], [[ATOMIC_CONT8]] ], !dbg [[DBG23]]
// PPC64-NEXT:    [[SHL:%.*]] = shl i32 [[TMP20]], [[TMP19]], !dbg [[DBG24:![0-9]+]]
// PPC64-NEXT:    store i32 [[SHL]], i32* [[ATOMIC_TEMP9]], align 4, !dbg [[DBG23]]
// PPC64-NEXT:    [[TMP21:%.*]] = load i32, i32* [[ATOMIC_TEMP9]], align 4, !dbg [[DBG23]]
// PPC64-NEXT:    [[TMP22:%.*]] = cmpxchg i32* @ix, i32 [[TMP20]], i32 [[TMP21]] monotonic monotonic, align 4, !dbg [[DBG23]]
// PPC64-NEXT:    [[TMP23]] = extractvalue { i32, i1 } [[TMP22]], 0, !dbg [[DBG23]]
// PPC64-NEXT:    [[TMP24:%.*]] = extractvalue { i32, i1 } [[TMP22]], 1, !dbg [[DBG23]]
// PPC64-NEXT:    br i1 [[TMP24]], label [[ATOMIC_EXIT10:%.*]], label [[ATOMIC_CONT8]], !dbg [[DBG23]]
// PPC64:       atomic_exit10:
// PPC64-NEXT:    [[TMP25:%.*]] = load i32, i32* @uiv, align 4, !dbg [[DBG25:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD11:%.*]] = load atomic i32, i32* @uix monotonic, align 4, !dbg [[DBG26:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT12:%.*]], !dbg [[DBG26]]
// PPC64:       atomic_cont12:
// PPC64-NEXT:    [[TMP26:%.*]] = phi i32 [ [[ATOMIC_LOAD11]], [[ATOMIC_EXIT10]] ], [ [[TMP29:%.*]], [[ATOMIC_CONT12]] ], !dbg [[DBG26]]
// PPC64-NEXT:    [[SHR:%.*]] = lshr i32 [[TMP26]], [[TMP25]], !dbg [[DBG27:![0-9]+]]
// PPC64-NEXT:    store i32 [[SHR]], i32* [[ATOMIC_TEMP13]], align 4, !dbg [[DBG26]]
// PPC64-NEXT:    [[TMP27:%.*]] = load i32, i32* [[ATOMIC_TEMP13]], align 4, !dbg [[DBG26]]
// PPC64-NEXT:    [[TMP28:%.*]] = cmpxchg i32* @uix, i32 [[TMP26]], i32 [[TMP27]] monotonic monotonic, align 4, !dbg [[DBG26]]
// PPC64-NEXT:    [[TMP29]] = extractvalue { i32, i1 } [[TMP28]], 0, !dbg [[DBG26]]
// PPC64-NEXT:    [[TMP30:%.*]] = extractvalue { i32, i1 } [[TMP28]], 1, !dbg [[DBG26]]
// PPC64-NEXT:    br i1 [[TMP30]], label [[ATOMIC_EXIT14:%.*]], label [[ATOMIC_CONT12]], !dbg [[DBG26]]
// PPC64:       atomic_exit14:
// PPC64-NEXT:    [[TMP31:%.*]] = load i64, i64* @lv, align 8, !dbg [[DBG28:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD15:%.*]] = load atomic i64, i64* @lx monotonic, align 8, !dbg [[DBG29:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT16:%.*]], !dbg [[DBG29]]
// PPC64:       atomic_cont16:
// PPC64-NEXT:    [[TMP32:%.*]] = phi i64 [ [[ATOMIC_LOAD15]], [[ATOMIC_EXIT14]] ], [ [[TMP35:%.*]], [[ATOMIC_CONT16]] ], !dbg [[DBG29]]
// PPC64-NEXT:    [[DIV:%.*]] = sdiv i64 [[TMP32]], [[TMP31]], !dbg [[DBG30:![0-9]+]]
// PPC64-NEXT:    store i64 [[DIV]], i64* [[ATOMIC_TEMP17]], align 8, !dbg [[DBG29]]
// PPC64-NEXT:    [[TMP33:%.*]] = load i64, i64* [[ATOMIC_TEMP17]], align 8, !dbg [[DBG29]]
// PPC64-NEXT:    [[TMP34:%.*]] = cmpxchg i64* @lx, i64 [[TMP32]], i64 [[TMP33]] monotonic monotonic, align 8, !dbg [[DBG29]]
// PPC64-NEXT:    [[TMP35]] = extractvalue { i64, i1 } [[TMP34]], 0, !dbg [[DBG29]]
// PPC64-NEXT:    [[TMP36:%.*]] = extractvalue { i64, i1 } [[TMP34]], 1, !dbg [[DBG29]]
// PPC64-NEXT:    br i1 [[TMP36]], label [[ATOMIC_EXIT18:%.*]], label [[ATOMIC_CONT16]], !dbg [[DBG29]]
// PPC64:       atomic_exit18:
// PPC64-NEXT:    [[TMP37:%.*]] = load i64, i64* @ulv, align 8, !dbg [[DBG31:![0-9]+]]
// PPC64-NEXT:    [[TMP38:%.*]] = atomicrmw and i64* @ulx, i64 [[TMP37]] monotonic, align 8, !dbg [[DBG32:![0-9]+]]
// PPC64-NEXT:    [[TMP39:%.*]] = load i64, i64* @llv, align 8, !dbg [[DBG33:![0-9]+]]
// PPC64-NEXT:    [[TMP40:%.*]] = atomicrmw xor i64* @llx, i64 [[TMP39]] monotonic, align 8, !dbg [[DBG34:![0-9]+]]
// PPC64-NEXT:    [[TMP41:%.*]] = load i64, i64* @ullv, align 8, !dbg [[DBG35:![0-9]+]]
// PPC64-NEXT:    [[TMP42:%.*]] = atomicrmw or i64* @ullx, i64 [[TMP41]] monotonic, align 8, !dbg [[DBG36:![0-9]+]]
// PPC64-NEXT:    [[TMP43:%.*]] = load float, float* @fv, align 4, !dbg [[DBG37:![0-9]+]]
// PPC64-NEXT:    [[TMP44:%.*]] = atomicrmw fadd float* @fx, float [[TMP43]] monotonic, align 4, !dbg [[DBG38:![0-9]+]]
// PPC64-NEXT:    [[TMP45:%.*]] = load double, double* @dv, align 8, !dbg [[DBG39:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD19:%.*]] = load atomic i64, i64* bitcast (double* @dx to i64*) monotonic, align 8, !dbg [[DBG40:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT20:%.*]], !dbg [[DBG40]]
// PPC64:       atomic_cont20:
// PPC64-NEXT:    [[TMP46:%.*]] = phi i64 [ [[ATOMIC_LOAD19]], [[ATOMIC_EXIT18]] ], [ [[TMP51:%.*]], [[ATOMIC_CONT20]] ], !dbg [[DBG40]]
// PPC64-NEXT:    [[TMP47:%.*]] = bitcast double* [[ATOMIC_TEMP21]] to i64*, !dbg [[DBG40]]
// PPC64-NEXT:    [[TMP48:%.*]] = bitcast i64 [[TMP46]] to double, !dbg [[DBG40]]
// PPC64-NEXT:    [[SUB:%.*]] = fsub double [[TMP45]], [[TMP48]], !dbg [[DBG41:![0-9]+]]
// PPC64-NEXT:    store double [[SUB]], double* [[ATOMIC_TEMP21]], align 8, !dbg [[DBG40]]
// PPC64-NEXT:    [[TMP49:%.*]] = load i64, i64* [[TMP47]], align 8, !dbg [[DBG40]]
// PPC64-NEXT:    [[TMP50:%.*]] = cmpxchg i64* bitcast (double* @dx to i64*), i64 [[TMP46]], i64 [[TMP49]] monotonic monotonic, align 8, !dbg [[DBG40]]
// PPC64-NEXT:    [[TMP51]] = extractvalue { i64, i1 } [[TMP50]], 0, !dbg [[DBG40]]
// PPC64-NEXT:    [[TMP52:%.*]] = extractvalue { i64, i1 } [[TMP50]], 1, !dbg [[DBG40]]
// PPC64-NEXT:    br i1 [[TMP52]], label [[ATOMIC_EXIT22:%.*]], label [[ATOMIC_CONT20]], !dbg [[DBG40]]
// PPC64:       atomic_exit22:
// PPC64-NEXT:    [[TMP53:%.*]] = load ppc_fp128, ppc_fp128* @ldv, align 16, !dbg [[DBG42:![0-9]+]]
// PPC64-NEXT:    [[TMP54:%.*]] = bitcast ppc_fp128* [[ATOMIC_TEMP23]] to i8*, !dbg [[DBG43:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 16, i8* noundef bitcast (ppc_fp128* @ldx to i8*), i8* noundef [[TMP54]], i32 noundef signext 0), !dbg [[DBG43]]
// PPC64-NEXT:    br label [[ATOMIC_CONT24:%.*]], !dbg [[DBG43]]
// PPC64:       atomic_cont24:
// PPC64-NEXT:    [[TMP55:%.*]] = load ppc_fp128, ppc_fp128* [[ATOMIC_TEMP23]], align 16, !dbg [[DBG43]]
// PPC64-NEXT:    [[MUL26:%.*]] = fmul ppc_fp128 [[TMP55]], [[TMP53]], !dbg [[DBG44:![0-9]+]]
// PPC64-NEXT:    store ppc_fp128 [[MUL26]], ppc_fp128* [[ATOMIC_TEMP25]], align 16, !dbg [[DBG43]]
// PPC64-NEXT:    [[TMP56:%.*]] = bitcast ppc_fp128* [[ATOMIC_TEMP23]] to i8*, !dbg [[DBG43]]
// PPC64-NEXT:    [[TMP57:%.*]] = bitcast ppc_fp128* [[ATOMIC_TEMP25]] to i8*, !dbg [[DBG43]]
// PPC64-NEXT:    [[CALL:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, i8* noundef bitcast (ppc_fp128* @ldx to i8*), i8* noundef [[TMP56]], i8* noundef [[TMP57]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG43]]
// PPC64-NEXT:    br i1 [[CALL]], label [[ATOMIC_EXIT27:%.*]], label [[ATOMIC_CONT24]], !dbg [[DBG43]]
// PPC64:       atomic_exit27:
// PPC64-NEXT:    [[CIV_REAL:%.*]] = load i32, i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 0), align 4, !dbg [[DBG45:![0-9]+]]
// PPC64-NEXT:    [[CIV_IMAG:%.*]] = load i32, i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 1), align 4, !dbg [[DBG45]]
// PPC64-NEXT:    [[TMP58:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP28]] to i8*, !dbg [[DBG46:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP58]], i32 noundef signext 0), !dbg [[DBG46]]
// PPC64-NEXT:    br label [[ATOMIC_CONT29:%.*]], !dbg [[DBG46]]
// PPC64:       atomic_cont29:
// PPC64-NEXT:    [[ATOMIC_TEMP28_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP28]], i32 0, i32 0, !dbg [[DBG46]]
// PPC64-NEXT:    [[ATOMIC_TEMP28_REAL:%.*]] = load i32, i32* [[ATOMIC_TEMP28_REALP]], align 4, !dbg [[DBG46]]
// PPC64-NEXT:    [[ATOMIC_TEMP28_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP28]], i32 0, i32 1, !dbg [[DBG46]]
// PPC64-NEXT:    [[ATOMIC_TEMP28_IMAG:%.*]] = load i32, i32* [[ATOMIC_TEMP28_IMAGP]], align 4, !dbg [[DBG46]]
// PPC64-NEXT:    [[TMP59:%.*]] = mul i32 [[CIV_REAL]], [[ATOMIC_TEMP28_REAL]], !dbg [[DBG47:![0-9]+]]
// PPC64-NEXT:    [[TMP60:%.*]] = mul i32 [[CIV_IMAG]], [[ATOMIC_TEMP28_IMAG]], !dbg [[DBG47]]
// PPC64-NEXT:    [[TMP61:%.*]] = add i32 [[TMP59]], [[TMP60]], !dbg [[DBG47]]
// PPC64-NEXT:    [[TMP62:%.*]] = mul i32 [[ATOMIC_TEMP28_REAL]], [[ATOMIC_TEMP28_REAL]], !dbg [[DBG47]]
// PPC64-NEXT:    [[TMP63:%.*]] = mul i32 [[ATOMIC_TEMP28_IMAG]], [[ATOMIC_TEMP28_IMAG]], !dbg [[DBG47]]
// PPC64-NEXT:    [[TMP64:%.*]] = add i32 [[TMP62]], [[TMP63]], !dbg [[DBG47]]
// PPC64-NEXT:    [[TMP65:%.*]] = mul i32 [[CIV_IMAG]], [[ATOMIC_TEMP28_REAL]], !dbg [[DBG47]]
// PPC64-NEXT:    [[TMP66:%.*]] = mul i32 [[CIV_REAL]], [[ATOMIC_TEMP28_IMAG]], !dbg [[DBG47]]
// PPC64-NEXT:    [[TMP67:%.*]] = sub i32 [[TMP65]], [[TMP66]], !dbg [[DBG47]]
// PPC64-NEXT:    [[TMP68:%.*]] = sdiv i32 [[TMP61]], [[TMP64]], !dbg [[DBG47]]
// PPC64-NEXT:    [[TMP69:%.*]] = sdiv i32 [[TMP67]], [[TMP64]], !dbg [[DBG47]]
// PPC64-NEXT:    [[ATOMIC_TEMP30_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP30]], i32 0, i32 0, !dbg [[DBG46]]
// PPC64-NEXT:    [[ATOMIC_TEMP30_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP30]], i32 0, i32 1, !dbg [[DBG46]]
// PPC64-NEXT:    store i32 [[TMP68]], i32* [[ATOMIC_TEMP30_REALP]], align 4, !dbg [[DBG46]]
// PPC64-NEXT:    store i32 [[TMP69]], i32* [[ATOMIC_TEMP30_IMAGP]], align 4, !dbg [[DBG46]]
// PPC64-NEXT:    [[TMP70:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP28]] to i8*, !dbg [[DBG46]]
// PPC64-NEXT:    [[TMP71:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP30]] to i8*, !dbg [[DBG46]]
// PPC64-NEXT:    [[CALL31:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP70]], i8* noundef [[TMP71]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG46]]
// PPC64-NEXT:    br i1 [[CALL31]], label [[ATOMIC_EXIT32:%.*]], label [[ATOMIC_CONT29]], !dbg [[DBG46]]
// PPC64:       atomic_exit32:
// PPC64-NEXT:    [[CFV_REAL:%.*]] = load float, float* getelementptr inbounds ({ float, float }, { float, float }* @cfv, i32 0, i32 0), align 4, !dbg [[DBG48:![0-9]+]]
// PPC64-NEXT:    [[CFV_IMAG:%.*]] = load float, float* getelementptr inbounds ({ float, float }, { float, float }* @cfv, i32 0, i32 1), align 4, !dbg [[DBG48]]
// PPC64-NEXT:    [[TMP72:%.*]] = bitcast { float, float }* [[ATOMIC_TEMP33]] to i8*, !dbg [[DBG49:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 8, i8* noundef bitcast ({ float, float }* @cfx to i8*), i8* noundef [[TMP72]], i32 noundef signext 0), !dbg [[DBG49]]
// PPC64-NEXT:    br label [[ATOMIC_CONT34:%.*]], !dbg [[DBG49]]
// PPC64:       atomic_cont34:
// PPC64-NEXT:    [[ATOMIC_TEMP33_REALP:%.*]] = getelementptr inbounds { float, float }, { float, float }* [[ATOMIC_TEMP33]], i32 0, i32 0, !dbg [[DBG49]]
// PPC64-NEXT:    [[ATOMIC_TEMP33_REAL:%.*]] = load float, float* [[ATOMIC_TEMP33_REALP]], align 4, !dbg [[DBG49]]
// PPC64-NEXT:    [[ATOMIC_TEMP33_IMAGP:%.*]] = getelementptr inbounds { float, float }, { float, float }* [[ATOMIC_TEMP33]], i32 0, i32 1, !dbg [[DBG49]]
// PPC64-NEXT:    [[ATOMIC_TEMP33_IMAG:%.*]] = load float, float* [[ATOMIC_TEMP33_IMAGP]], align 4, !dbg [[DBG49]]
// PPC64-NEXT:    [[ADD_R:%.*]] = fadd float [[CFV_REAL]], [[ATOMIC_TEMP33_REAL]], !dbg [[DBG50:![0-9]+]]
// PPC64-NEXT:    [[ADD_I:%.*]] = fadd float [[CFV_IMAG]], [[ATOMIC_TEMP33_IMAG]], !dbg [[DBG50]]
// PPC64-NEXT:    [[ATOMIC_TEMP35_REALP:%.*]] = getelementptr inbounds { float, float }, { float, float }* [[ATOMIC_TEMP35]], i32 0, i32 0, !dbg [[DBG49]]
// PPC64-NEXT:    [[ATOMIC_TEMP35_IMAGP:%.*]] = getelementptr inbounds { float, float }, { float, float }* [[ATOMIC_TEMP35]], i32 0, i32 1, !dbg [[DBG49]]
// PPC64-NEXT:    store float [[ADD_R]], float* [[ATOMIC_TEMP35_REALP]], align 4, !dbg [[DBG49]]
// PPC64-NEXT:    store float [[ADD_I]], float* [[ATOMIC_TEMP35_IMAGP]], align 4, !dbg [[DBG49]]
// PPC64-NEXT:    [[TMP73:%.*]] = bitcast { float, float }* [[ATOMIC_TEMP33]] to i8*, !dbg [[DBG49]]
// PPC64-NEXT:    [[TMP74:%.*]] = bitcast { float, float }* [[ATOMIC_TEMP35]] to i8*, !dbg [[DBG49]]
// PPC64-NEXT:    [[CALL36:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, i8* noundef bitcast ({ float, float }* @cfx to i8*), i8* noundef [[TMP73]], i8* noundef [[TMP74]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG49]]
// PPC64-NEXT:    br i1 [[CALL36]], label [[ATOMIC_EXIT37:%.*]], label [[ATOMIC_CONT34]], !dbg [[DBG49]]
// PPC64:       atomic_exit37:
// PPC64-NEXT:    [[CDV_REAL:%.*]] = load double, double* getelementptr inbounds ({ double, double }, { double, double }* @cdv, i32 0, i32 0), align 8, !dbg [[DBG51:![0-9]+]]
// PPC64-NEXT:    [[CDV_IMAG:%.*]] = load double, double* getelementptr inbounds ({ double, double }, { double, double }* @cdv, i32 0, i32 1), align 8, !dbg [[DBG51]]
// PPC64-NEXT:    [[TMP75:%.*]] = bitcast { double, double }* [[ATOMIC_TEMP38]] to i8*, !dbg [[DBG52:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 16, i8* noundef bitcast ({ double, double }* @cdx to i8*), i8* noundef [[TMP75]], i32 noundef signext 5), !dbg [[DBG52]]
// PPC64-NEXT:    br label [[ATOMIC_CONT39:%.*]], !dbg [[DBG52]]
// PPC64:       atomic_cont39:
// PPC64-NEXT:    [[ATOMIC_TEMP38_REALP:%.*]] = getelementptr inbounds { double, double }, { double, double }* [[ATOMIC_TEMP38]], i32 0, i32 0, !dbg [[DBG52]]
// PPC64-NEXT:    [[ATOMIC_TEMP38_REAL:%.*]] = load double, double* [[ATOMIC_TEMP38_REALP]], align 8, !dbg [[DBG52]]
// PPC64-NEXT:    [[ATOMIC_TEMP38_IMAGP:%.*]] = getelementptr inbounds { double, double }, { double, double }* [[ATOMIC_TEMP38]], i32 0, i32 1, !dbg [[DBG52]]
// PPC64-NEXT:    [[ATOMIC_TEMP38_IMAG:%.*]] = load double, double* [[ATOMIC_TEMP38_IMAGP]], align 8, !dbg [[DBG52]]
// PPC64-NEXT:    [[SUB_R:%.*]] = fsub double [[ATOMIC_TEMP38_REAL]], [[CDV_REAL]], !dbg [[DBG53:![0-9]+]]
// PPC64-NEXT:    [[SUB_I:%.*]] = fsub double [[ATOMIC_TEMP38_IMAG]], [[CDV_IMAG]], !dbg [[DBG53]]
// PPC64-NEXT:    [[ATOMIC_TEMP40_REALP:%.*]] = getelementptr inbounds { double, double }, { double, double }* [[ATOMIC_TEMP40]], i32 0, i32 0, !dbg [[DBG52]]
// PPC64-NEXT:    [[ATOMIC_TEMP40_IMAGP:%.*]] = getelementptr inbounds { double, double }, { double, double }* [[ATOMIC_TEMP40]], i32 0, i32 1, !dbg [[DBG52]]
// PPC64-NEXT:    store double [[SUB_R]], double* [[ATOMIC_TEMP40_REALP]], align 8, !dbg [[DBG52]]
// PPC64-NEXT:    store double [[SUB_I]], double* [[ATOMIC_TEMP40_IMAGP]], align 8, !dbg [[DBG52]]
// PPC64-NEXT:    [[TMP76:%.*]] = bitcast { double, double }* [[ATOMIC_TEMP38]] to i8*, !dbg [[DBG52]]
// PPC64-NEXT:    [[TMP77:%.*]] = bitcast { double, double }* [[ATOMIC_TEMP40]] to i8*, !dbg [[DBG52]]
// PPC64-NEXT:    [[CALL41:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, i8* noundef bitcast ({ double, double }* @cdx to i8*), i8* noundef [[TMP76]], i8* noundef [[TMP77]], i32 noundef signext 5, i32 noundef signext 5), !dbg [[DBG52]]
// PPC64-NEXT:    br i1 [[CALL41]], label [[ATOMIC_EXIT42:%.*]], label [[ATOMIC_CONT39]], !dbg [[DBG52]]
// PPC64:       atomic_exit42:
// PPC64-NEXT:    fence release
// PPC64-NEXT:    [[TMP78:%.*]] = load i8, i8* @bv, align 1, !dbg [[DBG54:![0-9]+]]
// PPC64-NEXT:    [[TOBOOL:%.*]] = trunc i8 [[TMP78]] to i1, !dbg [[DBG54]]
// PPC64-NEXT:    [[CONV43:%.*]] = zext i1 [[TOBOOL]] to i64, !dbg [[DBG54]]
// PPC64-NEXT:    [[TMP79:%.*]] = atomicrmw and i64* @ulx, i64 [[CONV43]] monotonic, align 8, !dbg [[DBG55:![0-9]+]]
// PPC64-NEXT:    [[TMP80:%.*]] = load i8, i8* @cv, align 1, !dbg [[DBG56:![0-9]+]]
// PPC64-NEXT:    [[CONV44:%.*]] = sext i8 [[TMP80]] to i32, !dbg [[DBG56]]
// PPC64-NEXT:    [[ATOMIC_LOAD45:%.*]] = load atomic i8, i8* @bx monotonic, align 1, !dbg [[DBG57:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT46:%.*]], !dbg [[DBG57]]
// PPC64:       atomic_cont46:
// PPC64-NEXT:    [[TMP81:%.*]] = phi i8 [ [[ATOMIC_LOAD45]], [[ATOMIC_EXIT42]] ], [ [[TMP84:%.*]], [[ATOMIC_CONT46]] ], !dbg [[DBG57]]
// PPC64-NEXT:    [[TOBOOL48:%.*]] = trunc i8 [[TMP81]] to i1, !dbg [[DBG57]]
// PPC64-NEXT:    [[CONV49:%.*]] = zext i1 [[TOBOOL48]] to i32, !dbg [[DBG57]]
// PPC64-NEXT:    [[AND:%.*]] = and i32 [[CONV44]], [[CONV49]], !dbg [[DBG58:![0-9]+]]
// PPC64-NEXT:    [[TOBOOL50:%.*]] = icmp ne i32 [[AND]], 0, !dbg [[DBG56]]
// PPC64-NEXT:    [[FROMBOOL:%.*]] = zext i1 [[TOBOOL50]] to i8, !dbg [[DBG57]]
// PPC64-NEXT:    store i8 [[FROMBOOL]], i8* [[ATOMIC_TEMP47]], align 1, !dbg [[DBG57]]
// PPC64-NEXT:    [[TMP82:%.*]] = load i8, i8* [[ATOMIC_TEMP47]], align 1, !dbg [[DBG57]]
// PPC64-NEXT:    [[TMP83:%.*]] = cmpxchg i8* @bx, i8 [[TMP81]], i8 [[TMP82]] monotonic monotonic, align 1, !dbg [[DBG57]]
// PPC64-NEXT:    [[TMP84]] = extractvalue { i8, i1 } [[TMP83]], 0, !dbg [[DBG57]]
// PPC64-NEXT:    [[TMP85:%.*]] = extractvalue { i8, i1 } [[TMP83]], 1, !dbg [[DBG57]]
// PPC64-NEXT:    br i1 [[TMP85]], label [[ATOMIC_EXIT51:%.*]], label [[ATOMIC_CONT46]], !dbg [[DBG57]]
// PPC64:       atomic_exit51:
// PPC64-NEXT:    [[TMP86:%.*]] = load i8, i8* @ucv, align 1, !dbg [[DBG59:![0-9]+]]
// PPC64-NEXT:    [[CONV52:%.*]] = zext i8 [[TMP86]] to i32, !dbg [[DBG59]]
// PPC64-NEXT:    [[ATOMIC_LOAD53:%.*]] = load atomic i8, i8* @cx seq_cst, align 1, !dbg [[DBG60:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT54:%.*]], !dbg [[DBG60]]
// PPC64:       atomic_cont54:
// PPC64-NEXT:    [[TMP87:%.*]] = phi i8 [ [[ATOMIC_LOAD53]], [[ATOMIC_EXIT51]] ], [ [[TMP90:%.*]], [[ATOMIC_CONT54]] ], !dbg [[DBG60]]
// PPC64-NEXT:    [[CONV56:%.*]] = sext i8 [[TMP87]] to i32, !dbg [[DBG60]]
// PPC64-NEXT:    [[SHR57:%.*]] = ashr i32 [[CONV56]], [[CONV52]], !dbg [[DBG61:![0-9]+]]
// PPC64-NEXT:    [[CONV58:%.*]] = trunc i32 [[SHR57]] to i8, !dbg [[DBG60]]
// PPC64-NEXT:    store i8 [[CONV58]], i8* [[ATOMIC_TEMP55]], align 1, !dbg [[DBG60]]
// PPC64-NEXT:    [[TMP88:%.*]] = load i8, i8* [[ATOMIC_TEMP55]], align 1, !dbg [[DBG60]]
// PPC64-NEXT:    [[TMP89:%.*]] = cmpxchg i8* @cx, i8 [[TMP87]], i8 [[TMP88]] seq_cst seq_cst, align 1, !dbg [[DBG60]]
// PPC64-NEXT:    [[TMP90]] = extractvalue { i8, i1 } [[TMP89]], 0, !dbg [[DBG60]]
// PPC64-NEXT:    [[TMP91:%.*]] = extractvalue { i8, i1 } [[TMP89]], 1, !dbg [[DBG60]]
// PPC64-NEXT:    br i1 [[TMP91]], label [[ATOMIC_EXIT59:%.*]], label [[ATOMIC_CONT54]], !dbg [[DBG60]]
// PPC64:       atomic_exit59:
// PPC64-NEXT:    fence release
// PPC64-NEXT:    [[TMP92:%.*]] = load i16, i16* @sv, align 2, !dbg [[DBG62:![0-9]+]]
// PPC64-NEXT:    [[CONV60:%.*]] = sext i16 [[TMP92]] to i32, !dbg [[DBG62]]
// PPC64-NEXT:    [[ATOMIC_LOAD61:%.*]] = load atomic i64, i64* @ulx monotonic, align 8, !dbg [[DBG63:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT62:%.*]], !dbg [[DBG63]]
// PPC64:       atomic_cont62:
// PPC64-NEXT:    [[TMP93:%.*]] = phi i64 [ [[ATOMIC_LOAD61]], [[ATOMIC_EXIT59]] ], [ [[TMP96:%.*]], [[ATOMIC_CONT62]] ], !dbg [[DBG63]]
// PPC64-NEXT:    [[SH_PROM:%.*]] = trunc i64 [[TMP93]] to i32, !dbg [[DBG64:![0-9]+]]
// PPC64-NEXT:    [[SHL64:%.*]] = shl i32 [[CONV60]], [[SH_PROM]], !dbg [[DBG64]]
// PPC64-NEXT:    [[CONV65:%.*]] = sext i32 [[SHL64]] to i64, !dbg [[DBG62]]
// PPC64-NEXT:    store i64 [[CONV65]], i64* [[ATOMIC_TEMP63]], align 8, !dbg [[DBG63]]
// PPC64-NEXT:    [[TMP94:%.*]] = load i64, i64* [[ATOMIC_TEMP63]], align 8, !dbg [[DBG63]]
// PPC64-NEXT:    [[TMP95:%.*]] = cmpxchg i64* @ulx, i64 [[TMP93]], i64 [[TMP94]] monotonic monotonic, align 8, !dbg [[DBG63]]
// PPC64-NEXT:    [[TMP96]] = extractvalue { i64, i1 } [[TMP95]], 0, !dbg [[DBG63]]
// PPC64-NEXT:    [[TMP97:%.*]] = extractvalue { i64, i1 } [[TMP95]], 1, !dbg [[DBG63]]
// PPC64-NEXT:    br i1 [[TMP97]], label [[ATOMIC_EXIT66:%.*]], label [[ATOMIC_CONT62]], !dbg [[DBG63]]
// PPC64:       atomic_exit66:
// PPC64-NEXT:    [[TMP98:%.*]] = load i16, i16* @usv, align 2, !dbg [[DBG65:![0-9]+]]
// PPC64-NEXT:    [[CONV67:%.*]] = zext i16 [[TMP98]] to i64, !dbg [[DBG65]]
// PPC64-NEXT:    [[ATOMIC_LOAD68:%.*]] = load atomic i64, i64* @lx monotonic, align 8, !dbg [[DBG66:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT69:%.*]], !dbg [[DBG66]]
// PPC64:       atomic_cont69:
// PPC64-NEXT:    [[TMP99:%.*]] = phi i64 [ [[ATOMIC_LOAD68]], [[ATOMIC_EXIT66]] ], [ [[TMP102:%.*]], [[ATOMIC_CONT69]] ], !dbg [[DBG66]]
// PPC64-NEXT:    [[REM:%.*]] = srem i64 [[TMP99]], [[CONV67]], !dbg [[DBG67:![0-9]+]]
// PPC64-NEXT:    store i64 [[REM]], i64* [[ATOMIC_TEMP70]], align 8, !dbg [[DBG66]]
// PPC64-NEXT:    [[TMP100:%.*]] = load i64, i64* [[ATOMIC_TEMP70]], align 8, !dbg [[DBG66]]
// PPC64-NEXT:    [[TMP101:%.*]] = cmpxchg i64* @lx, i64 [[TMP99]], i64 [[TMP100]] monotonic monotonic, align 8, !dbg [[DBG66]]
// PPC64-NEXT:    [[TMP102]] = extractvalue { i64, i1 } [[TMP101]], 0, !dbg [[DBG66]]
// PPC64-NEXT:    [[TMP103:%.*]] = extractvalue { i64, i1 } [[TMP101]], 1, !dbg [[DBG66]]
// PPC64-NEXT:    br i1 [[TMP103]], label [[ATOMIC_EXIT71:%.*]], label [[ATOMIC_CONT69]], !dbg [[DBG66]]
// PPC64:       atomic_exit71:
// PPC64-NEXT:    [[TMP104:%.*]] = load i32, i32* @iv, align 4, !dbg [[DBG68:![0-9]+]]
// PPC64-NEXT:    [[TMP105:%.*]] = atomicrmw or i32* @uix, i32 [[TMP104]] seq_cst, align 4, !dbg [[DBG69:![0-9]+]]
// PPC64-NEXT:    fence release
// PPC64-NEXT:    [[TMP106:%.*]] = load i32, i32* @uiv, align 4, !dbg [[DBG70:![0-9]+]]
// PPC64-NEXT:    [[TMP107:%.*]] = atomicrmw and i32* @ix, i32 [[TMP106]] monotonic, align 4, !dbg [[DBG71:![0-9]+]]
// PPC64-NEXT:    [[TMP108:%.*]] = load i64, i64* @lv, align 8, !dbg [[DBG72:![0-9]+]]
// PPC64-NEXT:    [[TMP109:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP72]] to i8*, !dbg [[DBG73:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP109]], i32 noundef signext 0), !dbg [[DBG73]]
// PPC64-NEXT:    br label [[ATOMIC_CONT73:%.*]], !dbg [[DBG73]]
// PPC64:       atomic_cont73:
// PPC64-NEXT:    [[ATOMIC_TEMP72_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP72]], i32 0, i32 0, !dbg [[DBG73]]
// PPC64-NEXT:    [[ATOMIC_TEMP72_REAL:%.*]] = load i32, i32* [[ATOMIC_TEMP72_REALP]], align 4, !dbg [[DBG73]]
// PPC64-NEXT:    [[ATOMIC_TEMP72_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP72]], i32 0, i32 1, !dbg [[DBG73]]
// PPC64-NEXT:    [[ATOMIC_TEMP72_IMAG:%.*]] = load i32, i32* [[ATOMIC_TEMP72_IMAGP]], align 4, !dbg [[DBG73]]
// PPC64-NEXT:    [[CONV75:%.*]] = sext i32 [[ATOMIC_TEMP72_REAL]] to i64, !dbg [[DBG73]]
// PPC64-NEXT:    [[CONV76:%.*]] = sext i32 [[ATOMIC_TEMP72_IMAG]] to i64, !dbg [[DBG73]]
// PPC64-NEXT:    [[ADD_R77:%.*]] = add i64 [[TMP108]], [[CONV75]], !dbg [[DBG74:![0-9]+]]
// PPC64-NEXT:    [[ADD_I78:%.*]] = add i64 0, [[CONV76]], !dbg [[DBG74]]
// PPC64-NEXT:    [[CONV79:%.*]] = trunc i64 [[ADD_R77]] to i32, !dbg [[DBG72]]
// PPC64-NEXT:    [[CONV80:%.*]] = trunc i64 [[ADD_I78]] to i32, !dbg [[DBG72]]
// PPC64-NEXT:    [[ATOMIC_TEMP74_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP74]], i32 0, i32 0, !dbg [[DBG73]]
// PPC64-NEXT:    [[ATOMIC_TEMP74_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP74]], i32 0, i32 1, !dbg [[DBG73]]
// PPC64-NEXT:    store i32 [[CONV79]], i32* [[ATOMIC_TEMP74_REALP]], align 4, !dbg [[DBG73]]
// PPC64-NEXT:    store i32 [[CONV80]], i32* [[ATOMIC_TEMP74_IMAGP]], align 4, !dbg [[DBG73]]
// PPC64-NEXT:    [[TMP110:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP72]] to i8*, !dbg [[DBG73]]
// PPC64-NEXT:    [[TMP111:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP74]] to i8*, !dbg [[DBG73]]
// PPC64-NEXT:    [[CALL81:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP110]], i8* noundef [[TMP111]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG73]]
// PPC64-NEXT:    br i1 [[CALL81]], label [[ATOMIC_EXIT82:%.*]], label [[ATOMIC_CONT73]], !dbg [[DBG73]]
// PPC64:       atomic_exit82:
// PPC64-NEXT:    [[TMP112:%.*]] = load i64, i64* @ulv, align 8, !dbg [[DBG75:![0-9]+]]
// PPC64-NEXT:    [[CONV83:%.*]] = uitofp i64 [[TMP112]] to float, !dbg [[DBG75]]
// PPC64-NEXT:    [[ATOMIC_LOAD84:%.*]] = load atomic i32, i32* bitcast (float* @fx to i32*) monotonic, align 4, !dbg [[DBG76:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT85:%.*]], !dbg [[DBG76]]
// PPC64:       atomic_cont85:
// PPC64-NEXT:    [[TMP113:%.*]] = phi i32 [ [[ATOMIC_LOAD84]], [[ATOMIC_EXIT82]] ], [ [[TMP118:%.*]], [[ATOMIC_CONT85]] ], !dbg [[DBG76]]
// PPC64-NEXT:    [[TMP114:%.*]] = bitcast float* [[ATOMIC_TEMP86]] to i32*, !dbg [[DBG76]]
// PPC64-NEXT:    [[TMP115:%.*]] = bitcast i32 [[TMP113]] to float, !dbg [[DBG76]]
// PPC64-NEXT:    [[MUL87:%.*]] = fmul float [[TMP115]], [[CONV83]], !dbg [[DBG77:![0-9]+]]
// PPC64-NEXT:    store float [[MUL87]], float* [[ATOMIC_TEMP86]], align 4, !dbg [[DBG76]]
// PPC64-NEXT:    [[TMP116:%.*]] = load i32, i32* [[TMP114]], align 4, !dbg [[DBG76]]
// PPC64-NEXT:    [[TMP117:%.*]] = cmpxchg i32* bitcast (float* @fx to i32*), i32 [[TMP113]], i32 [[TMP116]] monotonic monotonic, align 4, !dbg [[DBG76]]
// PPC64-NEXT:    [[TMP118]] = extractvalue { i32, i1 } [[TMP117]], 0, !dbg [[DBG76]]
// PPC64-NEXT:    [[TMP119:%.*]] = extractvalue { i32, i1 } [[TMP117]], 1, !dbg [[DBG76]]
// PPC64-NEXT:    br i1 [[TMP119]], label [[ATOMIC_EXIT88:%.*]], label [[ATOMIC_CONT85]], !dbg [[DBG76]]
// PPC64:       atomic_exit88:
// PPC64-NEXT:    [[TMP120:%.*]] = load i64, i64* @llv, align 8, !dbg [[DBG78:![0-9]+]]
// PPC64-NEXT:    [[CONV89:%.*]] = sitofp i64 [[TMP120]] to double, !dbg [[DBG78]]
// PPC64-NEXT:    [[ATOMIC_LOAD90:%.*]] = load atomic i64, i64* bitcast (double* @dx to i64*) monotonic, align 8, !dbg [[DBG79:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT91:%.*]], !dbg [[DBG79]]
// PPC64:       atomic_cont91:
// PPC64-NEXT:    [[TMP121:%.*]] = phi i64 [ [[ATOMIC_LOAD90]], [[ATOMIC_EXIT88]] ], [ [[TMP126:%.*]], [[ATOMIC_CONT91]] ], !dbg [[DBG79]]
// PPC64-NEXT:    [[TMP122:%.*]] = bitcast double* [[ATOMIC_TEMP92]] to i64*, !dbg [[DBG79]]
// PPC64-NEXT:    [[TMP123:%.*]] = bitcast i64 [[TMP121]] to double, !dbg [[DBG79]]
// PPC64-NEXT:    [[DIV93:%.*]] = fdiv double [[TMP123]], [[CONV89]], !dbg [[DBG80:![0-9]+]]
// PPC64-NEXT:    store double [[DIV93]], double* [[ATOMIC_TEMP92]], align 8, !dbg [[DBG79]]
// PPC64-NEXT:    [[TMP124:%.*]] = load i64, i64* [[TMP122]], align 8, !dbg [[DBG79]]
// PPC64-NEXT:    [[TMP125:%.*]] = cmpxchg i64* bitcast (double* @dx to i64*), i64 [[TMP121]], i64 [[TMP124]] monotonic monotonic, align 8, !dbg [[DBG79]]
// PPC64-NEXT:    [[TMP126]] = extractvalue { i64, i1 } [[TMP125]], 0, !dbg [[DBG79]]
// PPC64-NEXT:    [[TMP127:%.*]] = extractvalue { i64, i1 } [[TMP125]], 1, !dbg [[DBG79]]
// PPC64-NEXT:    br i1 [[TMP127]], label [[ATOMIC_EXIT94:%.*]], label [[ATOMIC_CONT91]], !dbg [[DBG79]]
// PPC64:       atomic_exit94:
// PPC64-NEXT:    [[TMP128:%.*]] = load i64, i64* @ullv, align 8, !dbg [[DBG81:![0-9]+]]
// PPC64-NEXT:    [[CONV95:%.*]] = uitofp i64 [[TMP128]] to ppc_fp128, !dbg [[DBG81]]
// PPC64-NEXT:    [[TMP129:%.*]] = bitcast ppc_fp128* [[ATOMIC_TEMP96]] to i8*, !dbg [[DBG82:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 16, i8* noundef bitcast (ppc_fp128* @ldx to i8*), i8* noundef [[TMP129]], i32 noundef signext 0), !dbg [[DBG82]]
// PPC64-NEXT:    br label [[ATOMIC_CONT97:%.*]], !dbg [[DBG82]]
// PPC64:       atomic_cont97:
// PPC64-NEXT:    [[TMP130:%.*]] = load ppc_fp128, ppc_fp128* [[ATOMIC_TEMP96]], align 16, !dbg [[DBG82]]
// PPC64-NEXT:    [[SUB99:%.*]] = fsub ppc_fp128 [[TMP130]], [[CONV95]], !dbg [[DBG83:![0-9]+]]
// PPC64-NEXT:    store ppc_fp128 [[SUB99]], ppc_fp128* [[ATOMIC_TEMP98]], align 16, !dbg [[DBG82]]
// PPC64-NEXT:    [[TMP131:%.*]] = bitcast ppc_fp128* [[ATOMIC_TEMP96]] to i8*, !dbg [[DBG82]]
// PPC64-NEXT:    [[TMP132:%.*]] = bitcast ppc_fp128* [[ATOMIC_TEMP98]] to i8*, !dbg [[DBG82]]
// PPC64-NEXT:    [[CALL100:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, i8* noundef bitcast (ppc_fp128* @ldx to i8*), i8* noundef [[TMP131]], i8* noundef [[TMP132]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG82]]
// PPC64-NEXT:    br i1 [[CALL100]], label [[ATOMIC_EXIT101:%.*]], label [[ATOMIC_CONT97]], !dbg [[DBG82]]
// PPC64:       atomic_exit101:
// PPC64-NEXT:    [[TMP133:%.*]] = load float, float* @fv, align 4, !dbg [[DBG84:![0-9]+]]
// PPC64-NEXT:    [[TMP134:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP102]] to i8*, !dbg [[DBG85:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP134]], i32 noundef signext 0), !dbg [[DBG85]]
// PPC64-NEXT:    br label [[ATOMIC_CONT103:%.*]], !dbg [[DBG85]]
// PPC64:       atomic_cont103:
// PPC64-NEXT:    [[ATOMIC_TEMP102_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP102]], i32 0, i32 0, !dbg [[DBG85]]
// PPC64-NEXT:    [[ATOMIC_TEMP102_REAL:%.*]] = load i32, i32* [[ATOMIC_TEMP102_REALP]], align 4, !dbg [[DBG85]]
// PPC64-NEXT:    [[ATOMIC_TEMP102_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP102]], i32 0, i32 1, !dbg [[DBG85]]
// PPC64-NEXT:    [[ATOMIC_TEMP102_IMAG:%.*]] = load i32, i32* [[ATOMIC_TEMP102_IMAGP]], align 4, !dbg [[DBG85]]
// PPC64-NEXT:    [[CONV105:%.*]] = sitofp i32 [[ATOMIC_TEMP102_REAL]] to float, !dbg [[DBG85]]
// PPC64-NEXT:    [[CONV106:%.*]] = sitofp i32 [[ATOMIC_TEMP102_IMAG]] to float, !dbg [[DBG85]]
// PPC64-NEXT:    [[CALL107:%.*]] = call { float, float } @__divsc3(float noundef [[TMP133]], float noundef 0.000000e+00, float noundef [[CONV105]], float noundef [[CONV106]]) #[[ATTR2:[0-9]+]], !dbg [[DBG86:![0-9]+]]
// PPC64-NEXT:    [[TMP135:%.*]] = extractvalue { float, float } [[CALL107]], 0, !dbg [[DBG86]]
// PPC64-NEXT:    [[TMP136:%.*]] = extractvalue { float, float } [[CALL107]], 1, !dbg [[DBG86]]
// PPC64-NEXT:    [[CONV108:%.*]] = fptosi float [[TMP135]] to i32, !dbg [[DBG84]]
// PPC64-NEXT:    [[CONV109:%.*]] = fptosi float [[TMP136]] to i32, !dbg [[DBG84]]
// PPC64-NEXT:    [[ATOMIC_TEMP104_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP104]], i32 0, i32 0, !dbg [[DBG85]]
// PPC64-NEXT:    [[ATOMIC_TEMP104_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP104]], i32 0, i32 1, !dbg [[DBG85]]
// PPC64-NEXT:    store i32 [[CONV108]], i32* [[ATOMIC_TEMP104_REALP]], align 4, !dbg [[DBG85]]
// PPC64-NEXT:    store i32 [[CONV109]], i32* [[ATOMIC_TEMP104_IMAGP]], align 4, !dbg [[DBG85]]
// PPC64-NEXT:    [[TMP137:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP102]] to i8*, !dbg [[DBG85]]
// PPC64-NEXT:    [[TMP138:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP104]] to i8*, !dbg [[DBG85]]
// PPC64-NEXT:    [[CALL110:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP137]], i8* noundef [[TMP138]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG85]]
// PPC64-NEXT:    br i1 [[CALL110]], label [[ATOMIC_EXIT111:%.*]], label [[ATOMIC_CONT103]], !dbg [[DBG85]]
// PPC64:       atomic_exit111:
// PPC64-NEXT:    [[TMP139:%.*]] = load double, double* @dv, align 8, !dbg [[DBG87:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD112:%.*]] = load atomic i16, i16* @sx monotonic, align 2, !dbg [[DBG88:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT113:%.*]], !dbg [[DBG88]]
// PPC64:       atomic_cont113:
// PPC64-NEXT:    [[TMP140:%.*]] = phi i16 [ [[ATOMIC_LOAD112]], [[ATOMIC_EXIT111]] ], [ [[TMP143:%.*]], [[ATOMIC_CONT113]] ], !dbg [[DBG88]]
// PPC64-NEXT:    [[CONV115:%.*]] = sext i16 [[TMP140]] to i32, !dbg [[DBG88]]
// PPC64-NEXT:    [[CONV116:%.*]] = sitofp i32 [[CONV115]] to double, !dbg [[DBG88]]
// PPC64-NEXT:    [[ADD117:%.*]] = fadd double [[CONV116]], [[TMP139]], !dbg [[DBG89:![0-9]+]]
// PPC64-NEXT:    [[CONV118:%.*]] = fptosi double [[ADD117]] to i16, !dbg [[DBG88]]
// PPC64-NEXT:    store i16 [[CONV118]], i16* [[ATOMIC_TEMP114]], align 2, !dbg [[DBG88]]
// PPC64-NEXT:    [[TMP141:%.*]] = load i16, i16* [[ATOMIC_TEMP114]], align 2, !dbg [[DBG88]]
// PPC64-NEXT:    [[TMP142:%.*]] = cmpxchg i16* @sx, i16 [[TMP140]], i16 [[TMP141]] monotonic monotonic, align 2, !dbg [[DBG88]]
// PPC64-NEXT:    [[TMP143]] = extractvalue { i16, i1 } [[TMP142]], 0, !dbg [[DBG88]]
// PPC64-NEXT:    [[TMP144:%.*]] = extractvalue { i16, i1 } [[TMP142]], 1, !dbg [[DBG88]]
// PPC64-NEXT:    br i1 [[TMP144]], label [[ATOMIC_EXIT119:%.*]], label [[ATOMIC_CONT113]], !dbg [[DBG88]]
// PPC64:       atomic_exit119:
// PPC64-NEXT:    [[TMP145:%.*]] = load ppc_fp128, ppc_fp128* @ldv, align 16, !dbg [[DBG90:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD120:%.*]] = load atomic i8, i8* @bx monotonic, align 1, !dbg [[DBG91:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT121:%.*]], !dbg [[DBG91]]
// PPC64:       atomic_cont121:
// PPC64-NEXT:    [[TMP146:%.*]] = phi i8 [ [[ATOMIC_LOAD120]], [[ATOMIC_EXIT119]] ], [ [[TMP149:%.*]], [[ATOMIC_CONT121]] ], !dbg [[DBG91]]
// PPC64-NEXT:    [[TOBOOL123:%.*]] = trunc i8 [[TMP146]] to i1, !dbg [[DBG91]]
// PPC64-NEXT:    [[CONV124:%.*]] = zext i1 [[TOBOOL123]] to i32, !dbg [[DBG91]]
// PPC64-NEXT:    [[CONV125:%.*]] = sitofp i32 [[CONV124]] to ppc_fp128, !dbg [[DBG91]]
// PPC64-NEXT:    [[MUL126:%.*]] = fmul ppc_fp128 [[TMP145]], [[CONV125]], !dbg [[DBG92:![0-9]+]]
// PPC64-NEXT:    [[TOBOOL127:%.*]] = fcmp une ppc_fp128 [[MUL126]], 0xM00000000000000000000000000000000, !dbg [[DBG90]]
// PPC64-NEXT:    [[FROMBOOL128:%.*]] = zext i1 [[TOBOOL127]] to i8, !dbg [[DBG91]]
// PPC64-NEXT:    store i8 [[FROMBOOL128]], i8* [[ATOMIC_TEMP122]], align 1, !dbg [[DBG91]]
// PPC64-NEXT:    [[TMP147:%.*]] = load i8, i8* [[ATOMIC_TEMP122]], align 1, !dbg [[DBG91]]
// PPC64-NEXT:    [[TMP148:%.*]] = cmpxchg i8* @bx, i8 [[TMP146]], i8 [[TMP147]] release monotonic, align 1, !dbg [[DBG91]]
// PPC64-NEXT:    [[TMP149]] = extractvalue { i8, i1 } [[TMP148]], 0, !dbg [[DBG91]]
// PPC64-NEXT:    [[TMP150:%.*]] = extractvalue { i8, i1 } [[TMP148]], 1, !dbg [[DBG91]]
// PPC64-NEXT:    br i1 [[TMP150]], label [[ATOMIC_EXIT129:%.*]], label [[ATOMIC_CONT121]], !dbg [[DBG91]]
// PPC64:       atomic_exit129:
// PPC64-NEXT:    fence release
// PPC64-NEXT:    [[CIV_REAL130:%.*]] = load i32, i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 0), align 4, !dbg [[DBG93:![0-9]+]]
// PPC64-NEXT:    [[CIV_IMAG131:%.*]] = load i32, i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 1), align 4, !dbg [[DBG93]]
// PPC64-NEXT:    [[ATOMIC_LOAD132:%.*]] = load atomic i8, i8* @bx monotonic, align 1, !dbg [[DBG94:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT133:%.*]], !dbg [[DBG94]]
// PPC64:       atomic_cont133:
// PPC64-NEXT:    [[TMP151:%.*]] = phi i8 [ [[ATOMIC_LOAD132]], [[ATOMIC_EXIT129]] ], [ [[TMP154:%.*]], [[ATOMIC_CONT133]] ], !dbg [[DBG94]]
// PPC64-NEXT:    [[TOBOOL135:%.*]] = trunc i8 [[TMP151]] to i1, !dbg [[DBG94]]
// PPC64-NEXT:    [[CONV136:%.*]] = zext i1 [[TOBOOL135]] to i32, !dbg [[DBG94]]
// PPC64-NEXT:    [[SUB_R137:%.*]] = sub i32 [[CIV_REAL130]], [[CONV136]], !dbg [[DBG95:![0-9]+]]
// PPC64-NEXT:    [[SUB_I138:%.*]] = sub i32 [[CIV_IMAG131]], 0, !dbg [[DBG95]]
// PPC64-NEXT:    [[TOBOOL139:%.*]] = icmp ne i32 [[SUB_R137]], 0, !dbg [[DBG93]]
// PPC64-NEXT:    [[TOBOOL140:%.*]] = icmp ne i32 [[SUB_I138]], 0, !dbg [[DBG93]]
// PPC64-NEXT:    [[TOBOOL141:%.*]] = or i1 [[TOBOOL139]], [[TOBOOL140]], !dbg [[DBG93]]
// PPC64-NEXT:    [[FROMBOOL142:%.*]] = zext i1 [[TOBOOL141]] to i8, !dbg [[DBG94]]
// PPC64-NEXT:    store i8 [[FROMBOOL142]], i8* [[ATOMIC_TEMP134]], align 1, !dbg [[DBG94]]
// PPC64-NEXT:    [[TMP152:%.*]] = load i8, i8* [[ATOMIC_TEMP134]], align 1, !dbg [[DBG94]]
// PPC64-NEXT:    [[TMP153:%.*]] = cmpxchg i8* @bx, i8 [[TMP151]], i8 [[TMP152]] monotonic monotonic, align 1, !dbg [[DBG94]]
// PPC64-NEXT:    [[TMP154]] = extractvalue { i8, i1 } [[TMP153]], 0, !dbg [[DBG94]]
// PPC64-NEXT:    [[TMP155:%.*]] = extractvalue { i8, i1 } [[TMP153]], 1, !dbg [[DBG94]]
// PPC64-NEXT:    br i1 [[TMP155]], label [[ATOMIC_EXIT143:%.*]], label [[ATOMIC_CONT133]], !dbg [[DBG94]]
// PPC64:       atomic_exit143:
// PPC64-NEXT:    [[TMP156:%.*]] = load i16, i16* @sv, align 2, !dbg [[DBG96:![0-9]+]]
// PPC64-NEXT:    [[TMP157:%.*]] = load i8, i8* @bv, align 1, !dbg [[DBG97:![0-9]+]]
// PPC64-NEXT:    [[TOBOOL144:%.*]] = trunc i8 [[TMP157]] to i1, !dbg [[DBG97]]
// PPC64-NEXT:    [[CONV145:%.*]] = zext i1 [[TOBOOL144]] to i32, !dbg [[DBG97]]
// PPC64-NEXT:    [[TMP158:%.*]] = bitcast <4 x i32>* [[ATOMIC_TEMP146]] to i8*, !dbg [[DBG98:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 16, i8* noundef bitcast (<4 x i32>* @int4x to i8*), i8* noundef [[TMP158]], i32 noundef signext 0), !dbg [[DBG98]]
// PPC64-NEXT:    br label [[ATOMIC_CONT147:%.*]], !dbg [[DBG98]]
// PPC64:       atomic_cont147:
// PPC64-NEXT:    [[TMP159:%.*]] = load <4 x i32>, <4 x i32>* [[ATOMIC_TEMP146]], align 16, !dbg [[DBG98]]
// PPC64-NEXT:    store <4 x i32> [[TMP159]], <4 x i32>* [[ATOMIC_TEMP148]], align 16, !dbg [[DBG98]]
// PPC64-NEXT:    [[TMP160:%.*]] = load <4 x i32>, <4 x i32>* [[ATOMIC_TEMP146]], align 16, !dbg [[DBG98]]
// PPC64-NEXT:    store <4 x i32> [[TMP160]], <4 x i32>* [[ATOMIC_TEMP149]], align 16, !dbg [[DBG98]]
// PPC64-NEXT:    [[TMP161:%.*]] = load <4 x i32>, <4 x i32>* [[ATOMIC_TEMP149]], align 16, !dbg [[DBG98]]
// PPC64-NEXT:    [[VECEXT:%.*]] = extractelement <4 x i32> [[TMP161]], i16 [[TMP156]], !dbg [[DBG98]]
// PPC64-NEXT:    [[OR:%.*]] = or i32 [[VECEXT]], [[CONV145]], !dbg [[DBG99:![0-9]+]]
// PPC64-NEXT:    [[TMP162:%.*]] = load <4 x i32>, <4 x i32>* [[ATOMIC_TEMP148]], align 16, !dbg [[DBG98]]
// PPC64-NEXT:    [[VECINS:%.*]] = insertelement <4 x i32> [[TMP162]], i32 [[OR]], i16 [[TMP156]], !dbg [[DBG98]]
// PPC64-NEXT:    store <4 x i32> [[VECINS]], <4 x i32>* [[ATOMIC_TEMP148]], align 16, !dbg [[DBG98]]
// PPC64-NEXT:    [[TMP163:%.*]] = bitcast <4 x i32>* [[ATOMIC_TEMP146]] to i8*, !dbg [[DBG98]]
// PPC64-NEXT:    [[TMP164:%.*]] = bitcast <4 x i32>* [[ATOMIC_TEMP148]] to i8*, !dbg [[DBG98]]
// PPC64-NEXT:    [[CALL150:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, i8* noundef bitcast (<4 x i32>* @int4x to i8*), i8* noundef [[TMP163]], i8* noundef [[TMP164]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG98]]
// PPC64-NEXT:    br i1 [[CALL150]], label [[ATOMIC_EXIT151:%.*]], label [[ATOMIC_CONT147]], !dbg [[DBG98]]
// PPC64:       atomic_exit151:
// PPC64-NEXT:    [[TMP165:%.*]] = load ppc_fp128, ppc_fp128* @ldv, align 16, !dbg [[DBG100:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD152:%.*]] = load atomic i32, i32* bitcast (%struct.BitFields* @bfx to i32*) monotonic, align 4, !dbg [[DBG101:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT153:%.*]], !dbg [[DBG101]]
// PPC64:       atomic_cont153:
// PPC64-NEXT:    [[TMP166:%.*]] = phi i32 [ [[ATOMIC_LOAD152]], [[ATOMIC_EXIT151]] ], [ [[TMP169:%.*]], [[ATOMIC_CONT153]] ], !dbg [[DBG101]]
// PPC64-NEXT:    store i32 [[TMP166]], i32* [[ATOMIC_TEMP154]], align 4, !dbg [[DBG101]]
// PPC64-NEXT:    store i32 [[TMP166]], i32* [[ATOMIC_TEMP155]], align 4, !dbg [[DBG101]]
// PPC64-NEXT:    [[BF_LOAD:%.*]] = load i32, i32* [[ATOMIC_TEMP155]], align 4, !dbg [[DBG101]]
// PPC64-NEXT:    [[BF_ASHR:%.*]] = ashr i32 [[BF_LOAD]], 1, !dbg [[DBG101]]
// PPC64-NEXT:    [[CONV156:%.*]] = sitofp i32 [[BF_ASHR]] to ppc_fp128, !dbg [[DBG102:![0-9]+]]
// PPC64-NEXT:    [[SUB157:%.*]] = fsub ppc_fp128 [[CONV156]], [[TMP165]], !dbg [[DBG103:![0-9]+]]
// PPC64-NEXT:    [[CONV158:%.*]] = fptosi ppc_fp128 [[SUB157]] to i32, !dbg [[DBG102]]
// PPC64-NEXT:    [[BF_LOAD159:%.*]] = load i32, i32* [[ATOMIC_TEMP154]], align 4, !dbg [[DBG101]]
// PPC64-NEXT:    [[BF_VALUE:%.*]] = and i32 [[CONV158]], 2147483647, !dbg [[DBG101]]
// PPC64-NEXT:    [[BF_SHL:%.*]] = shl i32 [[BF_VALUE]], 1, !dbg [[DBG101]]
// PPC64-NEXT:    [[BF_CLEAR:%.*]] = and i32 [[BF_LOAD159]], 1, !dbg [[DBG101]]
// PPC64-NEXT:    [[BF_SET:%.*]] = or i32 [[BF_CLEAR]], [[BF_SHL]], !dbg [[DBG101]]
// PPC64-NEXT:    store i32 [[BF_SET]], i32* [[ATOMIC_TEMP154]], align 4, !dbg [[DBG101]]
// PPC64-NEXT:    [[TMP167:%.*]] = load i32, i32* [[ATOMIC_TEMP154]], align 4, !dbg [[DBG101]]
// PPC64-NEXT:    [[TMP168:%.*]] = cmpxchg i32* bitcast (%struct.BitFields* @bfx to i32*), i32 [[TMP166]], i32 [[TMP167]] monotonic monotonic, align 4, !dbg [[DBG101]]
// PPC64-NEXT:    [[TMP169]] = extractvalue { i32, i1 } [[TMP168]], 0, !dbg [[DBG101]]
// PPC64-NEXT:    [[TMP170:%.*]] = extractvalue { i32, i1 } [[TMP168]], 1, !dbg [[DBG101]]
// PPC64-NEXT:    br i1 [[TMP170]], label [[ATOMIC_EXIT160:%.*]], label [[ATOMIC_CONT153]], !dbg [[DBG101]]
// PPC64:       atomic_exit160:
// PPC64-NEXT:    [[TMP171:%.*]] = load ppc_fp128, ppc_fp128* @ldv, align 16, !dbg [[DBG104:![0-9]+]]
// PPC64-NEXT:    [[TMP172:%.*]] = bitcast i32* [[ATOMIC_TEMP161]] to i8*, !dbg [[DBG105:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 4, i8* noundef bitcast (%struct.BitFields_packed* @bfx_packed to i8*), i8* noundef [[TMP172]], i32 noundef signext 0), !dbg [[DBG105]]
// PPC64-NEXT:    br label [[ATOMIC_CONT162:%.*]], !dbg [[DBG105]]
// PPC64:       atomic_cont162:
// PPC64-NEXT:    [[TMP173:%.*]] = load i32, i32* [[ATOMIC_TEMP161]], align 1, !dbg [[DBG105]]
// PPC64-NEXT:    store i32 [[TMP173]], i32* [[ATOMIC_TEMP163]], align 1, !dbg [[DBG105]]
// PPC64-NEXT:    [[TMP174:%.*]] = load i32, i32* [[ATOMIC_TEMP161]], align 1, !dbg [[DBG105]]
// PPC64-NEXT:    store i32 [[TMP174]], i32* [[ATOMIC_TEMP164]], align 4, !dbg [[DBG105]]
// PPC64-NEXT:    [[BF_LOAD165:%.*]] = load i32, i32* [[ATOMIC_TEMP164]], align 1, !dbg [[DBG105]]
// PPC64-NEXT:    [[BF_ASHR166:%.*]] = ashr i32 [[BF_LOAD165]], 1, !dbg [[DBG105]]
// PPC64-NEXT:    [[CONV167:%.*]] = sitofp i32 [[BF_ASHR166]] to ppc_fp128, !dbg [[DBG106:![0-9]+]]
// PPC64-NEXT:    [[MUL168:%.*]] = fmul ppc_fp128 [[CONV167]], [[TMP171]], !dbg [[DBG107:![0-9]+]]
// PPC64-NEXT:    [[CONV169:%.*]] = fptosi ppc_fp128 [[MUL168]] to i32, !dbg [[DBG106]]
// PPC64-NEXT:    [[BF_LOAD170:%.*]] = load i32, i32* [[ATOMIC_TEMP163]], align 1, !dbg [[DBG105]]
// PPC64-NEXT:    [[BF_VALUE171:%.*]] = and i32 [[CONV169]], 2147483647, !dbg [[DBG105]]
// PPC64-NEXT:    [[BF_SHL172:%.*]] = shl i32 [[BF_VALUE171]], 1, !dbg [[DBG105]]
// PPC64-NEXT:    [[BF_CLEAR173:%.*]] = and i32 [[BF_LOAD170]], 1, !dbg [[DBG105]]
// PPC64-NEXT:    [[BF_SET174:%.*]] = or i32 [[BF_CLEAR173]], [[BF_SHL172]], !dbg [[DBG105]]
// PPC64-NEXT:    store i32 [[BF_SET174]], i32* [[ATOMIC_TEMP163]], align 1, !dbg [[DBG105]]
// PPC64-NEXT:    [[TMP175:%.*]] = bitcast i32* [[ATOMIC_TEMP161]] to i8*, !dbg [[DBG105]]
// PPC64-NEXT:    [[TMP176:%.*]] = bitcast i32* [[ATOMIC_TEMP163]] to i8*, !dbg [[DBG105]]
// PPC64-NEXT:    [[CALL175:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 4, i8* noundef bitcast (%struct.BitFields_packed* @bfx_packed to i8*), i8* noundef [[TMP175]], i8* noundef [[TMP176]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG105]]
// PPC64-NEXT:    br i1 [[CALL175]], label [[ATOMIC_EXIT176:%.*]], label [[ATOMIC_CONT162]], !dbg [[DBG105]]
// PPC64:       atomic_exit176:
// PPC64-NEXT:    [[TMP177:%.*]] = load ppc_fp128, ppc_fp128* @ldv, align 16, !dbg [[DBG108:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD177:%.*]] = load atomic i32, i32* getelementptr inbounds ([[STRUCT_BITFIELDS2:%.*]], %struct.BitFields2* @bfx2, i32 0, i32 0) monotonic, align 4, !dbg [[DBG109:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT178:%.*]], !dbg [[DBG109]]
// PPC64:       atomic_cont178:
// PPC64-NEXT:    [[TMP178:%.*]] = phi i32 [ [[ATOMIC_LOAD177]], [[ATOMIC_EXIT176]] ], [ [[TMP181:%.*]], [[ATOMIC_CONT178]] ], !dbg [[DBG109]]
// PPC64-NEXT:    store i32 [[TMP178]], i32* [[ATOMIC_TEMP179]], align 4, !dbg [[DBG109]]
// PPC64-NEXT:    store i32 [[TMP178]], i32* [[ATOMIC_TEMP180]], align 4, !dbg [[DBG109]]
// PPC64-NEXT:    [[BF_LOAD181:%.*]] = load i32, i32* [[ATOMIC_TEMP180]], align 4, !dbg [[DBG109]]
// PPC64-NEXT:    [[BF_SHL182:%.*]] = shl i32 [[BF_LOAD181]], 31, !dbg [[DBG109]]
// PPC64-NEXT:    [[BF_ASHR183:%.*]] = ashr i32 [[BF_SHL182]], 31, !dbg [[DBG109]]
// PPC64-NEXT:    [[CONV184:%.*]] = sitofp i32 [[BF_ASHR183]] to ppc_fp128, !dbg [[DBG110:![0-9]+]]
// PPC64-NEXT:    [[SUB185:%.*]] = fsub ppc_fp128 [[CONV184]], [[TMP177]], !dbg [[DBG111:![0-9]+]]
// PPC64-NEXT:    [[CONV186:%.*]] = fptosi ppc_fp128 [[SUB185]] to i32, !dbg [[DBG110]]
// PPC64-NEXT:    [[BF_LOAD187:%.*]] = load i32, i32* [[ATOMIC_TEMP179]], align 4, !dbg [[DBG109]]
// PPC64-NEXT:    [[BF_VALUE188:%.*]] = and i32 [[CONV186]], 1, !dbg [[DBG109]]
// PPC64-NEXT:    [[BF_CLEAR189:%.*]] = and i32 [[BF_LOAD187]], -2, !dbg [[DBG109]]
// PPC64-NEXT:    [[BF_SET190:%.*]] = or i32 [[BF_CLEAR189]], [[BF_VALUE188]], !dbg [[DBG109]]
// PPC64-NEXT:    store i32 [[BF_SET190]], i32* [[ATOMIC_TEMP179]], align 4, !dbg [[DBG109]]
// PPC64-NEXT:    [[TMP179:%.*]] = load i32, i32* [[ATOMIC_TEMP179]], align 4, !dbg [[DBG109]]
// PPC64-NEXT:    [[TMP180:%.*]] = cmpxchg i32* getelementptr inbounds ([[STRUCT_BITFIELDS2]], %struct.BitFields2* @bfx2, i32 0, i32 0), i32 [[TMP178]], i32 [[TMP179]] monotonic monotonic, align 4, !dbg [[DBG109]]
// PPC64-NEXT:    [[TMP181]] = extractvalue { i32, i1 } [[TMP180]], 0, !dbg [[DBG109]]
// PPC64-NEXT:    [[TMP182:%.*]] = extractvalue { i32, i1 } [[TMP180]], 1, !dbg [[DBG109]]
// PPC64-NEXT:    br i1 [[TMP182]], label [[ATOMIC_EXIT191:%.*]], label [[ATOMIC_CONT178]], !dbg [[DBG109]]
// PPC64:       atomic_exit191:
// PPC64-NEXT:    [[TMP183:%.*]] = load ppc_fp128, ppc_fp128* @ldv, align 16, !dbg [[DBG112:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD192:%.*]] = load atomic i8, i8* bitcast (%struct.BitFields2_packed* @bfx2_packed to i8*) monotonic, align 1, !dbg [[DBG113:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT193:%.*]], !dbg [[DBG113]]
// PPC64:       atomic_cont193:
// PPC64-NEXT:    [[TMP184:%.*]] = phi i8 [ [[ATOMIC_LOAD192]], [[ATOMIC_EXIT191]] ], [ [[TMP190:%.*]], [[ATOMIC_CONT193]] ], !dbg [[DBG113]]
// PPC64-NEXT:    [[TMP185:%.*]] = bitcast i32* [[ATOMIC_TEMP194]] to i8*, !dbg [[DBG113]]
// PPC64-NEXT:    store i8 [[TMP184]], i8* [[TMP185]], align 1, !dbg [[DBG113]]
// PPC64-NEXT:    [[TMP186:%.*]] = bitcast i32* [[ATOMIC_TEMP195]] to i8*, !dbg [[DBG113]]
// PPC64-NEXT:    store i8 [[TMP184]], i8* [[TMP186]], align 1, !dbg [[DBG113]]
// PPC64-NEXT:    [[BF_LOAD196:%.*]] = load i8, i8* [[TMP186]], align 1, !dbg [[DBG113]]
// PPC64-NEXT:    [[BF_SHL197:%.*]] = shl i8 [[BF_LOAD196]], 7, !dbg [[DBG113]]
// PPC64-NEXT:    [[BF_ASHR198:%.*]] = ashr i8 [[BF_SHL197]], 7, !dbg [[DBG113]]
// PPC64-NEXT:    [[BF_CAST:%.*]] = sext i8 [[BF_ASHR198]] to i32, !dbg [[DBG113]]
// PPC64-NEXT:    [[CONV199:%.*]] = sitofp i32 [[BF_CAST]] to ppc_fp128, !dbg [[DBG114:![0-9]+]]
// PPC64-NEXT:    [[DIV200:%.*]] = fdiv ppc_fp128 [[TMP183]], [[CONV199]], !dbg [[DBG115:![0-9]+]]
// PPC64-NEXT:    [[CONV201:%.*]] = fptosi ppc_fp128 [[DIV200]] to i32, !dbg [[DBG112]]
// PPC64-NEXT:    [[TMP187:%.*]] = trunc i32 [[CONV201]] to i8, !dbg [[DBG113]]
// PPC64-NEXT:    [[BF_LOAD202:%.*]] = load i8, i8* [[TMP185]], align 1, !dbg [[DBG113]]
// PPC64-NEXT:    [[BF_VALUE203:%.*]] = and i8 [[TMP187]], 1, !dbg [[DBG113]]
// PPC64-NEXT:    [[BF_CLEAR204:%.*]] = and i8 [[BF_LOAD202]], -2, !dbg [[DBG113]]
// PPC64-NEXT:    [[BF_SET205:%.*]] = or i8 [[BF_CLEAR204]], [[BF_VALUE203]], !dbg [[DBG113]]
// PPC64-NEXT:    store i8 [[BF_SET205]], i8* [[TMP185]], align 1, !dbg [[DBG113]]
// PPC64-NEXT:    [[TMP188:%.*]] = load i8, i8* [[TMP185]], align 1, !dbg [[DBG113]]
// PPC64-NEXT:    [[TMP189:%.*]] = cmpxchg i8* bitcast (%struct.BitFields2_packed* @bfx2_packed to i8*), i8 [[TMP184]], i8 [[TMP188]] monotonic monotonic, align 1, !dbg [[DBG113]]
// PPC64-NEXT:    [[TMP190]] = extractvalue { i8, i1 } [[TMP189]], 0, !dbg [[DBG113]]
// PPC64-NEXT:    [[TMP191:%.*]] = extractvalue { i8, i1 } [[TMP189]], 1, !dbg [[DBG113]]
// PPC64-NEXT:    br i1 [[TMP191]], label [[ATOMIC_EXIT206:%.*]], label [[ATOMIC_CONT193]], !dbg [[DBG113]]
// PPC64:       atomic_exit206:
// PPC64-NEXT:    [[TMP192:%.*]] = load ppc_fp128, ppc_fp128* @ldv, align 16, !dbg [[DBG116:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD207:%.*]] = load atomic i32, i32* getelementptr inbounds ([[STRUCT_BITFIELDS3:%.*]], %struct.BitFields3* @bfx3, i32 0, i32 0) monotonic, align 4, !dbg [[DBG117:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT208:%.*]], !dbg [[DBG117]]
// PPC64:       atomic_cont208:
// PPC64-NEXT:    [[TMP193:%.*]] = phi i32 [ [[ATOMIC_LOAD207]], [[ATOMIC_EXIT206]] ], [ [[TMP196:%.*]], [[ATOMIC_CONT208]] ], !dbg [[DBG117]]
// PPC64-NEXT:    store i32 [[TMP193]], i32* [[ATOMIC_TEMP209]], align 4, !dbg [[DBG117]]
// PPC64-NEXT:    store i32 [[TMP193]], i32* [[ATOMIC_TEMP210]], align 4, !dbg [[DBG117]]
// PPC64-NEXT:    [[BF_LOAD211:%.*]] = load i32, i32* [[ATOMIC_TEMP210]], align 4, !dbg [[DBG117]]
// PPC64-NEXT:    [[BF_SHL212:%.*]] = shl i32 [[BF_LOAD211]], 11, !dbg [[DBG117]]
// PPC64-NEXT:    [[BF_ASHR213:%.*]] = ashr i32 [[BF_SHL212]], 18, !dbg [[DBG117]]
// PPC64-NEXT:    [[CONV214:%.*]] = sitofp i32 [[BF_ASHR213]] to ppc_fp128, !dbg [[DBG118:![0-9]+]]
// PPC64-NEXT:    [[DIV215:%.*]] = fdiv ppc_fp128 [[CONV214]], [[TMP192]], !dbg [[DBG119:![0-9]+]]
// PPC64-NEXT:    [[CONV216:%.*]] = fptosi ppc_fp128 [[DIV215]] to i32, !dbg [[DBG118]]
// PPC64-NEXT:    [[BF_LOAD217:%.*]] = load i32, i32* [[ATOMIC_TEMP209]], align 4, !dbg [[DBG117]]
// PPC64-NEXT:    [[BF_VALUE218:%.*]] = and i32 [[CONV216]], 16383, !dbg [[DBG117]]
// PPC64-NEXT:    [[BF_SHL219:%.*]] = shl i32 [[BF_VALUE218]], 7, !dbg [[DBG117]]
// PPC64-NEXT:    [[BF_CLEAR220:%.*]] = and i32 [[BF_LOAD217]], -2097025, !dbg [[DBG117]]
// PPC64-NEXT:    [[BF_SET221:%.*]] = or i32 [[BF_CLEAR220]], [[BF_SHL219]], !dbg [[DBG117]]
// PPC64-NEXT:    store i32 [[BF_SET221]], i32* [[ATOMIC_TEMP209]], align 4, !dbg [[DBG117]]
// PPC64-NEXT:    [[TMP194:%.*]] = load i32, i32* [[ATOMIC_TEMP209]], align 4, !dbg [[DBG117]]
// PPC64-NEXT:    [[TMP195:%.*]] = cmpxchg i32* getelementptr inbounds ([[STRUCT_BITFIELDS3]], %struct.BitFields3* @bfx3, i32 0, i32 0), i32 [[TMP193]], i32 [[TMP194]] monotonic monotonic, align 4, !dbg [[DBG117]]
// PPC64-NEXT:    [[TMP196]] = extractvalue { i32, i1 } [[TMP195]], 0, !dbg [[DBG117]]
// PPC64-NEXT:    [[TMP197:%.*]] = extractvalue { i32, i1 } [[TMP195]], 1, !dbg [[DBG117]]
// PPC64-NEXT:    br i1 [[TMP197]], label [[ATOMIC_EXIT222:%.*]], label [[ATOMIC_CONT208]], !dbg [[DBG117]]
// PPC64:       atomic_exit222:
// PPC64-NEXT:    [[TMP198:%.*]] = load ppc_fp128, ppc_fp128* @ldv, align 16, !dbg [[DBG120:![0-9]+]]
// PPC64-NEXT:    [[TMP199:%.*]] = bitcast i32* [[ATOMIC_TEMP223]] to i24*, !dbg [[DBG121:![0-9]+]]
// PPC64-NEXT:    [[TMP200:%.*]] = bitcast i24* [[TMP199]] to i8*, !dbg [[DBG121]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 3, i8* noundef bitcast (%struct.BitFields3_packed* @bfx3_packed to i8*), i8* noundef [[TMP200]], i32 noundef signext 0), !dbg [[DBG121]]
// PPC64-NEXT:    br label [[ATOMIC_CONT224:%.*]], !dbg [[DBG121]]
// PPC64:       atomic_cont224:
// PPC64-NEXT:    [[TMP201:%.*]] = bitcast i32* [[ATOMIC_TEMP225]] to i24*, !dbg [[DBG121]]
// PPC64-NEXT:    [[TMP202:%.*]] = load i24, i24* [[TMP199]], align 1, !dbg [[DBG121]]
// PPC64-NEXT:    store i24 [[TMP202]], i24* [[TMP201]], align 1, !dbg [[DBG121]]
// PPC64-NEXT:    [[TMP203:%.*]] = load i24, i24* [[TMP199]], align 1, !dbg [[DBG121]]
// PPC64-NEXT:    [[TMP204:%.*]] = bitcast i32* [[ATOMIC_TEMP226]] to i24*, !dbg [[DBG121]]
// PPC64-NEXT:    store i24 [[TMP203]], i24* [[TMP204]], align 1, !dbg [[DBG121]]
// PPC64-NEXT:    [[BF_LOAD227:%.*]] = load i24, i24* [[TMP204]], align 1, !dbg [[DBG121]]
// PPC64-NEXT:    [[BF_SHL228:%.*]] = shl i24 [[BF_LOAD227]], 3, !dbg [[DBG121]]
// PPC64-NEXT:    [[BF_ASHR229:%.*]] = ashr i24 [[BF_SHL228]], 10, !dbg [[DBG121]]
// PPC64-NEXT:    [[BF_CAST230:%.*]] = sext i24 [[BF_ASHR229]] to i32, !dbg [[DBG121]]
// PPC64-NEXT:    [[CONV231:%.*]] = sitofp i32 [[BF_CAST230]] to ppc_fp128, !dbg [[DBG122:![0-9]+]]
// PPC64-NEXT:    [[ADD232:%.*]] = fadd ppc_fp128 [[CONV231]], [[TMP198]], !dbg [[DBG123:![0-9]+]]
// PPC64-NEXT:    [[CONV233:%.*]] = fptosi ppc_fp128 [[ADD232]] to i32, !dbg [[DBG122]]
// PPC64-NEXT:    [[TMP205:%.*]] = trunc i32 [[CONV233]] to i24, !dbg [[DBG121]]
// PPC64-NEXT:    [[BF_LOAD234:%.*]] = load i24, i24* [[TMP201]], align 1, !dbg [[DBG121]]
// PPC64-NEXT:    [[BF_VALUE235:%.*]] = and i24 [[TMP205]], 16383, !dbg [[DBG121]]
// PPC64-NEXT:    [[BF_SHL236:%.*]] = shl i24 [[BF_VALUE235]], 7, !dbg [[DBG121]]
// PPC64-NEXT:    [[BF_CLEAR237:%.*]] = and i24 [[BF_LOAD234]], -2097025, !dbg [[DBG121]]
// PPC64-NEXT:    [[BF_SET238:%.*]] = or i24 [[BF_CLEAR237]], [[BF_SHL236]], !dbg [[DBG121]]
// PPC64-NEXT:    store i24 [[BF_SET238]], i24* [[TMP201]], align 1, !dbg [[DBG121]]
// PPC64-NEXT:    [[TMP206:%.*]] = bitcast i24* [[TMP199]] to i8*, !dbg [[DBG121]]
// PPC64-NEXT:    [[TMP207:%.*]] = bitcast i24* [[TMP201]] to i8*, !dbg [[DBG121]]
// PPC64-NEXT:    [[CALL239:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 3, i8* noundef bitcast (%struct.BitFields3_packed* @bfx3_packed to i8*), i8* noundef [[TMP206]], i8* noundef [[TMP207]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG121]]
// PPC64-NEXT:    br i1 [[CALL239]], label [[ATOMIC_EXIT240:%.*]], label [[ATOMIC_CONT224]], !dbg [[DBG121]]
// PPC64:       atomic_exit240:
// PPC64-NEXT:    [[TMP208:%.*]] = load ppc_fp128, ppc_fp128* @ldv, align 16, !dbg [[DBG124:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD241:%.*]] = load atomic i64, i64* bitcast (%struct.BitFields4* @bfx4 to i64*) monotonic, align 8, !dbg [[DBG125:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT242:%.*]], !dbg [[DBG125]]
// PPC64:       atomic_cont242:
// PPC64-NEXT:    [[TMP209:%.*]] = phi i64 [ [[ATOMIC_LOAD241]], [[ATOMIC_EXIT240]] ], [ [[TMP213:%.*]], [[ATOMIC_CONT242]] ], !dbg [[DBG125]]
// PPC64-NEXT:    store i64 [[TMP209]], i64* [[ATOMIC_TEMP243]], align 8, !dbg [[DBG125]]
// PPC64-NEXT:    store i64 [[TMP209]], i64* [[ATOMIC_TEMP244]], align 8, !dbg [[DBG125]]
// PPC64-NEXT:    [[BF_LOAD245:%.*]] = load i64, i64* [[ATOMIC_TEMP244]], align 8, !dbg [[DBG125]]
// PPC64-NEXT:    [[BF_SHL246:%.*]] = shl i64 [[BF_LOAD245]], 48, !dbg [[DBG125]]
// PPC64-NEXT:    [[BF_ASHR247:%.*]] = ashr i64 [[BF_SHL246]], 63, !dbg [[DBG125]]
// PPC64-NEXT:    [[BF_CAST248:%.*]] = trunc i64 [[BF_ASHR247]] to i32, !dbg [[DBG125]]
// PPC64-NEXT:    [[CONV249:%.*]] = sitofp i32 [[BF_CAST248]] to ppc_fp128, !dbg [[DBG126:![0-9]+]]
// PPC64-NEXT:    [[MUL250:%.*]] = fmul ppc_fp128 [[CONV249]], [[TMP208]], !dbg [[DBG127:![0-9]+]]
// PPC64-NEXT:    [[CONV251:%.*]] = fptosi ppc_fp128 [[MUL250]] to i32, !dbg [[DBG126]]
// PPC64-NEXT:    [[TMP210:%.*]] = zext i32 [[CONV251]] to i64, !dbg [[DBG125]]
// PPC64-NEXT:    [[BF_LOAD252:%.*]] = load i64, i64* [[ATOMIC_TEMP243]], align 8, !dbg [[DBG125]]
// PPC64-NEXT:    [[BF_VALUE253:%.*]] = and i64 [[TMP210]], 1, !dbg [[DBG125]]
// PPC64-NEXT:    [[BF_SHL254:%.*]] = shl i64 [[BF_VALUE253]], 15, !dbg [[DBG125]]
// PPC64-NEXT:    [[BF_CLEAR255:%.*]] = and i64 [[BF_LOAD252]], -32769, !dbg [[DBG125]]
// PPC64-NEXT:    [[BF_SET256:%.*]] = or i64 [[BF_CLEAR255]], [[BF_SHL254]], !dbg [[DBG125]]
// PPC64-NEXT:    store i64 [[BF_SET256]], i64* [[ATOMIC_TEMP243]], align 8, !dbg [[DBG125]]
// PPC64-NEXT:    [[TMP211:%.*]] = load i64, i64* [[ATOMIC_TEMP243]], align 8, !dbg [[DBG125]]
// PPC64-NEXT:    [[TMP212:%.*]] = cmpxchg i64* bitcast (%struct.BitFields4* @bfx4 to i64*), i64 [[TMP209]], i64 [[TMP211]] monotonic monotonic, align 8, !dbg [[DBG125]]
// PPC64-NEXT:    [[TMP213]] = extractvalue { i64, i1 } [[TMP212]], 0, !dbg [[DBG125]]
// PPC64-NEXT:    [[TMP214:%.*]] = extractvalue { i64, i1 } [[TMP212]], 1, !dbg [[DBG125]]
// PPC64-NEXT:    br i1 [[TMP214]], label [[ATOMIC_EXIT257:%.*]], label [[ATOMIC_CONT242]], !dbg [[DBG125]]
// PPC64:       atomic_exit257:
// PPC64-NEXT:    [[TMP215:%.*]] = load ppc_fp128, ppc_fp128* @ldv, align 16, !dbg [[DBG128:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD258:%.*]] = load atomic i8, i8* getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED:%.*]], %struct.BitFields4_packed* @bfx4_packed, i32 0, i32 0, i32 0) monotonic, align 1, !dbg [[DBG129:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT259:%.*]], !dbg [[DBG129]]
// PPC64:       atomic_cont259:
// PPC64-NEXT:    [[TMP216:%.*]] = phi i8 [ [[ATOMIC_LOAD258]], [[ATOMIC_EXIT257]] ], [ [[TMP222:%.*]], [[ATOMIC_CONT259]] ], !dbg [[DBG129]]
// PPC64-NEXT:    [[TMP217:%.*]] = bitcast i32* [[ATOMIC_TEMP260]] to i8*, !dbg [[DBG129]]
// PPC64-NEXT:    store i8 [[TMP216]], i8* [[TMP217]], align 1, !dbg [[DBG129]]
// PPC64-NEXT:    [[TMP218:%.*]] = bitcast i32* [[ATOMIC_TEMP261]] to i8*, !dbg [[DBG129]]
// PPC64-NEXT:    store i8 [[TMP216]], i8* [[TMP218]], align 1, !dbg [[DBG129]]
// PPC64-NEXT:    [[BF_LOAD262:%.*]] = load i8, i8* [[TMP218]], align 1, !dbg [[DBG129]]
// PPC64-NEXT:    [[BF_ASHR263:%.*]] = ashr i8 [[BF_LOAD262]], 7, !dbg [[DBG129]]
// PPC64-NEXT:    [[BF_CAST264:%.*]] = sext i8 [[BF_ASHR263]] to i32, !dbg [[DBG129]]
// PPC64-NEXT:    [[CONV265:%.*]] = sitofp i32 [[BF_CAST264]] to ppc_fp128, !dbg [[DBG130:![0-9]+]]
// PPC64-NEXT:    [[SUB266:%.*]] = fsub ppc_fp128 [[CONV265]], [[TMP215]], !dbg [[DBG131:![0-9]+]]
// PPC64-NEXT:    [[CONV267:%.*]] = fptosi ppc_fp128 [[SUB266]] to i32, !dbg [[DBG130]]
// PPC64-NEXT:    [[TMP219:%.*]] = trunc i32 [[CONV267]] to i8, !dbg [[DBG129]]
// PPC64-NEXT:    [[BF_LOAD268:%.*]] = load i8, i8* [[TMP217]], align 1, !dbg [[DBG129]]
// PPC64-NEXT:    [[BF_VALUE269:%.*]] = and i8 [[TMP219]], 1, !dbg [[DBG129]]
// PPC64-NEXT:    [[BF_SHL270:%.*]] = shl i8 [[BF_VALUE269]], 7, !dbg [[DBG129]]
// PPC64-NEXT:    [[BF_CLEAR271:%.*]] = and i8 [[BF_LOAD268]], 127, !dbg [[DBG129]]
// PPC64-NEXT:    [[BF_SET272:%.*]] = or i8 [[BF_CLEAR271]], [[BF_SHL270]], !dbg [[DBG129]]
// PPC64-NEXT:    store i8 [[BF_SET272]], i8* [[TMP217]], align 1, !dbg [[DBG129]]
// PPC64-NEXT:    [[TMP220:%.*]] = load i8, i8* [[TMP217]], align 1, !dbg [[DBG129]]
// PPC64-NEXT:    [[TMP221:%.*]] = cmpxchg i8* getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED]], %struct.BitFields4_packed* @bfx4_packed, i32 0, i32 0, i32 0), i8 [[TMP216]], i8 [[TMP220]] monotonic monotonic, align 1, !dbg [[DBG129]]
// PPC64-NEXT:    [[TMP222]] = extractvalue { i8, i1 } [[TMP221]], 0, !dbg [[DBG129]]
// PPC64-NEXT:    [[TMP223:%.*]] = extractvalue { i8, i1 } [[TMP221]], 1, !dbg [[DBG129]]
// PPC64-NEXT:    br i1 [[TMP223]], label [[ATOMIC_EXIT273:%.*]], label [[ATOMIC_CONT259]], !dbg [[DBG129]]
// PPC64:       atomic_exit273:
// PPC64-NEXT:    [[TMP224:%.*]] = load ppc_fp128, ppc_fp128* @ldv, align 16, !dbg [[DBG132:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD274:%.*]] = load atomic i64, i64* bitcast (%struct.BitFields4* @bfx4 to i64*) monotonic, align 8, !dbg [[DBG133:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT275:%.*]], !dbg [[DBG133]]
// PPC64:       atomic_cont275:
// PPC64-NEXT:    [[TMP225:%.*]] = phi i64 [ [[ATOMIC_LOAD274]], [[ATOMIC_EXIT273]] ], [ [[TMP228:%.*]], [[ATOMIC_CONT275]] ], !dbg [[DBG133]]
// PPC64-NEXT:    store i64 [[TMP225]], i64* [[ATOMIC_TEMP276]], align 8, !dbg [[DBG133]]
// PPC64-NEXT:    store i64 [[TMP225]], i64* [[ATOMIC_TEMP277]], align 8, !dbg [[DBG133]]
// PPC64-NEXT:    [[BF_LOAD278:%.*]] = load i64, i64* [[ATOMIC_TEMP277]], align 8, !dbg [[DBG133]]
// PPC64-NEXT:    [[BF_SHL279:%.*]] = shl i64 [[BF_LOAD278]], 49, !dbg [[DBG133]]
// PPC64-NEXT:    [[BF_ASHR280:%.*]] = ashr i64 [[BF_SHL279]], 57, !dbg [[DBG133]]
// PPC64-NEXT:    [[CONV281:%.*]] = sitofp i64 [[BF_ASHR280]] to ppc_fp128, !dbg [[DBG134:![0-9]+]]
// PPC64-NEXT:    [[DIV282:%.*]] = fdiv ppc_fp128 [[CONV281]], [[TMP224]], !dbg [[DBG135:![0-9]+]]
// PPC64-NEXT:    [[CONV283:%.*]] = fptosi ppc_fp128 [[DIV282]] to i64, !dbg [[DBG134]]
// PPC64-NEXT:    [[BF_LOAD284:%.*]] = load i64, i64* [[ATOMIC_TEMP276]], align 8, !dbg [[DBG133]]
// PPC64-NEXT:    [[BF_VALUE285:%.*]] = and i64 [[CONV283]], 127, !dbg [[DBG133]]
// PPC64-NEXT:    [[BF_SHL286:%.*]] = shl i64 [[BF_VALUE285]], 8, !dbg [[DBG133]]
// PPC64-NEXT:    [[BF_CLEAR287:%.*]] = and i64 [[BF_LOAD284]], -32513, !dbg [[DBG133]]
// PPC64-NEXT:    [[BF_SET288:%.*]] = or i64 [[BF_CLEAR287]], [[BF_SHL286]], !dbg [[DBG133]]
// PPC64-NEXT:    store i64 [[BF_SET288]], i64* [[ATOMIC_TEMP276]], align 8, !dbg [[DBG133]]
// PPC64-NEXT:    [[TMP226:%.*]] = load i64, i64* [[ATOMIC_TEMP276]], align 8, !dbg [[DBG133]]
// PPC64-NEXT:    [[TMP227:%.*]] = cmpxchg i64* bitcast (%struct.BitFields4* @bfx4 to i64*), i64 [[TMP225]], i64 [[TMP226]] monotonic monotonic, align 8, !dbg [[DBG133]]
// PPC64-NEXT:    [[TMP228]] = extractvalue { i64, i1 } [[TMP227]], 0, !dbg [[DBG133]]
// PPC64-NEXT:    [[TMP229:%.*]] = extractvalue { i64, i1 } [[TMP227]], 1, !dbg [[DBG133]]
// PPC64-NEXT:    br i1 [[TMP229]], label [[ATOMIC_EXIT289:%.*]], label [[ATOMIC_CONT275]], !dbg [[DBG133]]
// PPC64:       atomic_exit289:
// PPC64-NEXT:    [[TMP230:%.*]] = load ppc_fp128, ppc_fp128* @ldv, align 16, !dbg [[DBG136:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD290:%.*]] = load atomic i8, i8* getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED]], %struct.BitFields4_packed* @bfx4_packed, i32 0, i32 0, i32 0) monotonic, align 1, !dbg [[DBG137:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT291:%.*]], !dbg [[DBG137]]
// PPC64:       atomic_cont291:
// PPC64-NEXT:    [[TMP231:%.*]] = phi i8 [ [[ATOMIC_LOAD290]], [[ATOMIC_EXIT289]] ], [ [[TMP237:%.*]], [[ATOMIC_CONT291]] ], !dbg [[DBG137]]
// PPC64-NEXT:    [[TMP232:%.*]] = bitcast i64* [[ATOMIC_TEMP292]] to i8*, !dbg [[DBG137]]
// PPC64-NEXT:    store i8 [[TMP231]], i8* [[TMP232]], align 1, !dbg [[DBG137]]
// PPC64-NEXT:    [[TMP233:%.*]] = bitcast i64* [[ATOMIC_TEMP293]] to i8*, !dbg [[DBG137]]
// PPC64-NEXT:    store i8 [[TMP231]], i8* [[TMP233]], align 1, !dbg [[DBG137]]
// PPC64-NEXT:    [[BF_LOAD294:%.*]] = load i8, i8* [[TMP233]], align 1, !dbg [[DBG137]]
// PPC64-NEXT:    [[BF_SHL295:%.*]] = shl i8 [[BF_LOAD294]], 1, !dbg [[DBG137]]
// PPC64-NEXT:    [[BF_ASHR296:%.*]] = ashr i8 [[BF_SHL295]], 1, !dbg [[DBG137]]
// PPC64-NEXT:    [[BF_CAST297:%.*]] = sext i8 [[BF_ASHR296]] to i64, !dbg [[DBG137]]
// PPC64-NEXT:    [[CONV298:%.*]] = sitofp i64 [[BF_CAST297]] to ppc_fp128, !dbg [[DBG138:![0-9]+]]
// PPC64-NEXT:    [[ADD299:%.*]] = fadd ppc_fp128 [[CONV298]], [[TMP230]], !dbg [[DBG139:![0-9]+]]
// PPC64-NEXT:    [[CONV300:%.*]] = fptosi ppc_fp128 [[ADD299]] to i64, !dbg [[DBG138]]
// PPC64-NEXT:    [[TMP234:%.*]] = trunc i64 [[CONV300]] to i8, !dbg [[DBG137]]
// PPC64-NEXT:    [[BF_LOAD301:%.*]] = load i8, i8* [[TMP232]], align 1, !dbg [[DBG137]]
// PPC64-NEXT:    [[BF_VALUE302:%.*]] = and i8 [[TMP234]], 127, !dbg [[DBG137]]
// PPC64-NEXT:    [[BF_CLEAR303:%.*]] = and i8 [[BF_LOAD301]], -128, !dbg [[DBG137]]
// PPC64-NEXT:    [[BF_SET304:%.*]] = or i8 [[BF_CLEAR303]], [[BF_VALUE302]], !dbg [[DBG137]]
// PPC64-NEXT:    store i8 [[BF_SET304]], i8* [[TMP232]], align 1, !dbg [[DBG137]]
// PPC64-NEXT:    [[TMP235:%.*]] = load i8, i8* [[TMP232]], align 1, !dbg [[DBG137]]
// PPC64-NEXT:    [[TMP236:%.*]] = cmpxchg i8* getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED]], %struct.BitFields4_packed* @bfx4_packed, i32 0, i32 0, i32 0), i8 [[TMP231]], i8 [[TMP235]] monotonic monotonic, align 1, !dbg [[DBG137]]
// PPC64-NEXT:    [[TMP237]] = extractvalue { i8, i1 } [[TMP236]], 0, !dbg [[DBG137]]
// PPC64-NEXT:    [[TMP238:%.*]] = extractvalue { i8, i1 } [[TMP236]], 1, !dbg [[DBG137]]
// PPC64-NEXT:    br i1 [[TMP238]], label [[ATOMIC_EXIT305:%.*]], label [[ATOMIC_CONT291]], !dbg [[DBG137]]
// PPC64:       atomic_exit305:
// PPC64-NEXT:    [[TMP239:%.*]] = load i64, i64* @ulv, align 8, !dbg [[DBG140:![0-9]+]]
// PPC64-NEXT:    [[CONV306:%.*]] = uitofp i64 [[TMP239]] to float, !dbg [[DBG140]]
// PPC64-NEXT:    [[ATOMIC_LOAD307:%.*]] = load atomic i64, i64* bitcast (<2 x float>* @float2x to i64*) monotonic, align 8, !dbg [[DBG141:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT308:%.*]], !dbg [[DBG141]]
// PPC64:       atomic_cont308:
// PPC64-NEXT:    [[TMP240:%.*]] = phi i64 [ [[ATOMIC_LOAD307]], [[ATOMIC_EXIT305]] ], [ [[TMP249:%.*]], [[ATOMIC_CONT308]] ], !dbg [[DBG141]]
// PPC64-NEXT:    [[TMP241:%.*]] = bitcast <2 x float>* [[ATOMIC_TEMP309]] to i64*, !dbg [[DBG141]]
// PPC64-NEXT:    store i64 [[TMP240]], i64* [[TMP241]], align 8, !dbg [[DBG141]]
// PPC64-NEXT:    [[TMP242:%.*]] = bitcast i64 [[TMP240]] to <2 x float>, !dbg [[DBG141]]
// PPC64-NEXT:    store <2 x float> [[TMP242]], <2 x float>* [[ATOMIC_TEMP310]], align 8, !dbg [[DBG141]]
// PPC64-NEXT:    [[TMP243:%.*]] = load <2 x float>, <2 x float>* [[ATOMIC_TEMP310]], align 8, !dbg [[DBG141]]
// PPC64-NEXT:    [[TMP244:%.*]] = extractelement <2 x float> [[TMP243]], i64 0, !dbg [[DBG141]]
// PPC64-NEXT:    [[SUB311:%.*]] = fsub float [[CONV306]], [[TMP244]], !dbg [[DBG142:![0-9]+]]
// PPC64-NEXT:    [[TMP245:%.*]] = load <2 x float>, <2 x float>* [[ATOMIC_TEMP309]], align 8, !dbg [[DBG141]]
// PPC64-NEXT:    [[TMP246:%.*]] = insertelement <2 x float> [[TMP245]], float [[SUB311]], i64 0, !dbg [[DBG141]]
// PPC64-NEXT:    store <2 x float> [[TMP246]], <2 x float>* [[ATOMIC_TEMP309]], align 8, !dbg [[DBG141]]
// PPC64-NEXT:    [[TMP247:%.*]] = load i64, i64* [[TMP241]], align 8, !dbg [[DBG141]]
// PPC64-NEXT:    [[TMP248:%.*]] = cmpxchg i64* bitcast (<2 x float>* @float2x to i64*), i64 [[TMP240]], i64 [[TMP247]] monotonic monotonic, align 8, !dbg [[DBG141]]
// PPC64-NEXT:    [[TMP249]] = extractvalue { i64, i1 } [[TMP248]], 0, !dbg [[DBG141]]
// PPC64-NEXT:    [[TMP250:%.*]] = extractvalue { i64, i1 } [[TMP248]], 1, !dbg [[DBG141]]
// PPC64-NEXT:    br i1 [[TMP250]], label [[ATOMIC_EXIT312:%.*]], label [[ATOMIC_CONT308]], !dbg [[DBG141]]
// PPC64:       atomic_exit312:
// PPC64-NEXT:    ret i32 0, !dbg [[DBG143:![0-9]+]]
//
//
// AARCH64-LABEL: define {{[^@]+}}@main
// AARCH64-SAME: () #[[ATTR0:[0-9]+]] !dbg [[DBG5:![0-9]+]] {
// AARCH64-NEXT:  entry:
// AARCH64-NEXT:    [[RETVAL:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca i16, align 2
// AARCH64-NEXT:    [[ATOMIC_TEMP5:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP9:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP13:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP17:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP21:%.*]] = alloca double, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP25:%.*]] = alloca fp128, align 16
// AARCH64-NEXT:    [[ATOMIC_TEMP28:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP30:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP32:%.*]] = alloca { float, float }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP34:%.*]] = alloca { float, float }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP37:%.*]] = alloca { double, double }, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP39:%.*]] = alloca { double, double }, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP46:%.*]] = alloca i8, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP54:%.*]] = alloca i8, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP62:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP69:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP71:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP73:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP85:%.*]] = alloca float, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP91:%.*]] = alloca double, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP95:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP97:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP107:%.*]] = alloca i16, align 2
// AARCH64-NEXT:    [[ATOMIC_TEMP115:%.*]] = alloca i8, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP127:%.*]] = alloca i8, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP141:%.*]] = alloca <4 x i32>, align 16
// AARCH64-NEXT:    [[ATOMIC_TEMP142:%.*]] = alloca <4 x i32>, align 16
// AARCH64-NEXT:    [[ATOMIC_TEMP146:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP147:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP153:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP155:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP156:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP171:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP172:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP186:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP187:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP201:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP202:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP215:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP217:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP218:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP235:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP236:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP252:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP253:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP268:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP269:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP284:%.*]] = alloca i64, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP285:%.*]] = alloca i64, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP301:%.*]] = alloca <2 x float>, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP302:%.*]] = alloca <2 x float>, align 8
// AARCH64-NEXT:    store i32 0, i32* [[RETVAL]], align 4
// AARCH64-NEXT:    [[TMP0:%.*]] = atomicrmw fadd double* @dv, double 1.000000e+00 monotonic, align 8, !dbg [[DBG9:![0-9]+]]
// AARCH64-NEXT:    [[TMP1:%.*]] = atomicrmw add i8* @bx, i8 1 monotonic, align 1, !dbg [[DBG10:![0-9]+]]
// AARCH64-NEXT:    [[TMP2:%.*]] = atomicrmw add i8* @cx, i8 1 monotonic, align 1, !dbg [[DBG11:![0-9]+]]
// AARCH64-NEXT:    [[TMP3:%.*]] = atomicrmw sub i8* @ucx, i8 1 monotonic, align 1, !dbg [[DBG12:![0-9]+]]
// AARCH64-NEXT:    [[TMP4:%.*]] = atomicrmw sub i16* @sx, i16 1 monotonic, align 2, !dbg [[DBG13:![0-9]+]]
// AARCH64-NEXT:    [[TMP5:%.*]] = load i16, i16* @usv, align 2, !dbg [[DBG14:![0-9]+]]
// AARCH64-NEXT:    [[CONV:%.*]] = zext i16 [[TMP5]] to i32, !dbg [[DBG14]]
// AARCH64-NEXT:    [[ATOMIC_LOAD:%.*]] = load atomic i16, i16* @usx monotonic, align 2, !dbg [[DBG15:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT:%.*]], !dbg [[DBG15]]
// AARCH64:       atomic_cont:
// AARCH64-NEXT:    [[TMP6:%.*]] = phi i16 [ [[ATOMIC_LOAD]], [[ENTRY:%.*]] ], [ [[TMP9:%.*]], [[ATOMIC_CONT]] ], !dbg [[DBG15]]
// AARCH64-NEXT:    [[CONV1:%.*]] = zext i16 [[TMP6]] to i32, !dbg [[DBG15]]
// AARCH64-NEXT:    [[ADD:%.*]] = add nsw i32 [[CONV1]], [[CONV]], !dbg [[DBG16:![0-9]+]]
// AARCH64-NEXT:    [[CONV2:%.*]] = trunc i32 [[ADD]] to i16, !dbg [[DBG15]]
// AARCH64-NEXT:    store i16 [[CONV2]], i16* [[ATOMIC_TEMP]], align 2, !dbg [[DBG15]]
// AARCH64-NEXT:    [[TMP7:%.*]] = load i16, i16* [[ATOMIC_TEMP]], align 2, !dbg [[DBG15]]
// AARCH64-NEXT:    [[TMP8:%.*]] = cmpxchg i16* @usx, i16 [[TMP6]], i16 [[TMP7]] monotonic monotonic, align 2, !dbg [[DBG15]]
// AARCH64-NEXT:    [[TMP9]] = extractvalue { i16, i1 } [[TMP8]], 0, !dbg [[DBG15]]
// AARCH64-NEXT:    [[TMP10:%.*]] = extractvalue { i16, i1 } [[TMP8]], 1, !dbg [[DBG15]]
// AARCH64-NEXT:    br i1 [[TMP10]], label [[ATOMIC_EXIT:%.*]], label [[ATOMIC_CONT]], !dbg [[DBG15]]
// AARCH64:       atomic_exit:
// AARCH64-NEXT:    [[TMP11:%.*]] = load i32, i32* @iv, align 4, !dbg [[DBG17:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD3:%.*]] = load atomic i32, i32* @ix monotonic, align 4, !dbg [[DBG18:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT4:%.*]], !dbg [[DBG18]]
// AARCH64:       atomic_cont4:
// AARCH64-NEXT:    [[TMP12:%.*]] = phi i32 [ [[ATOMIC_LOAD3]], [[ATOMIC_EXIT]] ], [ [[TMP15:%.*]], [[ATOMIC_CONT4]] ], !dbg [[DBG18]]
// AARCH64-NEXT:    [[MUL:%.*]] = mul nsw i32 [[TMP12]], [[TMP11]], !dbg [[DBG19:![0-9]+]]
// AARCH64-NEXT:    store i32 [[MUL]], i32* [[ATOMIC_TEMP5]], align 4, !dbg [[DBG18]]
// AARCH64-NEXT:    [[TMP13:%.*]] = load i32, i32* [[ATOMIC_TEMP5]], align 4, !dbg [[DBG18]]
// AARCH64-NEXT:    [[TMP14:%.*]] = cmpxchg i32* @ix, i32 [[TMP12]], i32 [[TMP13]] monotonic monotonic, align 4, !dbg [[DBG18]]
// AARCH64-NEXT:    [[TMP15]] = extractvalue { i32, i1 } [[TMP14]], 0, !dbg [[DBG18]]
// AARCH64-NEXT:    [[TMP16:%.*]] = extractvalue { i32, i1 } [[TMP14]], 1, !dbg [[DBG18]]
// AARCH64-NEXT:    br i1 [[TMP16]], label [[ATOMIC_EXIT6:%.*]], label [[ATOMIC_CONT4]], !dbg [[DBG18]]
// AARCH64:       atomic_exit6:
// AARCH64-NEXT:    [[TMP17:%.*]] = load i32, i32* @uiv, align 4, !dbg [[DBG20:![0-9]+]]
// AARCH64-NEXT:    [[TMP18:%.*]] = atomicrmw sub i32* @uix, i32 [[TMP17]] monotonic, align 4, !dbg [[DBG21:![0-9]+]]
// AARCH64-NEXT:    [[TMP19:%.*]] = load i32, i32* @iv, align 4, !dbg [[DBG22:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD7:%.*]] = load atomic i32, i32* @ix monotonic, align 4, !dbg [[DBG23:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT8:%.*]], !dbg [[DBG23]]
// AARCH64:       atomic_cont8:
// AARCH64-NEXT:    [[TMP20:%.*]] = phi i32 [ [[ATOMIC_LOAD7]], [[ATOMIC_EXIT6]] ], [ [[TMP23:%.*]], [[ATOMIC_CONT8]] ], !dbg [[DBG23]]
// AARCH64-NEXT:    [[SHL:%.*]] = shl i32 [[TMP20]], [[TMP19]], !dbg [[DBG24:![0-9]+]]
// AARCH64-NEXT:    store i32 [[SHL]], i32* [[ATOMIC_TEMP9]], align 4, !dbg [[DBG23]]
// AARCH64-NEXT:    [[TMP21:%.*]] = load i32, i32* [[ATOMIC_TEMP9]], align 4, !dbg [[DBG23]]
// AARCH64-NEXT:    [[TMP22:%.*]] = cmpxchg i32* @ix, i32 [[TMP20]], i32 [[TMP21]] monotonic monotonic, align 4, !dbg [[DBG23]]
// AARCH64-NEXT:    [[TMP23]] = extractvalue { i32, i1 } [[TMP22]], 0, !dbg [[DBG23]]
// AARCH64-NEXT:    [[TMP24:%.*]] = extractvalue { i32, i1 } [[TMP22]], 1, !dbg [[DBG23]]
// AARCH64-NEXT:    br i1 [[TMP24]], label [[ATOMIC_EXIT10:%.*]], label [[ATOMIC_CONT8]], !dbg [[DBG23]]
// AARCH64:       atomic_exit10:
// AARCH64-NEXT:    [[TMP25:%.*]] = load i32, i32* @uiv, align 4, !dbg [[DBG25:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD11:%.*]] = load atomic i32, i32* @uix monotonic, align 4, !dbg [[DBG26:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT12:%.*]], !dbg [[DBG26]]
// AARCH64:       atomic_cont12:
// AARCH64-NEXT:    [[TMP26:%.*]] = phi i32 [ [[ATOMIC_LOAD11]], [[ATOMIC_EXIT10]] ], [ [[TMP29:%.*]], [[ATOMIC_CONT12]] ], !dbg [[DBG26]]
// AARCH64-NEXT:    [[SHR:%.*]] = lshr i32 [[TMP26]], [[TMP25]], !dbg [[DBG27:![0-9]+]]
// AARCH64-NEXT:    store i32 [[SHR]], i32* [[ATOMIC_TEMP13]], align 4, !dbg [[DBG26]]
// AARCH64-NEXT:    [[TMP27:%.*]] = load i32, i32* [[ATOMIC_TEMP13]], align 4, !dbg [[DBG26]]
// AARCH64-NEXT:    [[TMP28:%.*]] = cmpxchg i32* @uix, i32 [[TMP26]], i32 [[TMP27]] monotonic monotonic, align 4, !dbg [[DBG26]]
// AARCH64-NEXT:    [[TMP29]] = extractvalue { i32, i1 } [[TMP28]], 0, !dbg [[DBG26]]
// AARCH64-NEXT:    [[TMP30:%.*]] = extractvalue { i32, i1 } [[TMP28]], 1, !dbg [[DBG26]]
// AARCH64-NEXT:    br i1 [[TMP30]], label [[ATOMIC_EXIT14:%.*]], label [[ATOMIC_CONT12]], !dbg [[DBG26]]
// AARCH64:       atomic_exit14:
// AARCH64-NEXT:    [[TMP31:%.*]] = load i64, i64* @lv, align 8, !dbg [[DBG28:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD15:%.*]] = load atomic i64, i64* @lx monotonic, align 8, !dbg [[DBG29:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT16:%.*]], !dbg [[DBG29]]
// AARCH64:       atomic_cont16:
// AARCH64-NEXT:    [[TMP32:%.*]] = phi i64 [ [[ATOMIC_LOAD15]], [[ATOMIC_EXIT14]] ], [ [[TMP35:%.*]], [[ATOMIC_CONT16]] ], !dbg [[DBG29]]
// AARCH64-NEXT:    [[DIV:%.*]] = sdiv i64 [[TMP32]], [[TMP31]], !dbg [[DBG30:![0-9]+]]
// AARCH64-NEXT:    store i64 [[DIV]], i64* [[ATOMIC_TEMP17]], align 8, !dbg [[DBG29]]
// AARCH64-NEXT:    [[TMP33:%.*]] = load i64, i64* [[ATOMIC_TEMP17]], align 8, !dbg [[DBG29]]
// AARCH64-NEXT:    [[TMP34:%.*]] = cmpxchg i64* @lx, i64 [[TMP32]], i64 [[TMP33]] monotonic monotonic, align 8, !dbg [[DBG29]]
// AARCH64-NEXT:    [[TMP35]] = extractvalue { i64, i1 } [[TMP34]], 0, !dbg [[DBG29]]
// AARCH64-NEXT:    [[TMP36:%.*]] = extractvalue { i64, i1 } [[TMP34]], 1, !dbg [[DBG29]]
// AARCH64-NEXT:    br i1 [[TMP36]], label [[ATOMIC_EXIT18:%.*]], label [[ATOMIC_CONT16]], !dbg [[DBG29]]
// AARCH64:       atomic_exit18:
// AARCH64-NEXT:    [[TMP37:%.*]] = load i64, i64* @ulv, align 8, !dbg [[DBG31:![0-9]+]]
// AARCH64-NEXT:    [[TMP38:%.*]] = atomicrmw and i64* @ulx, i64 [[TMP37]] monotonic, align 8, !dbg [[DBG32:![0-9]+]]
// AARCH64-NEXT:    [[TMP39:%.*]] = load i64, i64* @llv, align 8, !dbg [[DBG33:![0-9]+]]
// AARCH64-NEXT:    [[TMP40:%.*]] = atomicrmw xor i64* @llx, i64 [[TMP39]] monotonic, align 8, !dbg [[DBG34:![0-9]+]]
// AARCH64-NEXT:    [[TMP41:%.*]] = load i64, i64* @ullv, align 8, !dbg [[DBG35:![0-9]+]]
// AARCH64-NEXT:    [[TMP42:%.*]] = atomicrmw or i64* @ullx, i64 [[TMP41]] monotonic, align 8, !dbg [[DBG36:![0-9]+]]
// AARCH64-NEXT:    [[TMP43:%.*]] = load float, float* @fv, align 4, !dbg [[DBG37:![0-9]+]]
// AARCH64-NEXT:    [[TMP44:%.*]] = atomicrmw fadd float* @fx, float [[TMP43]] monotonic, align 4, !dbg [[DBG38:![0-9]+]]
// AARCH64-NEXT:    [[TMP45:%.*]] = load double, double* @dv, align 8, !dbg [[DBG39:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD19:%.*]] = load atomic i64, i64* bitcast (double* @dx to i64*) monotonic, align 8, !dbg [[DBG40:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT20:%.*]], !dbg [[DBG40]]
// AARCH64:       atomic_cont20:
// AARCH64-NEXT:    [[TMP46:%.*]] = phi i64 [ [[ATOMIC_LOAD19]], [[ATOMIC_EXIT18]] ], [ [[TMP51:%.*]], [[ATOMIC_CONT20]] ], !dbg [[DBG40]]
// AARCH64-NEXT:    [[TMP47:%.*]] = bitcast double* [[ATOMIC_TEMP21]] to i64*, !dbg [[DBG40]]
// AARCH64-NEXT:    [[TMP48:%.*]] = bitcast i64 [[TMP46]] to double, !dbg [[DBG40]]
// AARCH64-NEXT:    [[SUB:%.*]] = fsub double [[TMP45]], [[TMP48]], !dbg [[DBG41:![0-9]+]]
// AARCH64-NEXT:    store double [[SUB]], double* [[ATOMIC_TEMP21]], align 8, !dbg [[DBG40]]
// AARCH64-NEXT:    [[TMP49:%.*]] = load i64, i64* [[TMP47]], align 8, !dbg [[DBG40]]
// AARCH64-NEXT:    [[TMP50:%.*]] = cmpxchg i64* bitcast (double* @dx to i64*), i64 [[TMP46]], i64 [[TMP49]] monotonic monotonic, align 8, !dbg [[DBG40]]
// AARCH64-NEXT:    [[TMP51]] = extractvalue { i64, i1 } [[TMP50]], 0, !dbg [[DBG40]]
// AARCH64-NEXT:    [[TMP52:%.*]] = extractvalue { i64, i1 } [[TMP50]], 1, !dbg [[DBG40]]
// AARCH64-NEXT:    br i1 [[TMP52]], label [[ATOMIC_EXIT22:%.*]], label [[ATOMIC_CONT20]], !dbg [[DBG40]]
// AARCH64:       atomic_exit22:
// AARCH64-NEXT:    [[TMP53:%.*]] = load fp128, fp128* @ldv, align 16, !dbg [[DBG42:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD23:%.*]] = load atomic i128, i128* bitcast (fp128* @ldx to i128*) monotonic, align 16, !dbg [[DBG43:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT24:%.*]], !dbg [[DBG43]]
// AARCH64:       atomic_cont24:
// AARCH64-NEXT:    [[TMP54:%.*]] = phi i128 [ [[ATOMIC_LOAD23]], [[ATOMIC_EXIT22]] ], [ [[TMP59:%.*]], [[ATOMIC_CONT24]] ], !dbg [[DBG43]]
// AARCH64-NEXT:    [[TMP55:%.*]] = bitcast fp128* [[ATOMIC_TEMP25]] to i128*, !dbg [[DBG43]]
// AARCH64-NEXT:    [[TMP56:%.*]] = bitcast i128 [[TMP54]] to fp128, !dbg [[DBG43]]
// AARCH64-NEXT:    [[MUL26:%.*]] = fmul fp128 [[TMP56]], [[TMP53]], !dbg [[DBG44:![0-9]+]]
// AARCH64-NEXT:    store fp128 [[MUL26]], fp128* [[ATOMIC_TEMP25]], align 16, !dbg [[DBG43]]
// AARCH64-NEXT:    [[TMP57:%.*]] = load i128, i128* [[TMP55]], align 16, !dbg [[DBG43]]
// AARCH64-NEXT:    [[TMP58:%.*]] = cmpxchg i128* bitcast (fp128* @ldx to i128*), i128 [[TMP54]], i128 [[TMP57]] monotonic monotonic, align 16, !dbg [[DBG43]]
// AARCH64-NEXT:    [[TMP59]] = extractvalue { i128, i1 } [[TMP58]], 0, !dbg [[DBG43]]
// AARCH64-NEXT:    [[TMP60:%.*]] = extractvalue { i128, i1 } [[TMP58]], 1, !dbg [[DBG43]]
// AARCH64-NEXT:    br i1 [[TMP60]], label [[ATOMIC_EXIT27:%.*]], label [[ATOMIC_CONT24]], !dbg [[DBG43]]
// AARCH64:       atomic_exit27:
// AARCH64-NEXT:    [[CIV_REAL:%.*]] = load i32, i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 0), align 4, !dbg [[DBG45:![0-9]+]]
// AARCH64-NEXT:    [[CIV_IMAG:%.*]] = load i32, i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 1), align 4, !dbg [[DBG45]]
// AARCH64-NEXT:    [[TMP61:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP28]] to i8*, !dbg [[DBG46:![0-9]+]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP61]], i32 noundef 0), !dbg [[DBG46]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT29:%.*]], !dbg [[DBG46]]
// AARCH64:       atomic_cont29:
// AARCH64-NEXT:    [[ATOMIC_TEMP28_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP28]], i32 0, i32 0, !dbg [[DBG46]]
// AARCH64-NEXT:    [[ATOMIC_TEMP28_REAL:%.*]] = load i32, i32* [[ATOMIC_TEMP28_REALP]], align 4, !dbg [[DBG46]]
// AARCH64-NEXT:    [[ATOMIC_TEMP28_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP28]], i32 0, i32 1, !dbg [[DBG46]]
// AARCH64-NEXT:    [[ATOMIC_TEMP28_IMAG:%.*]] = load i32, i32* [[ATOMIC_TEMP28_IMAGP]], align 4, !dbg [[DBG46]]
// AARCH64-NEXT:    [[TMP62:%.*]] = mul i32 [[CIV_REAL]], [[ATOMIC_TEMP28_REAL]], !dbg [[DBG47:![0-9]+]]
// AARCH64-NEXT:    [[TMP63:%.*]] = mul i32 [[CIV_IMAG]], [[ATOMIC_TEMP28_IMAG]], !dbg [[DBG47]]
// AARCH64-NEXT:    [[TMP64:%.*]] = add i32 [[TMP62]], [[TMP63]], !dbg [[DBG47]]
// AARCH64-NEXT:    [[TMP65:%.*]] = mul i32 [[ATOMIC_TEMP28_REAL]], [[ATOMIC_TEMP28_REAL]], !dbg [[DBG47]]
// AARCH64-NEXT:    [[TMP66:%.*]] = mul i32 [[ATOMIC_TEMP28_IMAG]], [[ATOMIC_TEMP28_IMAG]], !dbg [[DBG47]]
// AARCH64-NEXT:    [[TMP67:%.*]] = add i32 [[TMP65]], [[TMP66]], !dbg [[DBG47]]
// AARCH64-NEXT:    [[TMP68:%.*]] = mul i32 [[CIV_IMAG]], [[ATOMIC_TEMP28_REAL]], !dbg [[DBG47]]
// AARCH64-NEXT:    [[TMP69:%.*]] = mul i32 [[CIV_REAL]], [[ATOMIC_TEMP28_IMAG]], !dbg [[DBG47]]
// AARCH64-NEXT:    [[TMP70:%.*]] = sub i32 [[TMP68]], [[TMP69]], !dbg [[DBG47]]
// AARCH64-NEXT:    [[TMP71:%.*]] = sdiv i32 [[TMP64]], [[TMP67]], !dbg [[DBG47]]
// AARCH64-NEXT:    [[TMP72:%.*]] = sdiv i32 [[TMP70]], [[TMP67]], !dbg [[DBG47]]
// AARCH64-NEXT:    [[ATOMIC_TEMP30_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP30]], i32 0, i32 0, !dbg [[DBG46]]
// AARCH64-NEXT:    [[ATOMIC_TEMP30_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP30]], i32 0, i32 1, !dbg [[DBG46]]
// AARCH64-NEXT:    store i32 [[TMP71]], i32* [[ATOMIC_TEMP30_REALP]], align 4, !dbg [[DBG46]]
// AARCH64-NEXT:    store i32 [[TMP72]], i32* [[ATOMIC_TEMP30_IMAGP]], align 4, !dbg [[DBG46]]
// AARCH64-NEXT:    [[TMP73:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP28]] to i8*, !dbg [[DBG46]]
// AARCH64-NEXT:    [[TMP74:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP30]] to i8*, !dbg [[DBG46]]
// AARCH64-NEXT:    [[CALL:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP73]], i8* noundef [[TMP74]], i32 noundef 0, i32 noundef 0), !dbg [[DBG46]]
// AARCH64-NEXT:    br i1 [[CALL]], label [[ATOMIC_EXIT31:%.*]], label [[ATOMIC_CONT29]], !dbg [[DBG46]]
// AARCH64:       atomic_exit31:
// AARCH64-NEXT:    [[CFV_REAL:%.*]] = load float, float* getelementptr inbounds ({ float, float }, { float, float }* @cfv, i32 0, i32 0), align 4, !dbg [[DBG48:![0-9]+]]
// AARCH64-NEXT:    [[CFV_IMAG:%.*]] = load float, float* getelementptr inbounds ({ float, float }, { float, float }* @cfv, i32 0, i32 1), align 4, !dbg [[DBG48]]
// AARCH64-NEXT:    [[TMP75:%.*]] = bitcast { float, float }* [[ATOMIC_TEMP32]] to i8*, !dbg [[DBG49:![0-9]+]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 8, i8* noundef bitcast ({ float, float }* @cfx to i8*), i8* noundef [[TMP75]], i32 noundef 0), !dbg [[DBG49]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT33:%.*]], !dbg [[DBG49]]
// AARCH64:       atomic_cont33:
// AARCH64-NEXT:    [[ATOMIC_TEMP32_REALP:%.*]] = getelementptr inbounds { float, float }, { float, float }* [[ATOMIC_TEMP32]], i32 0, i32 0, !dbg [[DBG49]]
// AARCH64-NEXT:    [[ATOMIC_TEMP32_REAL:%.*]] = load float, float* [[ATOMIC_TEMP32_REALP]], align 4, !dbg [[DBG49]]
// AARCH64-NEXT:    [[ATOMIC_TEMP32_IMAGP:%.*]] = getelementptr inbounds { float, float }, { float, float }* [[ATOMIC_TEMP32]], i32 0, i32 1, !dbg [[DBG49]]
// AARCH64-NEXT:    [[ATOMIC_TEMP32_IMAG:%.*]] = load float, float* [[ATOMIC_TEMP32_IMAGP]], align 4, !dbg [[DBG49]]
// AARCH64-NEXT:    [[ADD_R:%.*]] = fadd float [[CFV_REAL]], [[ATOMIC_TEMP32_REAL]], !dbg [[DBG50:![0-9]+]]
// AARCH64-NEXT:    [[ADD_I:%.*]] = fadd float [[CFV_IMAG]], [[ATOMIC_TEMP32_IMAG]], !dbg [[DBG50]]
// AARCH64-NEXT:    [[ATOMIC_TEMP34_REALP:%.*]] = getelementptr inbounds { float, float }, { float, float }* [[ATOMIC_TEMP34]], i32 0, i32 0, !dbg [[DBG49]]
// AARCH64-NEXT:    [[ATOMIC_TEMP34_IMAGP:%.*]] = getelementptr inbounds { float, float }, { float, float }* [[ATOMIC_TEMP34]], i32 0, i32 1, !dbg [[DBG49]]
// AARCH64-NEXT:    store float [[ADD_R]], float* [[ATOMIC_TEMP34_REALP]], align 4, !dbg [[DBG49]]
// AARCH64-NEXT:    store float [[ADD_I]], float* [[ATOMIC_TEMP34_IMAGP]], align 4, !dbg [[DBG49]]
// AARCH64-NEXT:    [[TMP76:%.*]] = bitcast { float, float }* [[ATOMIC_TEMP32]] to i8*, !dbg [[DBG49]]
// AARCH64-NEXT:    [[TMP77:%.*]] = bitcast { float, float }* [[ATOMIC_TEMP34]] to i8*, !dbg [[DBG49]]
// AARCH64-NEXT:    [[CALL35:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 8, i8* noundef bitcast ({ float, float }* @cfx to i8*), i8* noundef [[TMP76]], i8* noundef [[TMP77]], i32 noundef 0, i32 noundef 0), !dbg [[DBG49]]
// AARCH64-NEXT:    br i1 [[CALL35]], label [[ATOMIC_EXIT36:%.*]], label [[ATOMIC_CONT33]], !dbg [[DBG49]]
// AARCH64:       atomic_exit36:
// AARCH64-NEXT:    [[CDV_REAL:%.*]] = load double, double* getelementptr inbounds ({ double, double }, { double, double }* @cdv, i32 0, i32 0), align 8, !dbg [[DBG51:![0-9]+]]
// AARCH64-NEXT:    [[CDV_IMAG:%.*]] = load double, double* getelementptr inbounds ({ double, double }, { double, double }* @cdv, i32 0, i32 1), align 8, !dbg [[DBG51]]
// AARCH64-NEXT:    [[TMP78:%.*]] = bitcast { double, double }* [[ATOMIC_TEMP37]] to i8*, !dbg [[DBG52:![0-9]+]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 16, i8* noundef bitcast ({ double, double }* @cdx to i8*), i8* noundef [[TMP78]], i32 noundef 5), !dbg [[DBG52]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT38:%.*]], !dbg [[DBG52]]
// AARCH64:       atomic_cont38:
// AARCH64-NEXT:    [[ATOMIC_TEMP37_REALP:%.*]] = getelementptr inbounds { double, double }, { double, double }* [[ATOMIC_TEMP37]], i32 0, i32 0, !dbg [[DBG52]]
// AARCH64-NEXT:    [[ATOMIC_TEMP37_REAL:%.*]] = load double, double* [[ATOMIC_TEMP37_REALP]], align 8, !dbg [[DBG52]]
// AARCH64-NEXT:    [[ATOMIC_TEMP37_IMAGP:%.*]] = getelementptr inbounds { double, double }, { double, double }* [[ATOMIC_TEMP37]], i32 0, i32 1, !dbg [[DBG52]]
// AARCH64-NEXT:    [[ATOMIC_TEMP37_IMAG:%.*]] = load double, double* [[ATOMIC_TEMP37_IMAGP]], align 8, !dbg [[DBG52]]
// AARCH64-NEXT:    [[SUB_R:%.*]] = fsub double [[ATOMIC_TEMP37_REAL]], [[CDV_REAL]], !dbg [[DBG53:![0-9]+]]
// AARCH64-NEXT:    [[SUB_I:%.*]] = fsub double [[ATOMIC_TEMP37_IMAG]], [[CDV_IMAG]], !dbg [[DBG53]]
// AARCH64-NEXT:    [[ATOMIC_TEMP39_REALP:%.*]] = getelementptr inbounds { double, double }, { double, double }* [[ATOMIC_TEMP39]], i32 0, i32 0, !dbg [[DBG52]]
// AARCH64-NEXT:    [[ATOMIC_TEMP39_IMAGP:%.*]] = getelementptr inbounds { double, double }, { double, double }* [[ATOMIC_TEMP39]], i32 0, i32 1, !dbg [[DBG52]]
// AARCH64-NEXT:    store double [[SUB_R]], double* [[ATOMIC_TEMP39_REALP]], align 8, !dbg [[DBG52]]
// AARCH64-NEXT:    store double [[SUB_I]], double* [[ATOMIC_TEMP39_IMAGP]], align 8, !dbg [[DBG52]]
// AARCH64-NEXT:    [[TMP79:%.*]] = bitcast { double, double }* [[ATOMIC_TEMP37]] to i8*, !dbg [[DBG52]]
// AARCH64-NEXT:    [[TMP80:%.*]] = bitcast { double, double }* [[ATOMIC_TEMP39]] to i8*, !dbg [[DBG52]]
// AARCH64-NEXT:    [[CALL40:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 16, i8* noundef bitcast ({ double, double }* @cdx to i8*), i8* noundef [[TMP79]], i8* noundef [[TMP80]], i32 noundef 5, i32 noundef 5), !dbg [[DBG52]]
// AARCH64-NEXT:    br i1 [[CALL40]], label [[ATOMIC_EXIT41:%.*]], label [[ATOMIC_CONT38]], !dbg [[DBG52]]
// AARCH64:       atomic_exit41:
// AARCH64-NEXT:    fence release
// AARCH64-NEXT:    [[TMP81:%.*]] = load i8, i8* @bv, align 1, !dbg [[DBG54:![0-9]+]]
// AARCH64-NEXT:    [[TOBOOL:%.*]] = trunc i8 [[TMP81]] to i1, !dbg [[DBG54]]
// AARCH64-NEXT:    [[CONV42:%.*]] = zext i1 [[TOBOOL]] to i64, !dbg [[DBG54]]
// AARCH64-NEXT:    [[TMP82:%.*]] = atomicrmw and i64* @ulx, i64 [[CONV42]] monotonic, align 8, !dbg [[DBG55:![0-9]+]]
// AARCH64-NEXT:    [[TMP83:%.*]] = load i8, i8* @cv, align 1, !dbg [[DBG56:![0-9]+]]
// AARCH64-NEXT:    [[CONV43:%.*]] = sext i8 [[TMP83]] to i32, !dbg [[DBG56]]
// AARCH64-NEXT:    [[ATOMIC_LOAD44:%.*]] = load atomic i8, i8* @bx monotonic, align 1, !dbg [[DBG57:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT45:%.*]], !dbg [[DBG57]]
// AARCH64:       atomic_cont45:
// AARCH64-NEXT:    [[TMP84:%.*]] = phi i8 [ [[ATOMIC_LOAD44]], [[ATOMIC_EXIT41]] ], [ [[TMP87:%.*]], [[ATOMIC_CONT45]] ], !dbg [[DBG57]]
// AARCH64-NEXT:    [[TOBOOL47:%.*]] = trunc i8 [[TMP84]] to i1, !dbg [[DBG57]]
// AARCH64-NEXT:    [[CONV48:%.*]] = zext i1 [[TOBOOL47]] to i32, !dbg [[DBG57]]
// AARCH64-NEXT:    [[AND:%.*]] = and i32 [[CONV43]], [[CONV48]], !dbg [[DBG58:![0-9]+]]
// AARCH64-NEXT:    [[TOBOOL49:%.*]] = icmp ne i32 [[AND]], 0, !dbg [[DBG56]]
// AARCH64-NEXT:    [[FROMBOOL:%.*]] = zext i1 [[TOBOOL49]] to i8, !dbg [[DBG57]]
// AARCH64-NEXT:    store i8 [[FROMBOOL]], i8* [[ATOMIC_TEMP46]], align 1, !dbg [[DBG57]]
// AARCH64-NEXT:    [[TMP85:%.*]] = load i8, i8* [[ATOMIC_TEMP46]], align 1, !dbg [[DBG57]]
// AARCH64-NEXT:    [[TMP86:%.*]] = cmpxchg i8* @bx, i8 [[TMP84]], i8 [[TMP85]] monotonic monotonic, align 1, !dbg [[DBG57]]
// AARCH64-NEXT:    [[TMP87]] = extractvalue { i8, i1 } [[TMP86]], 0, !dbg [[DBG57]]
// AARCH64-NEXT:    [[TMP88:%.*]] = extractvalue { i8, i1 } [[TMP86]], 1, !dbg [[DBG57]]
// AARCH64-NEXT:    br i1 [[TMP88]], label [[ATOMIC_EXIT50:%.*]], label [[ATOMIC_CONT45]], !dbg [[DBG57]]
// AARCH64:       atomic_exit50:
// AARCH64-NEXT:    [[TMP89:%.*]] = load i8, i8* @ucv, align 1, !dbg [[DBG59:![0-9]+]]
// AARCH64-NEXT:    [[CONV51:%.*]] = zext i8 [[TMP89]] to i32, !dbg [[DBG59]]
// AARCH64-NEXT:    [[ATOMIC_LOAD52:%.*]] = load atomic i8, i8* @cx seq_cst, align 1, !dbg [[DBG60:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT53:%.*]], !dbg [[DBG60]]
// AARCH64:       atomic_cont53:
// AARCH64-NEXT:    [[TMP90:%.*]] = phi i8 [ [[ATOMIC_LOAD52]], [[ATOMIC_EXIT50]] ], [ [[TMP93:%.*]], [[ATOMIC_CONT53]] ], !dbg [[DBG60]]
// AARCH64-NEXT:    [[CONV55:%.*]] = sext i8 [[TMP90]] to i32, !dbg [[DBG60]]
// AARCH64-NEXT:    [[SHR56:%.*]] = ashr i32 [[CONV55]], [[CONV51]], !dbg [[DBG61:![0-9]+]]
// AARCH64-NEXT:    [[CONV57:%.*]] = trunc i32 [[SHR56]] to i8, !dbg [[DBG60]]
// AARCH64-NEXT:    store i8 [[CONV57]], i8* [[ATOMIC_TEMP54]], align 1, !dbg [[DBG60]]
// AARCH64-NEXT:    [[TMP91:%.*]] = load i8, i8* [[ATOMIC_TEMP54]], align 1, !dbg [[DBG60]]
// AARCH64-NEXT:    [[TMP92:%.*]] = cmpxchg i8* @cx, i8 [[TMP90]], i8 [[TMP91]] seq_cst seq_cst, align 1, !dbg [[DBG60]]
// AARCH64-NEXT:    [[TMP93]] = extractvalue { i8, i1 } [[TMP92]], 0, !dbg [[DBG60]]
// AARCH64-NEXT:    [[TMP94:%.*]] = extractvalue { i8, i1 } [[TMP92]], 1, !dbg [[DBG60]]
// AARCH64-NEXT:    br i1 [[TMP94]], label [[ATOMIC_EXIT58:%.*]], label [[ATOMIC_CONT53]], !dbg [[DBG60]]
// AARCH64:       atomic_exit58:
// AARCH64-NEXT:    fence release
// AARCH64-NEXT:    [[TMP95:%.*]] = load i16, i16* @sv, align 2, !dbg [[DBG62:![0-9]+]]
// AARCH64-NEXT:    [[CONV59:%.*]] = sext i16 [[TMP95]] to i32, !dbg [[DBG62]]
// AARCH64-NEXT:    [[ATOMIC_LOAD60:%.*]] = load atomic i64, i64* @ulx monotonic, align 8, !dbg [[DBG63:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT61:%.*]], !dbg [[DBG63]]
// AARCH64:       atomic_cont61:
// AARCH64-NEXT:    [[TMP96:%.*]] = phi i64 [ [[ATOMIC_LOAD60]], [[ATOMIC_EXIT58]] ], [ [[TMP99:%.*]], [[ATOMIC_CONT61]] ], !dbg [[DBG63]]
// AARCH64-NEXT:    [[SH_PROM:%.*]] = trunc i64 [[TMP96]] to i32, !dbg [[DBG64:![0-9]+]]
// AARCH64-NEXT:    [[SHL63:%.*]] = shl i32 [[CONV59]], [[SH_PROM]], !dbg [[DBG64]]
// AARCH64-NEXT:    [[CONV64:%.*]] = sext i32 [[SHL63]] to i64, !dbg [[DBG62]]
// AARCH64-NEXT:    store i64 [[CONV64]], i64* [[ATOMIC_TEMP62]], align 8, !dbg [[DBG63]]
// AARCH64-NEXT:    [[TMP97:%.*]] = load i64, i64* [[ATOMIC_TEMP62]], align 8, !dbg [[DBG63]]
// AARCH64-NEXT:    [[TMP98:%.*]] = cmpxchg i64* @ulx, i64 [[TMP96]], i64 [[TMP97]] monotonic monotonic, align 8, !dbg [[DBG63]]
// AARCH64-NEXT:    [[TMP99]] = extractvalue { i64, i1 } [[TMP98]], 0, !dbg [[DBG63]]
// AARCH64-NEXT:    [[TMP100:%.*]] = extractvalue { i64, i1 } [[TMP98]], 1, !dbg [[DBG63]]
// AARCH64-NEXT:    br i1 [[TMP100]], label [[ATOMIC_EXIT65:%.*]], label [[ATOMIC_CONT61]], !dbg [[DBG63]]
// AARCH64:       atomic_exit65:
// AARCH64-NEXT:    [[TMP101:%.*]] = load i16, i16* @usv, align 2, !dbg [[DBG65:![0-9]+]]
// AARCH64-NEXT:    [[CONV66:%.*]] = zext i16 [[TMP101]] to i64, !dbg [[DBG65]]
// AARCH64-NEXT:    [[ATOMIC_LOAD67:%.*]] = load atomic i64, i64* @lx monotonic, align 8, !dbg [[DBG66:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT68:%.*]], !dbg [[DBG66]]
// AARCH64:       atomic_cont68:
// AARCH64-NEXT:    [[TMP102:%.*]] = phi i64 [ [[ATOMIC_LOAD67]], [[ATOMIC_EXIT65]] ], [ [[TMP105:%.*]], [[ATOMIC_CONT68]] ], !dbg [[DBG66]]
// AARCH64-NEXT:    [[REM:%.*]] = srem i64 [[TMP102]], [[CONV66]], !dbg [[DBG67:![0-9]+]]
// AARCH64-NEXT:    store i64 [[REM]], i64* [[ATOMIC_TEMP69]], align 8, !dbg [[DBG66]]
// AARCH64-NEXT:    [[TMP103:%.*]] = load i64, i64* [[ATOMIC_TEMP69]], align 8, !dbg [[DBG66]]
// AARCH64-NEXT:    [[TMP104:%.*]] = cmpxchg i64* @lx, i64 [[TMP102]], i64 [[TMP103]] monotonic monotonic, align 8, !dbg [[DBG66]]
// AARCH64-NEXT:    [[TMP105]] = extractvalue { i64, i1 } [[TMP104]], 0, !dbg [[DBG66]]
// AARCH64-NEXT:    [[TMP106:%.*]] = extractvalue { i64, i1 } [[TMP104]], 1, !dbg [[DBG66]]
// AARCH64-NEXT:    br i1 [[TMP106]], label [[ATOMIC_EXIT70:%.*]], label [[ATOMIC_CONT68]], !dbg [[DBG66]]
// AARCH64:       atomic_exit70:
// AARCH64-NEXT:    [[TMP107:%.*]] = load i32, i32* @iv, align 4, !dbg [[DBG68:![0-9]+]]
// AARCH64-NEXT:    [[TMP108:%.*]] = atomicrmw or i32* @uix, i32 [[TMP107]] seq_cst, align 4, !dbg [[DBG69:![0-9]+]]
// AARCH64-NEXT:    fence release
// AARCH64-NEXT:    [[TMP109:%.*]] = load i32, i32* @uiv, align 4, !dbg [[DBG70:![0-9]+]]
// AARCH64-NEXT:    [[TMP110:%.*]] = atomicrmw and i32* @ix, i32 [[TMP109]] monotonic, align 4, !dbg [[DBG71:![0-9]+]]
// AARCH64-NEXT:    [[TMP111:%.*]] = load i64, i64* @lv, align 8, !dbg [[DBG72:![0-9]+]]
// AARCH64-NEXT:    [[TMP112:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP71]] to i8*, !dbg [[DBG73:![0-9]+]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP112]], i32 noundef 0), !dbg [[DBG73]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT72:%.*]], !dbg [[DBG73]]
// AARCH64:       atomic_cont72:
// AARCH64-NEXT:    [[ATOMIC_TEMP71_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP71]], i32 0, i32 0, !dbg [[DBG73]]
// AARCH64-NEXT:    [[ATOMIC_TEMP71_REAL:%.*]] = load i32, i32* [[ATOMIC_TEMP71_REALP]], align 4, !dbg [[DBG73]]
// AARCH64-NEXT:    [[ATOMIC_TEMP71_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP71]], i32 0, i32 1, !dbg [[DBG73]]
// AARCH64-NEXT:    [[ATOMIC_TEMP71_IMAG:%.*]] = load i32, i32* [[ATOMIC_TEMP71_IMAGP]], align 4, !dbg [[DBG73]]
// AARCH64-NEXT:    [[CONV74:%.*]] = sext i32 [[ATOMIC_TEMP71_REAL]] to i64, !dbg [[DBG73]]
// AARCH64-NEXT:    [[CONV75:%.*]] = sext i32 [[ATOMIC_TEMP71_IMAG]] to i64, !dbg [[DBG73]]
// AARCH64-NEXT:    [[ADD_R76:%.*]] = add i64 [[TMP111]], [[CONV74]], !dbg [[DBG74:![0-9]+]]
// AARCH64-NEXT:    [[ADD_I77:%.*]] = add i64 0, [[CONV75]], !dbg [[DBG74]]
// AARCH64-NEXT:    [[CONV78:%.*]] = trunc i64 [[ADD_R76]] to i32, !dbg [[DBG72]]
// AARCH64-NEXT:    [[CONV79:%.*]] = trunc i64 [[ADD_I77]] to i32, !dbg [[DBG72]]
// AARCH64-NEXT:    [[ATOMIC_TEMP73_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP73]], i32 0, i32 0, !dbg [[DBG73]]
// AARCH64-NEXT:    [[ATOMIC_TEMP73_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP73]], i32 0, i32 1, !dbg [[DBG73]]
// AARCH64-NEXT:    store i32 [[CONV78]], i32* [[ATOMIC_TEMP73_REALP]], align 4, !dbg [[DBG73]]
// AARCH64-NEXT:    store i32 [[CONV79]], i32* [[ATOMIC_TEMP73_IMAGP]], align 4, !dbg [[DBG73]]
// AARCH64-NEXT:    [[TMP113:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP71]] to i8*, !dbg [[DBG73]]
// AARCH64-NEXT:    [[TMP114:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP73]] to i8*, !dbg [[DBG73]]
// AARCH64-NEXT:    [[CALL80:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP113]], i8* noundef [[TMP114]], i32 noundef 0, i32 noundef 0), !dbg [[DBG73]]
// AARCH64-NEXT:    br i1 [[CALL80]], label [[ATOMIC_EXIT81:%.*]], label [[ATOMIC_CONT72]], !dbg [[DBG73]]
// AARCH64:       atomic_exit81:
// AARCH64-NEXT:    [[TMP115:%.*]] = load i64, i64* @ulv, align 8, !dbg [[DBG75:![0-9]+]]
// AARCH64-NEXT:    [[CONV82:%.*]] = uitofp i64 [[TMP115]] to float, !dbg [[DBG75]]
// AARCH64-NEXT:    [[ATOMIC_LOAD83:%.*]] = load atomic i32, i32* bitcast (float* @fx to i32*) monotonic, align 4, !dbg [[DBG76:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT84:%.*]], !dbg [[DBG76]]
// AARCH64:       atomic_cont84:
// AARCH64-NEXT:    [[TMP116:%.*]] = phi i32 [ [[ATOMIC_LOAD83]], [[ATOMIC_EXIT81]] ], [ [[TMP121:%.*]], [[ATOMIC_CONT84]] ], !dbg [[DBG76]]
// AARCH64-NEXT:    [[TMP117:%.*]] = bitcast float* [[ATOMIC_TEMP85]] to i32*, !dbg [[DBG76]]
// AARCH64-NEXT:    [[TMP118:%.*]] = bitcast i32 [[TMP116]] to float, !dbg [[DBG76]]
// AARCH64-NEXT:    [[MUL86:%.*]] = fmul float [[TMP118]], [[CONV82]], !dbg [[DBG77:![0-9]+]]
// AARCH64-NEXT:    store float [[MUL86]], float* [[ATOMIC_TEMP85]], align 4, !dbg [[DBG76]]
// AARCH64-NEXT:    [[TMP119:%.*]] = load i32, i32* [[TMP117]], align 4, !dbg [[DBG76]]
// AARCH64-NEXT:    [[TMP120:%.*]] = cmpxchg i32* bitcast (float* @fx to i32*), i32 [[TMP116]], i32 [[TMP119]] monotonic monotonic, align 4, !dbg [[DBG76]]
// AARCH64-NEXT:    [[TMP121]] = extractvalue { i32, i1 } [[TMP120]], 0, !dbg [[DBG76]]
// AARCH64-NEXT:    [[TMP122:%.*]] = extractvalue { i32, i1 } [[TMP120]], 1, !dbg [[DBG76]]
// AARCH64-NEXT:    br i1 [[TMP122]], label [[ATOMIC_EXIT87:%.*]], label [[ATOMIC_CONT84]], !dbg [[DBG76]]
// AARCH64:       atomic_exit87:
// AARCH64-NEXT:    [[TMP123:%.*]] = load i64, i64* @llv, align 8, !dbg [[DBG78:![0-9]+]]
// AARCH64-NEXT:    [[CONV88:%.*]] = sitofp i64 [[TMP123]] to double, !dbg [[DBG78]]
// AARCH64-NEXT:    [[ATOMIC_LOAD89:%.*]] = load atomic i64, i64* bitcast (double* @dx to i64*) monotonic, align 8, !dbg [[DBG79:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT90:%.*]], !dbg [[DBG79]]
// AARCH64:       atomic_cont90:
// AARCH64-NEXT:    [[TMP124:%.*]] = phi i64 [ [[ATOMIC_LOAD89]], [[ATOMIC_EXIT87]] ], [ [[TMP129:%.*]], [[ATOMIC_CONT90]] ], !dbg [[DBG79]]
// AARCH64-NEXT:    [[TMP125:%.*]] = bitcast double* [[ATOMIC_TEMP91]] to i64*, !dbg [[DBG79]]
// AARCH64-NEXT:    [[TMP126:%.*]] = bitcast i64 [[TMP124]] to double, !dbg [[DBG79]]
// AARCH64-NEXT:    [[DIV92:%.*]] = fdiv double [[TMP126]], [[CONV88]], !dbg [[DBG80:![0-9]+]]
// AARCH64-NEXT:    store double [[DIV92]], double* [[ATOMIC_TEMP91]], align 8, !dbg [[DBG79]]
// AARCH64-NEXT:    [[TMP127:%.*]] = load i64, i64* [[TMP125]], align 8, !dbg [[DBG79]]
// AARCH64-NEXT:    [[TMP128:%.*]] = cmpxchg i64* bitcast (double* @dx to i64*), i64 [[TMP124]], i64 [[TMP127]] monotonic monotonic, align 8, !dbg [[DBG79]]
// AARCH64-NEXT:    [[TMP129]] = extractvalue { i64, i1 } [[TMP128]], 0, !dbg [[DBG79]]
// AARCH64-NEXT:    [[TMP130:%.*]] = extractvalue { i64, i1 } [[TMP128]], 1, !dbg [[DBG79]]
// AARCH64-NEXT:    br i1 [[TMP130]], label [[ATOMIC_EXIT93:%.*]], label [[ATOMIC_CONT90]], !dbg [[DBG79]]
// AARCH64:       atomic_exit93:
// AARCH64-NEXT:    [[TMP131:%.*]] = load i64, i64* @ullv, align 8, !dbg [[DBG81:![0-9]+]]
// AARCH64-NEXT:    [[CONV94:%.*]] = uitofp i64 [[TMP131]] to fp128, !dbg [[DBG81]]
// AARCH64-NEXT:    [[TMP132:%.*]] = atomicrmw fsub fp128* @ldx, fp128 [[CONV94]] monotonic, align 16, !dbg [[DBG82:![0-9]+]]
// AARCH64-NEXT:    [[TMP133:%.*]] = load float, float* @fv, align 4, !dbg [[DBG83:![0-9]+]]
// AARCH64-NEXT:    [[TMP134:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP95]] to i8*, !dbg [[DBG84:![0-9]+]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP134]], i32 noundef 0), !dbg [[DBG84]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT96:%.*]], !dbg [[DBG84]]
// AARCH64:       atomic_cont96:
// AARCH64-NEXT:    [[ATOMIC_TEMP95_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP95]], i32 0, i32 0, !dbg [[DBG84]]
// AARCH64-NEXT:    [[ATOMIC_TEMP95_REAL:%.*]] = load i32, i32* [[ATOMIC_TEMP95_REALP]], align 4, !dbg [[DBG84]]
// AARCH64-NEXT:    [[ATOMIC_TEMP95_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP95]], i32 0, i32 1, !dbg [[DBG84]]
// AARCH64-NEXT:    [[ATOMIC_TEMP95_IMAG:%.*]] = load i32, i32* [[ATOMIC_TEMP95_IMAGP]], align 4, !dbg [[DBG84]]
// AARCH64-NEXT:    [[CONV98:%.*]] = sitofp i32 [[ATOMIC_TEMP95_REAL]] to float, !dbg [[DBG84]]
// AARCH64-NEXT:    [[CONV99:%.*]] = sitofp i32 [[ATOMIC_TEMP95_IMAG]] to float, !dbg [[DBG84]]
// AARCH64-NEXT:    [[CALL100:%.*]] = call { float, float } @__divsc3(float noundef [[TMP133]], float noundef 0.000000e+00, float noundef [[CONV98]], float noundef [[CONV99]]) #[[ATTR2:[0-9]+]], !dbg [[DBG85:![0-9]+]]
// AARCH64-NEXT:    [[TMP135:%.*]] = extractvalue { float, float } [[CALL100]], 0, !dbg [[DBG85]]
// AARCH64-NEXT:    [[TMP136:%.*]] = extractvalue { float, float } [[CALL100]], 1, !dbg [[DBG85]]
// AARCH64-NEXT:    [[CONV101:%.*]] = fptosi float [[TMP135]] to i32, !dbg [[DBG83]]
// AARCH64-NEXT:    [[CONV102:%.*]] = fptosi float [[TMP136]] to i32, !dbg [[DBG83]]
// AARCH64-NEXT:    [[ATOMIC_TEMP97_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP97]], i32 0, i32 0, !dbg [[DBG84]]
// AARCH64-NEXT:    [[ATOMIC_TEMP97_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP97]], i32 0, i32 1, !dbg [[DBG84]]
// AARCH64-NEXT:    store i32 [[CONV101]], i32* [[ATOMIC_TEMP97_REALP]], align 4, !dbg [[DBG84]]
// AARCH64-NEXT:    store i32 [[CONV102]], i32* [[ATOMIC_TEMP97_IMAGP]], align 4, !dbg [[DBG84]]
// AARCH64-NEXT:    [[TMP137:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP95]] to i8*, !dbg [[DBG84]]
// AARCH64-NEXT:    [[TMP138:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP97]] to i8*, !dbg [[DBG84]]
// AARCH64-NEXT:    [[CALL103:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP137]], i8* noundef [[TMP138]], i32 noundef 0, i32 noundef 0), !dbg [[DBG84]]
// AARCH64-NEXT:    br i1 [[CALL103]], label [[ATOMIC_EXIT104:%.*]], label [[ATOMIC_CONT96]], !dbg [[DBG84]]
// AARCH64:       atomic_exit104:
// AARCH64-NEXT:    [[TMP139:%.*]] = load double, double* @dv, align 8, !dbg [[DBG86:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD105:%.*]] = load atomic i16, i16* @sx monotonic, align 2, !dbg [[DBG87:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT106:%.*]], !dbg [[DBG87]]
// AARCH64:       atomic_cont106:
// AARCH64-NEXT:    [[TMP140:%.*]] = phi i16 [ [[ATOMIC_LOAD105]], [[ATOMIC_EXIT104]] ], [ [[TMP143:%.*]], [[ATOMIC_CONT106]] ], !dbg [[DBG87]]
// AARCH64-NEXT:    [[CONV108:%.*]] = sext i16 [[TMP140]] to i32, !dbg [[DBG87]]
// AARCH64-NEXT:    [[CONV109:%.*]] = sitofp i32 [[CONV108]] to double, !dbg [[DBG87]]
// AARCH64-NEXT:    [[ADD110:%.*]] = fadd double [[CONV109]], [[TMP139]], !dbg [[DBG88:![0-9]+]]
// AARCH64-NEXT:    [[CONV111:%.*]] = fptosi double [[ADD110]] to i16, !dbg [[DBG87]]
// AARCH64-NEXT:    store i16 [[CONV111]], i16* [[ATOMIC_TEMP107]], align 2, !dbg [[DBG87]]
// AARCH64-NEXT:    [[TMP141:%.*]] = load i16, i16* [[ATOMIC_TEMP107]], align 2, !dbg [[DBG87]]
// AARCH64-NEXT:    [[TMP142:%.*]] = cmpxchg i16* @sx, i16 [[TMP140]], i16 [[TMP141]] monotonic monotonic, align 2, !dbg [[DBG87]]
// AARCH64-NEXT:    [[TMP143]] = extractvalue { i16, i1 } [[TMP142]], 0, !dbg [[DBG87]]
// AARCH64-NEXT:    [[TMP144:%.*]] = extractvalue { i16, i1 } [[TMP142]], 1, !dbg [[DBG87]]
// AARCH64-NEXT:    br i1 [[TMP144]], label [[ATOMIC_EXIT112:%.*]], label [[ATOMIC_CONT106]], !dbg [[DBG87]]
// AARCH64:       atomic_exit112:
// AARCH64-NEXT:    [[TMP145:%.*]] = load fp128, fp128* @ldv, align 16, !dbg [[DBG89:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD113:%.*]] = load atomic i8, i8* @bx monotonic, align 1, !dbg [[DBG90:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT114:%.*]], !dbg [[DBG90]]
// AARCH64:       atomic_cont114:
// AARCH64-NEXT:    [[TMP146:%.*]] = phi i8 [ [[ATOMIC_LOAD113]], [[ATOMIC_EXIT112]] ], [ [[TMP149:%.*]], [[ATOMIC_CONT114]] ], !dbg [[DBG90]]
// AARCH64-NEXT:    [[TOBOOL116:%.*]] = trunc i8 [[TMP146]] to i1, !dbg [[DBG90]]
// AARCH64-NEXT:    [[CONV117:%.*]] = zext i1 [[TOBOOL116]] to i32, !dbg [[DBG90]]
// AARCH64-NEXT:    [[CONV118:%.*]] = sitofp i32 [[CONV117]] to fp128, !dbg [[DBG90]]
// AARCH64-NEXT:    [[MUL119:%.*]] = fmul fp128 [[TMP145]], [[CONV118]], !dbg [[DBG91:![0-9]+]]
// AARCH64-NEXT:    [[TOBOOL120:%.*]] = fcmp une fp128 [[MUL119]], 0xL00000000000000000000000000000000, !dbg [[DBG89]]
// AARCH64-NEXT:    [[FROMBOOL121:%.*]] = zext i1 [[TOBOOL120]] to i8, !dbg [[DBG90]]
// AARCH64-NEXT:    store i8 [[FROMBOOL121]], i8* [[ATOMIC_TEMP115]], align 1, !dbg [[DBG90]]
// AARCH64-NEXT:    [[TMP147:%.*]] = load i8, i8* [[ATOMIC_TEMP115]], align 1, !dbg [[DBG90]]
// AARCH64-NEXT:    [[TMP148:%.*]] = cmpxchg i8* @bx, i8 [[TMP146]], i8 [[TMP147]] release monotonic, align 1, !dbg [[DBG90]]
// AARCH64-NEXT:    [[TMP149]] = extractvalue { i8, i1 } [[TMP148]], 0, !dbg [[DBG90]]
// AARCH64-NEXT:    [[TMP150:%.*]] = extractvalue { i8, i1 } [[TMP148]], 1, !dbg [[DBG90]]
// AARCH64-NEXT:    br i1 [[TMP150]], label [[ATOMIC_EXIT122:%.*]], label [[ATOMIC_CONT114]], !dbg [[DBG90]]
// AARCH64:       atomic_exit122:
// AARCH64-NEXT:    fence release
// AARCH64-NEXT:    [[CIV_REAL123:%.*]] = load i32, i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 0), align 4, !dbg [[DBG92:![0-9]+]]
// AARCH64-NEXT:    [[CIV_IMAG124:%.*]] = load i32, i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 1), align 4, !dbg [[DBG92]]
// AARCH64-NEXT:    [[ATOMIC_LOAD125:%.*]] = load atomic i8, i8* @bx monotonic, align 1, !dbg [[DBG93:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT126:%.*]], !dbg [[DBG93]]
// AARCH64:       atomic_cont126:
// AARCH64-NEXT:    [[TMP151:%.*]] = phi i8 [ [[ATOMIC_LOAD125]], [[ATOMIC_EXIT122]] ], [ [[TMP154:%.*]], [[ATOMIC_CONT126]] ], !dbg [[DBG93]]
// AARCH64-NEXT:    [[TOBOOL128:%.*]] = trunc i8 [[TMP151]] to i1, !dbg [[DBG93]]
// AARCH64-NEXT:    [[CONV129:%.*]] = zext i1 [[TOBOOL128]] to i32, !dbg [[DBG93]]
// AARCH64-NEXT:    [[SUB_R130:%.*]] = sub i32 [[CIV_REAL123]], [[CONV129]], !dbg [[DBG94:![0-9]+]]
// AARCH64-NEXT:    [[SUB_I131:%.*]] = sub i32 [[CIV_IMAG124]], 0, !dbg [[DBG94]]
// AARCH64-NEXT:    [[TOBOOL132:%.*]] = icmp ne i32 [[SUB_R130]], 0, !dbg [[DBG92]]
// AARCH64-NEXT:    [[TOBOOL133:%.*]] = icmp ne i32 [[SUB_I131]], 0, !dbg [[DBG92]]
// AARCH64-NEXT:    [[TOBOOL134:%.*]] = or i1 [[TOBOOL132]], [[TOBOOL133]], !dbg [[DBG92]]
// AARCH64-NEXT:    [[FROMBOOL135:%.*]] = zext i1 [[TOBOOL134]] to i8, !dbg [[DBG93]]
// AARCH64-NEXT:    store i8 [[FROMBOOL135]], i8* [[ATOMIC_TEMP127]], align 1, !dbg [[DBG93]]
// AARCH64-NEXT:    [[TMP152:%.*]] = load i8, i8* [[ATOMIC_TEMP127]], align 1, !dbg [[DBG93]]
// AARCH64-NEXT:    [[TMP153:%.*]] = cmpxchg i8* @bx, i8 [[TMP151]], i8 [[TMP152]] monotonic monotonic, align 1, !dbg [[DBG93]]
// AARCH64-NEXT:    [[TMP154]] = extractvalue { i8, i1 } [[TMP153]], 0, !dbg [[DBG93]]
// AARCH64-NEXT:    [[TMP155:%.*]] = extractvalue { i8, i1 } [[TMP153]], 1, !dbg [[DBG93]]
// AARCH64-NEXT:    br i1 [[TMP155]], label [[ATOMIC_EXIT136:%.*]], label [[ATOMIC_CONT126]], !dbg [[DBG93]]
// AARCH64:       atomic_exit136:
// AARCH64-NEXT:    [[TMP156:%.*]] = load i16, i16* @sv, align 2, !dbg [[DBG95:![0-9]+]]
// AARCH64-NEXT:    [[TMP157:%.*]] = load i8, i8* @bv, align 1, !dbg [[DBG96:![0-9]+]]
// AARCH64-NEXT:    [[TOBOOL137:%.*]] = trunc i8 [[TMP157]] to i1, !dbg [[DBG96]]
// AARCH64-NEXT:    [[CONV138:%.*]] = zext i1 [[TOBOOL137]] to i32, !dbg [[DBG96]]
// AARCH64-NEXT:    [[ATOMIC_LOAD139:%.*]] = load atomic i128, i128* bitcast (<4 x i32>* @int4x to i128*) monotonic, align 16, !dbg [[DBG97:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT140:%.*]], !dbg [[DBG97]]
// AARCH64:       atomic_cont140:
// AARCH64-NEXT:    [[TMP158:%.*]] = phi i128 [ [[ATOMIC_LOAD139]], [[ATOMIC_EXIT136]] ], [ [[TMP165:%.*]], [[ATOMIC_CONT140]] ], !dbg [[DBG97]]
// AARCH64-NEXT:    [[TMP159:%.*]] = bitcast <4 x i32>* [[ATOMIC_TEMP141]] to i128*, !dbg [[DBG97]]
// AARCH64-NEXT:    store i128 [[TMP158]], i128* [[TMP159]], align 16, !dbg [[DBG97]]
// AARCH64-NEXT:    [[TMP160:%.*]] = bitcast i128 [[TMP158]] to <4 x i32>, !dbg [[DBG97]]
// AARCH64-NEXT:    store <4 x i32> [[TMP160]], <4 x i32>* [[ATOMIC_TEMP142]], align 16, !dbg [[DBG97]]
// AARCH64-NEXT:    [[TMP161:%.*]] = load <4 x i32>, <4 x i32>* [[ATOMIC_TEMP142]], align 16, !dbg [[DBG97]]
// AARCH64-NEXT:    [[VECEXT:%.*]] = extractelement <4 x i32> [[TMP161]], i16 [[TMP156]], !dbg [[DBG97]]
// AARCH64-NEXT:    [[OR:%.*]] = or i32 [[VECEXT]], [[CONV138]], !dbg [[DBG98:![0-9]+]]
// AARCH64-NEXT:    [[TMP162:%.*]] = load <4 x i32>, <4 x i32>* [[ATOMIC_TEMP141]], align 16, !dbg [[DBG97]]
// AARCH64-NEXT:    [[VECINS:%.*]] = insertelement <4 x i32> [[TMP162]], i32 [[OR]], i16 [[TMP156]], !dbg [[DBG97]]
// AARCH64-NEXT:    store <4 x i32> [[VECINS]], <4 x i32>* [[ATOMIC_TEMP141]], align 16, !dbg [[DBG97]]
// AARCH64-NEXT:    [[TMP163:%.*]] = load i128, i128* [[TMP159]], align 16, !dbg [[DBG97]]
// AARCH64-NEXT:    [[TMP164:%.*]] = cmpxchg i128* bitcast (<4 x i32>* @int4x to i128*), i128 [[TMP158]], i128 [[TMP163]] monotonic monotonic, align 16, !dbg [[DBG97]]
// AARCH64-NEXT:    [[TMP165]] = extractvalue { i128, i1 } [[TMP164]], 0, !dbg [[DBG97]]
// AARCH64-NEXT:    [[TMP166:%.*]] = extractvalue { i128, i1 } [[TMP164]], 1, !dbg [[DBG97]]
// AARCH64-NEXT:    br i1 [[TMP166]], label [[ATOMIC_EXIT143:%.*]], label [[ATOMIC_CONT140]], !dbg [[DBG97]]
// AARCH64:       atomic_exit143:
// AARCH64-NEXT:    [[TMP167:%.*]] = load fp128, fp128* @ldv, align 16, !dbg [[DBG99:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD144:%.*]] = load atomic i32, i32* bitcast (i8* getelementptr (i8, i8* bitcast (%struct.BitFields* @bfx to i8*), i64 4) to i32*) monotonic, align 4, !dbg [[DBG100:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT145:%.*]], !dbg [[DBG100]]
// AARCH64:       atomic_cont145:
// AARCH64-NEXT:    [[TMP168:%.*]] = phi i32 [ [[ATOMIC_LOAD144]], [[ATOMIC_EXIT143]] ], [ [[TMP171:%.*]], [[ATOMIC_CONT145]] ], !dbg [[DBG100]]
// AARCH64-NEXT:    store i32 [[TMP168]], i32* [[ATOMIC_TEMP146]], align 4, !dbg [[DBG100]]
// AARCH64-NEXT:    store i32 [[TMP168]], i32* [[ATOMIC_TEMP147]], align 4, !dbg [[DBG100]]
// AARCH64-NEXT:    [[BF_LOAD:%.*]] = load i32, i32* [[ATOMIC_TEMP147]], align 4, !dbg [[DBG100]]
// AARCH64-NEXT:    [[BF_SHL:%.*]] = shl i32 [[BF_LOAD]], 1, !dbg [[DBG100]]
// AARCH64-NEXT:    [[BF_ASHR:%.*]] = ashr i32 [[BF_SHL]], 1, !dbg [[DBG100]]
// AARCH64-NEXT:    [[CONV148:%.*]] = sitofp i32 [[BF_ASHR]] to fp128, !dbg [[DBG101:![0-9]+]]
// AARCH64-NEXT:    [[SUB149:%.*]] = fsub fp128 [[CONV148]], [[TMP167]], !dbg [[DBG102:![0-9]+]]
// AARCH64-NEXT:    [[CONV150:%.*]] = fptosi fp128 [[SUB149]] to i32, !dbg [[DBG101]]
// AARCH64-NEXT:    [[BF_LOAD151:%.*]] = load i32, i32* [[ATOMIC_TEMP146]], align 4, !dbg [[DBG100]]
// AARCH64-NEXT:    [[BF_VALUE:%.*]] = and i32 [[CONV150]], 2147483647, !dbg [[DBG100]]
// AARCH64-NEXT:    [[BF_CLEAR:%.*]] = and i32 [[BF_LOAD151]], -2147483648, !dbg [[DBG100]]
// AARCH64-NEXT:    [[BF_SET:%.*]] = or i32 [[BF_CLEAR]], [[BF_VALUE]], !dbg [[DBG100]]
// AARCH64-NEXT:    store i32 [[BF_SET]], i32* [[ATOMIC_TEMP146]], align 4, !dbg [[DBG100]]
// AARCH64-NEXT:    [[TMP169:%.*]] = load i32, i32* [[ATOMIC_TEMP146]], align 4, !dbg [[DBG100]]
// AARCH64-NEXT:    [[TMP170:%.*]] = cmpxchg i32* bitcast (i8* getelementptr (i8, i8* bitcast (%struct.BitFields* @bfx to i8*), i64 4) to i32*), i32 [[TMP168]], i32 [[TMP169]] monotonic monotonic, align 4, !dbg [[DBG100]]
// AARCH64-NEXT:    [[TMP171]] = extractvalue { i32, i1 } [[TMP170]], 0, !dbg [[DBG100]]
// AARCH64-NEXT:    [[TMP172:%.*]] = extractvalue { i32, i1 } [[TMP170]], 1, !dbg [[DBG100]]
// AARCH64-NEXT:    br i1 [[TMP172]], label [[ATOMIC_EXIT152:%.*]], label [[ATOMIC_CONT145]], !dbg [[DBG100]]
// AARCH64:       atomic_exit152:
// AARCH64-NEXT:    [[TMP173:%.*]] = load fp128, fp128* @ldv, align 16, !dbg [[DBG103:![0-9]+]]
// AARCH64-NEXT:    [[TMP174:%.*]] = bitcast i32* [[ATOMIC_TEMP153]] to i8*, !dbg [[DBG104:![0-9]+]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 4, i8* noundef getelementptr (i8, i8* bitcast (%struct.BitFields_packed* @bfx_packed to i8*), i64 4), i8* noundef [[TMP174]], i32 noundef 0), !dbg [[DBG104]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT154:%.*]], !dbg [[DBG104]]
// AARCH64:       atomic_cont154:
// AARCH64-NEXT:    [[TMP175:%.*]] = load i32, i32* [[ATOMIC_TEMP153]], align 1, !dbg [[DBG104]]
// AARCH64-NEXT:    store i32 [[TMP175]], i32* [[ATOMIC_TEMP155]], align 1, !dbg [[DBG104]]
// AARCH64-NEXT:    [[TMP176:%.*]] = load i32, i32* [[ATOMIC_TEMP153]], align 1, !dbg [[DBG104]]
// AARCH64-NEXT:    store i32 [[TMP176]], i32* [[ATOMIC_TEMP156]], align 4, !dbg [[DBG104]]
// AARCH64-NEXT:    [[BF_LOAD157:%.*]] = load i32, i32* [[ATOMIC_TEMP156]], align 1, !dbg [[DBG104]]
// AARCH64-NEXT:    [[BF_SHL158:%.*]] = shl i32 [[BF_LOAD157]], 1, !dbg [[DBG104]]
// AARCH64-NEXT:    [[BF_ASHR159:%.*]] = ashr i32 [[BF_SHL158]], 1, !dbg [[DBG104]]
// AARCH64-NEXT:    [[CONV160:%.*]] = sitofp i32 [[BF_ASHR159]] to fp128, !dbg [[DBG105:![0-9]+]]
// AARCH64-NEXT:    [[MUL161:%.*]] = fmul fp128 [[CONV160]], [[TMP173]], !dbg [[DBG106:![0-9]+]]
// AARCH64-NEXT:    [[CONV162:%.*]] = fptosi fp128 [[MUL161]] to i32, !dbg [[DBG105]]
// AARCH64-NEXT:    [[BF_LOAD163:%.*]] = load i32, i32* [[ATOMIC_TEMP155]], align 1, !dbg [[DBG104]]
// AARCH64-NEXT:    [[BF_VALUE164:%.*]] = and i32 [[CONV162]], 2147483647, !dbg [[DBG104]]
// AARCH64-NEXT:    [[BF_CLEAR165:%.*]] = and i32 [[BF_LOAD163]], -2147483648, !dbg [[DBG104]]
// AARCH64-NEXT:    [[BF_SET166:%.*]] = or i32 [[BF_CLEAR165]], [[BF_VALUE164]], !dbg [[DBG104]]
// AARCH64-NEXT:    store i32 [[BF_SET166]], i32* [[ATOMIC_TEMP155]], align 1, !dbg [[DBG104]]
// AARCH64-NEXT:    [[TMP177:%.*]] = bitcast i32* [[ATOMIC_TEMP153]] to i8*, !dbg [[DBG104]]
// AARCH64-NEXT:    [[TMP178:%.*]] = bitcast i32* [[ATOMIC_TEMP155]] to i8*, !dbg [[DBG104]]
// AARCH64-NEXT:    [[CALL167:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 4, i8* noundef getelementptr (i8, i8* bitcast (%struct.BitFields_packed* @bfx_packed to i8*), i64 4), i8* noundef [[TMP177]], i8* noundef [[TMP178]], i32 noundef 0, i32 noundef 0), !dbg [[DBG104]]
// AARCH64-NEXT:    br i1 [[CALL167]], label [[ATOMIC_EXIT168:%.*]], label [[ATOMIC_CONT154]], !dbg [[DBG104]]
// AARCH64:       atomic_exit168:
// AARCH64-NEXT:    [[TMP179:%.*]] = load fp128, fp128* @ldv, align 16, !dbg [[DBG107:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD169:%.*]] = load atomic i32, i32* getelementptr inbounds ([[STRUCT_BITFIELDS2:%.*]], %struct.BitFields2* @bfx2, i32 0, i32 0) monotonic, align 4, !dbg [[DBG108:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT170:%.*]], !dbg [[DBG108]]
// AARCH64:       atomic_cont170:
// AARCH64-NEXT:    [[TMP180:%.*]] = phi i32 [ [[ATOMIC_LOAD169]], [[ATOMIC_EXIT168]] ], [ [[TMP183:%.*]], [[ATOMIC_CONT170]] ], !dbg [[DBG108]]
// AARCH64-NEXT:    store i32 [[TMP180]], i32* [[ATOMIC_TEMP171]], align 4, !dbg [[DBG108]]
// AARCH64-NEXT:    store i32 [[TMP180]], i32* [[ATOMIC_TEMP172]], align 4, !dbg [[DBG108]]
// AARCH64-NEXT:    [[BF_LOAD173:%.*]] = load i32, i32* [[ATOMIC_TEMP172]], align 4, !dbg [[DBG108]]
// AARCH64-NEXT:    [[BF_ASHR174:%.*]] = ashr i32 [[BF_LOAD173]], 31, !dbg [[DBG108]]
// AARCH64-NEXT:    [[CONV175:%.*]] = sitofp i32 [[BF_ASHR174]] to fp128, !dbg [[DBG109:![0-9]+]]
// AARCH64-NEXT:    [[SUB176:%.*]] = fsub fp128 [[CONV175]], [[TMP179]], !dbg [[DBG110:![0-9]+]]
// AARCH64-NEXT:    [[CONV177:%.*]] = fptosi fp128 [[SUB176]] to i32, !dbg [[DBG109]]
// AARCH64-NEXT:    [[BF_LOAD178:%.*]] = load i32, i32* [[ATOMIC_TEMP171]], align 4, !dbg [[DBG108]]
// AARCH64-NEXT:    [[BF_VALUE179:%.*]] = and i32 [[CONV177]], 1, !dbg [[DBG108]]
// AARCH64-NEXT:    [[BF_SHL180:%.*]] = shl i32 [[BF_VALUE179]], 31, !dbg [[DBG108]]
// AARCH64-NEXT:    [[BF_CLEAR181:%.*]] = and i32 [[BF_LOAD178]], 2147483647, !dbg [[DBG108]]
// AARCH64-NEXT:    [[BF_SET182:%.*]] = or i32 [[BF_CLEAR181]], [[BF_SHL180]], !dbg [[DBG108]]
// AARCH64-NEXT:    store i32 [[BF_SET182]], i32* [[ATOMIC_TEMP171]], align 4, !dbg [[DBG108]]
// AARCH64-NEXT:    [[TMP181:%.*]] = load i32, i32* [[ATOMIC_TEMP171]], align 4, !dbg [[DBG108]]
// AARCH64-NEXT:    [[TMP182:%.*]] = cmpxchg i32* getelementptr inbounds ([[STRUCT_BITFIELDS2]], %struct.BitFields2* @bfx2, i32 0, i32 0), i32 [[TMP180]], i32 [[TMP181]] monotonic monotonic, align 4, !dbg [[DBG108]]
// AARCH64-NEXT:    [[TMP183]] = extractvalue { i32, i1 } [[TMP182]], 0, !dbg [[DBG108]]
// AARCH64-NEXT:    [[TMP184:%.*]] = extractvalue { i32, i1 } [[TMP182]], 1, !dbg [[DBG108]]
// AARCH64-NEXT:    br i1 [[TMP184]], label [[ATOMIC_EXIT183:%.*]], label [[ATOMIC_CONT170]], !dbg [[DBG108]]
// AARCH64:       atomic_exit183:
// AARCH64-NEXT:    [[TMP185:%.*]] = load fp128, fp128* @ldv, align 16, !dbg [[DBG111:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD184:%.*]] = load atomic i8, i8* getelementptr (i8, i8* bitcast (%struct.BitFields2_packed* @bfx2_packed to i8*), i64 3) monotonic, align 1, !dbg [[DBG112:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT185:%.*]], !dbg [[DBG112]]
// AARCH64:       atomic_cont185:
// AARCH64-NEXT:    [[TMP186:%.*]] = phi i8 [ [[ATOMIC_LOAD184]], [[ATOMIC_EXIT183]] ], [ [[TMP192:%.*]], [[ATOMIC_CONT185]] ], !dbg [[DBG112]]
// AARCH64-NEXT:    [[TMP187:%.*]] = bitcast i32* [[ATOMIC_TEMP186]] to i8*, !dbg [[DBG112]]
// AARCH64-NEXT:    store i8 [[TMP186]], i8* [[TMP187]], align 1, !dbg [[DBG112]]
// AARCH64-NEXT:    [[TMP188:%.*]] = bitcast i32* [[ATOMIC_TEMP187]] to i8*, !dbg [[DBG112]]
// AARCH64-NEXT:    store i8 [[TMP186]], i8* [[TMP188]], align 1, !dbg [[DBG112]]
// AARCH64-NEXT:    [[BF_LOAD188:%.*]] = load i8, i8* [[TMP188]], align 1, !dbg [[DBG112]]
// AARCH64-NEXT:    [[BF_ASHR189:%.*]] = ashr i8 [[BF_LOAD188]], 7, !dbg [[DBG112]]
// AARCH64-NEXT:    [[BF_CAST:%.*]] = sext i8 [[BF_ASHR189]] to i32, !dbg [[DBG112]]
// AARCH64-NEXT:    [[CONV190:%.*]] = sitofp i32 [[BF_CAST]] to fp128, !dbg [[DBG113:![0-9]+]]
// AARCH64-NEXT:    [[DIV191:%.*]] = fdiv fp128 [[TMP185]], [[CONV190]], !dbg [[DBG114:![0-9]+]]
// AARCH64-NEXT:    [[CONV192:%.*]] = fptosi fp128 [[DIV191]] to i32, !dbg [[DBG111]]
// AARCH64-NEXT:    [[TMP189:%.*]] = trunc i32 [[CONV192]] to i8, !dbg [[DBG112]]
// AARCH64-NEXT:    [[BF_LOAD193:%.*]] = load i8, i8* [[TMP187]], align 1, !dbg [[DBG112]]
// AARCH64-NEXT:    [[BF_VALUE194:%.*]] = and i8 [[TMP189]], 1, !dbg [[DBG112]]
// AARCH64-NEXT:    [[BF_SHL195:%.*]] = shl i8 [[BF_VALUE194]], 7, !dbg [[DBG112]]
// AARCH64-NEXT:    [[BF_CLEAR196:%.*]] = and i8 [[BF_LOAD193]], 127, !dbg [[DBG112]]
// AARCH64-NEXT:    [[BF_SET197:%.*]] = or i8 [[BF_CLEAR196]], [[BF_SHL195]], !dbg [[DBG112]]
// AARCH64-NEXT:    store i8 [[BF_SET197]], i8* [[TMP187]], align 1, !dbg [[DBG112]]
// AARCH64-NEXT:    [[TMP190:%.*]] = load i8, i8* [[TMP187]], align 1, !dbg [[DBG112]]
// AARCH64-NEXT:    [[TMP191:%.*]] = cmpxchg i8* getelementptr (i8, i8* bitcast (%struct.BitFields2_packed* @bfx2_packed to i8*), i64 3), i8 [[TMP186]], i8 [[TMP190]] monotonic monotonic, align 1, !dbg [[DBG112]]
// AARCH64-NEXT:    [[TMP192]] = extractvalue { i8, i1 } [[TMP191]], 0, !dbg [[DBG112]]
// AARCH64-NEXT:    [[TMP193:%.*]] = extractvalue { i8, i1 } [[TMP191]], 1, !dbg [[DBG112]]
// AARCH64-NEXT:    br i1 [[TMP193]], label [[ATOMIC_EXIT198:%.*]], label [[ATOMIC_CONT185]], !dbg [[DBG112]]
// AARCH64:       atomic_exit198:
// AARCH64-NEXT:    [[TMP194:%.*]] = load fp128, fp128* @ldv, align 16, !dbg [[DBG115:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD199:%.*]] = load atomic i32, i32* getelementptr inbounds ([[STRUCT_BITFIELDS3:%.*]], %struct.BitFields3* @bfx3, i32 0, i32 0) monotonic, align 4, !dbg [[DBG116:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT200:%.*]], !dbg [[DBG116]]
// AARCH64:       atomic_cont200:
// AARCH64-NEXT:    [[TMP195:%.*]] = phi i32 [ [[ATOMIC_LOAD199]], [[ATOMIC_EXIT198]] ], [ [[TMP198:%.*]], [[ATOMIC_CONT200]] ], !dbg [[DBG116]]
// AARCH64-NEXT:    store i32 [[TMP195]], i32* [[ATOMIC_TEMP201]], align 4, !dbg [[DBG116]]
// AARCH64-NEXT:    store i32 [[TMP195]], i32* [[ATOMIC_TEMP202]], align 4, !dbg [[DBG116]]
// AARCH64-NEXT:    [[BF_LOAD203:%.*]] = load i32, i32* [[ATOMIC_TEMP202]], align 4, !dbg [[DBG116]]
// AARCH64-NEXT:    [[BF_SHL204:%.*]] = shl i32 [[BF_LOAD203]], 7, !dbg [[DBG116]]
// AARCH64-NEXT:    [[BF_ASHR205:%.*]] = ashr i32 [[BF_SHL204]], 18, !dbg [[DBG116]]
// AARCH64-NEXT:    [[CONV206:%.*]] = sitofp i32 [[BF_ASHR205]] to fp128, !dbg [[DBG117:![0-9]+]]
// AARCH64-NEXT:    [[DIV207:%.*]] = fdiv fp128 [[CONV206]], [[TMP194]], !dbg [[DBG118:![0-9]+]]
// AARCH64-NEXT:    [[CONV208:%.*]] = fptosi fp128 [[DIV207]] to i32, !dbg [[DBG117]]
// AARCH64-NEXT:    [[BF_LOAD209:%.*]] = load i32, i32* [[ATOMIC_TEMP201]], align 4, !dbg [[DBG116]]
// AARCH64-NEXT:    [[BF_VALUE210:%.*]] = and i32 [[CONV208]], 16383, !dbg [[DBG116]]
// AARCH64-NEXT:    [[BF_SHL211:%.*]] = shl i32 [[BF_VALUE210]], 11, !dbg [[DBG116]]
// AARCH64-NEXT:    [[BF_CLEAR212:%.*]] = and i32 [[BF_LOAD209]], -33552385, !dbg [[DBG116]]
// AARCH64-NEXT:    [[BF_SET213:%.*]] = or i32 [[BF_CLEAR212]], [[BF_SHL211]], !dbg [[DBG116]]
// AARCH64-NEXT:    store i32 [[BF_SET213]], i32* [[ATOMIC_TEMP201]], align 4, !dbg [[DBG116]]
// AARCH64-NEXT:    [[TMP196:%.*]] = load i32, i32* [[ATOMIC_TEMP201]], align 4, !dbg [[DBG116]]
// AARCH64-NEXT:    [[TMP197:%.*]] = cmpxchg i32* getelementptr inbounds ([[STRUCT_BITFIELDS3]], %struct.BitFields3* @bfx3, i32 0, i32 0), i32 [[TMP195]], i32 [[TMP196]] monotonic monotonic, align 4, !dbg [[DBG116]]
// AARCH64-NEXT:    [[TMP198]] = extractvalue { i32, i1 } [[TMP197]], 0, !dbg [[DBG116]]
// AARCH64-NEXT:    [[TMP199:%.*]] = extractvalue { i32, i1 } [[TMP197]], 1, !dbg [[DBG116]]
// AARCH64-NEXT:    br i1 [[TMP199]], label [[ATOMIC_EXIT214:%.*]], label [[ATOMIC_CONT200]], !dbg [[DBG116]]
// AARCH64:       atomic_exit214:
// AARCH64-NEXT:    [[TMP200:%.*]] = load fp128, fp128* @ldv, align 16, !dbg [[DBG119:![0-9]+]]
// AARCH64-NEXT:    [[TMP201:%.*]] = bitcast i32* [[ATOMIC_TEMP215]] to i24*, !dbg [[DBG120:![0-9]+]]
// AARCH64-NEXT:    [[TMP202:%.*]] = bitcast i24* [[TMP201]] to i8*, !dbg [[DBG120]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 3, i8* noundef getelementptr (i8, i8* bitcast (%struct.BitFields3_packed* @bfx3_packed to i8*), i64 1), i8* noundef [[TMP202]], i32 noundef 0), !dbg [[DBG120]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT216:%.*]], !dbg [[DBG120]]
// AARCH64:       atomic_cont216:
// AARCH64-NEXT:    [[TMP203:%.*]] = bitcast i32* [[ATOMIC_TEMP217]] to i24*, !dbg [[DBG120]]
// AARCH64-NEXT:    [[TMP204:%.*]] = load i24, i24* [[TMP201]], align 1, !dbg [[DBG120]]
// AARCH64-NEXT:    store i24 [[TMP204]], i24* [[TMP203]], align 1, !dbg [[DBG120]]
// AARCH64-NEXT:    [[TMP205:%.*]] = load i24, i24* [[TMP201]], align 1, !dbg [[DBG120]]
// AARCH64-NEXT:    [[TMP206:%.*]] = bitcast i32* [[ATOMIC_TEMP218]] to i24*, !dbg [[DBG120]]
// AARCH64-NEXT:    store i24 [[TMP205]], i24* [[TMP206]], align 1, !dbg [[DBG120]]
// AARCH64-NEXT:    [[BF_LOAD219:%.*]] = load i24, i24* [[TMP206]], align 1, !dbg [[DBG120]]
// AARCH64-NEXT:    [[BF_SHL220:%.*]] = shl i24 [[BF_LOAD219]], 7, !dbg [[DBG120]]
// AARCH64-NEXT:    [[BF_ASHR221:%.*]] = ashr i24 [[BF_SHL220]], 10, !dbg [[DBG120]]
// AARCH64-NEXT:    [[BF_CAST222:%.*]] = sext i24 [[BF_ASHR221]] to i32, !dbg [[DBG120]]
// AARCH64-NEXT:    [[CONV223:%.*]] = sitofp i32 [[BF_CAST222]] to fp128, !dbg [[DBG121:![0-9]+]]
// AARCH64-NEXT:    [[ADD224:%.*]] = fadd fp128 [[CONV223]], [[TMP200]], !dbg [[DBG122:![0-9]+]]
// AARCH64-NEXT:    [[CONV225:%.*]] = fptosi fp128 [[ADD224]] to i32, !dbg [[DBG121]]
// AARCH64-NEXT:    [[TMP207:%.*]] = trunc i32 [[CONV225]] to i24, !dbg [[DBG120]]
// AARCH64-NEXT:    [[BF_LOAD226:%.*]] = load i24, i24* [[TMP203]], align 1, !dbg [[DBG120]]
// AARCH64-NEXT:    [[BF_VALUE227:%.*]] = and i24 [[TMP207]], 16383, !dbg [[DBG120]]
// AARCH64-NEXT:    [[BF_SHL228:%.*]] = shl i24 [[BF_VALUE227]], 3, !dbg [[DBG120]]
// AARCH64-NEXT:    [[BF_CLEAR229:%.*]] = and i24 [[BF_LOAD226]], -131065, !dbg [[DBG120]]
// AARCH64-NEXT:    [[BF_SET230:%.*]] = or i24 [[BF_CLEAR229]], [[BF_SHL228]], !dbg [[DBG120]]
// AARCH64-NEXT:    store i24 [[BF_SET230]], i24* [[TMP203]], align 1, !dbg [[DBG120]]
// AARCH64-NEXT:    [[TMP208:%.*]] = bitcast i24* [[TMP201]] to i8*, !dbg [[DBG120]]
// AARCH64-NEXT:    [[TMP209:%.*]] = bitcast i24* [[TMP203]] to i8*, !dbg [[DBG120]]
// AARCH64-NEXT:    [[CALL231:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 3, i8* noundef getelementptr (i8, i8* bitcast (%struct.BitFields3_packed* @bfx3_packed to i8*), i64 1), i8* noundef [[TMP208]], i8* noundef [[TMP209]], i32 noundef 0, i32 noundef 0), !dbg [[DBG120]]
// AARCH64-NEXT:    br i1 [[CALL231]], label [[ATOMIC_EXIT232:%.*]], label [[ATOMIC_CONT216]], !dbg [[DBG120]]
// AARCH64:       atomic_exit232:
// AARCH64-NEXT:    [[TMP210:%.*]] = load fp128, fp128* @ldv, align 16, !dbg [[DBG123:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD233:%.*]] = load atomic i64, i64* bitcast (%struct.BitFields4* @bfx4 to i64*) monotonic, align 8, !dbg [[DBG124:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT234:%.*]], !dbg [[DBG124]]
// AARCH64:       atomic_cont234:
// AARCH64-NEXT:    [[TMP211:%.*]] = phi i64 [ [[ATOMIC_LOAD233]], [[ATOMIC_EXIT232]] ], [ [[TMP215:%.*]], [[ATOMIC_CONT234]] ], !dbg [[DBG124]]
// AARCH64-NEXT:    store i64 [[TMP211]], i64* [[ATOMIC_TEMP235]], align 8, !dbg [[DBG124]]
// AARCH64-NEXT:    store i64 [[TMP211]], i64* [[ATOMIC_TEMP236]], align 8, !dbg [[DBG124]]
// AARCH64-NEXT:    [[BF_LOAD237:%.*]] = load i64, i64* [[ATOMIC_TEMP236]], align 8, !dbg [[DBG124]]
// AARCH64-NEXT:    [[BF_SHL238:%.*]] = shl i64 [[BF_LOAD237]], 47, !dbg [[DBG124]]
// AARCH64-NEXT:    [[BF_ASHR239:%.*]] = ashr i64 [[BF_SHL238]], 63, !dbg [[DBG124]]
// AARCH64-NEXT:    [[BF_CAST240:%.*]] = trunc i64 [[BF_ASHR239]] to i32, !dbg [[DBG124]]
// AARCH64-NEXT:    [[CONV241:%.*]] = sitofp i32 [[BF_CAST240]] to fp128, !dbg [[DBG125:![0-9]+]]
// AARCH64-NEXT:    [[MUL242:%.*]] = fmul fp128 [[CONV241]], [[TMP210]], !dbg [[DBG126:![0-9]+]]
// AARCH64-NEXT:    [[CONV243:%.*]] = fptosi fp128 [[MUL242]] to i32, !dbg [[DBG125]]
// AARCH64-NEXT:    [[TMP212:%.*]] = zext i32 [[CONV243]] to i64, !dbg [[DBG124]]
// AARCH64-NEXT:    [[BF_LOAD244:%.*]] = load i64, i64* [[ATOMIC_TEMP235]], align 8, !dbg [[DBG124]]
// AARCH64-NEXT:    [[BF_VALUE245:%.*]] = and i64 [[TMP212]], 1, !dbg [[DBG124]]
// AARCH64-NEXT:    [[BF_SHL246:%.*]] = shl i64 [[BF_VALUE245]], 16, !dbg [[DBG124]]
// AARCH64-NEXT:    [[BF_CLEAR247:%.*]] = and i64 [[BF_LOAD244]], -65537, !dbg [[DBG124]]
// AARCH64-NEXT:    [[BF_SET248:%.*]] = or i64 [[BF_CLEAR247]], [[BF_SHL246]], !dbg [[DBG124]]
// AARCH64-NEXT:    store i64 [[BF_SET248]], i64* [[ATOMIC_TEMP235]], align 8, !dbg [[DBG124]]
// AARCH64-NEXT:    [[TMP213:%.*]] = load i64, i64* [[ATOMIC_TEMP235]], align 8, !dbg [[DBG124]]
// AARCH64-NEXT:    [[TMP214:%.*]] = cmpxchg i64* bitcast (%struct.BitFields4* @bfx4 to i64*), i64 [[TMP211]], i64 [[TMP213]] monotonic monotonic, align 8, !dbg [[DBG124]]
// AARCH64-NEXT:    [[TMP215]] = extractvalue { i64, i1 } [[TMP214]], 0, !dbg [[DBG124]]
// AARCH64-NEXT:    [[TMP216:%.*]] = extractvalue { i64, i1 } [[TMP214]], 1, !dbg [[DBG124]]
// AARCH64-NEXT:    br i1 [[TMP216]], label [[ATOMIC_EXIT249:%.*]], label [[ATOMIC_CONT234]], !dbg [[DBG124]]
// AARCH64:       atomic_exit249:
// AARCH64-NEXT:    [[TMP217:%.*]] = load fp128, fp128* @ldv, align 16, !dbg [[DBG127:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD250:%.*]] = load atomic i8, i8* getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED:%.*]], %struct.BitFields4_packed* @bfx4_packed, i32 0, i32 0, i64 2) monotonic, align 1, !dbg [[DBG128:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT251:%.*]], !dbg [[DBG128]]
// AARCH64:       atomic_cont251:
// AARCH64-NEXT:    [[TMP218:%.*]] = phi i8 [ [[ATOMIC_LOAD250]], [[ATOMIC_EXIT249]] ], [ [[TMP224:%.*]], [[ATOMIC_CONT251]] ], !dbg [[DBG128]]
// AARCH64-NEXT:    [[TMP219:%.*]] = bitcast i32* [[ATOMIC_TEMP252]] to i8*, !dbg [[DBG128]]
// AARCH64-NEXT:    store i8 [[TMP218]], i8* [[TMP219]], align 1, !dbg [[DBG128]]
// AARCH64-NEXT:    [[TMP220:%.*]] = bitcast i32* [[ATOMIC_TEMP253]] to i8*, !dbg [[DBG128]]
// AARCH64-NEXT:    store i8 [[TMP218]], i8* [[TMP220]], align 1, !dbg [[DBG128]]
// AARCH64-NEXT:    [[BF_LOAD254:%.*]] = load i8, i8* [[TMP220]], align 1, !dbg [[DBG128]]
// AARCH64-NEXT:    [[BF_SHL255:%.*]] = shl i8 [[BF_LOAD254]], 7, !dbg [[DBG128]]
// AARCH64-NEXT:    [[BF_ASHR256:%.*]] = ashr i8 [[BF_SHL255]], 7, !dbg [[DBG128]]
// AARCH64-NEXT:    [[BF_CAST257:%.*]] = sext i8 [[BF_ASHR256]] to i32, !dbg [[DBG128]]
// AARCH64-NEXT:    [[CONV258:%.*]] = sitofp i32 [[BF_CAST257]] to fp128, !dbg [[DBG129:![0-9]+]]
// AARCH64-NEXT:    [[SUB259:%.*]] = fsub fp128 [[CONV258]], [[TMP217]], !dbg [[DBG130:![0-9]+]]
// AARCH64-NEXT:    [[CONV260:%.*]] = fptosi fp128 [[SUB259]] to i32, !dbg [[DBG129]]
// AARCH64-NEXT:    [[TMP221:%.*]] = trunc i32 [[CONV260]] to i8, !dbg [[DBG128]]
// AARCH64-NEXT:    [[BF_LOAD261:%.*]] = load i8, i8* [[TMP219]], align 1, !dbg [[DBG128]]
// AARCH64-NEXT:    [[BF_VALUE262:%.*]] = and i8 [[TMP221]], 1, !dbg [[DBG128]]
// AARCH64-NEXT:    [[BF_CLEAR263:%.*]] = and i8 [[BF_LOAD261]], -2, !dbg [[DBG128]]
// AARCH64-NEXT:    [[BF_SET264:%.*]] = or i8 [[BF_CLEAR263]], [[BF_VALUE262]], !dbg [[DBG128]]
// AARCH64-NEXT:    store i8 [[BF_SET264]], i8* [[TMP219]], align 1, !dbg [[DBG128]]
// AARCH64-NEXT:    [[TMP222:%.*]] = load i8, i8* [[TMP219]], align 1, !dbg [[DBG128]]
// AARCH64-NEXT:    [[TMP223:%.*]] = cmpxchg i8* getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED]], %struct.BitFields4_packed* @bfx4_packed, i32 0, i32 0, i64 2), i8 [[TMP218]], i8 [[TMP222]] monotonic monotonic, align 1, !dbg [[DBG128]]
// AARCH64-NEXT:    [[TMP224]] = extractvalue { i8, i1 } [[TMP223]], 0, !dbg [[DBG128]]
// AARCH64-NEXT:    [[TMP225:%.*]] = extractvalue { i8, i1 } [[TMP223]], 1, !dbg [[DBG128]]
// AARCH64-NEXT:    br i1 [[TMP225]], label [[ATOMIC_EXIT265:%.*]], label [[ATOMIC_CONT251]], !dbg [[DBG128]]
// AARCH64:       atomic_exit265:
// AARCH64-NEXT:    [[TMP226:%.*]] = load fp128, fp128* @ldv, align 16, !dbg [[DBG131:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD266:%.*]] = load atomic i64, i64* bitcast (%struct.BitFields4* @bfx4 to i64*) monotonic, align 8, !dbg [[DBG132:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT267:%.*]], !dbg [[DBG132]]
// AARCH64:       atomic_cont267:
// AARCH64-NEXT:    [[TMP227:%.*]] = phi i64 [ [[ATOMIC_LOAD266]], [[ATOMIC_EXIT265]] ], [ [[TMP230:%.*]], [[ATOMIC_CONT267]] ], !dbg [[DBG132]]
// AARCH64-NEXT:    store i64 [[TMP227]], i64* [[ATOMIC_TEMP268]], align 8, !dbg [[DBG132]]
// AARCH64-NEXT:    store i64 [[TMP227]], i64* [[ATOMIC_TEMP269]], align 8, !dbg [[DBG132]]
// AARCH64-NEXT:    [[BF_LOAD270:%.*]] = load i64, i64* [[ATOMIC_TEMP269]], align 8, !dbg [[DBG132]]
// AARCH64-NEXT:    [[BF_SHL271:%.*]] = shl i64 [[BF_LOAD270]], 40, !dbg [[DBG132]]
// AARCH64-NEXT:    [[BF_ASHR272:%.*]] = ashr i64 [[BF_SHL271]], 57, !dbg [[DBG132]]
// AARCH64-NEXT:    [[CONV273:%.*]] = sitofp i64 [[BF_ASHR272]] to fp128, !dbg [[DBG133:![0-9]+]]
// AARCH64-NEXT:    [[DIV274:%.*]] = fdiv fp128 [[CONV273]], [[TMP226]], !dbg [[DBG134:![0-9]+]]
// AARCH64-NEXT:    [[CONV275:%.*]] = fptosi fp128 [[DIV274]] to i64, !dbg [[DBG133]]
// AARCH64-NEXT:    [[BF_LOAD276:%.*]] = load i64, i64* [[ATOMIC_TEMP268]], align 8, !dbg [[DBG132]]
// AARCH64-NEXT:    [[BF_VALUE277:%.*]] = and i64 [[CONV275]], 127, !dbg [[DBG132]]
// AARCH64-NEXT:    [[BF_SHL278:%.*]] = shl i64 [[BF_VALUE277]], 17, !dbg [[DBG132]]
// AARCH64-NEXT:    [[BF_CLEAR279:%.*]] = and i64 [[BF_LOAD276]], -16646145, !dbg [[DBG132]]
// AARCH64-NEXT:    [[BF_SET280:%.*]] = or i64 [[BF_CLEAR279]], [[BF_SHL278]], !dbg [[DBG132]]
// AARCH64-NEXT:    store i64 [[BF_SET280]], i64* [[ATOMIC_TEMP268]], align 8, !dbg [[DBG132]]
// AARCH64-NEXT:    [[TMP228:%.*]] = load i64, i64* [[ATOMIC_TEMP268]], align 8, !dbg [[DBG132]]
// AARCH64-NEXT:    [[TMP229:%.*]] = cmpxchg i64* bitcast (%struct.BitFields4* @bfx4 to i64*), i64 [[TMP227]], i64 [[TMP228]] monotonic monotonic, align 8, !dbg [[DBG132]]
// AARCH64-NEXT:    [[TMP230]] = extractvalue { i64, i1 } [[TMP229]], 0, !dbg [[DBG132]]
// AARCH64-NEXT:    [[TMP231:%.*]] = extractvalue { i64, i1 } [[TMP229]], 1, !dbg [[DBG132]]
// AARCH64-NEXT:    br i1 [[TMP231]], label [[ATOMIC_EXIT281:%.*]], label [[ATOMIC_CONT267]], !dbg [[DBG132]]
// AARCH64:       atomic_exit281:
// AARCH64-NEXT:    [[TMP232:%.*]] = load fp128, fp128* @ldv, align 16, !dbg [[DBG135:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD282:%.*]] = load atomic i8, i8* getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED]], %struct.BitFields4_packed* @bfx4_packed, i32 0, i32 0, i64 2) monotonic, align 1, !dbg [[DBG136:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT283:%.*]], !dbg [[DBG136]]
// AARCH64:       atomic_cont283:
// AARCH64-NEXT:    [[TMP233:%.*]] = phi i8 [ [[ATOMIC_LOAD282]], [[ATOMIC_EXIT281]] ], [ [[TMP239:%.*]], [[ATOMIC_CONT283]] ], !dbg [[DBG136]]
// AARCH64-NEXT:    [[TMP234:%.*]] = bitcast i64* [[ATOMIC_TEMP284]] to i8*, !dbg [[DBG136]]
// AARCH64-NEXT:    store i8 [[TMP233]], i8* [[TMP234]], align 1, !dbg [[DBG136]]
// AARCH64-NEXT:    [[TMP235:%.*]] = bitcast i64* [[ATOMIC_TEMP285]] to i8*, !dbg [[DBG136]]
// AARCH64-NEXT:    store i8 [[TMP233]], i8* [[TMP235]], align 1, !dbg [[DBG136]]
// AARCH64-NEXT:    [[BF_LOAD286:%.*]] = load i8, i8* [[TMP235]], align 1, !dbg [[DBG136]]
// AARCH64-NEXT:    [[BF_ASHR287:%.*]] = ashr i8 [[BF_LOAD286]], 1, !dbg [[DBG136]]
// AARCH64-NEXT:    [[BF_CAST288:%.*]] = sext i8 [[BF_ASHR287]] to i64, !dbg [[DBG136]]
// AARCH64-NEXT:    [[CONV289:%.*]] = sitofp i64 [[BF_CAST288]] to fp128, !dbg [[DBG137:![0-9]+]]
// AARCH64-NEXT:    [[ADD290:%.*]] = fadd fp128 [[CONV289]], [[TMP232]], !dbg [[DBG138:![0-9]+]]
// AARCH64-NEXT:    [[CONV291:%.*]] = fptosi fp128 [[ADD290]] to i64, !dbg [[DBG137]]
// AARCH64-NEXT:    [[TMP236:%.*]] = trunc i64 [[CONV291]] to i8, !dbg [[DBG136]]
// AARCH64-NEXT:    [[BF_LOAD292:%.*]] = load i8, i8* [[TMP234]], align 1, !dbg [[DBG136]]
// AARCH64-NEXT:    [[BF_VALUE293:%.*]] = and i8 [[TMP236]], 127, !dbg [[DBG136]]
// AARCH64-NEXT:    [[BF_SHL294:%.*]] = shl i8 [[BF_VALUE293]], 1, !dbg [[DBG136]]
// AARCH64-NEXT:    [[BF_CLEAR295:%.*]] = and i8 [[BF_LOAD292]], 1, !dbg [[DBG136]]
// AARCH64-NEXT:    [[BF_SET296:%.*]] = or i8 [[BF_CLEAR295]], [[BF_SHL294]], !dbg [[DBG136]]
// AARCH64-NEXT:    store i8 [[BF_SET296]], i8* [[TMP234]], align 1, !dbg [[DBG136]]
// AARCH64-NEXT:    [[TMP237:%.*]] = load i8, i8* [[TMP234]], align 1, !dbg [[DBG136]]
// AARCH64-NEXT:    [[TMP238:%.*]] = cmpxchg i8* getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED]], %struct.BitFields4_packed* @bfx4_packed, i32 0, i32 0, i64 2), i8 [[TMP233]], i8 [[TMP237]] monotonic monotonic, align 1, !dbg [[DBG136]]
// AARCH64-NEXT:    [[TMP239]] = extractvalue { i8, i1 } [[TMP238]], 0, !dbg [[DBG136]]
// AARCH64-NEXT:    [[TMP240:%.*]] = extractvalue { i8, i1 } [[TMP238]], 1, !dbg [[DBG136]]
// AARCH64-NEXT:    br i1 [[TMP240]], label [[ATOMIC_EXIT297:%.*]], label [[ATOMIC_CONT283]], !dbg [[DBG136]]
// AARCH64:       atomic_exit297:
// AARCH64-NEXT:    [[TMP241:%.*]] = load i64, i64* @ulv, align 8, !dbg [[DBG139:![0-9]+]]
// AARCH64-NEXT:    [[CONV298:%.*]] = uitofp i64 [[TMP241]] to float, !dbg [[DBG139]]
// AARCH64-NEXT:    [[ATOMIC_LOAD299:%.*]] = load atomic i64, i64* bitcast (<2 x float>* @float2x to i64*) monotonic, align 8, !dbg [[DBG140:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT300:%.*]], !dbg [[DBG140]]
// AARCH64:       atomic_cont300:
// AARCH64-NEXT:    [[TMP242:%.*]] = phi i64 [ [[ATOMIC_LOAD299]], [[ATOMIC_EXIT297]] ], [ [[TMP251:%.*]], [[ATOMIC_CONT300]] ], !dbg [[DBG140]]
// AARCH64-NEXT:    [[TMP243:%.*]] = bitcast <2 x float>* [[ATOMIC_TEMP301]] to i64*, !dbg [[DBG140]]
// AARCH64-NEXT:    store i64 [[TMP242]], i64* [[TMP243]], align 8, !dbg [[DBG140]]
// AARCH64-NEXT:    [[TMP244:%.*]] = bitcast i64 [[TMP242]] to <2 x float>, !dbg [[DBG140]]
// AARCH64-NEXT:    store <2 x float> [[TMP244]], <2 x float>* [[ATOMIC_TEMP302]], align 8, !dbg [[DBG140]]
// AARCH64-NEXT:    [[TMP245:%.*]] = load <2 x float>, <2 x float>* [[ATOMIC_TEMP302]], align 8, !dbg [[DBG140]]
// AARCH64-NEXT:    [[TMP246:%.*]] = extractelement <2 x float> [[TMP245]], i64 0, !dbg [[DBG140]]
// AARCH64-NEXT:    [[SUB303:%.*]] = fsub float [[CONV298]], [[TMP246]], !dbg [[DBG141:![0-9]+]]
// AARCH64-NEXT:    [[TMP247:%.*]] = load <2 x float>, <2 x float>* [[ATOMIC_TEMP301]], align 8, !dbg [[DBG140]]
// AARCH64-NEXT:    [[TMP248:%.*]] = insertelement <2 x float> [[TMP247]], float [[SUB303]], i64 0, !dbg [[DBG140]]
// AARCH64-NEXT:    store <2 x float> [[TMP248]], <2 x float>* [[ATOMIC_TEMP301]], align 8, !dbg [[DBG140]]
// AARCH64-NEXT:    [[TMP249:%.*]] = load i64, i64* [[TMP243]], align 8, !dbg [[DBG140]]
// AARCH64-NEXT:    [[TMP250:%.*]] = cmpxchg i64* bitcast (<2 x float>* @float2x to i64*), i64 [[TMP242]], i64 [[TMP249]] monotonic monotonic, align 8, !dbg [[DBG140]]
// AARCH64-NEXT:    [[TMP251]] = extractvalue { i64, i1 } [[TMP250]], 0, !dbg [[DBG140]]
// AARCH64-NEXT:    [[TMP252:%.*]] = extractvalue { i64, i1 } [[TMP250]], 1, !dbg [[DBG140]]
// AARCH64-NEXT:    br i1 [[TMP252]], label [[ATOMIC_EXIT304:%.*]], label [[ATOMIC_CONT300]], !dbg [[DBG140]]
// AARCH64:       atomic_exit304:
// AARCH64-NEXT:    ret i32 0, !dbg [[DBG142:![0-9]+]]
//
