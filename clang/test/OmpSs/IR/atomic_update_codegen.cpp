// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --function-signature --include-generated-funcs
// RUN: %clang_cc1 -x c -triple x86_64-gnu-linux -verify -fompss-2 -disable-llvm-passes -ferror-limit 100 %s -emit-llvm -o - | FileCheck %s --check-prefixes=LIN64
// RUN: %clang_cc1 -x c -triple ppc64 -verify -fompss-2 -disable-llvm-passes -ferror-limit 100 %s -emit-llvm -o - | FileCheck %s --check-prefixes=PPC64
// RUN: %clang_cc1 -x c -triple aarch64 -verify -fompss-2 -disable-llvm-passes -ferror-limit 100 %s -emit-llvm -o - | FileCheck %s --check-prefixes=AARCH64
// expected-no-diagnostics
#ifndef HEADER
#define HEADER

_Bool bv, bx;
char cv, cx;
unsigned char ucv, ucx;
short sv, sx;
unsigned short usv, usx;
int iv, ix;
unsigned int uiv, uix;
long lv, lx;
unsigned long ulv, ulx;
long long llv, llx;
unsigned long long ullv, ullx;
float fv, fx;
double dv, dx;
long double ldv, ldx;
_Complex int civ, cix;
_Complex float cfv, cfx;
_Complex double cdv, cdx;

typedef int int4 __attribute__((__vector_size__(16)));
int4 int4x;

struct BitFields {
  int : 32;
  int a : 31;
} bfx;

struct BitFields_packed {
  int : 32;
  int a : 31;
} __attribute__ ((__packed__)) bfx_packed;

struct BitFields2 {
  int : 31;
  int a : 1;
} bfx2;

struct BitFields2_packed {
  int : 31;
  int a : 1;
} __attribute__ ((__packed__)) bfx2_packed;

struct BitFields3 {
  int : 11;
  int a : 14;
} bfx3;

struct BitFields3_packed {
  int : 11;
  int a : 14;
} __attribute__ ((__packed__)) bfx3_packed;

struct BitFields4 {
  short : 16;
  int a: 1;
  long b : 7;
} bfx4;

struct BitFields4_packed {
  short : 16;
  int a: 1;
  long b : 7;
} __attribute__ ((__packed__)) bfx4_packed;

typedef float float2 __attribute__((ext_vector_type(2)));
float2 float2x;

#if defined(__x86_64__)
// Register "0" is currently an invalid register for global register variables.
// Use "esp" instead of "0".
// register int rix __asm__("0");
register int rix __asm__("esp");
#endif

int main(void) {
#pragma oss atomic
  ++dv;
#pragma oss atomic
  bx++;
#pragma oss atomic update
  ++cx;
#pragma oss atomic
  ucx--;
#pragma oss atomic update
  --sx;
#pragma oss atomic
  usx += usv;
#pragma oss atomic update
  ix *= iv;
#pragma oss atomic
  uix -= uiv;
#pragma oss atomic update
  ix <<= iv;
#pragma oss atomic
  uix >>= uiv;
#pragma oss atomic update
  lx /= lv;
#pragma oss atomic
  ulx &= ulv;
#pragma oss atomic update
  llx ^= llv;
#pragma oss atomic
  ullx |= ullv;
#pragma oss atomic update
  fx = fx + fv;
#pragma oss atomic
  dx = dv - dx;
#pragma oss atomic update
  ldx = ldx * ldv;
// <Skip checks for complex calculations>
#pragma oss atomic
  cix = civ / cix;
// <Skip checks for complex calculations>
#pragma oss atomic update
  cfx = cfv + cfx;
// <Skip checks for complex calculations>
#pragma oss atomic seq_cst
  cdx = cdx - cdv;
#pragma oss atomic update
  ulx = ulx & bv;
#pragma oss atomic
  bx = cv & bx;
#pragma oss atomic update, seq_cst
  cx = cx >> ucv;
#pragma oss atomic update
  ulx = sv << ulx;
#pragma oss atomic
  lx = lx % usv;
#pragma oss atomic seq_cst, update
  uix = iv | uix;
#pragma oss atomic
  ix = ix & uiv;
// <Skip checks for complex calculations>
#pragma oss atomic update
  cix = lv + cix;
#pragma oss atomic
  fx = fx * ulv;
#pragma oss atomic update
  dx /= llv;
#pragma oss atomic
  ldx -= ullv;
// <Skip checks for complex calculations>
#pragma oss atomic update
  cix = fv / cix;
#pragma oss atomic
  sx = sx + dv;
#pragma oss atomic update release
  bx = ldv * bx;
#pragma oss atomic
  bx = civ - bx;
#pragma oss atomic update
  int4x[sv] |= bv;
#pragma oss atomic
  bfx.a = bfx.a - ldv;
#pragma oss atomic update
  bfx_packed.a *= ldv;
#pragma oss atomic
  bfx2.a -= ldv;
#pragma oss atomic update
  bfx2_packed.a = ldv / bfx2_packed.a;
#pragma oss atomic
  bfx3.a /= ldv;
#pragma oss atomic update
  bfx3_packed.a += ldv;
#pragma oss atomic
  bfx4.a = bfx4.a * ldv;
#pragma oss atomic relaxed update
  bfx4_packed.a -= ldv;
#pragma oss atomic
  bfx4.b /= ldv;
#pragma oss atomic update relaxed
  bfx4_packed.b += ldv;
#pragma oss atomic relaxed
  float2x.x = ulv - float2x.x;
#if defined(__x86_64__)
#pragma oss atomic seq_cst
  rix = dv / rix;
#endif
  return 0;
}

#endif
// LIN64-LABEL: define {{[^@]+}}@main
// LIN64-SAME: () #[[ATTR0:[0-9]+]] !dbg [[DBG6:![0-9]+]] {
// LIN64-NEXT:  entry:
// LIN64-NEXT:    [[RETVAL:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca i16, align 2
// LIN64-NEXT:    [[ATOMIC_TEMP5:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP9:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP13:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP17:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP21:%.*]] = alloca double, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP23:%.*]] = alloca x86_fp80, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP25:%.*]] = alloca x86_fp80, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP28:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP30:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP33:%.*]] = alloca { float, float }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP35:%.*]] = alloca { float, float }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP38:%.*]] = alloca { double, double }, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP40:%.*]] = alloca { double, double }, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP47:%.*]] = alloca i8, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP54:%.*]] = alloca i8, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP62:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP69:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP71:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP73:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP85:%.*]] = alloca float, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP91:%.*]] = alloca double, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP95:%.*]] = alloca x86_fp80, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP97:%.*]] = alloca x86_fp80, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP101:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP103:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[COERCE:%.*]] = alloca { float, float }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP113:%.*]] = alloca i16, align 2
// LIN64-NEXT:    [[ATOMIC_TEMP121:%.*]] = alloca i8, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP133:%.*]] = alloca i8, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP145:%.*]] = alloca <4 x i32>, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP147:%.*]] = alloca <4 x i32>, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP148:%.*]] = alloca <4 x i32>, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP153:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP154:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP160:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP162:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP163:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP178:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP179:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP193:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP194:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP208:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP209:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP222:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP224:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP225:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP242:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP243:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP259:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP260:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP275:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP276:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP291:%.*]] = alloca i64, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP292:%.*]] = alloca i64, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP308:%.*]] = alloca <2 x float>, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP309:%.*]] = alloca <2 x float>, align 8
// LIN64-NEXT:    store i32 0, ptr [[RETVAL]], align 4
// LIN64-NEXT:    [[TMP0:%.*]] = atomicrmw fadd ptr @dv, double 1.000000e+00 monotonic, align 8, !dbg [[DBG10:![0-9]+]]
// LIN64-NEXT:    [[TMP1:%.*]] = atomicrmw add ptr @bx, i8 1 monotonic, align 1, !dbg [[DBG11:![0-9]+]]
// LIN64-NEXT:    [[TMP2:%.*]] = atomicrmw add ptr @cx, i8 1 monotonic, align 1, !dbg [[DBG12:![0-9]+]]
// LIN64-NEXT:    [[TMP3:%.*]] = atomicrmw sub ptr @ucx, i8 1 monotonic, align 1, !dbg [[DBG13:![0-9]+]]
// LIN64-NEXT:    [[TMP4:%.*]] = atomicrmw sub ptr @sx, i16 1 monotonic, align 2, !dbg [[DBG14:![0-9]+]]
// LIN64-NEXT:    [[TMP5:%.*]] = load i16, ptr @usv, align 2, !dbg [[DBG15:![0-9]+]]
// LIN64-NEXT:    [[CONV:%.*]] = zext i16 [[TMP5]] to i32, !dbg [[DBG15]]
// LIN64-NEXT:    [[ATOMIC_LOAD:%.*]] = load atomic i16, ptr @usx monotonic, align 2, !dbg [[DBG16:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT:%.*]], !dbg [[DBG16]]
// LIN64:       atomic_cont:
// LIN64-NEXT:    [[TMP6:%.*]] = phi i16 [ [[ATOMIC_LOAD]], [[ENTRY:%.*]] ], [ [[TMP9:%.*]], [[ATOMIC_CONT]] ], !dbg [[DBG16]]
// LIN64-NEXT:    [[CONV1:%.*]] = zext i16 [[TMP6]] to i32, !dbg [[DBG16]]
// LIN64-NEXT:    [[ADD:%.*]] = add nsw i32 [[CONV1]], [[CONV]], !dbg [[DBG17:![0-9]+]]
// LIN64-NEXT:    [[CONV2:%.*]] = trunc i32 [[ADD]] to i16, !dbg [[DBG16]]
// LIN64-NEXT:    store i16 [[CONV2]], ptr [[ATOMIC_TEMP]], align 2, !dbg [[DBG16]]
// LIN64-NEXT:    [[TMP7:%.*]] = load i16, ptr [[ATOMIC_TEMP]], align 2, !dbg [[DBG16]]
// LIN64-NEXT:    [[TMP8:%.*]] = cmpxchg ptr @usx, i16 [[TMP6]], i16 [[TMP7]] monotonic monotonic, align 2, !dbg [[DBG16]]
// LIN64-NEXT:    [[TMP9]] = extractvalue { i16, i1 } [[TMP8]], 0, !dbg [[DBG16]]
// LIN64-NEXT:    [[TMP10:%.*]] = extractvalue { i16, i1 } [[TMP8]], 1, !dbg [[DBG16]]
// LIN64-NEXT:    br i1 [[TMP10]], label [[ATOMIC_EXIT:%.*]], label [[ATOMIC_CONT]], !dbg [[DBG16]]
// LIN64:       atomic_exit:
// LIN64-NEXT:    [[TMP11:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG18:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD3:%.*]] = load atomic i32, ptr @ix monotonic, align 4, !dbg [[DBG19:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT4:%.*]], !dbg [[DBG19]]
// LIN64:       atomic_cont4:
// LIN64-NEXT:    [[TMP12:%.*]] = phi i32 [ [[ATOMIC_LOAD3]], [[ATOMIC_EXIT]] ], [ [[TMP15:%.*]], [[ATOMIC_CONT4]] ], !dbg [[DBG19]]
// LIN64-NEXT:    [[MUL:%.*]] = mul nsw i32 [[TMP12]], [[TMP11]], !dbg [[DBG20:![0-9]+]]
// LIN64-NEXT:    store i32 [[MUL]], ptr [[ATOMIC_TEMP5]], align 4, !dbg [[DBG19]]
// LIN64-NEXT:    [[TMP13:%.*]] = load i32, ptr [[ATOMIC_TEMP5]], align 4, !dbg [[DBG19]]
// LIN64-NEXT:    [[TMP14:%.*]] = cmpxchg ptr @ix, i32 [[TMP12]], i32 [[TMP13]] monotonic monotonic, align 4, !dbg [[DBG19]]
// LIN64-NEXT:    [[TMP15]] = extractvalue { i32, i1 } [[TMP14]], 0, !dbg [[DBG19]]
// LIN64-NEXT:    [[TMP16:%.*]] = extractvalue { i32, i1 } [[TMP14]], 1, !dbg [[DBG19]]
// LIN64-NEXT:    br i1 [[TMP16]], label [[ATOMIC_EXIT6:%.*]], label [[ATOMIC_CONT4]], !dbg [[DBG19]]
// LIN64:       atomic_exit6:
// LIN64-NEXT:    [[TMP17:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG21:![0-9]+]]
// LIN64-NEXT:    [[TMP18:%.*]] = atomicrmw sub ptr @uix, i32 [[TMP17]] monotonic, align 4, !dbg [[DBG22:![0-9]+]]
// LIN64-NEXT:    [[TMP19:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG23:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD7:%.*]] = load atomic i32, ptr @ix monotonic, align 4, !dbg [[DBG24:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT8:%.*]], !dbg [[DBG24]]
// LIN64:       atomic_cont8:
// LIN64-NEXT:    [[TMP20:%.*]] = phi i32 [ [[ATOMIC_LOAD7]], [[ATOMIC_EXIT6]] ], [ [[TMP23:%.*]], [[ATOMIC_CONT8]] ], !dbg [[DBG24]]
// LIN64-NEXT:    [[SHL:%.*]] = shl i32 [[TMP20]], [[TMP19]], !dbg [[DBG25:![0-9]+]]
// LIN64-NEXT:    store i32 [[SHL]], ptr [[ATOMIC_TEMP9]], align 4, !dbg [[DBG24]]
// LIN64-NEXT:    [[TMP21:%.*]] = load i32, ptr [[ATOMIC_TEMP9]], align 4, !dbg [[DBG24]]
// LIN64-NEXT:    [[TMP22:%.*]] = cmpxchg ptr @ix, i32 [[TMP20]], i32 [[TMP21]] monotonic monotonic, align 4, !dbg [[DBG24]]
// LIN64-NEXT:    [[TMP23]] = extractvalue { i32, i1 } [[TMP22]], 0, !dbg [[DBG24]]
// LIN64-NEXT:    [[TMP24:%.*]] = extractvalue { i32, i1 } [[TMP22]], 1, !dbg [[DBG24]]
// LIN64-NEXT:    br i1 [[TMP24]], label [[ATOMIC_EXIT10:%.*]], label [[ATOMIC_CONT8]], !dbg [[DBG24]]
// LIN64:       atomic_exit10:
// LIN64-NEXT:    [[TMP25:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG26:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD11:%.*]] = load atomic i32, ptr @uix monotonic, align 4, !dbg [[DBG27:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT12:%.*]], !dbg [[DBG27]]
// LIN64:       atomic_cont12:
// LIN64-NEXT:    [[TMP26:%.*]] = phi i32 [ [[ATOMIC_LOAD11]], [[ATOMIC_EXIT10]] ], [ [[TMP29:%.*]], [[ATOMIC_CONT12]] ], !dbg [[DBG27]]
// LIN64-NEXT:    [[SHR:%.*]] = lshr i32 [[TMP26]], [[TMP25]], !dbg [[DBG28:![0-9]+]]
// LIN64-NEXT:    store i32 [[SHR]], ptr [[ATOMIC_TEMP13]], align 4, !dbg [[DBG27]]
// LIN64-NEXT:    [[TMP27:%.*]] = load i32, ptr [[ATOMIC_TEMP13]], align 4, !dbg [[DBG27]]
// LIN64-NEXT:    [[TMP28:%.*]] = cmpxchg ptr @uix, i32 [[TMP26]], i32 [[TMP27]] monotonic monotonic, align 4, !dbg [[DBG27]]
// LIN64-NEXT:    [[TMP29]] = extractvalue { i32, i1 } [[TMP28]], 0, !dbg [[DBG27]]
// LIN64-NEXT:    [[TMP30:%.*]] = extractvalue { i32, i1 } [[TMP28]], 1, !dbg [[DBG27]]
// LIN64-NEXT:    br i1 [[TMP30]], label [[ATOMIC_EXIT14:%.*]], label [[ATOMIC_CONT12]], !dbg [[DBG27]]
// LIN64:       atomic_exit14:
// LIN64-NEXT:    [[TMP31:%.*]] = load i64, ptr @lv, align 8, !dbg [[DBG29:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD15:%.*]] = load atomic i64, ptr @lx monotonic, align 8, !dbg [[DBG30:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT16:%.*]], !dbg [[DBG30]]
// LIN64:       atomic_cont16:
// LIN64-NEXT:    [[TMP32:%.*]] = phi i64 [ [[ATOMIC_LOAD15]], [[ATOMIC_EXIT14]] ], [ [[TMP35:%.*]], [[ATOMIC_CONT16]] ], !dbg [[DBG30]]
// LIN64-NEXT:    [[DIV:%.*]] = sdiv i64 [[TMP32]], [[TMP31]], !dbg [[DBG31:![0-9]+]]
// LIN64-NEXT:    store i64 [[DIV]], ptr [[ATOMIC_TEMP17]], align 8, !dbg [[DBG30]]
// LIN64-NEXT:    [[TMP33:%.*]] = load i64, ptr [[ATOMIC_TEMP17]], align 8, !dbg [[DBG30]]
// LIN64-NEXT:    [[TMP34:%.*]] = cmpxchg ptr @lx, i64 [[TMP32]], i64 [[TMP33]] monotonic monotonic, align 8, !dbg [[DBG30]]
// LIN64-NEXT:    [[TMP35]] = extractvalue { i64, i1 } [[TMP34]], 0, !dbg [[DBG30]]
// LIN64-NEXT:    [[TMP36:%.*]] = extractvalue { i64, i1 } [[TMP34]], 1, !dbg [[DBG30]]
// LIN64-NEXT:    br i1 [[TMP36]], label [[ATOMIC_EXIT18:%.*]], label [[ATOMIC_CONT16]], !dbg [[DBG30]]
// LIN64:       atomic_exit18:
// LIN64-NEXT:    [[TMP37:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG32:![0-9]+]]
// LIN64-NEXT:    [[TMP38:%.*]] = atomicrmw and ptr @ulx, i64 [[TMP37]] monotonic, align 8, !dbg [[DBG33:![0-9]+]]
// LIN64-NEXT:    [[TMP39:%.*]] = load i64, ptr @llv, align 8, !dbg [[DBG34:![0-9]+]]
// LIN64-NEXT:    [[TMP40:%.*]] = atomicrmw xor ptr @llx, i64 [[TMP39]] monotonic, align 8, !dbg [[DBG35:![0-9]+]]
// LIN64-NEXT:    [[TMP41:%.*]] = load i64, ptr @ullv, align 8, !dbg [[DBG36:![0-9]+]]
// LIN64-NEXT:    [[TMP42:%.*]] = atomicrmw or ptr @ullx, i64 [[TMP41]] monotonic, align 8, !dbg [[DBG37:![0-9]+]]
// LIN64-NEXT:    [[TMP43:%.*]] = load float, ptr @fv, align 4, !dbg [[DBG38:![0-9]+]]
// LIN64-NEXT:    [[TMP44:%.*]] = atomicrmw fadd ptr @fx, float [[TMP43]] monotonic, align 4, !dbg [[DBG39:![0-9]+]]
// LIN64-NEXT:    [[TMP45:%.*]] = load double, ptr @dv, align 8, !dbg [[DBG40:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD19:%.*]] = load atomic i64, ptr @dx monotonic, align 8, !dbg [[DBG41:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT20:%.*]], !dbg [[DBG41]]
// LIN64:       atomic_cont20:
// LIN64-NEXT:    [[TMP46:%.*]] = phi i64 [ [[ATOMIC_LOAD19]], [[ATOMIC_EXIT18]] ], [ [[TMP50:%.*]], [[ATOMIC_CONT20]] ], !dbg [[DBG41]]
// LIN64-NEXT:    [[TMP47:%.*]] = bitcast i64 [[TMP46]] to double, !dbg [[DBG41]]
// LIN64-NEXT:    [[SUB:%.*]] = fsub double [[TMP45]], [[TMP47]], !dbg [[DBG42:![0-9]+]]
// LIN64-NEXT:    store double [[SUB]], ptr [[ATOMIC_TEMP21]], align 8, !dbg [[DBG41]]
// LIN64-NEXT:    [[TMP48:%.*]] = load i64, ptr [[ATOMIC_TEMP21]], align 8, !dbg [[DBG41]]
// LIN64-NEXT:    [[TMP49:%.*]] = cmpxchg ptr @dx, i64 [[TMP46]], i64 [[TMP48]] monotonic monotonic, align 8, !dbg [[DBG41]]
// LIN64-NEXT:    [[TMP50]] = extractvalue { i64, i1 } [[TMP49]], 0, !dbg [[DBG41]]
// LIN64-NEXT:    [[TMP51:%.*]] = extractvalue { i64, i1 } [[TMP49]], 1, !dbg [[DBG41]]
// LIN64-NEXT:    br i1 [[TMP51]], label [[ATOMIC_EXIT22:%.*]], label [[ATOMIC_CONT20]], !dbg [[DBG41]]
// LIN64:       atomic_exit22:
// LIN64-NEXT:    [[TMP52:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG43:![0-9]+]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 16, ptr noundef @ldx, ptr noundef [[ATOMIC_TEMP23]], i32 noundef 0), !dbg [[DBG44:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT24:%.*]], !dbg [[DBG44]]
// LIN64:       atomic_cont24:
// LIN64-NEXT:    [[TMP53:%.*]] = load x86_fp80, ptr [[ATOMIC_TEMP23]], align 16, !dbg [[DBG44]]
// LIN64-NEXT:    store x86_fp80 [[TMP53]], ptr [[ATOMIC_TEMP25]], align 16, !dbg [[DBG44]]
// LIN64-NEXT:    [[TMP54:%.*]] = load x86_fp80, ptr [[ATOMIC_TEMP23]], align 16, !dbg [[DBG44]]
// LIN64-NEXT:    [[MUL26:%.*]] = fmul x86_fp80 [[TMP54]], [[TMP52]], !dbg [[DBG45:![0-9]+]]
// LIN64-NEXT:    store x86_fp80 [[MUL26]], ptr [[ATOMIC_TEMP25]], align 16, !dbg [[DBG44]]
// LIN64-NEXT:    [[CALL:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, ptr noundef @ldx, ptr noundef [[ATOMIC_TEMP23]], ptr noundef [[ATOMIC_TEMP25]], i32 noundef 0, i32 noundef 0), !dbg [[DBG44]]
// LIN64-NEXT:    br i1 [[CALL]], label [[ATOMIC_EXIT27:%.*]], label [[ATOMIC_CONT24]], !dbg [[DBG44]]
// LIN64:       atomic_exit27:
// LIN64-NEXT:    [[CIV_REAL:%.*]] = load i32, ptr @civ, align 4, !dbg [[DBG46:![0-9]+]]
// LIN64-NEXT:    [[CIV_IMAG:%.*]] = load i32, ptr getelementptr inbounds nuw ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG46]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP28]], i32 noundef 0), !dbg [[DBG47:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT29:%.*]], !dbg [[DBG47]]
// LIN64:       atomic_cont29:
// LIN64-NEXT:    [[ATOMIC_TEMP28_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP28]], i32 0, i32 0, !dbg [[DBG47]]
// LIN64-NEXT:    [[ATOMIC_TEMP28_REAL:%.*]] = load i32, ptr [[ATOMIC_TEMP28_REALP]], align 4, !dbg [[DBG47]]
// LIN64-NEXT:    [[ATOMIC_TEMP28_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP28]], i32 0, i32 1, !dbg [[DBG47]]
// LIN64-NEXT:    [[ATOMIC_TEMP28_IMAG:%.*]] = load i32, ptr [[ATOMIC_TEMP28_IMAGP]], align 4, !dbg [[DBG47]]
// LIN64-NEXT:    [[TMP55:%.*]] = mul i32 [[CIV_REAL]], [[ATOMIC_TEMP28_REAL]], !dbg [[DBG48:![0-9]+]]
// LIN64-NEXT:    [[TMP56:%.*]] = mul i32 [[CIV_IMAG]], [[ATOMIC_TEMP28_IMAG]], !dbg [[DBG48]]
// LIN64-NEXT:    [[TMP57:%.*]] = add i32 [[TMP55]], [[TMP56]], !dbg [[DBG48]]
// LIN64-NEXT:    [[TMP58:%.*]] = mul i32 [[ATOMIC_TEMP28_REAL]], [[ATOMIC_TEMP28_REAL]], !dbg [[DBG48]]
// LIN64-NEXT:    [[TMP59:%.*]] = mul i32 [[ATOMIC_TEMP28_IMAG]], [[ATOMIC_TEMP28_IMAG]], !dbg [[DBG48]]
// LIN64-NEXT:    [[TMP60:%.*]] = add i32 [[TMP58]], [[TMP59]], !dbg [[DBG48]]
// LIN64-NEXT:    [[TMP61:%.*]] = mul i32 [[CIV_IMAG]], [[ATOMIC_TEMP28_REAL]], !dbg [[DBG48]]
// LIN64-NEXT:    [[TMP62:%.*]] = mul i32 [[CIV_REAL]], [[ATOMIC_TEMP28_IMAG]], !dbg [[DBG48]]
// LIN64-NEXT:    [[TMP63:%.*]] = sub i32 [[TMP61]], [[TMP62]], !dbg [[DBG48]]
// LIN64-NEXT:    [[TMP64:%.*]] = sdiv i32 [[TMP57]], [[TMP60]], !dbg [[DBG48]]
// LIN64-NEXT:    [[TMP65:%.*]] = sdiv i32 [[TMP63]], [[TMP60]], !dbg [[DBG48]]
// LIN64-NEXT:    [[ATOMIC_TEMP30_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP30]], i32 0, i32 0, !dbg [[DBG47]]
// LIN64-NEXT:    [[ATOMIC_TEMP30_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP30]], i32 0, i32 1, !dbg [[DBG47]]
// LIN64-NEXT:    store i32 [[TMP64]], ptr [[ATOMIC_TEMP30_REALP]], align 4, !dbg [[DBG47]]
// LIN64-NEXT:    store i32 [[TMP65]], ptr [[ATOMIC_TEMP30_IMAGP]], align 4, !dbg [[DBG47]]
// LIN64-NEXT:    [[CALL31:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP28]], ptr noundef [[ATOMIC_TEMP30]], i32 noundef 0, i32 noundef 0), !dbg [[DBG47]]
// LIN64-NEXT:    br i1 [[CALL31]], label [[ATOMIC_EXIT32:%.*]], label [[ATOMIC_CONT29]], !dbg [[DBG47]]
// LIN64:       atomic_exit32:
// LIN64-NEXT:    [[CFV_REAL:%.*]] = load float, ptr @cfv, align 4, !dbg [[DBG49:![0-9]+]]
// LIN64-NEXT:    [[CFV_IMAG:%.*]] = load float, ptr getelementptr inbounds nuw ({ float, float }, ptr @cfv, i32 0, i32 1), align 4, !dbg [[DBG49]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cfx, ptr noundef [[ATOMIC_TEMP33]], i32 noundef 0), !dbg [[DBG50:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT34:%.*]], !dbg [[DBG50]]
// LIN64:       atomic_cont34:
// LIN64-NEXT:    [[ATOMIC_TEMP33_REALP:%.*]] = getelementptr inbounds nuw { float, float }, ptr [[ATOMIC_TEMP33]], i32 0, i32 0, !dbg [[DBG50]]
// LIN64-NEXT:    [[ATOMIC_TEMP33_REAL:%.*]] = load float, ptr [[ATOMIC_TEMP33_REALP]], align 4, !dbg [[DBG50]]
// LIN64-NEXT:    [[ATOMIC_TEMP33_IMAGP:%.*]] = getelementptr inbounds nuw { float, float }, ptr [[ATOMIC_TEMP33]], i32 0, i32 1, !dbg [[DBG50]]
// LIN64-NEXT:    [[ATOMIC_TEMP33_IMAG:%.*]] = load float, ptr [[ATOMIC_TEMP33_IMAGP]], align 4, !dbg [[DBG50]]
// LIN64-NEXT:    [[ADD_R:%.*]] = fadd float [[CFV_REAL]], [[ATOMIC_TEMP33_REAL]], !dbg [[DBG51:![0-9]+]]
// LIN64-NEXT:    [[ADD_I:%.*]] = fadd float [[CFV_IMAG]], [[ATOMIC_TEMP33_IMAG]], !dbg [[DBG51]]
// LIN64-NEXT:    [[ATOMIC_TEMP35_REALP:%.*]] = getelementptr inbounds nuw { float, float }, ptr [[ATOMIC_TEMP35]], i32 0, i32 0, !dbg [[DBG50]]
// LIN64-NEXT:    [[ATOMIC_TEMP35_IMAGP:%.*]] = getelementptr inbounds nuw { float, float }, ptr [[ATOMIC_TEMP35]], i32 0, i32 1, !dbg [[DBG50]]
// LIN64-NEXT:    store float [[ADD_R]], ptr [[ATOMIC_TEMP35_REALP]], align 4, !dbg [[DBG50]]
// LIN64-NEXT:    store float [[ADD_I]], ptr [[ATOMIC_TEMP35_IMAGP]], align 4, !dbg [[DBG50]]
// LIN64-NEXT:    [[CALL36:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cfx, ptr noundef [[ATOMIC_TEMP33]], ptr noundef [[ATOMIC_TEMP35]], i32 noundef 0, i32 noundef 0), !dbg [[DBG50]]
// LIN64-NEXT:    br i1 [[CALL36]], label [[ATOMIC_EXIT37:%.*]], label [[ATOMIC_CONT34]], !dbg [[DBG50]]
// LIN64:       atomic_exit37:
// LIN64-NEXT:    [[CDV_REAL:%.*]] = load double, ptr @cdv, align 8, !dbg [[DBG52:![0-9]+]]
// LIN64-NEXT:    [[CDV_IMAG:%.*]] = load double, ptr getelementptr inbounds nuw ({ double, double }, ptr @cdv, i32 0, i32 1), align 8, !dbg [[DBG52]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 16, ptr noundef @cdx, ptr noundef [[ATOMIC_TEMP38]], i32 noundef 5), !dbg [[DBG53:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT39:%.*]], !dbg [[DBG53]]
// LIN64:       atomic_cont39:
// LIN64-NEXT:    [[ATOMIC_TEMP38_REALP:%.*]] = getelementptr inbounds nuw { double, double }, ptr [[ATOMIC_TEMP38]], i32 0, i32 0, !dbg [[DBG53]]
// LIN64-NEXT:    [[ATOMIC_TEMP38_REAL:%.*]] = load double, ptr [[ATOMIC_TEMP38_REALP]], align 8, !dbg [[DBG53]]
// LIN64-NEXT:    [[ATOMIC_TEMP38_IMAGP:%.*]] = getelementptr inbounds nuw { double, double }, ptr [[ATOMIC_TEMP38]], i32 0, i32 1, !dbg [[DBG53]]
// LIN64-NEXT:    [[ATOMIC_TEMP38_IMAG:%.*]] = load double, ptr [[ATOMIC_TEMP38_IMAGP]], align 8, !dbg [[DBG53]]
// LIN64-NEXT:    [[SUB_R:%.*]] = fsub double [[ATOMIC_TEMP38_REAL]], [[CDV_REAL]], !dbg [[DBG54:![0-9]+]]
// LIN64-NEXT:    [[SUB_I:%.*]] = fsub double [[ATOMIC_TEMP38_IMAG]], [[CDV_IMAG]], !dbg [[DBG54]]
// LIN64-NEXT:    [[ATOMIC_TEMP40_REALP:%.*]] = getelementptr inbounds nuw { double, double }, ptr [[ATOMIC_TEMP40]], i32 0, i32 0, !dbg [[DBG53]]
// LIN64-NEXT:    [[ATOMIC_TEMP40_IMAGP:%.*]] = getelementptr inbounds nuw { double, double }, ptr [[ATOMIC_TEMP40]], i32 0, i32 1, !dbg [[DBG53]]
// LIN64-NEXT:    store double [[SUB_R]], ptr [[ATOMIC_TEMP40_REALP]], align 8, !dbg [[DBG53]]
// LIN64-NEXT:    store double [[SUB_I]], ptr [[ATOMIC_TEMP40_IMAGP]], align 8, !dbg [[DBG53]]
// LIN64-NEXT:    [[CALL41:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, ptr noundef @cdx, ptr noundef [[ATOMIC_TEMP38]], ptr noundef [[ATOMIC_TEMP40]], i32 noundef 5, i32 noundef 5), !dbg [[DBG53]]
// LIN64-NEXT:    br i1 [[CALL41]], label [[ATOMIC_EXIT42:%.*]], label [[ATOMIC_CONT39]], !dbg [[DBG53]]
// LIN64:       atomic_exit42:
// LIN64-NEXT:    fence release
// LIN64-NEXT:    [[TMP66:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG55:![0-9]+]]
// LIN64-NEXT:    [[LOADEDV:%.*]] = trunc i8 [[TMP66]] to i1, !dbg [[DBG55]]
// LIN64-NEXT:    [[CONV43:%.*]] = zext i1 [[LOADEDV]] to i64, !dbg [[DBG55]]
// LIN64-NEXT:    [[TMP67:%.*]] = atomicrmw and ptr @ulx, i64 [[CONV43]] monotonic, align 8, !dbg [[DBG56:![0-9]+]]
// LIN64-NEXT:    [[TMP68:%.*]] = load i8, ptr @cv, align 1, !dbg [[DBG57:![0-9]+]]
// LIN64-NEXT:    [[CONV44:%.*]] = sext i8 [[TMP68]] to i32, !dbg [[DBG57]]
// LIN64-NEXT:    [[ATOMIC_LOAD45:%.*]] = load atomic i8, ptr @bx monotonic, align 1, !dbg [[DBG58:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT46:%.*]], !dbg [[DBG58]]
// LIN64:       atomic_cont46:
// LIN64-NEXT:    [[TMP69:%.*]] = phi i8 [ [[ATOMIC_LOAD45]], [[ATOMIC_EXIT42]] ], [ [[TMP72:%.*]], [[ATOMIC_CONT46]] ], !dbg [[DBG58]]
// LIN64-NEXT:    [[LOADEDV48:%.*]] = trunc i8 [[TMP69]] to i1, !dbg [[DBG58]]
// LIN64-NEXT:    [[CONV49:%.*]] = zext i1 [[LOADEDV48]] to i32, !dbg [[DBG58]]
// LIN64-NEXT:    [[AND:%.*]] = and i32 [[CONV44]], [[CONV49]], !dbg [[DBG59:![0-9]+]]
// LIN64-NEXT:    [[TOBOOL:%.*]] = icmp ne i32 [[AND]], 0, !dbg [[DBG57]]
// LIN64-NEXT:    [[STOREDV:%.*]] = zext i1 [[TOBOOL]] to i8, !dbg [[DBG58]]
// LIN64-NEXT:    store i8 [[STOREDV]], ptr [[ATOMIC_TEMP47]], align 1, !dbg [[DBG58]]
// LIN64-NEXT:    [[TMP70:%.*]] = load i8, ptr [[ATOMIC_TEMP47]], align 1, !dbg [[DBG58]]
// LIN64-NEXT:    [[TMP71:%.*]] = cmpxchg ptr @bx, i8 [[TMP69]], i8 [[TMP70]] monotonic monotonic, align 1, !dbg [[DBG58]]
// LIN64-NEXT:    [[TMP72]] = extractvalue { i8, i1 } [[TMP71]], 0, !dbg [[DBG58]]
// LIN64-NEXT:    [[TMP73:%.*]] = extractvalue { i8, i1 } [[TMP71]], 1, !dbg [[DBG58]]
// LIN64-NEXT:    br i1 [[TMP73]], label [[ATOMIC_EXIT50:%.*]], label [[ATOMIC_CONT46]], !dbg [[DBG58]]
// LIN64:       atomic_exit50:
// LIN64-NEXT:    [[TMP74:%.*]] = load i8, ptr @ucv, align 1, !dbg [[DBG60:![0-9]+]]
// LIN64-NEXT:    [[CONV51:%.*]] = zext i8 [[TMP74]] to i32, !dbg [[DBG60]]
// LIN64-NEXT:    [[ATOMIC_LOAD52:%.*]] = load atomic i8, ptr @cx seq_cst, align 1, !dbg [[DBG61:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT53:%.*]], !dbg [[DBG61]]
// LIN64:       atomic_cont53:
// LIN64-NEXT:    [[TMP75:%.*]] = phi i8 [ [[ATOMIC_LOAD52]], [[ATOMIC_EXIT50]] ], [ [[TMP78:%.*]], [[ATOMIC_CONT53]] ], !dbg [[DBG61]]
// LIN64-NEXT:    [[CONV55:%.*]] = sext i8 [[TMP75]] to i32, !dbg [[DBG61]]
// LIN64-NEXT:    [[SHR56:%.*]] = ashr i32 [[CONV55]], [[CONV51]], !dbg [[DBG62:![0-9]+]]
// LIN64-NEXT:    [[CONV57:%.*]] = trunc i32 [[SHR56]] to i8, !dbg [[DBG61]]
// LIN64-NEXT:    store i8 [[CONV57]], ptr [[ATOMIC_TEMP54]], align 1, !dbg [[DBG61]]
// LIN64-NEXT:    [[TMP76:%.*]] = load i8, ptr [[ATOMIC_TEMP54]], align 1, !dbg [[DBG61]]
// LIN64-NEXT:    [[TMP77:%.*]] = cmpxchg ptr @cx, i8 [[TMP75]], i8 [[TMP76]] seq_cst seq_cst, align 1, !dbg [[DBG61]]
// LIN64-NEXT:    [[TMP78]] = extractvalue { i8, i1 } [[TMP77]], 0, !dbg [[DBG61]]
// LIN64-NEXT:    [[TMP79:%.*]] = extractvalue { i8, i1 } [[TMP77]], 1, !dbg [[DBG61]]
// LIN64-NEXT:    br i1 [[TMP79]], label [[ATOMIC_EXIT58:%.*]], label [[ATOMIC_CONT53]], !dbg [[DBG61]]
// LIN64:       atomic_exit58:
// LIN64-NEXT:    fence release
// LIN64-NEXT:    [[TMP80:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG63:![0-9]+]]
// LIN64-NEXT:    [[CONV59:%.*]] = sext i16 [[TMP80]] to i32, !dbg [[DBG63]]
// LIN64-NEXT:    [[ATOMIC_LOAD60:%.*]] = load atomic i64, ptr @ulx monotonic, align 8, !dbg [[DBG64:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT61:%.*]], !dbg [[DBG64]]
// LIN64:       atomic_cont61:
// LIN64-NEXT:    [[TMP81:%.*]] = phi i64 [ [[ATOMIC_LOAD60]], [[ATOMIC_EXIT58]] ], [ [[TMP84:%.*]], [[ATOMIC_CONT61]] ], !dbg [[DBG64]]
// LIN64-NEXT:    [[SH_PROM:%.*]] = trunc i64 [[TMP81]] to i32, !dbg [[DBG65:![0-9]+]]
// LIN64-NEXT:    [[SHL63:%.*]] = shl i32 [[CONV59]], [[SH_PROM]], !dbg [[DBG65]]
// LIN64-NEXT:    [[CONV64:%.*]] = sext i32 [[SHL63]] to i64, !dbg [[DBG63]]
// LIN64-NEXT:    store i64 [[CONV64]], ptr [[ATOMIC_TEMP62]], align 8, !dbg [[DBG64]]
// LIN64-NEXT:    [[TMP82:%.*]] = load i64, ptr [[ATOMIC_TEMP62]], align 8, !dbg [[DBG64]]
// LIN64-NEXT:    [[TMP83:%.*]] = cmpxchg ptr @ulx, i64 [[TMP81]], i64 [[TMP82]] monotonic monotonic, align 8, !dbg [[DBG64]]
// LIN64-NEXT:    [[TMP84]] = extractvalue { i64, i1 } [[TMP83]], 0, !dbg [[DBG64]]
// LIN64-NEXT:    [[TMP85:%.*]] = extractvalue { i64, i1 } [[TMP83]], 1, !dbg [[DBG64]]
// LIN64-NEXT:    br i1 [[TMP85]], label [[ATOMIC_EXIT65:%.*]], label [[ATOMIC_CONT61]], !dbg [[DBG64]]
// LIN64:       atomic_exit65:
// LIN64-NEXT:    [[TMP86:%.*]] = load i16, ptr @usv, align 2, !dbg [[DBG66:![0-9]+]]
// LIN64-NEXT:    [[CONV66:%.*]] = zext i16 [[TMP86]] to i64, !dbg [[DBG66]]
// LIN64-NEXT:    [[ATOMIC_LOAD67:%.*]] = load atomic i64, ptr @lx monotonic, align 8, !dbg [[DBG67:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT68:%.*]], !dbg [[DBG67]]
// LIN64:       atomic_cont68:
// LIN64-NEXT:    [[TMP87:%.*]] = phi i64 [ [[ATOMIC_LOAD67]], [[ATOMIC_EXIT65]] ], [ [[TMP90:%.*]], [[ATOMIC_CONT68]] ], !dbg [[DBG67]]
// LIN64-NEXT:    [[REM:%.*]] = srem i64 [[TMP87]], [[CONV66]], !dbg [[DBG68:![0-9]+]]
// LIN64-NEXT:    store i64 [[REM]], ptr [[ATOMIC_TEMP69]], align 8, !dbg [[DBG67]]
// LIN64-NEXT:    [[TMP88:%.*]] = load i64, ptr [[ATOMIC_TEMP69]], align 8, !dbg [[DBG67]]
// LIN64-NEXT:    [[TMP89:%.*]] = cmpxchg ptr @lx, i64 [[TMP87]], i64 [[TMP88]] monotonic monotonic, align 8, !dbg [[DBG67]]
// LIN64-NEXT:    [[TMP90]] = extractvalue { i64, i1 } [[TMP89]], 0, !dbg [[DBG67]]
// LIN64-NEXT:    [[TMP91:%.*]] = extractvalue { i64, i1 } [[TMP89]], 1, !dbg [[DBG67]]
// LIN64-NEXT:    br i1 [[TMP91]], label [[ATOMIC_EXIT70:%.*]], label [[ATOMIC_CONT68]], !dbg [[DBG67]]
// LIN64:       atomic_exit70:
// LIN64-NEXT:    [[TMP92:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG69:![0-9]+]]
// LIN64-NEXT:    [[TMP93:%.*]] = atomicrmw or ptr @uix, i32 [[TMP92]] seq_cst, align 4, !dbg [[DBG70:![0-9]+]]
// LIN64-NEXT:    fence release
// LIN64-NEXT:    [[TMP94:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG71:![0-9]+]]
// LIN64-NEXT:    [[TMP95:%.*]] = atomicrmw and ptr @ix, i32 [[TMP94]] monotonic, align 4, !dbg [[DBG72:![0-9]+]]
// LIN64-NEXT:    [[TMP96:%.*]] = load i64, ptr @lv, align 8, !dbg [[DBG73:![0-9]+]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP71]], i32 noundef 0), !dbg [[DBG74:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT72:%.*]], !dbg [[DBG74]]
// LIN64:       atomic_cont72:
// LIN64-NEXT:    [[ATOMIC_TEMP71_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP71]], i32 0, i32 0, !dbg [[DBG74]]
// LIN64-NEXT:    [[ATOMIC_TEMP71_REAL:%.*]] = load i32, ptr [[ATOMIC_TEMP71_REALP]], align 4, !dbg [[DBG74]]
// LIN64-NEXT:    [[ATOMIC_TEMP71_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP71]], i32 0, i32 1, !dbg [[DBG74]]
// LIN64-NEXT:    [[ATOMIC_TEMP71_IMAG:%.*]] = load i32, ptr [[ATOMIC_TEMP71_IMAGP]], align 4, !dbg [[DBG74]]
// LIN64-NEXT:    [[CONV74:%.*]] = sext i32 [[ATOMIC_TEMP71_REAL]] to i64, !dbg [[DBG74]]
// LIN64-NEXT:    [[CONV75:%.*]] = sext i32 [[ATOMIC_TEMP71_IMAG]] to i64, !dbg [[DBG74]]
// LIN64-NEXT:    [[ADD_R76:%.*]] = add i64 [[TMP96]], [[CONV74]], !dbg [[DBG75:![0-9]+]]
// LIN64-NEXT:    [[ADD_I77:%.*]] = add i64 0, [[CONV75]], !dbg [[DBG75]]
// LIN64-NEXT:    [[CONV78:%.*]] = trunc i64 [[ADD_R76]] to i32, !dbg [[DBG73]]
// LIN64-NEXT:    [[CONV79:%.*]] = trunc i64 [[ADD_I77]] to i32, !dbg [[DBG73]]
// LIN64-NEXT:    [[ATOMIC_TEMP73_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP73]], i32 0, i32 0, !dbg [[DBG74]]
// LIN64-NEXT:    [[ATOMIC_TEMP73_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP73]], i32 0, i32 1, !dbg [[DBG74]]
// LIN64-NEXT:    store i32 [[CONV78]], ptr [[ATOMIC_TEMP73_REALP]], align 4, !dbg [[DBG74]]
// LIN64-NEXT:    store i32 [[CONV79]], ptr [[ATOMIC_TEMP73_IMAGP]], align 4, !dbg [[DBG74]]
// LIN64-NEXT:    [[CALL80:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP71]], ptr noundef [[ATOMIC_TEMP73]], i32 noundef 0, i32 noundef 0), !dbg [[DBG74]]
// LIN64-NEXT:    br i1 [[CALL80]], label [[ATOMIC_EXIT81:%.*]], label [[ATOMIC_CONT72]], !dbg [[DBG74]]
// LIN64:       atomic_exit81:
// LIN64-NEXT:    [[TMP97:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG76:![0-9]+]]
// LIN64-NEXT:    [[CONV82:%.*]] = uitofp i64 [[TMP97]] to float, !dbg [[DBG76]]
// LIN64-NEXT:    [[ATOMIC_LOAD83:%.*]] = load atomic i32, ptr @fx monotonic, align 4, !dbg [[DBG77:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT84:%.*]], !dbg [[DBG77]]
// LIN64:       atomic_cont84:
// LIN64-NEXT:    [[TMP98:%.*]] = phi i32 [ [[ATOMIC_LOAD83]], [[ATOMIC_EXIT81]] ], [ [[TMP102:%.*]], [[ATOMIC_CONT84]] ], !dbg [[DBG77]]
// LIN64-NEXT:    [[TMP99:%.*]] = bitcast i32 [[TMP98]] to float, !dbg [[DBG77]]
// LIN64-NEXT:    [[MUL86:%.*]] = fmul float [[TMP99]], [[CONV82]], !dbg [[DBG78:![0-9]+]]
// LIN64-NEXT:    store float [[MUL86]], ptr [[ATOMIC_TEMP85]], align 4, !dbg [[DBG77]]
// LIN64-NEXT:    [[TMP100:%.*]] = load i32, ptr [[ATOMIC_TEMP85]], align 4, !dbg [[DBG77]]
// LIN64-NEXT:    [[TMP101:%.*]] = cmpxchg ptr @fx, i32 [[TMP98]], i32 [[TMP100]] monotonic monotonic, align 4, !dbg [[DBG77]]
// LIN64-NEXT:    [[TMP102]] = extractvalue { i32, i1 } [[TMP101]], 0, !dbg [[DBG77]]
// LIN64-NEXT:    [[TMP103:%.*]] = extractvalue { i32, i1 } [[TMP101]], 1, !dbg [[DBG77]]
// LIN64-NEXT:    br i1 [[TMP103]], label [[ATOMIC_EXIT87:%.*]], label [[ATOMIC_CONT84]], !dbg [[DBG77]]
// LIN64:       atomic_exit87:
// LIN64-NEXT:    [[TMP104:%.*]] = load i64, ptr @llv, align 8, !dbg [[DBG79:![0-9]+]]
// LIN64-NEXT:    [[CONV88:%.*]] = sitofp i64 [[TMP104]] to double, !dbg [[DBG79]]
// LIN64-NEXT:    [[ATOMIC_LOAD89:%.*]] = load atomic i64, ptr @dx monotonic, align 8, !dbg [[DBG80:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT90:%.*]], !dbg [[DBG80]]
// LIN64:       atomic_cont90:
// LIN64-NEXT:    [[TMP105:%.*]] = phi i64 [ [[ATOMIC_LOAD89]], [[ATOMIC_EXIT87]] ], [ [[TMP109:%.*]], [[ATOMIC_CONT90]] ], !dbg [[DBG80]]
// LIN64-NEXT:    [[TMP106:%.*]] = bitcast i64 [[TMP105]] to double, !dbg [[DBG80]]
// LIN64-NEXT:    [[DIV92:%.*]] = fdiv double [[TMP106]], [[CONV88]], !dbg [[DBG81:![0-9]+]]
// LIN64-NEXT:    store double [[DIV92]], ptr [[ATOMIC_TEMP91]], align 8, !dbg [[DBG80]]
// LIN64-NEXT:    [[TMP107:%.*]] = load i64, ptr [[ATOMIC_TEMP91]], align 8, !dbg [[DBG80]]
// LIN64-NEXT:    [[TMP108:%.*]] = cmpxchg ptr @dx, i64 [[TMP105]], i64 [[TMP107]] monotonic monotonic, align 8, !dbg [[DBG80]]
// LIN64-NEXT:    [[TMP109]] = extractvalue { i64, i1 } [[TMP108]], 0, !dbg [[DBG80]]
// LIN64-NEXT:    [[TMP110:%.*]] = extractvalue { i64, i1 } [[TMP108]], 1, !dbg [[DBG80]]
// LIN64-NEXT:    br i1 [[TMP110]], label [[ATOMIC_EXIT93:%.*]], label [[ATOMIC_CONT90]], !dbg [[DBG80]]
// LIN64:       atomic_exit93:
// LIN64-NEXT:    [[TMP111:%.*]] = load i64, ptr @ullv, align 8, !dbg [[DBG82:![0-9]+]]
// LIN64-NEXT:    [[CONV94:%.*]] = uitofp i64 [[TMP111]] to x86_fp80, !dbg [[DBG82]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 16, ptr noundef @ldx, ptr noundef [[ATOMIC_TEMP95]], i32 noundef 0), !dbg [[DBG83:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT96:%.*]], !dbg [[DBG83]]
// LIN64:       atomic_cont96:
// LIN64-NEXT:    [[TMP112:%.*]] = load x86_fp80, ptr [[ATOMIC_TEMP95]], align 16, !dbg [[DBG83]]
// LIN64-NEXT:    store x86_fp80 [[TMP112]], ptr [[ATOMIC_TEMP97]], align 16, !dbg [[DBG83]]
// LIN64-NEXT:    [[TMP113:%.*]] = load x86_fp80, ptr [[ATOMIC_TEMP95]], align 16, !dbg [[DBG83]]
// LIN64-NEXT:    [[SUB98:%.*]] = fsub x86_fp80 [[TMP113]], [[CONV94]], !dbg [[DBG84:![0-9]+]]
// LIN64-NEXT:    store x86_fp80 [[SUB98]], ptr [[ATOMIC_TEMP97]], align 16, !dbg [[DBG83]]
// LIN64-NEXT:    [[CALL99:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, ptr noundef @ldx, ptr noundef [[ATOMIC_TEMP95]], ptr noundef [[ATOMIC_TEMP97]], i32 noundef 0, i32 noundef 0), !dbg [[DBG83]]
// LIN64-NEXT:    br i1 [[CALL99]], label [[ATOMIC_EXIT100:%.*]], label [[ATOMIC_CONT96]], !dbg [[DBG83]]
// LIN64:       atomic_exit100:
// LIN64-NEXT:    [[TMP114:%.*]] = load float, ptr @fv, align 4, !dbg [[DBG85:![0-9]+]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP101]], i32 noundef 0), !dbg [[DBG86:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT102:%.*]], !dbg [[DBG86]]
// LIN64:       atomic_cont102:
// LIN64-NEXT:    [[ATOMIC_TEMP101_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP101]], i32 0, i32 0, !dbg [[DBG86]]
// LIN64-NEXT:    [[ATOMIC_TEMP101_REAL:%.*]] = load i32, ptr [[ATOMIC_TEMP101_REALP]], align 4, !dbg [[DBG86]]
// LIN64-NEXT:    [[ATOMIC_TEMP101_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP101]], i32 0, i32 1, !dbg [[DBG86]]
// LIN64-NEXT:    [[ATOMIC_TEMP101_IMAG:%.*]] = load i32, ptr [[ATOMIC_TEMP101_IMAGP]], align 4, !dbg [[DBG86]]
// LIN64-NEXT:    [[CONV104:%.*]] = sitofp i32 [[ATOMIC_TEMP101_REAL]] to float, !dbg [[DBG86]]
// LIN64-NEXT:    [[CONV105:%.*]] = sitofp i32 [[ATOMIC_TEMP101_IMAG]] to float, !dbg [[DBG86]]
// LIN64-NEXT:    [[CALL106:%.*]] = call <2 x float> @__divsc3(float noundef [[TMP114]], float noundef 0.000000e+00, float noundef [[CONV104]], float noundef [[CONV105]]) #[[ATTR2:[0-9]+]], !dbg [[DBG87:![0-9]+]]
// LIN64-NEXT:    store <2 x float> [[CALL106]], ptr [[COERCE]], align 4, !dbg [[DBG87]]
// LIN64-NEXT:    [[COERCE_REALP:%.*]] = getelementptr inbounds nuw { float, float }, ptr [[COERCE]], i32 0, i32 0, !dbg [[DBG87]]
// LIN64-NEXT:    [[COERCE_REAL:%.*]] = load float, ptr [[COERCE_REALP]], align 4, !dbg [[DBG87]]
// LIN64-NEXT:    [[COERCE_IMAGP:%.*]] = getelementptr inbounds nuw { float, float }, ptr [[COERCE]], i32 0, i32 1, !dbg [[DBG87]]
// LIN64-NEXT:    [[COERCE_IMAG:%.*]] = load float, ptr [[COERCE_IMAGP]], align 4, !dbg [[DBG87]]
// LIN64-NEXT:    [[CONV107:%.*]] = fptosi float [[COERCE_REAL]] to i32, !dbg [[DBG85]]
// LIN64-NEXT:    [[CONV108:%.*]] = fptosi float [[COERCE_IMAG]] to i32, !dbg [[DBG85]]
// LIN64-NEXT:    [[ATOMIC_TEMP103_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP103]], i32 0, i32 0, !dbg [[DBG86]]
// LIN64-NEXT:    [[ATOMIC_TEMP103_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP103]], i32 0, i32 1, !dbg [[DBG86]]
// LIN64-NEXT:    store i32 [[CONV107]], ptr [[ATOMIC_TEMP103_REALP]], align 4, !dbg [[DBG86]]
// LIN64-NEXT:    store i32 [[CONV108]], ptr [[ATOMIC_TEMP103_IMAGP]], align 4, !dbg [[DBG86]]
// LIN64-NEXT:    [[CALL109:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP101]], ptr noundef [[ATOMIC_TEMP103]], i32 noundef 0, i32 noundef 0), !dbg [[DBG86]]
// LIN64-NEXT:    br i1 [[CALL109]], label [[ATOMIC_EXIT110:%.*]], label [[ATOMIC_CONT102]], !dbg [[DBG86]]
// LIN64:       atomic_exit110:
// LIN64-NEXT:    [[TMP115:%.*]] = load double, ptr @dv, align 8, !dbg [[DBG88:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD111:%.*]] = load atomic i16, ptr @sx monotonic, align 2, !dbg [[DBG89:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT112:%.*]], !dbg [[DBG89]]
// LIN64:       atomic_cont112:
// LIN64-NEXT:    [[TMP116:%.*]] = phi i16 [ [[ATOMIC_LOAD111]], [[ATOMIC_EXIT110]] ], [ [[TMP119:%.*]], [[ATOMIC_CONT112]] ], !dbg [[DBG89]]
// LIN64-NEXT:    [[CONV114:%.*]] = sext i16 [[TMP116]] to i32, !dbg [[DBG89]]
// LIN64-NEXT:    [[CONV115:%.*]] = sitofp i32 [[CONV114]] to double, !dbg [[DBG89]]
// LIN64-NEXT:    [[ADD116:%.*]] = fadd double [[CONV115]], [[TMP115]], !dbg [[DBG90:![0-9]+]]
// LIN64-NEXT:    [[CONV117:%.*]] = fptosi double [[ADD116]] to i16, !dbg [[DBG89]]
// LIN64-NEXT:    store i16 [[CONV117]], ptr [[ATOMIC_TEMP113]], align 2, !dbg [[DBG89]]
// LIN64-NEXT:    [[TMP117:%.*]] = load i16, ptr [[ATOMIC_TEMP113]], align 2, !dbg [[DBG89]]
// LIN64-NEXT:    [[TMP118:%.*]] = cmpxchg ptr @sx, i16 [[TMP116]], i16 [[TMP117]] monotonic monotonic, align 2, !dbg [[DBG89]]
// LIN64-NEXT:    [[TMP119]] = extractvalue { i16, i1 } [[TMP118]], 0, !dbg [[DBG89]]
// LIN64-NEXT:    [[TMP120:%.*]] = extractvalue { i16, i1 } [[TMP118]], 1, !dbg [[DBG89]]
// LIN64-NEXT:    br i1 [[TMP120]], label [[ATOMIC_EXIT118:%.*]], label [[ATOMIC_CONT112]], !dbg [[DBG89]]
// LIN64:       atomic_exit118:
// LIN64-NEXT:    [[TMP121:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG91:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD119:%.*]] = load atomic i8, ptr @bx monotonic, align 1, !dbg [[DBG92:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT120:%.*]], !dbg [[DBG92]]
// LIN64:       atomic_cont120:
// LIN64-NEXT:    [[TMP122:%.*]] = phi i8 [ [[ATOMIC_LOAD119]], [[ATOMIC_EXIT118]] ], [ [[TMP125:%.*]], [[ATOMIC_CONT120]] ], !dbg [[DBG92]]
// LIN64-NEXT:    [[LOADEDV122:%.*]] = trunc i8 [[TMP122]] to i1, !dbg [[DBG92]]
// LIN64-NEXT:    [[CONV123:%.*]] = zext i1 [[LOADEDV122]] to i32, !dbg [[DBG92]]
// LIN64-NEXT:    [[CONV124:%.*]] = sitofp i32 [[CONV123]] to x86_fp80, !dbg [[DBG92]]
// LIN64-NEXT:    [[MUL125:%.*]] = fmul x86_fp80 [[TMP121]], [[CONV124]], !dbg [[DBG93:![0-9]+]]
// LIN64-NEXT:    [[TOBOOL126:%.*]] = fcmp une x86_fp80 [[MUL125]], 0xK00000000000000000000, !dbg [[DBG91]]
// LIN64-NEXT:    [[STOREDV127:%.*]] = zext i1 [[TOBOOL126]] to i8, !dbg [[DBG92]]
// LIN64-NEXT:    store i8 [[STOREDV127]], ptr [[ATOMIC_TEMP121]], align 1, !dbg [[DBG92]]
// LIN64-NEXT:    [[TMP123:%.*]] = load i8, ptr [[ATOMIC_TEMP121]], align 1, !dbg [[DBG92]]
// LIN64-NEXT:    [[TMP124:%.*]] = cmpxchg ptr @bx, i8 [[TMP122]], i8 [[TMP123]] release monotonic, align 1, !dbg [[DBG92]]
// LIN64-NEXT:    [[TMP125]] = extractvalue { i8, i1 } [[TMP124]], 0, !dbg [[DBG92]]
// LIN64-NEXT:    [[TMP126:%.*]] = extractvalue { i8, i1 } [[TMP124]], 1, !dbg [[DBG92]]
// LIN64-NEXT:    br i1 [[TMP126]], label [[ATOMIC_EXIT128:%.*]], label [[ATOMIC_CONT120]], !dbg [[DBG92]]
// LIN64:       atomic_exit128:
// LIN64-NEXT:    fence release
// LIN64-NEXT:    [[CIV_REAL129:%.*]] = load i32, ptr @civ, align 4, !dbg [[DBG94:![0-9]+]]
// LIN64-NEXT:    [[CIV_IMAG130:%.*]] = load i32, ptr getelementptr inbounds nuw ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG94]]
// LIN64-NEXT:    [[ATOMIC_LOAD131:%.*]] = load atomic i8, ptr @bx monotonic, align 1, !dbg [[DBG95:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT132:%.*]], !dbg [[DBG95]]
// LIN64:       atomic_cont132:
// LIN64-NEXT:    [[TMP127:%.*]] = phi i8 [ [[ATOMIC_LOAD131]], [[ATOMIC_EXIT128]] ], [ [[TMP130:%.*]], [[ATOMIC_CONT132]] ], !dbg [[DBG95]]
// LIN64-NEXT:    [[LOADEDV134:%.*]] = trunc i8 [[TMP127]] to i1, !dbg [[DBG95]]
// LIN64-NEXT:    [[CONV135:%.*]] = zext i1 [[LOADEDV134]] to i32, !dbg [[DBG95]]
// LIN64-NEXT:    [[SUB_R136:%.*]] = sub i32 [[CIV_REAL129]], [[CONV135]], !dbg [[DBG96:![0-9]+]]
// LIN64-NEXT:    [[SUB_I137:%.*]] = sub i32 [[CIV_IMAG130]], 0, !dbg [[DBG96]]
// LIN64-NEXT:    [[TOBOOL138:%.*]] = icmp ne i32 [[SUB_R136]], 0, !dbg [[DBG94]]
// LIN64-NEXT:    [[TOBOOL139:%.*]] = icmp ne i32 [[SUB_I137]], 0, !dbg [[DBG94]]
// LIN64-NEXT:    [[TOBOOL140:%.*]] = or i1 [[TOBOOL138]], [[TOBOOL139]], !dbg [[DBG94]]
// LIN64-NEXT:    [[STOREDV141:%.*]] = zext i1 [[TOBOOL140]] to i8, !dbg [[DBG95]]
// LIN64-NEXT:    store i8 [[STOREDV141]], ptr [[ATOMIC_TEMP133]], align 1, !dbg [[DBG95]]
// LIN64-NEXT:    [[TMP128:%.*]] = load i8, ptr [[ATOMIC_TEMP133]], align 1, !dbg [[DBG95]]
// LIN64-NEXT:    [[TMP129:%.*]] = cmpxchg ptr @bx, i8 [[TMP127]], i8 [[TMP128]] monotonic monotonic, align 1, !dbg [[DBG95]]
// LIN64-NEXT:    [[TMP130]] = extractvalue { i8, i1 } [[TMP129]], 0, !dbg [[DBG95]]
// LIN64-NEXT:    [[TMP131:%.*]] = extractvalue { i8, i1 } [[TMP129]], 1, !dbg [[DBG95]]
// LIN64-NEXT:    br i1 [[TMP131]], label [[ATOMIC_EXIT142:%.*]], label [[ATOMIC_CONT132]], !dbg [[DBG95]]
// LIN64:       atomic_exit142:
// LIN64-NEXT:    [[TMP132:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG97:![0-9]+]]
// LIN64-NEXT:    [[TMP133:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG98:![0-9]+]]
// LIN64-NEXT:    [[LOADEDV143:%.*]] = trunc i8 [[TMP133]] to i1, !dbg [[DBG98]]
// LIN64-NEXT:    [[CONV144:%.*]] = zext i1 [[LOADEDV143]] to i32, !dbg [[DBG98]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 16, ptr noundef @int4x, ptr noundef [[ATOMIC_TEMP145]], i32 noundef 0), !dbg [[DBG99:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT146:%.*]], !dbg [[DBG99]]
// LIN64:       atomic_cont146:
// LIN64-NEXT:    [[TMP134:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP145]], align 16, !dbg [[DBG99]]
// LIN64-NEXT:    store <4 x i32> [[TMP134]], ptr [[ATOMIC_TEMP147]], align 16, !dbg [[DBG99]]
// LIN64-NEXT:    [[TMP135:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP145]], align 16, !dbg [[DBG99]]
// LIN64-NEXT:    store <4 x i32> [[TMP135]], ptr [[ATOMIC_TEMP148]], align 16, !dbg [[DBG99]]
// LIN64-NEXT:    [[TMP136:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP148]], align 16, !dbg [[DBG99]]
// LIN64-NEXT:    [[VECEXT:%.*]] = extractelement <4 x i32> [[TMP136]], i16 [[TMP132]], !dbg [[DBG99]]
// LIN64-NEXT:    [[OR:%.*]] = or i32 [[VECEXT]], [[CONV144]], !dbg [[DBG100:![0-9]+]]
// LIN64-NEXT:    [[TMP137:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP147]], align 16, !dbg [[DBG99]]
// LIN64-NEXT:    [[VECINS:%.*]] = insertelement <4 x i32> [[TMP137]], i32 [[OR]], i16 [[TMP132]], !dbg [[DBG99]]
// LIN64-NEXT:    store <4 x i32> [[VECINS]], ptr [[ATOMIC_TEMP147]], align 16, !dbg [[DBG99]]
// LIN64-NEXT:    [[CALL149:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, ptr noundef @int4x, ptr noundef [[ATOMIC_TEMP145]], ptr noundef [[ATOMIC_TEMP147]], i32 noundef 0, i32 noundef 0), !dbg [[DBG99]]
// LIN64-NEXT:    br i1 [[CALL149]], label [[ATOMIC_EXIT150:%.*]], label [[ATOMIC_CONT146]], !dbg [[DBG99]]
// LIN64:       atomic_exit150:
// LIN64-NEXT:    [[TMP138:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG101:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD151:%.*]] = load atomic i32, ptr getelementptr (i8, ptr @bfx, i64 4) monotonic, align 4, !dbg [[DBG102:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT152:%.*]], !dbg [[DBG102]]
// LIN64:       atomic_cont152:
// LIN64-NEXT:    [[TMP139:%.*]] = phi i32 [ [[ATOMIC_LOAD151]], [[ATOMIC_EXIT150]] ], [ [[TMP142:%.*]], [[ATOMIC_CONT152]] ], !dbg [[DBG102]]
// LIN64-NEXT:    store i32 [[TMP139]], ptr [[ATOMIC_TEMP153]], align 4, !dbg [[DBG102]]
// LIN64-NEXT:    store i32 [[TMP139]], ptr [[ATOMIC_TEMP154]], align 4, !dbg [[DBG102]]
// LIN64-NEXT:    [[BF_LOAD:%.*]] = load i32, ptr [[ATOMIC_TEMP154]], align 4, !dbg [[DBG102]]
// LIN64-NEXT:    [[BF_SHL:%.*]] = shl i32 [[BF_LOAD]], 1, !dbg [[DBG102]]
// LIN64-NEXT:    [[BF_ASHR:%.*]] = ashr i32 [[BF_SHL]], 1, !dbg [[DBG102]]
// LIN64-NEXT:    [[CONV155:%.*]] = sitofp i32 [[BF_ASHR]] to x86_fp80, !dbg [[DBG103:![0-9]+]]
// LIN64-NEXT:    [[SUB156:%.*]] = fsub x86_fp80 [[CONV155]], [[TMP138]], !dbg [[DBG104:![0-9]+]]
// LIN64-NEXT:    [[CONV157:%.*]] = fptosi x86_fp80 [[SUB156]] to i32, !dbg [[DBG103]]
// LIN64-NEXT:    [[BF_LOAD158:%.*]] = load i32, ptr [[ATOMIC_TEMP153]], align 4, !dbg [[DBG102]]
// LIN64-NEXT:    [[BF_VALUE:%.*]] = and i32 [[CONV157]], 2147483647, !dbg [[DBG102]]
// LIN64-NEXT:    [[BF_CLEAR:%.*]] = and i32 [[BF_LOAD158]], -2147483648, !dbg [[DBG102]]
// LIN64-NEXT:    [[BF_SET:%.*]] = or i32 [[BF_CLEAR]], [[BF_VALUE]], !dbg [[DBG102]]
// LIN64-NEXT:    store i32 [[BF_SET]], ptr [[ATOMIC_TEMP153]], align 4, !dbg [[DBG102]]
// LIN64-NEXT:    [[TMP140:%.*]] = load i32, ptr [[ATOMIC_TEMP153]], align 4, !dbg [[DBG102]]
// LIN64-NEXT:    [[TMP141:%.*]] = cmpxchg ptr getelementptr (i8, ptr @bfx, i64 4), i32 [[TMP139]], i32 [[TMP140]] monotonic monotonic, align 4, !dbg [[DBG102]]
// LIN64-NEXT:    [[TMP142]] = extractvalue { i32, i1 } [[TMP141]], 0, !dbg [[DBG102]]
// LIN64-NEXT:    [[TMP143:%.*]] = extractvalue { i32, i1 } [[TMP141]], 1, !dbg [[DBG102]]
// LIN64-NEXT:    br i1 [[TMP143]], label [[ATOMIC_EXIT159:%.*]], label [[ATOMIC_CONT152]], !dbg [[DBG102]]
// LIN64:       atomic_exit159:
// LIN64-NEXT:    [[TMP144:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG105:![0-9]+]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 4, ptr noundef getelementptr (i8, ptr @bfx_packed, i64 4), ptr noundef [[ATOMIC_TEMP160]], i32 noundef 0), !dbg [[DBG106:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT161:%.*]], !dbg [[DBG106]]
// LIN64:       atomic_cont161:
// LIN64-NEXT:    [[TMP145:%.*]] = load i32, ptr [[ATOMIC_TEMP160]], align 1, !dbg [[DBG106]]
// LIN64-NEXT:    store i32 [[TMP145]], ptr [[ATOMIC_TEMP162]], align 1, !dbg [[DBG106]]
// LIN64-NEXT:    [[TMP146:%.*]] = load i32, ptr [[ATOMIC_TEMP160]], align 1, !dbg [[DBG106]]
// LIN64-NEXT:    store i32 [[TMP146]], ptr [[ATOMIC_TEMP163]], align 4, !dbg [[DBG106]]
// LIN64-NEXT:    [[BF_LOAD164:%.*]] = load i32, ptr [[ATOMIC_TEMP163]], align 1, !dbg [[DBG106]]
// LIN64-NEXT:    [[BF_SHL165:%.*]] = shl i32 [[BF_LOAD164]], 1, !dbg [[DBG106]]
// LIN64-NEXT:    [[BF_ASHR166:%.*]] = ashr i32 [[BF_SHL165]], 1, !dbg [[DBG106]]
// LIN64-NEXT:    [[CONV167:%.*]] = sitofp i32 [[BF_ASHR166]] to x86_fp80, !dbg [[DBG107:![0-9]+]]
// LIN64-NEXT:    [[MUL168:%.*]] = fmul x86_fp80 [[CONV167]], [[TMP144]], !dbg [[DBG108:![0-9]+]]
// LIN64-NEXT:    [[CONV169:%.*]] = fptosi x86_fp80 [[MUL168]] to i32, !dbg [[DBG107]]
// LIN64-NEXT:    [[BF_LOAD170:%.*]] = load i32, ptr [[ATOMIC_TEMP162]], align 1, !dbg [[DBG106]]
// LIN64-NEXT:    [[BF_VALUE171:%.*]] = and i32 [[CONV169]], 2147483647, !dbg [[DBG106]]
// LIN64-NEXT:    [[BF_CLEAR172:%.*]] = and i32 [[BF_LOAD170]], -2147483648, !dbg [[DBG106]]
// LIN64-NEXT:    [[BF_SET173:%.*]] = or i32 [[BF_CLEAR172]], [[BF_VALUE171]], !dbg [[DBG106]]
// LIN64-NEXT:    store i32 [[BF_SET173]], ptr [[ATOMIC_TEMP162]], align 1, !dbg [[DBG106]]
// LIN64-NEXT:    [[CALL174:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 4, ptr noundef getelementptr (i8, ptr @bfx_packed, i64 4), ptr noundef [[ATOMIC_TEMP160]], ptr noundef [[ATOMIC_TEMP162]], i32 noundef 0, i32 noundef 0), !dbg [[DBG106]]
// LIN64-NEXT:    br i1 [[CALL174]], label [[ATOMIC_EXIT175:%.*]], label [[ATOMIC_CONT161]], !dbg [[DBG106]]
// LIN64:       atomic_exit175:
// LIN64-NEXT:    [[TMP147:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG109:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD176:%.*]] = load atomic i32, ptr @bfx2 monotonic, align 4, !dbg [[DBG110:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT177:%.*]], !dbg [[DBG110]]
// LIN64:       atomic_cont177:
// LIN64-NEXT:    [[TMP148:%.*]] = phi i32 [ [[ATOMIC_LOAD176]], [[ATOMIC_EXIT175]] ], [ [[TMP151:%.*]], [[ATOMIC_CONT177]] ], !dbg [[DBG110]]
// LIN64-NEXT:    store i32 [[TMP148]], ptr [[ATOMIC_TEMP178]], align 4, !dbg [[DBG110]]
// LIN64-NEXT:    store i32 [[TMP148]], ptr [[ATOMIC_TEMP179]], align 4, !dbg [[DBG110]]
// LIN64-NEXT:    [[BF_LOAD180:%.*]] = load i32, ptr [[ATOMIC_TEMP179]], align 4, !dbg [[DBG110]]
// LIN64-NEXT:    [[BF_ASHR181:%.*]] = ashr i32 [[BF_LOAD180]], 31, !dbg [[DBG110]]
// LIN64-NEXT:    [[CONV182:%.*]] = sitofp i32 [[BF_ASHR181]] to x86_fp80, !dbg [[DBG111:![0-9]+]]
// LIN64-NEXT:    [[SUB183:%.*]] = fsub x86_fp80 [[CONV182]], [[TMP147]], !dbg [[DBG112:![0-9]+]]
// LIN64-NEXT:    [[CONV184:%.*]] = fptosi x86_fp80 [[SUB183]] to i32, !dbg [[DBG111]]
// LIN64-NEXT:    [[BF_LOAD185:%.*]] = load i32, ptr [[ATOMIC_TEMP178]], align 4, !dbg [[DBG110]]
// LIN64-NEXT:    [[BF_VALUE186:%.*]] = and i32 [[CONV184]], 1, !dbg [[DBG110]]
// LIN64-NEXT:    [[BF_SHL187:%.*]] = shl i32 [[BF_VALUE186]], 31, !dbg [[DBG110]]
// LIN64-NEXT:    [[BF_CLEAR188:%.*]] = and i32 [[BF_LOAD185]], 2147483647, !dbg [[DBG110]]
// LIN64-NEXT:    [[BF_SET189:%.*]] = or i32 [[BF_CLEAR188]], [[BF_SHL187]], !dbg [[DBG110]]
// LIN64-NEXT:    store i32 [[BF_SET189]], ptr [[ATOMIC_TEMP178]], align 4, !dbg [[DBG110]]
// LIN64-NEXT:    [[TMP149:%.*]] = load i32, ptr [[ATOMIC_TEMP178]], align 4, !dbg [[DBG110]]
// LIN64-NEXT:    [[TMP150:%.*]] = cmpxchg ptr @bfx2, i32 [[TMP148]], i32 [[TMP149]] monotonic monotonic, align 4, !dbg [[DBG110]]
// LIN64-NEXT:    [[TMP151]] = extractvalue { i32, i1 } [[TMP150]], 0, !dbg [[DBG110]]
// LIN64-NEXT:    [[TMP152:%.*]] = extractvalue { i32, i1 } [[TMP150]], 1, !dbg [[DBG110]]
// LIN64-NEXT:    br i1 [[TMP152]], label [[ATOMIC_EXIT190:%.*]], label [[ATOMIC_CONT177]], !dbg [[DBG110]]
// LIN64:       atomic_exit190:
// LIN64-NEXT:    [[TMP153:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG113:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD191:%.*]] = load atomic i8, ptr getelementptr (i8, ptr @bfx2_packed, i64 3) monotonic, align 1, !dbg [[DBG114:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT192:%.*]], !dbg [[DBG114]]
// LIN64:       atomic_cont192:
// LIN64-NEXT:    [[TMP154:%.*]] = phi i8 [ [[ATOMIC_LOAD191]], [[ATOMIC_EXIT190]] ], [ [[TMP158:%.*]], [[ATOMIC_CONT192]] ], !dbg [[DBG114]]
// LIN64-NEXT:    store i8 [[TMP154]], ptr [[ATOMIC_TEMP193]], align 1, !dbg [[DBG114]]
// LIN64-NEXT:    store i8 [[TMP154]], ptr [[ATOMIC_TEMP194]], align 1, !dbg [[DBG114]]
// LIN64-NEXT:    [[BF_LOAD195:%.*]] = load i8, ptr [[ATOMIC_TEMP194]], align 1, !dbg [[DBG114]]
// LIN64-NEXT:    [[BF_ASHR196:%.*]] = ashr i8 [[BF_LOAD195]], 7, !dbg [[DBG114]]
// LIN64-NEXT:    [[BF_CAST:%.*]] = sext i8 [[BF_ASHR196]] to i32, !dbg [[DBG114]]
// LIN64-NEXT:    [[CONV197:%.*]] = sitofp i32 [[BF_CAST]] to x86_fp80, !dbg [[DBG115:![0-9]+]]
// LIN64-NEXT:    [[DIV198:%.*]] = fdiv x86_fp80 [[TMP153]], [[CONV197]], !dbg [[DBG116:![0-9]+]]
// LIN64-NEXT:    [[CONV199:%.*]] = fptosi x86_fp80 [[DIV198]] to i32, !dbg [[DBG113]]
// LIN64-NEXT:    [[TMP155:%.*]] = trunc i32 [[CONV199]] to i8, !dbg [[DBG114]]
// LIN64-NEXT:    [[BF_LOAD200:%.*]] = load i8, ptr [[ATOMIC_TEMP193]], align 1, !dbg [[DBG114]]
// LIN64-NEXT:    [[BF_VALUE201:%.*]] = and i8 [[TMP155]], 1, !dbg [[DBG114]]
// LIN64-NEXT:    [[BF_SHL202:%.*]] = shl i8 [[BF_VALUE201]], 7, !dbg [[DBG114]]
// LIN64-NEXT:    [[BF_CLEAR203:%.*]] = and i8 [[BF_LOAD200]], 127, !dbg [[DBG114]]
// LIN64-NEXT:    [[BF_SET204:%.*]] = or i8 [[BF_CLEAR203]], [[BF_SHL202]], !dbg [[DBG114]]
// LIN64-NEXT:    store i8 [[BF_SET204]], ptr [[ATOMIC_TEMP193]], align 1, !dbg [[DBG114]]
// LIN64-NEXT:    [[TMP156:%.*]] = load i8, ptr [[ATOMIC_TEMP193]], align 1, !dbg [[DBG114]]
// LIN64-NEXT:    [[TMP157:%.*]] = cmpxchg ptr getelementptr (i8, ptr @bfx2_packed, i64 3), i8 [[TMP154]], i8 [[TMP156]] monotonic monotonic, align 1, !dbg [[DBG114]]
// LIN64-NEXT:    [[TMP158]] = extractvalue { i8, i1 } [[TMP157]], 0, !dbg [[DBG114]]
// LIN64-NEXT:    [[TMP159:%.*]] = extractvalue { i8, i1 } [[TMP157]], 1, !dbg [[DBG114]]
// LIN64-NEXT:    br i1 [[TMP159]], label [[ATOMIC_EXIT205:%.*]], label [[ATOMIC_CONT192]], !dbg [[DBG114]]
// LIN64:       atomic_exit205:
// LIN64-NEXT:    [[TMP160:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG117:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD206:%.*]] = load atomic i32, ptr @bfx3 monotonic, align 4, !dbg [[DBG118:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT207:%.*]], !dbg [[DBG118]]
// LIN64:       atomic_cont207:
// LIN64-NEXT:    [[TMP161:%.*]] = phi i32 [ [[ATOMIC_LOAD206]], [[ATOMIC_EXIT205]] ], [ [[TMP164:%.*]], [[ATOMIC_CONT207]] ], !dbg [[DBG118]]
// LIN64-NEXT:    store i32 [[TMP161]], ptr [[ATOMIC_TEMP208]], align 4, !dbg [[DBG118]]
// LIN64-NEXT:    store i32 [[TMP161]], ptr [[ATOMIC_TEMP209]], align 4, !dbg [[DBG118]]
// LIN64-NEXT:    [[BF_LOAD210:%.*]] = load i32, ptr [[ATOMIC_TEMP209]], align 4, !dbg [[DBG118]]
// LIN64-NEXT:    [[BF_SHL211:%.*]] = shl i32 [[BF_LOAD210]], 7, !dbg [[DBG118]]
// LIN64-NEXT:    [[BF_ASHR212:%.*]] = ashr i32 [[BF_SHL211]], 18, !dbg [[DBG118]]
// LIN64-NEXT:    [[CONV213:%.*]] = sitofp i32 [[BF_ASHR212]] to x86_fp80, !dbg [[DBG119:![0-9]+]]
// LIN64-NEXT:    [[DIV214:%.*]] = fdiv x86_fp80 [[CONV213]], [[TMP160]], !dbg [[DBG120:![0-9]+]]
// LIN64-NEXT:    [[CONV215:%.*]] = fptosi x86_fp80 [[DIV214]] to i32, !dbg [[DBG119]]
// LIN64-NEXT:    [[BF_LOAD216:%.*]] = load i32, ptr [[ATOMIC_TEMP208]], align 4, !dbg [[DBG118]]
// LIN64-NEXT:    [[BF_VALUE217:%.*]] = and i32 [[CONV215]], 16383, !dbg [[DBG118]]
// LIN64-NEXT:    [[BF_SHL218:%.*]] = shl i32 [[BF_VALUE217]], 11, !dbg [[DBG118]]
// LIN64-NEXT:    [[BF_CLEAR219:%.*]] = and i32 [[BF_LOAD216]], -33552385, !dbg [[DBG118]]
// LIN64-NEXT:    [[BF_SET220:%.*]] = or i32 [[BF_CLEAR219]], [[BF_SHL218]], !dbg [[DBG118]]
// LIN64-NEXT:    store i32 [[BF_SET220]], ptr [[ATOMIC_TEMP208]], align 4, !dbg [[DBG118]]
// LIN64-NEXT:    [[TMP162:%.*]] = load i32, ptr [[ATOMIC_TEMP208]], align 4, !dbg [[DBG118]]
// LIN64-NEXT:    [[TMP163:%.*]] = cmpxchg ptr @bfx3, i32 [[TMP161]], i32 [[TMP162]] monotonic monotonic, align 4, !dbg [[DBG118]]
// LIN64-NEXT:    [[TMP164]] = extractvalue { i32, i1 } [[TMP163]], 0, !dbg [[DBG118]]
// LIN64-NEXT:    [[TMP165:%.*]] = extractvalue { i32, i1 } [[TMP163]], 1, !dbg [[DBG118]]
// LIN64-NEXT:    br i1 [[TMP165]], label [[ATOMIC_EXIT221:%.*]], label [[ATOMIC_CONT207]], !dbg [[DBG118]]
// LIN64:       atomic_exit221:
// LIN64-NEXT:    [[TMP166:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG121:![0-9]+]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 3, ptr noundef getelementptr (i8, ptr @bfx3_packed, i64 1), ptr noundef [[ATOMIC_TEMP222]], i32 noundef 0), !dbg [[DBG122:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT223:%.*]], !dbg [[DBG122]]
// LIN64:       atomic_cont223:
// LIN64-NEXT:    [[TMP167:%.*]] = load i24, ptr [[ATOMIC_TEMP222]], align 1, !dbg [[DBG122]]
// LIN64-NEXT:    store i24 [[TMP167]], ptr [[ATOMIC_TEMP224]], align 1, !dbg [[DBG122]]
// LIN64-NEXT:    [[TMP168:%.*]] = load i24, ptr [[ATOMIC_TEMP222]], align 1, !dbg [[DBG122]]
// LIN64-NEXT:    store i24 [[TMP168]], ptr [[ATOMIC_TEMP225]], align 1, !dbg [[DBG122]]
// LIN64-NEXT:    [[BF_LOAD226:%.*]] = load i24, ptr [[ATOMIC_TEMP225]], align 1, !dbg [[DBG122]]
// LIN64-NEXT:    [[BF_SHL227:%.*]] = shl i24 [[BF_LOAD226]], 7, !dbg [[DBG122]]
// LIN64-NEXT:    [[BF_ASHR228:%.*]] = ashr i24 [[BF_SHL227]], 10, !dbg [[DBG122]]
// LIN64-NEXT:    [[BF_CAST229:%.*]] = sext i24 [[BF_ASHR228]] to i32, !dbg [[DBG122]]
// LIN64-NEXT:    [[CONV230:%.*]] = sitofp i32 [[BF_CAST229]] to x86_fp80, !dbg [[DBG123:![0-9]+]]
// LIN64-NEXT:    [[ADD231:%.*]] = fadd x86_fp80 [[CONV230]], [[TMP166]], !dbg [[DBG124:![0-9]+]]
// LIN64-NEXT:    [[CONV232:%.*]] = fptosi x86_fp80 [[ADD231]] to i32, !dbg [[DBG123]]
// LIN64-NEXT:    [[TMP169:%.*]] = trunc i32 [[CONV232]] to i24, !dbg [[DBG122]]
// LIN64-NEXT:    [[BF_LOAD233:%.*]] = load i24, ptr [[ATOMIC_TEMP224]], align 1, !dbg [[DBG122]]
// LIN64-NEXT:    [[BF_VALUE234:%.*]] = and i24 [[TMP169]], 16383, !dbg [[DBG122]]
// LIN64-NEXT:    [[BF_SHL235:%.*]] = shl i24 [[BF_VALUE234]], 3, !dbg [[DBG122]]
// LIN64-NEXT:    [[BF_CLEAR236:%.*]] = and i24 [[BF_LOAD233]], -131065, !dbg [[DBG122]]
// LIN64-NEXT:    [[BF_SET237:%.*]] = or i24 [[BF_CLEAR236]], [[BF_SHL235]], !dbg [[DBG122]]
// LIN64-NEXT:    store i24 [[BF_SET237]], ptr [[ATOMIC_TEMP224]], align 1, !dbg [[DBG122]]
// LIN64-NEXT:    [[CALL238:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 3, ptr noundef getelementptr (i8, ptr @bfx3_packed, i64 1), ptr noundef [[ATOMIC_TEMP222]], ptr noundef [[ATOMIC_TEMP224]], i32 noundef 0, i32 noundef 0), !dbg [[DBG122]]
// LIN64-NEXT:    br i1 [[CALL238]], label [[ATOMIC_EXIT239:%.*]], label [[ATOMIC_CONT223]], !dbg [[DBG122]]
// LIN64:       atomic_exit239:
// LIN64-NEXT:    [[TMP170:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG125:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD240:%.*]] = load atomic i64, ptr @bfx4 monotonic, align 8, !dbg [[DBG126:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT241:%.*]], !dbg [[DBG126]]
// LIN64:       atomic_cont241:
// LIN64-NEXT:    [[TMP171:%.*]] = phi i64 [ [[ATOMIC_LOAD240]], [[ATOMIC_EXIT239]] ], [ [[TMP175:%.*]], [[ATOMIC_CONT241]] ], !dbg [[DBG126]]
// LIN64-NEXT:    store i64 [[TMP171]], ptr [[ATOMIC_TEMP242]], align 8, !dbg [[DBG126]]
// LIN64-NEXT:    store i64 [[TMP171]], ptr [[ATOMIC_TEMP243]], align 8, !dbg [[DBG126]]
// LIN64-NEXT:    [[BF_LOAD244:%.*]] = load i64, ptr [[ATOMIC_TEMP243]], align 8, !dbg [[DBG126]]
// LIN64-NEXT:    [[BF_SHL245:%.*]] = shl i64 [[BF_LOAD244]], 47, !dbg [[DBG126]]
// LIN64-NEXT:    [[BF_ASHR246:%.*]] = ashr i64 [[BF_SHL245]], 63, !dbg [[DBG126]]
// LIN64-NEXT:    [[BF_CAST247:%.*]] = trunc i64 [[BF_ASHR246]] to i32, !dbg [[DBG126]]
// LIN64-NEXT:    [[CONV248:%.*]] = sitofp i32 [[BF_CAST247]] to x86_fp80, !dbg [[DBG127:![0-9]+]]
// LIN64-NEXT:    [[MUL249:%.*]] = fmul x86_fp80 [[CONV248]], [[TMP170]], !dbg [[DBG128:![0-9]+]]
// LIN64-NEXT:    [[CONV250:%.*]] = fptosi x86_fp80 [[MUL249]] to i32, !dbg [[DBG127]]
// LIN64-NEXT:    [[TMP172:%.*]] = zext i32 [[CONV250]] to i64, !dbg [[DBG126]]
// LIN64-NEXT:    [[BF_LOAD251:%.*]] = load i64, ptr [[ATOMIC_TEMP242]], align 8, !dbg [[DBG126]]
// LIN64-NEXT:    [[BF_VALUE252:%.*]] = and i64 [[TMP172]], 1, !dbg [[DBG126]]
// LIN64-NEXT:    [[BF_SHL253:%.*]] = shl i64 [[BF_VALUE252]], 16, !dbg [[DBG126]]
// LIN64-NEXT:    [[BF_CLEAR254:%.*]] = and i64 [[BF_LOAD251]], -65537, !dbg [[DBG126]]
// LIN64-NEXT:    [[BF_SET255:%.*]] = or i64 [[BF_CLEAR254]], [[BF_SHL253]], !dbg [[DBG126]]
// LIN64-NEXT:    store i64 [[BF_SET255]], ptr [[ATOMIC_TEMP242]], align 8, !dbg [[DBG126]]
// LIN64-NEXT:    [[TMP173:%.*]] = load i64, ptr [[ATOMIC_TEMP242]], align 8, !dbg [[DBG126]]
// LIN64-NEXT:    [[TMP174:%.*]] = cmpxchg ptr @bfx4, i64 [[TMP171]], i64 [[TMP173]] monotonic monotonic, align 8, !dbg [[DBG126]]
// LIN64-NEXT:    [[TMP175]] = extractvalue { i64, i1 } [[TMP174]], 0, !dbg [[DBG126]]
// LIN64-NEXT:    [[TMP176:%.*]] = extractvalue { i64, i1 } [[TMP174]], 1, !dbg [[DBG126]]
// LIN64-NEXT:    br i1 [[TMP176]], label [[ATOMIC_EXIT256:%.*]], label [[ATOMIC_CONT241]], !dbg [[DBG126]]
// LIN64:       atomic_exit256:
// LIN64-NEXT:    [[TMP177:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG129:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD257:%.*]] = load atomic i8, ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED:%.*]], ptr @bfx4_packed, i32 0, i32 1) monotonic, align 1, !dbg [[DBG130:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT258:%.*]], !dbg [[DBG130]]
// LIN64:       atomic_cont258:
// LIN64-NEXT:    [[TMP178:%.*]] = phi i8 [ [[ATOMIC_LOAD257]], [[ATOMIC_EXIT256]] ], [ [[TMP182:%.*]], [[ATOMIC_CONT258]] ], !dbg [[DBG130]]
// LIN64-NEXT:    store i8 [[TMP178]], ptr [[ATOMIC_TEMP259]], align 1, !dbg [[DBG130]]
// LIN64-NEXT:    store i8 [[TMP178]], ptr [[ATOMIC_TEMP260]], align 1, !dbg [[DBG130]]
// LIN64-NEXT:    [[BF_LOAD261:%.*]] = load i8, ptr [[ATOMIC_TEMP260]], align 1, !dbg [[DBG130]]
// LIN64-NEXT:    [[BF_SHL262:%.*]] = shl i8 [[BF_LOAD261]], 7, !dbg [[DBG130]]
// LIN64-NEXT:    [[BF_ASHR263:%.*]] = ashr i8 [[BF_SHL262]], 7, !dbg [[DBG130]]
// LIN64-NEXT:    [[BF_CAST264:%.*]] = sext i8 [[BF_ASHR263]] to i32, !dbg [[DBG130]]
// LIN64-NEXT:    [[CONV265:%.*]] = sitofp i32 [[BF_CAST264]] to x86_fp80, !dbg [[DBG131:![0-9]+]]
// LIN64-NEXT:    [[SUB266:%.*]] = fsub x86_fp80 [[CONV265]], [[TMP177]], !dbg [[DBG132:![0-9]+]]
// LIN64-NEXT:    [[CONV267:%.*]] = fptosi x86_fp80 [[SUB266]] to i32, !dbg [[DBG131]]
// LIN64-NEXT:    [[TMP179:%.*]] = trunc i32 [[CONV267]] to i8, !dbg [[DBG130]]
// LIN64-NEXT:    [[BF_LOAD268:%.*]] = load i8, ptr [[ATOMIC_TEMP259]], align 1, !dbg [[DBG130]]
// LIN64-NEXT:    [[BF_VALUE269:%.*]] = and i8 [[TMP179]], 1, !dbg [[DBG130]]
// LIN64-NEXT:    [[BF_CLEAR270:%.*]] = and i8 [[BF_LOAD268]], -2, !dbg [[DBG130]]
// LIN64-NEXT:    [[BF_SET271:%.*]] = or i8 [[BF_CLEAR270]], [[BF_VALUE269]], !dbg [[DBG130]]
// LIN64-NEXT:    store i8 [[BF_SET271]], ptr [[ATOMIC_TEMP259]], align 1, !dbg [[DBG130]]
// LIN64-NEXT:    [[TMP180:%.*]] = load i8, ptr [[ATOMIC_TEMP259]], align 1, !dbg [[DBG130]]
// LIN64-NEXT:    [[TMP181:%.*]] = cmpxchg ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1), i8 [[TMP178]], i8 [[TMP180]] monotonic monotonic, align 1, !dbg [[DBG130]]
// LIN64-NEXT:    [[TMP182]] = extractvalue { i8, i1 } [[TMP181]], 0, !dbg [[DBG130]]
// LIN64-NEXT:    [[TMP183:%.*]] = extractvalue { i8, i1 } [[TMP181]], 1, !dbg [[DBG130]]
// LIN64-NEXT:    br i1 [[TMP183]], label [[ATOMIC_EXIT272:%.*]], label [[ATOMIC_CONT258]], !dbg [[DBG130]]
// LIN64:       atomic_exit272:
// LIN64-NEXT:    [[TMP184:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG133:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD273:%.*]] = load atomic i64, ptr @bfx4 monotonic, align 8, !dbg [[DBG134:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT274:%.*]], !dbg [[DBG134]]
// LIN64:       atomic_cont274:
// LIN64-NEXT:    [[TMP185:%.*]] = phi i64 [ [[ATOMIC_LOAD273]], [[ATOMIC_EXIT272]] ], [ [[TMP188:%.*]], [[ATOMIC_CONT274]] ], !dbg [[DBG134]]
// LIN64-NEXT:    store i64 [[TMP185]], ptr [[ATOMIC_TEMP275]], align 8, !dbg [[DBG134]]
// LIN64-NEXT:    store i64 [[TMP185]], ptr [[ATOMIC_TEMP276]], align 8, !dbg [[DBG134]]
// LIN64-NEXT:    [[BF_LOAD277:%.*]] = load i64, ptr [[ATOMIC_TEMP276]], align 8, !dbg [[DBG134]]
// LIN64-NEXT:    [[BF_SHL278:%.*]] = shl i64 [[BF_LOAD277]], 40, !dbg [[DBG134]]
// LIN64-NEXT:    [[BF_ASHR279:%.*]] = ashr i64 [[BF_SHL278]], 57, !dbg [[DBG134]]
// LIN64-NEXT:    [[CONV280:%.*]] = sitofp i64 [[BF_ASHR279]] to x86_fp80, !dbg [[DBG135:![0-9]+]]
// LIN64-NEXT:    [[DIV281:%.*]] = fdiv x86_fp80 [[CONV280]], [[TMP184]], !dbg [[DBG136:![0-9]+]]
// LIN64-NEXT:    [[CONV282:%.*]] = fptosi x86_fp80 [[DIV281]] to i64, !dbg [[DBG135]]
// LIN64-NEXT:    [[BF_LOAD283:%.*]] = load i64, ptr [[ATOMIC_TEMP275]], align 8, !dbg [[DBG134]]
// LIN64-NEXT:    [[BF_VALUE284:%.*]] = and i64 [[CONV282]], 127, !dbg [[DBG134]]
// LIN64-NEXT:    [[BF_SHL285:%.*]] = shl i64 [[BF_VALUE284]], 17, !dbg [[DBG134]]
// LIN64-NEXT:    [[BF_CLEAR286:%.*]] = and i64 [[BF_LOAD283]], -16646145, !dbg [[DBG134]]
// LIN64-NEXT:    [[BF_SET287:%.*]] = or i64 [[BF_CLEAR286]], [[BF_SHL285]], !dbg [[DBG134]]
// LIN64-NEXT:    store i64 [[BF_SET287]], ptr [[ATOMIC_TEMP275]], align 8, !dbg [[DBG134]]
// LIN64-NEXT:    [[TMP186:%.*]] = load i64, ptr [[ATOMIC_TEMP275]], align 8, !dbg [[DBG134]]
// LIN64-NEXT:    [[TMP187:%.*]] = cmpxchg ptr @bfx4, i64 [[TMP185]], i64 [[TMP186]] monotonic monotonic, align 8, !dbg [[DBG134]]
// LIN64-NEXT:    [[TMP188]] = extractvalue { i64, i1 } [[TMP187]], 0, !dbg [[DBG134]]
// LIN64-NEXT:    [[TMP189:%.*]] = extractvalue { i64, i1 } [[TMP187]], 1, !dbg [[DBG134]]
// LIN64-NEXT:    br i1 [[TMP189]], label [[ATOMIC_EXIT288:%.*]], label [[ATOMIC_CONT274]], !dbg [[DBG134]]
// LIN64:       atomic_exit288:
// LIN64-NEXT:    [[TMP190:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG137:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD289:%.*]] = load atomic i8, ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1) monotonic, align 1, !dbg [[DBG138:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT290:%.*]], !dbg [[DBG138]]
// LIN64:       atomic_cont290:
// LIN64-NEXT:    [[TMP191:%.*]] = phi i8 [ [[ATOMIC_LOAD289]], [[ATOMIC_EXIT288]] ], [ [[TMP195:%.*]], [[ATOMIC_CONT290]] ], !dbg [[DBG138]]
// LIN64-NEXT:    store i8 [[TMP191]], ptr [[ATOMIC_TEMP291]], align 1, !dbg [[DBG138]]
// LIN64-NEXT:    store i8 [[TMP191]], ptr [[ATOMIC_TEMP292]], align 1, !dbg [[DBG138]]
// LIN64-NEXT:    [[BF_LOAD293:%.*]] = load i8, ptr [[ATOMIC_TEMP292]], align 1, !dbg [[DBG138]]
// LIN64-NEXT:    [[BF_ASHR294:%.*]] = ashr i8 [[BF_LOAD293]], 1, !dbg [[DBG138]]
// LIN64-NEXT:    [[BF_CAST295:%.*]] = sext i8 [[BF_ASHR294]] to i64, !dbg [[DBG138]]
// LIN64-NEXT:    [[CONV296:%.*]] = sitofp i64 [[BF_CAST295]] to x86_fp80, !dbg [[DBG139:![0-9]+]]
// LIN64-NEXT:    [[ADD297:%.*]] = fadd x86_fp80 [[CONV296]], [[TMP190]], !dbg [[DBG140:![0-9]+]]
// LIN64-NEXT:    [[CONV298:%.*]] = fptosi x86_fp80 [[ADD297]] to i64, !dbg [[DBG139]]
// LIN64-NEXT:    [[TMP192:%.*]] = trunc i64 [[CONV298]] to i8, !dbg [[DBG138]]
// LIN64-NEXT:    [[BF_LOAD299:%.*]] = load i8, ptr [[ATOMIC_TEMP291]], align 1, !dbg [[DBG138]]
// LIN64-NEXT:    [[BF_VALUE300:%.*]] = and i8 [[TMP192]], 127, !dbg [[DBG138]]
// LIN64-NEXT:    [[BF_SHL301:%.*]] = shl i8 [[BF_VALUE300]], 1, !dbg [[DBG138]]
// LIN64-NEXT:    [[BF_CLEAR302:%.*]] = and i8 [[BF_LOAD299]], 1, !dbg [[DBG138]]
// LIN64-NEXT:    [[BF_SET303:%.*]] = or i8 [[BF_CLEAR302]], [[BF_SHL301]], !dbg [[DBG138]]
// LIN64-NEXT:    store i8 [[BF_SET303]], ptr [[ATOMIC_TEMP291]], align 1, !dbg [[DBG138]]
// LIN64-NEXT:    [[TMP193:%.*]] = load i8, ptr [[ATOMIC_TEMP291]], align 1, !dbg [[DBG138]]
// LIN64-NEXT:    [[TMP194:%.*]] = cmpxchg ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1), i8 [[TMP191]], i8 [[TMP193]] monotonic monotonic, align 1, !dbg [[DBG138]]
// LIN64-NEXT:    [[TMP195]] = extractvalue { i8, i1 } [[TMP194]], 0, !dbg [[DBG138]]
// LIN64-NEXT:    [[TMP196:%.*]] = extractvalue { i8, i1 } [[TMP194]], 1, !dbg [[DBG138]]
// LIN64-NEXT:    br i1 [[TMP196]], label [[ATOMIC_EXIT304:%.*]], label [[ATOMIC_CONT290]], !dbg [[DBG138]]
// LIN64:       atomic_exit304:
// LIN64-NEXT:    [[TMP197:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG141:![0-9]+]]
// LIN64-NEXT:    [[CONV305:%.*]] = uitofp i64 [[TMP197]] to float, !dbg [[DBG141]]
// LIN64-NEXT:    [[ATOMIC_LOAD306:%.*]] = load atomic i64, ptr @float2x monotonic, align 8, !dbg [[DBG142:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT307:%.*]], !dbg [[DBG142]]
// LIN64:       atomic_cont307:
// LIN64-NEXT:    [[TMP198:%.*]] = phi i64 [ [[ATOMIC_LOAD306]], [[ATOMIC_EXIT304]] ], [ [[TMP206:%.*]], [[ATOMIC_CONT307]] ], !dbg [[DBG142]]
// LIN64-NEXT:    store i64 [[TMP198]], ptr [[ATOMIC_TEMP308]], align 8, !dbg [[DBG142]]
// LIN64-NEXT:    [[TMP199:%.*]] = bitcast i64 [[TMP198]] to <2 x float>, !dbg [[DBG142]]
// LIN64-NEXT:    store <2 x float> [[TMP199]], ptr [[ATOMIC_TEMP309]], align 8, !dbg [[DBG142]]
// LIN64-NEXT:    [[TMP200:%.*]] = load <2 x float>, ptr [[ATOMIC_TEMP309]], align 8, !dbg [[DBG142]]
// LIN64-NEXT:    [[TMP201:%.*]] = extractelement <2 x float> [[TMP200]], i64 0, !dbg [[DBG142]]
// LIN64-NEXT:    [[SUB310:%.*]] = fsub float [[CONV305]], [[TMP201]], !dbg [[DBG143:![0-9]+]]
// LIN64-NEXT:    [[TMP202:%.*]] = load <2 x float>, ptr [[ATOMIC_TEMP308]], align 8, !dbg [[DBG142]]
// LIN64-NEXT:    [[TMP203:%.*]] = insertelement <2 x float> [[TMP202]], float [[SUB310]], i64 0, !dbg [[DBG142]]
// LIN64-NEXT:    store <2 x float> [[TMP203]], ptr [[ATOMIC_TEMP308]], align 8, !dbg [[DBG142]]
// LIN64-NEXT:    [[TMP204:%.*]] = load i64, ptr [[ATOMIC_TEMP308]], align 8, !dbg [[DBG142]]
// LIN64-NEXT:    [[TMP205:%.*]] = cmpxchg ptr @float2x, i64 [[TMP198]], i64 [[TMP204]] monotonic monotonic, align 8, !dbg [[DBG142]]
// LIN64-NEXT:    [[TMP206]] = extractvalue { i64, i1 } [[TMP205]], 0, !dbg [[DBG142]]
// LIN64-NEXT:    [[TMP207:%.*]] = extractvalue { i64, i1 } [[TMP205]], 1, !dbg [[DBG142]]
// LIN64-NEXT:    br i1 [[TMP207]], label [[ATOMIC_EXIT311:%.*]], label [[ATOMIC_CONT307]], !dbg [[DBG142]]
// LIN64:       atomic_exit311:
// LIN64-NEXT:    [[TMP208:%.*]] = load double, ptr @dv, align 8, !dbg [[DBG144:![0-9]+]]
// LIN64-NEXT:    [[TMP209:%.*]] = call i32 @llvm.read_register.i32(metadata [[META2:![0-9]+]]), !dbg [[DBG145:![0-9]+]]
// LIN64-NEXT:    [[CONV312:%.*]] = sitofp i32 [[TMP209]] to double, !dbg [[DBG145]]
// LIN64-NEXT:    [[DIV313:%.*]] = fdiv double [[TMP208]], [[CONV312]], !dbg [[DBG146:![0-9]+]]
// LIN64-NEXT:    [[CONV314:%.*]] = fptosi double [[DIV313]] to i32, !dbg [[DBG144]]
// LIN64-NEXT:    call void @llvm.write_register.i32(metadata [[META2]], i32 [[CONV314]]), !dbg [[DBG145]]
// LIN64-NEXT:    fence release
// LIN64-NEXT:    ret i32 0, !dbg [[DBG147:![0-9]+]]
//
//
// PPC64-LABEL: define {{[^@]+}}@main
// PPC64-SAME: () #[[ATTR0:[0-9]+]] !dbg [[DBG6:![0-9]+]] {
// PPC64-NEXT:  entry:
// PPC64-NEXT:    [[RETVAL:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca i16, align 2
// PPC64-NEXT:    [[ATOMIC_TEMP5:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP9:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP13:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP17:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP21:%.*]] = alloca double, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP23:%.*]] = alloca ppc_fp128, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP25:%.*]] = alloca ppc_fp128, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP28:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP30:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP33:%.*]] = alloca { float, float }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP35:%.*]] = alloca { float, float }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP38:%.*]] = alloca { double, double }, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP40:%.*]] = alloca { double, double }, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP47:%.*]] = alloca i8, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP54:%.*]] = alloca i8, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP62:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP69:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP71:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP73:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP85:%.*]] = alloca float, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP91:%.*]] = alloca double, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP95:%.*]] = alloca ppc_fp128, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP97:%.*]] = alloca ppc_fp128, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP101:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP103:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP113:%.*]] = alloca i16, align 2
// PPC64-NEXT:    [[ATOMIC_TEMP121:%.*]] = alloca i8, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP133:%.*]] = alloca i8, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP145:%.*]] = alloca <4 x i32>, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP147:%.*]] = alloca <4 x i32>, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP148:%.*]] = alloca <4 x i32>, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP153:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP154:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP160:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP162:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP163:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP178:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP179:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP193:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP194:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP208:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP209:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP222:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP224:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP225:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP242:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP243:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP259:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP260:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP275:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP276:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP291:%.*]] = alloca i64, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP292:%.*]] = alloca i64, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP308:%.*]] = alloca <2 x float>, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP309:%.*]] = alloca <2 x float>, align 8
// PPC64-NEXT:    store i32 0, ptr [[RETVAL]], align 4
// PPC64-NEXT:    [[TMP0:%.*]] = atomicrmw fadd ptr @dv, double 1.000000e+00 monotonic, align 8, !dbg [[DBG10:![0-9]+]]
// PPC64-NEXT:    [[TMP1:%.*]] = atomicrmw add ptr @bx, i8 1 monotonic, align 1, !dbg [[DBG11:![0-9]+]]
// PPC64-NEXT:    [[TMP2:%.*]] = atomicrmw add ptr @cx, i8 1 monotonic, align 1, !dbg [[DBG12:![0-9]+]]
// PPC64-NEXT:    [[TMP3:%.*]] = atomicrmw sub ptr @ucx, i8 1 monotonic, align 1, !dbg [[DBG13:![0-9]+]]
// PPC64-NEXT:    [[TMP4:%.*]] = atomicrmw sub ptr @sx, i16 1 monotonic, align 2, !dbg [[DBG14:![0-9]+]]
// PPC64-NEXT:    [[TMP5:%.*]] = load i16, ptr @usv, align 2, !dbg [[DBG15:![0-9]+]]
// PPC64-NEXT:    [[CONV:%.*]] = zext i16 [[TMP5]] to i32, !dbg [[DBG15]]
// PPC64-NEXT:    [[ATOMIC_LOAD:%.*]] = load atomic i16, ptr @usx monotonic, align 2, !dbg [[DBG16:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT:%.*]], !dbg [[DBG16]]
// PPC64:       atomic_cont:
// PPC64-NEXT:    [[TMP6:%.*]] = phi i16 [ [[ATOMIC_LOAD]], [[ENTRY:%.*]] ], [ [[TMP9:%.*]], [[ATOMIC_CONT]] ], !dbg [[DBG16]]
// PPC64-NEXT:    [[CONV1:%.*]] = zext i16 [[TMP6]] to i32, !dbg [[DBG16]]
// PPC64-NEXT:    [[ADD:%.*]] = add nsw i32 [[CONV1]], [[CONV]], !dbg [[DBG17:![0-9]+]]
// PPC64-NEXT:    [[CONV2:%.*]] = trunc i32 [[ADD]] to i16, !dbg [[DBG16]]
// PPC64-NEXT:    store i16 [[CONV2]], ptr [[ATOMIC_TEMP]], align 2, !dbg [[DBG16]]
// PPC64-NEXT:    [[TMP7:%.*]] = load i16, ptr [[ATOMIC_TEMP]], align 2, !dbg [[DBG16]]
// PPC64-NEXT:    [[TMP8:%.*]] = cmpxchg ptr @usx, i16 [[TMP6]], i16 [[TMP7]] monotonic monotonic, align 2, !dbg [[DBG16]]
// PPC64-NEXT:    [[TMP9]] = extractvalue { i16, i1 } [[TMP8]], 0, !dbg [[DBG16]]
// PPC64-NEXT:    [[TMP10:%.*]] = extractvalue { i16, i1 } [[TMP8]], 1, !dbg [[DBG16]]
// PPC64-NEXT:    br i1 [[TMP10]], label [[ATOMIC_EXIT:%.*]], label [[ATOMIC_CONT]], !dbg [[DBG16]]
// PPC64:       atomic_exit:
// PPC64-NEXT:    [[TMP11:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG18:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD3:%.*]] = load atomic i32, ptr @ix monotonic, align 4, !dbg [[DBG19:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT4:%.*]], !dbg [[DBG19]]
// PPC64:       atomic_cont4:
// PPC64-NEXT:    [[TMP12:%.*]] = phi i32 [ [[ATOMIC_LOAD3]], [[ATOMIC_EXIT]] ], [ [[TMP15:%.*]], [[ATOMIC_CONT4]] ], !dbg [[DBG19]]
// PPC64-NEXT:    [[MUL:%.*]] = mul nsw i32 [[TMP12]], [[TMP11]], !dbg [[DBG20:![0-9]+]]
// PPC64-NEXT:    store i32 [[MUL]], ptr [[ATOMIC_TEMP5]], align 4, !dbg [[DBG19]]
// PPC64-NEXT:    [[TMP13:%.*]] = load i32, ptr [[ATOMIC_TEMP5]], align 4, !dbg [[DBG19]]
// PPC64-NEXT:    [[TMP14:%.*]] = cmpxchg ptr @ix, i32 [[TMP12]], i32 [[TMP13]] monotonic monotonic, align 4, !dbg [[DBG19]]
// PPC64-NEXT:    [[TMP15]] = extractvalue { i32, i1 } [[TMP14]], 0, !dbg [[DBG19]]
// PPC64-NEXT:    [[TMP16:%.*]] = extractvalue { i32, i1 } [[TMP14]], 1, !dbg [[DBG19]]
// PPC64-NEXT:    br i1 [[TMP16]], label [[ATOMIC_EXIT6:%.*]], label [[ATOMIC_CONT4]], !dbg [[DBG19]]
// PPC64:       atomic_exit6:
// PPC64-NEXT:    [[TMP17:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG21:![0-9]+]]
// PPC64-NEXT:    [[TMP18:%.*]] = atomicrmw sub ptr @uix, i32 [[TMP17]] monotonic, align 4, !dbg [[DBG22:![0-9]+]]
// PPC64-NEXT:    [[TMP19:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG23:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD7:%.*]] = load atomic i32, ptr @ix monotonic, align 4, !dbg [[DBG24:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT8:%.*]], !dbg [[DBG24]]
// PPC64:       atomic_cont8:
// PPC64-NEXT:    [[TMP20:%.*]] = phi i32 [ [[ATOMIC_LOAD7]], [[ATOMIC_EXIT6]] ], [ [[TMP23:%.*]], [[ATOMIC_CONT8]] ], !dbg [[DBG24]]
// PPC64-NEXT:    [[SHL:%.*]] = shl i32 [[TMP20]], [[TMP19]], !dbg [[DBG25:![0-9]+]]
// PPC64-NEXT:    store i32 [[SHL]], ptr [[ATOMIC_TEMP9]], align 4, !dbg [[DBG24]]
// PPC64-NEXT:    [[TMP21:%.*]] = load i32, ptr [[ATOMIC_TEMP9]], align 4, !dbg [[DBG24]]
// PPC64-NEXT:    [[TMP22:%.*]] = cmpxchg ptr @ix, i32 [[TMP20]], i32 [[TMP21]] monotonic monotonic, align 4, !dbg [[DBG24]]
// PPC64-NEXT:    [[TMP23]] = extractvalue { i32, i1 } [[TMP22]], 0, !dbg [[DBG24]]
// PPC64-NEXT:    [[TMP24:%.*]] = extractvalue { i32, i1 } [[TMP22]], 1, !dbg [[DBG24]]
// PPC64-NEXT:    br i1 [[TMP24]], label [[ATOMIC_EXIT10:%.*]], label [[ATOMIC_CONT8]], !dbg [[DBG24]]
// PPC64:       atomic_exit10:
// PPC64-NEXT:    [[TMP25:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG26:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD11:%.*]] = load atomic i32, ptr @uix monotonic, align 4, !dbg [[DBG27:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT12:%.*]], !dbg [[DBG27]]
// PPC64:       atomic_cont12:
// PPC64-NEXT:    [[TMP26:%.*]] = phi i32 [ [[ATOMIC_LOAD11]], [[ATOMIC_EXIT10]] ], [ [[TMP29:%.*]], [[ATOMIC_CONT12]] ], !dbg [[DBG27]]
// PPC64-NEXT:    [[SHR:%.*]] = lshr i32 [[TMP26]], [[TMP25]], !dbg [[DBG28:![0-9]+]]
// PPC64-NEXT:    store i32 [[SHR]], ptr [[ATOMIC_TEMP13]], align 4, !dbg [[DBG27]]
// PPC64-NEXT:    [[TMP27:%.*]] = load i32, ptr [[ATOMIC_TEMP13]], align 4, !dbg [[DBG27]]
// PPC64-NEXT:    [[TMP28:%.*]] = cmpxchg ptr @uix, i32 [[TMP26]], i32 [[TMP27]] monotonic monotonic, align 4, !dbg [[DBG27]]
// PPC64-NEXT:    [[TMP29]] = extractvalue { i32, i1 } [[TMP28]], 0, !dbg [[DBG27]]
// PPC64-NEXT:    [[TMP30:%.*]] = extractvalue { i32, i1 } [[TMP28]], 1, !dbg [[DBG27]]
// PPC64-NEXT:    br i1 [[TMP30]], label [[ATOMIC_EXIT14:%.*]], label [[ATOMIC_CONT12]], !dbg [[DBG27]]
// PPC64:       atomic_exit14:
// PPC64-NEXT:    [[TMP31:%.*]] = load i64, ptr @lv, align 8, !dbg [[DBG29:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD15:%.*]] = load atomic i64, ptr @lx monotonic, align 8, !dbg [[DBG30:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT16:%.*]], !dbg [[DBG30]]
// PPC64:       atomic_cont16:
// PPC64-NEXT:    [[TMP32:%.*]] = phi i64 [ [[ATOMIC_LOAD15]], [[ATOMIC_EXIT14]] ], [ [[TMP35:%.*]], [[ATOMIC_CONT16]] ], !dbg [[DBG30]]
// PPC64-NEXT:    [[DIV:%.*]] = sdiv i64 [[TMP32]], [[TMP31]], !dbg [[DBG31:![0-9]+]]
// PPC64-NEXT:    store i64 [[DIV]], ptr [[ATOMIC_TEMP17]], align 8, !dbg [[DBG30]]
// PPC64-NEXT:    [[TMP33:%.*]] = load i64, ptr [[ATOMIC_TEMP17]], align 8, !dbg [[DBG30]]
// PPC64-NEXT:    [[TMP34:%.*]] = cmpxchg ptr @lx, i64 [[TMP32]], i64 [[TMP33]] monotonic monotonic, align 8, !dbg [[DBG30]]
// PPC64-NEXT:    [[TMP35]] = extractvalue { i64, i1 } [[TMP34]], 0, !dbg [[DBG30]]
// PPC64-NEXT:    [[TMP36:%.*]] = extractvalue { i64, i1 } [[TMP34]], 1, !dbg [[DBG30]]
// PPC64-NEXT:    br i1 [[TMP36]], label [[ATOMIC_EXIT18:%.*]], label [[ATOMIC_CONT16]], !dbg [[DBG30]]
// PPC64:       atomic_exit18:
// PPC64-NEXT:    [[TMP37:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG32:![0-9]+]]
// PPC64-NEXT:    [[TMP38:%.*]] = atomicrmw and ptr @ulx, i64 [[TMP37]] monotonic, align 8, !dbg [[DBG33:![0-9]+]]
// PPC64-NEXT:    [[TMP39:%.*]] = load i64, ptr @llv, align 8, !dbg [[DBG34:![0-9]+]]
// PPC64-NEXT:    [[TMP40:%.*]] = atomicrmw xor ptr @llx, i64 [[TMP39]] monotonic, align 8, !dbg [[DBG35:![0-9]+]]
// PPC64-NEXT:    [[TMP41:%.*]] = load i64, ptr @ullv, align 8, !dbg [[DBG36:![0-9]+]]
// PPC64-NEXT:    [[TMP42:%.*]] = atomicrmw or ptr @ullx, i64 [[TMP41]] monotonic, align 8, !dbg [[DBG37:![0-9]+]]
// PPC64-NEXT:    [[TMP43:%.*]] = load float, ptr @fv, align 4, !dbg [[DBG38:![0-9]+]]
// PPC64-NEXT:    [[TMP44:%.*]] = atomicrmw fadd ptr @fx, float [[TMP43]] monotonic, align 4, !dbg [[DBG39:![0-9]+]]
// PPC64-NEXT:    [[TMP45:%.*]] = load double, ptr @dv, align 8, !dbg [[DBG40:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD19:%.*]] = load atomic i64, ptr @dx monotonic, align 8, !dbg [[DBG41:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT20:%.*]], !dbg [[DBG41]]
// PPC64:       atomic_cont20:
// PPC64-NEXT:    [[TMP46:%.*]] = phi i64 [ [[ATOMIC_LOAD19]], [[ATOMIC_EXIT18]] ], [ [[TMP50:%.*]], [[ATOMIC_CONT20]] ], !dbg [[DBG41]]
// PPC64-NEXT:    [[TMP47:%.*]] = bitcast i64 [[TMP46]] to double, !dbg [[DBG41]]
// PPC64-NEXT:    [[SUB:%.*]] = fsub double [[TMP45]], [[TMP47]], !dbg [[DBG42:![0-9]+]]
// PPC64-NEXT:    store double [[SUB]], ptr [[ATOMIC_TEMP21]], align 8, !dbg [[DBG41]]
// PPC64-NEXT:    [[TMP48:%.*]] = load i64, ptr [[ATOMIC_TEMP21]], align 8, !dbg [[DBG41]]
// PPC64-NEXT:    [[TMP49:%.*]] = cmpxchg ptr @dx, i64 [[TMP46]], i64 [[TMP48]] monotonic monotonic, align 8, !dbg [[DBG41]]
// PPC64-NEXT:    [[TMP50]] = extractvalue { i64, i1 } [[TMP49]], 0, !dbg [[DBG41]]
// PPC64-NEXT:    [[TMP51:%.*]] = extractvalue { i64, i1 } [[TMP49]], 1, !dbg [[DBG41]]
// PPC64-NEXT:    br i1 [[TMP51]], label [[ATOMIC_EXIT22:%.*]], label [[ATOMIC_CONT20]], !dbg [[DBG41]]
// PPC64:       atomic_exit22:
// PPC64-NEXT:    [[TMP52:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG43:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 16, ptr noundef @ldx, ptr noundef [[ATOMIC_TEMP23]], i32 noundef signext 0), !dbg [[DBG44:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT24:%.*]], !dbg [[DBG44]]
// PPC64:       atomic_cont24:
// PPC64-NEXT:    [[TMP53:%.*]] = load ppc_fp128, ptr [[ATOMIC_TEMP23]], align 16, !dbg [[DBG44]]
// PPC64-NEXT:    [[MUL26:%.*]] = fmul ppc_fp128 [[TMP53]], [[TMP52]], !dbg [[DBG45:![0-9]+]]
// PPC64-NEXT:    store ppc_fp128 [[MUL26]], ptr [[ATOMIC_TEMP25]], align 16, !dbg [[DBG44]]
// PPC64-NEXT:    [[CALL:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, ptr noundef @ldx, ptr noundef [[ATOMIC_TEMP23]], ptr noundef [[ATOMIC_TEMP25]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG44]]
// PPC64-NEXT:    br i1 [[CALL]], label [[ATOMIC_EXIT27:%.*]], label [[ATOMIC_CONT24]], !dbg [[DBG44]]
// PPC64:       atomic_exit27:
// PPC64-NEXT:    [[CIV_REAL:%.*]] = load i32, ptr @civ, align 4, !dbg [[DBG46:![0-9]+]]
// PPC64-NEXT:    [[CIV_IMAG:%.*]] = load i32, ptr getelementptr inbounds nuw ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG46]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP28]], i32 noundef signext 0), !dbg [[DBG47:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT29:%.*]], !dbg [[DBG47]]
// PPC64:       atomic_cont29:
// PPC64-NEXT:    [[ATOMIC_TEMP28_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP28]], i32 0, i32 0, !dbg [[DBG47]]
// PPC64-NEXT:    [[ATOMIC_TEMP28_REAL:%.*]] = load i32, ptr [[ATOMIC_TEMP28_REALP]], align 4, !dbg [[DBG47]]
// PPC64-NEXT:    [[ATOMIC_TEMP28_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP28]], i32 0, i32 1, !dbg [[DBG47]]
// PPC64-NEXT:    [[ATOMIC_TEMP28_IMAG:%.*]] = load i32, ptr [[ATOMIC_TEMP28_IMAGP]], align 4, !dbg [[DBG47]]
// PPC64-NEXT:    [[TMP54:%.*]] = mul i32 [[CIV_REAL]], [[ATOMIC_TEMP28_REAL]], !dbg [[DBG48:![0-9]+]]
// PPC64-NEXT:    [[TMP55:%.*]] = mul i32 [[CIV_IMAG]], [[ATOMIC_TEMP28_IMAG]], !dbg [[DBG48]]
// PPC64-NEXT:    [[TMP56:%.*]] = add i32 [[TMP54]], [[TMP55]], !dbg [[DBG48]]
// PPC64-NEXT:    [[TMP57:%.*]] = mul i32 [[ATOMIC_TEMP28_REAL]], [[ATOMIC_TEMP28_REAL]], !dbg [[DBG48]]
// PPC64-NEXT:    [[TMP58:%.*]] = mul i32 [[ATOMIC_TEMP28_IMAG]], [[ATOMIC_TEMP28_IMAG]], !dbg [[DBG48]]
// PPC64-NEXT:    [[TMP59:%.*]] = add i32 [[TMP57]], [[TMP58]], !dbg [[DBG48]]
// PPC64-NEXT:    [[TMP60:%.*]] = mul i32 [[CIV_IMAG]], [[ATOMIC_TEMP28_REAL]], !dbg [[DBG48]]
// PPC64-NEXT:    [[TMP61:%.*]] = mul i32 [[CIV_REAL]], [[ATOMIC_TEMP28_IMAG]], !dbg [[DBG48]]
// PPC64-NEXT:    [[TMP62:%.*]] = sub i32 [[TMP60]], [[TMP61]], !dbg [[DBG48]]
// PPC64-NEXT:    [[TMP63:%.*]] = sdiv i32 [[TMP56]], [[TMP59]], !dbg [[DBG48]]
// PPC64-NEXT:    [[TMP64:%.*]] = sdiv i32 [[TMP62]], [[TMP59]], !dbg [[DBG48]]
// PPC64-NEXT:    [[ATOMIC_TEMP30_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP30]], i32 0, i32 0, !dbg [[DBG47]]
// PPC64-NEXT:    [[ATOMIC_TEMP30_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP30]], i32 0, i32 1, !dbg [[DBG47]]
// PPC64-NEXT:    store i32 [[TMP63]], ptr [[ATOMIC_TEMP30_REALP]], align 4, !dbg [[DBG47]]
// PPC64-NEXT:    store i32 [[TMP64]], ptr [[ATOMIC_TEMP30_IMAGP]], align 4, !dbg [[DBG47]]
// PPC64-NEXT:    [[CALL31:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP28]], ptr noundef [[ATOMIC_TEMP30]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG47]]
// PPC64-NEXT:    br i1 [[CALL31]], label [[ATOMIC_EXIT32:%.*]], label [[ATOMIC_CONT29]], !dbg [[DBG47]]
// PPC64:       atomic_exit32:
// PPC64-NEXT:    [[CFV_REAL:%.*]] = load float, ptr @cfv, align 4, !dbg [[DBG49:![0-9]+]]
// PPC64-NEXT:    [[CFV_IMAG:%.*]] = load float, ptr getelementptr inbounds nuw ({ float, float }, ptr @cfv, i32 0, i32 1), align 4, !dbg [[DBG49]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cfx, ptr noundef [[ATOMIC_TEMP33]], i32 noundef signext 0), !dbg [[DBG50:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT34:%.*]], !dbg [[DBG50]]
// PPC64:       atomic_cont34:
// PPC64-NEXT:    [[ATOMIC_TEMP33_REALP:%.*]] = getelementptr inbounds nuw { float, float }, ptr [[ATOMIC_TEMP33]], i32 0, i32 0, !dbg [[DBG50]]
// PPC64-NEXT:    [[ATOMIC_TEMP33_REAL:%.*]] = load float, ptr [[ATOMIC_TEMP33_REALP]], align 4, !dbg [[DBG50]]
// PPC64-NEXT:    [[ATOMIC_TEMP33_IMAGP:%.*]] = getelementptr inbounds nuw { float, float }, ptr [[ATOMIC_TEMP33]], i32 0, i32 1, !dbg [[DBG50]]
// PPC64-NEXT:    [[ATOMIC_TEMP33_IMAG:%.*]] = load float, ptr [[ATOMIC_TEMP33_IMAGP]], align 4, !dbg [[DBG50]]
// PPC64-NEXT:    [[ADD_R:%.*]] = fadd float [[CFV_REAL]], [[ATOMIC_TEMP33_REAL]], !dbg [[DBG51:![0-9]+]]
// PPC64-NEXT:    [[ADD_I:%.*]] = fadd float [[CFV_IMAG]], [[ATOMIC_TEMP33_IMAG]], !dbg [[DBG51]]
// PPC64-NEXT:    [[ATOMIC_TEMP35_REALP:%.*]] = getelementptr inbounds nuw { float, float }, ptr [[ATOMIC_TEMP35]], i32 0, i32 0, !dbg [[DBG50]]
// PPC64-NEXT:    [[ATOMIC_TEMP35_IMAGP:%.*]] = getelementptr inbounds nuw { float, float }, ptr [[ATOMIC_TEMP35]], i32 0, i32 1, !dbg [[DBG50]]
// PPC64-NEXT:    store float [[ADD_R]], ptr [[ATOMIC_TEMP35_REALP]], align 4, !dbg [[DBG50]]
// PPC64-NEXT:    store float [[ADD_I]], ptr [[ATOMIC_TEMP35_IMAGP]], align 4, !dbg [[DBG50]]
// PPC64-NEXT:    [[CALL36:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cfx, ptr noundef [[ATOMIC_TEMP33]], ptr noundef [[ATOMIC_TEMP35]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG50]]
// PPC64-NEXT:    br i1 [[CALL36]], label [[ATOMIC_EXIT37:%.*]], label [[ATOMIC_CONT34]], !dbg [[DBG50]]
// PPC64:       atomic_exit37:
// PPC64-NEXT:    [[CDV_REAL:%.*]] = load double, ptr @cdv, align 8, !dbg [[DBG52:![0-9]+]]
// PPC64-NEXT:    [[CDV_IMAG:%.*]] = load double, ptr getelementptr inbounds nuw ({ double, double }, ptr @cdv, i32 0, i32 1), align 8, !dbg [[DBG52]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 16, ptr noundef @cdx, ptr noundef [[ATOMIC_TEMP38]], i32 noundef signext 5), !dbg [[DBG53:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT39:%.*]], !dbg [[DBG53]]
// PPC64:       atomic_cont39:
// PPC64-NEXT:    [[ATOMIC_TEMP38_REALP:%.*]] = getelementptr inbounds nuw { double, double }, ptr [[ATOMIC_TEMP38]], i32 0, i32 0, !dbg [[DBG53]]
// PPC64-NEXT:    [[ATOMIC_TEMP38_REAL:%.*]] = load double, ptr [[ATOMIC_TEMP38_REALP]], align 8, !dbg [[DBG53]]
// PPC64-NEXT:    [[ATOMIC_TEMP38_IMAGP:%.*]] = getelementptr inbounds nuw { double, double }, ptr [[ATOMIC_TEMP38]], i32 0, i32 1, !dbg [[DBG53]]
// PPC64-NEXT:    [[ATOMIC_TEMP38_IMAG:%.*]] = load double, ptr [[ATOMIC_TEMP38_IMAGP]], align 8, !dbg [[DBG53]]
// PPC64-NEXT:    [[SUB_R:%.*]] = fsub double [[ATOMIC_TEMP38_REAL]], [[CDV_REAL]], !dbg [[DBG54:![0-9]+]]
// PPC64-NEXT:    [[SUB_I:%.*]] = fsub double [[ATOMIC_TEMP38_IMAG]], [[CDV_IMAG]], !dbg [[DBG54]]
// PPC64-NEXT:    [[ATOMIC_TEMP40_REALP:%.*]] = getelementptr inbounds nuw { double, double }, ptr [[ATOMIC_TEMP40]], i32 0, i32 0, !dbg [[DBG53]]
// PPC64-NEXT:    [[ATOMIC_TEMP40_IMAGP:%.*]] = getelementptr inbounds nuw { double, double }, ptr [[ATOMIC_TEMP40]], i32 0, i32 1, !dbg [[DBG53]]
// PPC64-NEXT:    store double [[SUB_R]], ptr [[ATOMIC_TEMP40_REALP]], align 8, !dbg [[DBG53]]
// PPC64-NEXT:    store double [[SUB_I]], ptr [[ATOMIC_TEMP40_IMAGP]], align 8, !dbg [[DBG53]]
// PPC64-NEXT:    [[CALL41:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, ptr noundef @cdx, ptr noundef [[ATOMIC_TEMP38]], ptr noundef [[ATOMIC_TEMP40]], i32 noundef signext 5, i32 noundef signext 5), !dbg [[DBG53]]
// PPC64-NEXT:    br i1 [[CALL41]], label [[ATOMIC_EXIT42:%.*]], label [[ATOMIC_CONT39]], !dbg [[DBG53]]
// PPC64:       atomic_exit42:
// PPC64-NEXT:    fence release
// PPC64-NEXT:    [[TMP65:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG55:![0-9]+]]
// PPC64-NEXT:    [[LOADEDV:%.*]] = trunc i8 [[TMP65]] to i1, !dbg [[DBG55]]
// PPC64-NEXT:    [[CONV43:%.*]] = zext i1 [[LOADEDV]] to i64, !dbg [[DBG55]]
// PPC64-NEXT:    [[TMP66:%.*]] = atomicrmw and ptr @ulx, i64 [[CONV43]] monotonic, align 8, !dbg [[DBG56:![0-9]+]]
// PPC64-NEXT:    [[TMP67:%.*]] = load i8, ptr @cv, align 1, !dbg [[DBG57:![0-9]+]]
// PPC64-NEXT:    [[CONV44:%.*]] = sext i8 [[TMP67]] to i32, !dbg [[DBG57]]
// PPC64-NEXT:    [[ATOMIC_LOAD45:%.*]] = load atomic i8, ptr @bx monotonic, align 1, !dbg [[DBG58:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT46:%.*]], !dbg [[DBG58]]
// PPC64:       atomic_cont46:
// PPC64-NEXT:    [[TMP68:%.*]] = phi i8 [ [[ATOMIC_LOAD45]], [[ATOMIC_EXIT42]] ], [ [[TMP71:%.*]], [[ATOMIC_CONT46]] ], !dbg [[DBG58]]
// PPC64-NEXT:    [[LOADEDV48:%.*]] = trunc i8 [[TMP68]] to i1, !dbg [[DBG58]]
// PPC64-NEXT:    [[CONV49:%.*]] = zext i1 [[LOADEDV48]] to i32, !dbg [[DBG58]]
// PPC64-NEXT:    [[AND:%.*]] = and i32 [[CONV44]], [[CONV49]], !dbg [[DBG59:![0-9]+]]
// PPC64-NEXT:    [[TOBOOL:%.*]] = icmp ne i32 [[AND]], 0, !dbg [[DBG57]]
// PPC64-NEXT:    [[STOREDV:%.*]] = zext i1 [[TOBOOL]] to i8, !dbg [[DBG58]]
// PPC64-NEXT:    store i8 [[STOREDV]], ptr [[ATOMIC_TEMP47]], align 1, !dbg [[DBG58]]
// PPC64-NEXT:    [[TMP69:%.*]] = load i8, ptr [[ATOMIC_TEMP47]], align 1, !dbg [[DBG58]]
// PPC64-NEXT:    [[TMP70:%.*]] = cmpxchg ptr @bx, i8 [[TMP68]], i8 [[TMP69]] monotonic monotonic, align 1, !dbg [[DBG58]]
// PPC64-NEXT:    [[TMP71]] = extractvalue { i8, i1 } [[TMP70]], 0, !dbg [[DBG58]]
// PPC64-NEXT:    [[TMP72:%.*]] = extractvalue { i8, i1 } [[TMP70]], 1, !dbg [[DBG58]]
// PPC64-NEXT:    br i1 [[TMP72]], label [[ATOMIC_EXIT50:%.*]], label [[ATOMIC_CONT46]], !dbg [[DBG58]]
// PPC64:       atomic_exit50:
// PPC64-NEXT:    [[TMP73:%.*]] = load i8, ptr @ucv, align 1, !dbg [[DBG60:![0-9]+]]
// PPC64-NEXT:    [[CONV51:%.*]] = zext i8 [[TMP73]] to i32, !dbg [[DBG60]]
// PPC64-NEXT:    [[ATOMIC_LOAD52:%.*]] = load atomic i8, ptr @cx seq_cst, align 1, !dbg [[DBG61:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT53:%.*]], !dbg [[DBG61]]
// PPC64:       atomic_cont53:
// PPC64-NEXT:    [[TMP74:%.*]] = phi i8 [ [[ATOMIC_LOAD52]], [[ATOMIC_EXIT50]] ], [ [[TMP77:%.*]], [[ATOMIC_CONT53]] ], !dbg [[DBG61]]
// PPC64-NEXT:    [[CONV55:%.*]] = sext i8 [[TMP74]] to i32, !dbg [[DBG61]]
// PPC64-NEXT:    [[SHR56:%.*]] = ashr i32 [[CONV55]], [[CONV51]], !dbg [[DBG62:![0-9]+]]
// PPC64-NEXT:    [[CONV57:%.*]] = trunc i32 [[SHR56]] to i8, !dbg [[DBG61]]
// PPC64-NEXT:    store i8 [[CONV57]], ptr [[ATOMIC_TEMP54]], align 1, !dbg [[DBG61]]
// PPC64-NEXT:    [[TMP75:%.*]] = load i8, ptr [[ATOMIC_TEMP54]], align 1, !dbg [[DBG61]]
// PPC64-NEXT:    [[TMP76:%.*]] = cmpxchg ptr @cx, i8 [[TMP74]], i8 [[TMP75]] seq_cst seq_cst, align 1, !dbg [[DBG61]]
// PPC64-NEXT:    [[TMP77]] = extractvalue { i8, i1 } [[TMP76]], 0, !dbg [[DBG61]]
// PPC64-NEXT:    [[TMP78:%.*]] = extractvalue { i8, i1 } [[TMP76]], 1, !dbg [[DBG61]]
// PPC64-NEXT:    br i1 [[TMP78]], label [[ATOMIC_EXIT58:%.*]], label [[ATOMIC_CONT53]], !dbg [[DBG61]]
// PPC64:       atomic_exit58:
// PPC64-NEXT:    fence release
// PPC64-NEXT:    [[TMP79:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG63:![0-9]+]]
// PPC64-NEXT:    [[CONV59:%.*]] = sext i16 [[TMP79]] to i32, !dbg [[DBG63]]
// PPC64-NEXT:    [[ATOMIC_LOAD60:%.*]] = load atomic i64, ptr @ulx monotonic, align 8, !dbg [[DBG64:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT61:%.*]], !dbg [[DBG64]]
// PPC64:       atomic_cont61:
// PPC64-NEXT:    [[TMP80:%.*]] = phi i64 [ [[ATOMIC_LOAD60]], [[ATOMIC_EXIT58]] ], [ [[TMP83:%.*]], [[ATOMIC_CONT61]] ], !dbg [[DBG64]]
// PPC64-NEXT:    [[SH_PROM:%.*]] = trunc i64 [[TMP80]] to i32, !dbg [[DBG65:![0-9]+]]
// PPC64-NEXT:    [[SHL63:%.*]] = shl i32 [[CONV59]], [[SH_PROM]], !dbg [[DBG65]]
// PPC64-NEXT:    [[CONV64:%.*]] = sext i32 [[SHL63]] to i64, !dbg [[DBG63]]
// PPC64-NEXT:    store i64 [[CONV64]], ptr [[ATOMIC_TEMP62]], align 8, !dbg [[DBG64]]
// PPC64-NEXT:    [[TMP81:%.*]] = load i64, ptr [[ATOMIC_TEMP62]], align 8, !dbg [[DBG64]]
// PPC64-NEXT:    [[TMP82:%.*]] = cmpxchg ptr @ulx, i64 [[TMP80]], i64 [[TMP81]] monotonic monotonic, align 8, !dbg [[DBG64]]
// PPC64-NEXT:    [[TMP83]] = extractvalue { i64, i1 } [[TMP82]], 0, !dbg [[DBG64]]
// PPC64-NEXT:    [[TMP84:%.*]] = extractvalue { i64, i1 } [[TMP82]], 1, !dbg [[DBG64]]
// PPC64-NEXT:    br i1 [[TMP84]], label [[ATOMIC_EXIT65:%.*]], label [[ATOMIC_CONT61]], !dbg [[DBG64]]
// PPC64:       atomic_exit65:
// PPC64-NEXT:    [[TMP85:%.*]] = load i16, ptr @usv, align 2, !dbg [[DBG66:![0-9]+]]
// PPC64-NEXT:    [[CONV66:%.*]] = zext i16 [[TMP85]] to i64, !dbg [[DBG66]]
// PPC64-NEXT:    [[ATOMIC_LOAD67:%.*]] = load atomic i64, ptr @lx monotonic, align 8, !dbg [[DBG67:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT68:%.*]], !dbg [[DBG67]]
// PPC64:       atomic_cont68:
// PPC64-NEXT:    [[TMP86:%.*]] = phi i64 [ [[ATOMIC_LOAD67]], [[ATOMIC_EXIT65]] ], [ [[TMP89:%.*]], [[ATOMIC_CONT68]] ], !dbg [[DBG67]]
// PPC64-NEXT:    [[REM:%.*]] = srem i64 [[TMP86]], [[CONV66]], !dbg [[DBG68:![0-9]+]]
// PPC64-NEXT:    store i64 [[REM]], ptr [[ATOMIC_TEMP69]], align 8, !dbg [[DBG67]]
// PPC64-NEXT:    [[TMP87:%.*]] = load i64, ptr [[ATOMIC_TEMP69]], align 8, !dbg [[DBG67]]
// PPC64-NEXT:    [[TMP88:%.*]] = cmpxchg ptr @lx, i64 [[TMP86]], i64 [[TMP87]] monotonic monotonic, align 8, !dbg [[DBG67]]
// PPC64-NEXT:    [[TMP89]] = extractvalue { i64, i1 } [[TMP88]], 0, !dbg [[DBG67]]
// PPC64-NEXT:    [[TMP90:%.*]] = extractvalue { i64, i1 } [[TMP88]], 1, !dbg [[DBG67]]
// PPC64-NEXT:    br i1 [[TMP90]], label [[ATOMIC_EXIT70:%.*]], label [[ATOMIC_CONT68]], !dbg [[DBG67]]
// PPC64:       atomic_exit70:
// PPC64-NEXT:    [[TMP91:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG69:![0-9]+]]
// PPC64-NEXT:    [[TMP92:%.*]] = atomicrmw or ptr @uix, i32 [[TMP91]] seq_cst, align 4, !dbg [[DBG70:![0-9]+]]
// PPC64-NEXT:    fence release
// PPC64-NEXT:    [[TMP93:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG71:![0-9]+]]
// PPC64-NEXT:    [[TMP94:%.*]] = atomicrmw and ptr @ix, i32 [[TMP93]] monotonic, align 4, !dbg [[DBG72:![0-9]+]]
// PPC64-NEXT:    [[TMP95:%.*]] = load i64, ptr @lv, align 8, !dbg [[DBG73:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP71]], i32 noundef signext 0), !dbg [[DBG74:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT72:%.*]], !dbg [[DBG74]]
// PPC64:       atomic_cont72:
// PPC64-NEXT:    [[ATOMIC_TEMP71_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP71]], i32 0, i32 0, !dbg [[DBG74]]
// PPC64-NEXT:    [[ATOMIC_TEMP71_REAL:%.*]] = load i32, ptr [[ATOMIC_TEMP71_REALP]], align 4, !dbg [[DBG74]]
// PPC64-NEXT:    [[ATOMIC_TEMP71_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP71]], i32 0, i32 1, !dbg [[DBG74]]
// PPC64-NEXT:    [[ATOMIC_TEMP71_IMAG:%.*]] = load i32, ptr [[ATOMIC_TEMP71_IMAGP]], align 4, !dbg [[DBG74]]
// PPC64-NEXT:    [[CONV74:%.*]] = sext i32 [[ATOMIC_TEMP71_REAL]] to i64, !dbg [[DBG74]]
// PPC64-NEXT:    [[CONV75:%.*]] = sext i32 [[ATOMIC_TEMP71_IMAG]] to i64, !dbg [[DBG74]]
// PPC64-NEXT:    [[ADD_R76:%.*]] = add i64 [[TMP95]], [[CONV74]], !dbg [[DBG75:![0-9]+]]
// PPC64-NEXT:    [[ADD_I77:%.*]] = add i64 0, [[CONV75]], !dbg [[DBG75]]
// PPC64-NEXT:    [[CONV78:%.*]] = trunc i64 [[ADD_R76]] to i32, !dbg [[DBG73]]
// PPC64-NEXT:    [[CONV79:%.*]] = trunc i64 [[ADD_I77]] to i32, !dbg [[DBG73]]
// PPC64-NEXT:    [[ATOMIC_TEMP73_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP73]], i32 0, i32 0, !dbg [[DBG74]]
// PPC64-NEXT:    [[ATOMIC_TEMP73_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP73]], i32 0, i32 1, !dbg [[DBG74]]
// PPC64-NEXT:    store i32 [[CONV78]], ptr [[ATOMIC_TEMP73_REALP]], align 4, !dbg [[DBG74]]
// PPC64-NEXT:    store i32 [[CONV79]], ptr [[ATOMIC_TEMP73_IMAGP]], align 4, !dbg [[DBG74]]
// PPC64-NEXT:    [[CALL80:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP71]], ptr noundef [[ATOMIC_TEMP73]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG74]]
// PPC64-NEXT:    br i1 [[CALL80]], label [[ATOMIC_EXIT81:%.*]], label [[ATOMIC_CONT72]], !dbg [[DBG74]]
// PPC64:       atomic_exit81:
// PPC64-NEXT:    [[TMP96:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG76:![0-9]+]]
// PPC64-NEXT:    [[CONV82:%.*]] = uitofp i64 [[TMP96]] to float, !dbg [[DBG76]]
// PPC64-NEXT:    [[ATOMIC_LOAD83:%.*]] = load atomic i32, ptr @fx monotonic, align 4, !dbg [[DBG77:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT84:%.*]], !dbg [[DBG77]]
// PPC64:       atomic_cont84:
// PPC64-NEXT:    [[TMP97:%.*]] = phi i32 [ [[ATOMIC_LOAD83]], [[ATOMIC_EXIT81]] ], [ [[TMP101:%.*]], [[ATOMIC_CONT84]] ], !dbg [[DBG77]]
// PPC64-NEXT:    [[TMP98:%.*]] = bitcast i32 [[TMP97]] to float, !dbg [[DBG77]]
// PPC64-NEXT:    [[MUL86:%.*]] = fmul float [[TMP98]], [[CONV82]], !dbg [[DBG78:![0-9]+]]
// PPC64-NEXT:    store float [[MUL86]], ptr [[ATOMIC_TEMP85]], align 4, !dbg [[DBG77]]
// PPC64-NEXT:    [[TMP99:%.*]] = load i32, ptr [[ATOMIC_TEMP85]], align 4, !dbg [[DBG77]]
// PPC64-NEXT:    [[TMP100:%.*]] = cmpxchg ptr @fx, i32 [[TMP97]], i32 [[TMP99]] monotonic monotonic, align 4, !dbg [[DBG77]]
// PPC64-NEXT:    [[TMP101]] = extractvalue { i32, i1 } [[TMP100]], 0, !dbg [[DBG77]]
// PPC64-NEXT:    [[TMP102:%.*]] = extractvalue { i32, i1 } [[TMP100]], 1, !dbg [[DBG77]]
// PPC64-NEXT:    br i1 [[TMP102]], label [[ATOMIC_EXIT87:%.*]], label [[ATOMIC_CONT84]], !dbg [[DBG77]]
// PPC64:       atomic_exit87:
// PPC64-NEXT:    [[TMP103:%.*]] = load i64, ptr @llv, align 8, !dbg [[DBG79:![0-9]+]]
// PPC64-NEXT:    [[CONV88:%.*]] = sitofp i64 [[TMP103]] to double, !dbg [[DBG79]]
// PPC64-NEXT:    [[ATOMIC_LOAD89:%.*]] = load atomic i64, ptr @dx monotonic, align 8, !dbg [[DBG80:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT90:%.*]], !dbg [[DBG80]]
// PPC64:       atomic_cont90:
// PPC64-NEXT:    [[TMP104:%.*]] = phi i64 [ [[ATOMIC_LOAD89]], [[ATOMIC_EXIT87]] ], [ [[TMP108:%.*]], [[ATOMIC_CONT90]] ], !dbg [[DBG80]]
// PPC64-NEXT:    [[TMP105:%.*]] = bitcast i64 [[TMP104]] to double, !dbg [[DBG80]]
// PPC64-NEXT:    [[DIV92:%.*]] = fdiv double [[TMP105]], [[CONV88]], !dbg [[DBG81:![0-9]+]]
// PPC64-NEXT:    store double [[DIV92]], ptr [[ATOMIC_TEMP91]], align 8, !dbg [[DBG80]]
// PPC64-NEXT:    [[TMP106:%.*]] = load i64, ptr [[ATOMIC_TEMP91]], align 8, !dbg [[DBG80]]
// PPC64-NEXT:    [[TMP107:%.*]] = cmpxchg ptr @dx, i64 [[TMP104]], i64 [[TMP106]] monotonic monotonic, align 8, !dbg [[DBG80]]
// PPC64-NEXT:    [[TMP108]] = extractvalue { i64, i1 } [[TMP107]], 0, !dbg [[DBG80]]
// PPC64-NEXT:    [[TMP109:%.*]] = extractvalue { i64, i1 } [[TMP107]], 1, !dbg [[DBG80]]
// PPC64-NEXT:    br i1 [[TMP109]], label [[ATOMIC_EXIT93:%.*]], label [[ATOMIC_CONT90]], !dbg [[DBG80]]
// PPC64:       atomic_exit93:
// PPC64-NEXT:    [[TMP110:%.*]] = load i64, ptr @ullv, align 8, !dbg [[DBG82:![0-9]+]]
// PPC64-NEXT:    [[CONV94:%.*]] = uitofp i64 [[TMP110]] to ppc_fp128, !dbg [[DBG82]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 16, ptr noundef @ldx, ptr noundef [[ATOMIC_TEMP95]], i32 noundef signext 0), !dbg [[DBG83:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT96:%.*]], !dbg [[DBG83]]
// PPC64:       atomic_cont96:
// PPC64-NEXT:    [[TMP111:%.*]] = load ppc_fp128, ptr [[ATOMIC_TEMP95]], align 16, !dbg [[DBG83]]
// PPC64-NEXT:    [[SUB98:%.*]] = fsub ppc_fp128 [[TMP111]], [[CONV94]], !dbg [[DBG84:![0-9]+]]
// PPC64-NEXT:    store ppc_fp128 [[SUB98]], ptr [[ATOMIC_TEMP97]], align 16, !dbg [[DBG83]]
// PPC64-NEXT:    [[CALL99:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, ptr noundef @ldx, ptr noundef [[ATOMIC_TEMP95]], ptr noundef [[ATOMIC_TEMP97]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG83]]
// PPC64-NEXT:    br i1 [[CALL99]], label [[ATOMIC_EXIT100:%.*]], label [[ATOMIC_CONT96]], !dbg [[DBG83]]
// PPC64:       atomic_exit100:
// PPC64-NEXT:    [[TMP112:%.*]] = load float, ptr @fv, align 4, !dbg [[DBG85:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP101]], i32 noundef signext 0), !dbg [[DBG86:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT102:%.*]], !dbg [[DBG86]]
// PPC64:       atomic_cont102:
// PPC64-NEXT:    [[ATOMIC_TEMP101_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP101]], i32 0, i32 0, !dbg [[DBG86]]
// PPC64-NEXT:    [[ATOMIC_TEMP101_REAL:%.*]] = load i32, ptr [[ATOMIC_TEMP101_REALP]], align 4, !dbg [[DBG86]]
// PPC64-NEXT:    [[ATOMIC_TEMP101_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP101]], i32 0, i32 1, !dbg [[DBG86]]
// PPC64-NEXT:    [[ATOMIC_TEMP101_IMAG:%.*]] = load i32, ptr [[ATOMIC_TEMP101_IMAGP]], align 4, !dbg [[DBG86]]
// PPC64-NEXT:    [[CONV104:%.*]] = sitofp i32 [[ATOMIC_TEMP101_REAL]] to float, !dbg [[DBG86]]
// PPC64-NEXT:    [[CONV105:%.*]] = sitofp i32 [[ATOMIC_TEMP101_IMAG]] to float, !dbg [[DBG86]]
// PPC64-NEXT:    [[CALL106:%.*]] = call { float, float } @__divsc3(float noundef [[TMP112]], float noundef 0.000000e+00, float noundef [[CONV104]], float noundef [[CONV105]]) #[[ATTR2:[0-9]+]], !dbg [[DBG87:![0-9]+]]
// PPC64-NEXT:    [[TMP113:%.*]] = extractvalue { float, float } [[CALL106]], 0, !dbg [[DBG87]]
// PPC64-NEXT:    [[TMP114:%.*]] = extractvalue { float, float } [[CALL106]], 1, !dbg [[DBG87]]
// PPC64-NEXT:    [[CONV107:%.*]] = fptosi float [[TMP113]] to i32, !dbg [[DBG85]]
// PPC64-NEXT:    [[CONV108:%.*]] = fptosi float [[TMP114]] to i32, !dbg [[DBG85]]
// PPC64-NEXT:    [[ATOMIC_TEMP103_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP103]], i32 0, i32 0, !dbg [[DBG86]]
// PPC64-NEXT:    [[ATOMIC_TEMP103_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP103]], i32 0, i32 1, !dbg [[DBG86]]
// PPC64-NEXT:    store i32 [[CONV107]], ptr [[ATOMIC_TEMP103_REALP]], align 4, !dbg [[DBG86]]
// PPC64-NEXT:    store i32 [[CONV108]], ptr [[ATOMIC_TEMP103_IMAGP]], align 4, !dbg [[DBG86]]
// PPC64-NEXT:    [[CALL109:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP101]], ptr noundef [[ATOMIC_TEMP103]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG86]]
// PPC64-NEXT:    br i1 [[CALL109]], label [[ATOMIC_EXIT110:%.*]], label [[ATOMIC_CONT102]], !dbg [[DBG86]]
// PPC64:       atomic_exit110:
// PPC64-NEXT:    [[TMP115:%.*]] = load double, ptr @dv, align 8, !dbg [[DBG88:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD111:%.*]] = load atomic i16, ptr @sx monotonic, align 2, !dbg [[DBG89:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT112:%.*]], !dbg [[DBG89]]
// PPC64:       atomic_cont112:
// PPC64-NEXT:    [[TMP116:%.*]] = phi i16 [ [[ATOMIC_LOAD111]], [[ATOMIC_EXIT110]] ], [ [[TMP119:%.*]], [[ATOMIC_CONT112]] ], !dbg [[DBG89]]
// PPC64-NEXT:    [[CONV114:%.*]] = sext i16 [[TMP116]] to i32, !dbg [[DBG89]]
// PPC64-NEXT:    [[CONV115:%.*]] = sitofp i32 [[CONV114]] to double, !dbg [[DBG89]]
// PPC64-NEXT:    [[ADD116:%.*]] = fadd double [[CONV115]], [[TMP115]], !dbg [[DBG90:![0-9]+]]
// PPC64-NEXT:    [[CONV117:%.*]] = fptosi double [[ADD116]] to i16, !dbg [[DBG89]]
// PPC64-NEXT:    store i16 [[CONV117]], ptr [[ATOMIC_TEMP113]], align 2, !dbg [[DBG89]]
// PPC64-NEXT:    [[TMP117:%.*]] = load i16, ptr [[ATOMIC_TEMP113]], align 2, !dbg [[DBG89]]
// PPC64-NEXT:    [[TMP118:%.*]] = cmpxchg ptr @sx, i16 [[TMP116]], i16 [[TMP117]] monotonic monotonic, align 2, !dbg [[DBG89]]
// PPC64-NEXT:    [[TMP119]] = extractvalue { i16, i1 } [[TMP118]], 0, !dbg [[DBG89]]
// PPC64-NEXT:    [[TMP120:%.*]] = extractvalue { i16, i1 } [[TMP118]], 1, !dbg [[DBG89]]
// PPC64-NEXT:    br i1 [[TMP120]], label [[ATOMIC_EXIT118:%.*]], label [[ATOMIC_CONT112]], !dbg [[DBG89]]
// PPC64:       atomic_exit118:
// PPC64-NEXT:    [[TMP121:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG91:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD119:%.*]] = load atomic i8, ptr @bx monotonic, align 1, !dbg [[DBG92:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT120:%.*]], !dbg [[DBG92]]
// PPC64:       atomic_cont120:
// PPC64-NEXT:    [[TMP122:%.*]] = phi i8 [ [[ATOMIC_LOAD119]], [[ATOMIC_EXIT118]] ], [ [[TMP125:%.*]], [[ATOMIC_CONT120]] ], !dbg [[DBG92]]
// PPC64-NEXT:    [[LOADEDV122:%.*]] = trunc i8 [[TMP122]] to i1, !dbg [[DBG92]]
// PPC64-NEXT:    [[CONV123:%.*]] = zext i1 [[LOADEDV122]] to i32, !dbg [[DBG92]]
// PPC64-NEXT:    [[CONV124:%.*]] = sitofp i32 [[CONV123]] to ppc_fp128, !dbg [[DBG92]]
// PPC64-NEXT:    [[MUL125:%.*]] = fmul ppc_fp128 [[TMP121]], [[CONV124]], !dbg [[DBG93:![0-9]+]]
// PPC64-NEXT:    [[TOBOOL126:%.*]] = fcmp une ppc_fp128 [[MUL125]], 0xM00000000000000000000000000000000, !dbg [[DBG91]]
// PPC64-NEXT:    [[STOREDV127:%.*]] = zext i1 [[TOBOOL126]] to i8, !dbg [[DBG92]]
// PPC64-NEXT:    store i8 [[STOREDV127]], ptr [[ATOMIC_TEMP121]], align 1, !dbg [[DBG92]]
// PPC64-NEXT:    [[TMP123:%.*]] = load i8, ptr [[ATOMIC_TEMP121]], align 1, !dbg [[DBG92]]
// PPC64-NEXT:    [[TMP124:%.*]] = cmpxchg ptr @bx, i8 [[TMP122]], i8 [[TMP123]] release monotonic, align 1, !dbg [[DBG92]]
// PPC64-NEXT:    [[TMP125]] = extractvalue { i8, i1 } [[TMP124]], 0, !dbg [[DBG92]]
// PPC64-NEXT:    [[TMP126:%.*]] = extractvalue { i8, i1 } [[TMP124]], 1, !dbg [[DBG92]]
// PPC64-NEXT:    br i1 [[TMP126]], label [[ATOMIC_EXIT128:%.*]], label [[ATOMIC_CONT120]], !dbg [[DBG92]]
// PPC64:       atomic_exit128:
// PPC64-NEXT:    fence release
// PPC64-NEXT:    [[CIV_REAL129:%.*]] = load i32, ptr @civ, align 4, !dbg [[DBG94:![0-9]+]]
// PPC64-NEXT:    [[CIV_IMAG130:%.*]] = load i32, ptr getelementptr inbounds nuw ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG94]]
// PPC64-NEXT:    [[ATOMIC_LOAD131:%.*]] = load atomic i8, ptr @bx monotonic, align 1, !dbg [[DBG95:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT132:%.*]], !dbg [[DBG95]]
// PPC64:       atomic_cont132:
// PPC64-NEXT:    [[TMP127:%.*]] = phi i8 [ [[ATOMIC_LOAD131]], [[ATOMIC_EXIT128]] ], [ [[TMP130:%.*]], [[ATOMIC_CONT132]] ], !dbg [[DBG95]]
// PPC64-NEXT:    [[LOADEDV134:%.*]] = trunc i8 [[TMP127]] to i1, !dbg [[DBG95]]
// PPC64-NEXT:    [[CONV135:%.*]] = zext i1 [[LOADEDV134]] to i32, !dbg [[DBG95]]
// PPC64-NEXT:    [[SUB_R136:%.*]] = sub i32 [[CIV_REAL129]], [[CONV135]], !dbg [[DBG96:![0-9]+]]
// PPC64-NEXT:    [[SUB_I137:%.*]] = sub i32 [[CIV_IMAG130]], 0, !dbg [[DBG96]]
// PPC64-NEXT:    [[TOBOOL138:%.*]] = icmp ne i32 [[SUB_R136]], 0, !dbg [[DBG94]]
// PPC64-NEXT:    [[TOBOOL139:%.*]] = icmp ne i32 [[SUB_I137]], 0, !dbg [[DBG94]]
// PPC64-NEXT:    [[TOBOOL140:%.*]] = or i1 [[TOBOOL138]], [[TOBOOL139]], !dbg [[DBG94]]
// PPC64-NEXT:    [[STOREDV141:%.*]] = zext i1 [[TOBOOL140]] to i8, !dbg [[DBG95]]
// PPC64-NEXT:    store i8 [[STOREDV141]], ptr [[ATOMIC_TEMP133]], align 1, !dbg [[DBG95]]
// PPC64-NEXT:    [[TMP128:%.*]] = load i8, ptr [[ATOMIC_TEMP133]], align 1, !dbg [[DBG95]]
// PPC64-NEXT:    [[TMP129:%.*]] = cmpxchg ptr @bx, i8 [[TMP127]], i8 [[TMP128]] monotonic monotonic, align 1, !dbg [[DBG95]]
// PPC64-NEXT:    [[TMP130]] = extractvalue { i8, i1 } [[TMP129]], 0, !dbg [[DBG95]]
// PPC64-NEXT:    [[TMP131:%.*]] = extractvalue { i8, i1 } [[TMP129]], 1, !dbg [[DBG95]]
// PPC64-NEXT:    br i1 [[TMP131]], label [[ATOMIC_EXIT142:%.*]], label [[ATOMIC_CONT132]], !dbg [[DBG95]]
// PPC64:       atomic_exit142:
// PPC64-NEXT:    [[TMP132:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG97:![0-9]+]]
// PPC64-NEXT:    [[TMP133:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG98:![0-9]+]]
// PPC64-NEXT:    [[LOADEDV143:%.*]] = trunc i8 [[TMP133]] to i1, !dbg [[DBG98]]
// PPC64-NEXT:    [[CONV144:%.*]] = zext i1 [[LOADEDV143]] to i32, !dbg [[DBG98]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 16, ptr noundef @int4x, ptr noundef [[ATOMIC_TEMP145]], i32 noundef signext 0), !dbg [[DBG99:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT146:%.*]], !dbg [[DBG99]]
// PPC64:       atomic_cont146:
// PPC64-NEXT:    [[TMP134:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP145]], align 16, !dbg [[DBG99]]
// PPC64-NEXT:    store <4 x i32> [[TMP134]], ptr [[ATOMIC_TEMP147]], align 16, !dbg [[DBG99]]
// PPC64-NEXT:    [[TMP135:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP145]], align 16, !dbg [[DBG99]]
// PPC64-NEXT:    store <4 x i32> [[TMP135]], ptr [[ATOMIC_TEMP148]], align 16, !dbg [[DBG99]]
// PPC64-NEXT:    [[TMP136:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP148]], align 16, !dbg [[DBG99]]
// PPC64-NEXT:    [[VECEXT:%.*]] = extractelement <4 x i32> [[TMP136]], i16 [[TMP132]], !dbg [[DBG99]]
// PPC64-NEXT:    [[OR:%.*]] = or i32 [[VECEXT]], [[CONV144]], !dbg [[DBG100:![0-9]+]]
// PPC64-NEXT:    [[TMP137:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP147]], align 16, !dbg [[DBG99]]
// PPC64-NEXT:    [[VECINS:%.*]] = insertelement <4 x i32> [[TMP137]], i32 [[OR]], i16 [[TMP132]], !dbg [[DBG99]]
// PPC64-NEXT:    store <4 x i32> [[VECINS]], ptr [[ATOMIC_TEMP147]], align 16, !dbg [[DBG99]]
// PPC64-NEXT:    [[CALL149:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, ptr noundef @int4x, ptr noundef [[ATOMIC_TEMP145]], ptr noundef [[ATOMIC_TEMP147]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG99]]
// PPC64-NEXT:    br i1 [[CALL149]], label [[ATOMIC_EXIT150:%.*]], label [[ATOMIC_CONT146]], !dbg [[DBG99]]
// PPC64:       atomic_exit150:
// PPC64-NEXT:    [[TMP138:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG101:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD151:%.*]] = load atomic i32, ptr @bfx monotonic, align 4, !dbg [[DBG102:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT152:%.*]], !dbg [[DBG102]]
// PPC64:       atomic_cont152:
// PPC64-NEXT:    [[TMP139:%.*]] = phi i32 [ [[ATOMIC_LOAD151]], [[ATOMIC_EXIT150]] ], [ [[TMP142:%.*]], [[ATOMIC_CONT152]] ], !dbg [[DBG102]]
// PPC64-NEXT:    store i32 [[TMP139]], ptr [[ATOMIC_TEMP153]], align 4, !dbg [[DBG102]]
// PPC64-NEXT:    store i32 [[TMP139]], ptr [[ATOMIC_TEMP154]], align 4, !dbg [[DBG102]]
// PPC64-NEXT:    [[BF_LOAD:%.*]] = load i32, ptr [[ATOMIC_TEMP154]], align 4, !dbg [[DBG102]]
// PPC64-NEXT:    [[BF_ASHR:%.*]] = ashr i32 [[BF_LOAD]], 1, !dbg [[DBG102]]
// PPC64-NEXT:    [[CONV155:%.*]] = sitofp i32 [[BF_ASHR]] to ppc_fp128, !dbg [[DBG103:![0-9]+]]
// PPC64-NEXT:    [[SUB156:%.*]] = fsub ppc_fp128 [[CONV155]], [[TMP138]], !dbg [[DBG104:![0-9]+]]
// PPC64-NEXT:    [[CONV157:%.*]] = fptosi ppc_fp128 [[SUB156]] to i32, !dbg [[DBG103]]
// PPC64-NEXT:    [[BF_LOAD158:%.*]] = load i32, ptr [[ATOMIC_TEMP153]], align 4, !dbg [[DBG102]]
// PPC64-NEXT:    [[BF_VALUE:%.*]] = and i32 [[CONV157]], 2147483647, !dbg [[DBG102]]
// PPC64-NEXT:    [[BF_SHL:%.*]] = shl i32 [[BF_VALUE]], 1, !dbg [[DBG102]]
// PPC64-NEXT:    [[BF_CLEAR:%.*]] = and i32 [[BF_LOAD158]], 1, !dbg [[DBG102]]
// PPC64-NEXT:    [[BF_SET:%.*]] = or i32 [[BF_CLEAR]], [[BF_SHL]], !dbg [[DBG102]]
// PPC64-NEXT:    store i32 [[BF_SET]], ptr [[ATOMIC_TEMP153]], align 4, !dbg [[DBG102]]
// PPC64-NEXT:    [[TMP140:%.*]] = load i32, ptr [[ATOMIC_TEMP153]], align 4, !dbg [[DBG102]]
// PPC64-NEXT:    [[TMP141:%.*]] = cmpxchg ptr @bfx, i32 [[TMP139]], i32 [[TMP140]] monotonic monotonic, align 4, !dbg [[DBG102]]
// PPC64-NEXT:    [[TMP142]] = extractvalue { i32, i1 } [[TMP141]], 0, !dbg [[DBG102]]
// PPC64-NEXT:    [[TMP143:%.*]] = extractvalue { i32, i1 } [[TMP141]], 1, !dbg [[DBG102]]
// PPC64-NEXT:    br i1 [[TMP143]], label [[ATOMIC_EXIT159:%.*]], label [[ATOMIC_CONT152]], !dbg [[DBG102]]
// PPC64:       atomic_exit159:
// PPC64-NEXT:    [[TMP144:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG105:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 4, ptr noundef @bfx_packed, ptr noundef [[ATOMIC_TEMP160]], i32 noundef signext 0), !dbg [[DBG106:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT161:%.*]], !dbg [[DBG106]]
// PPC64:       atomic_cont161:
// PPC64-NEXT:    [[TMP145:%.*]] = load i32, ptr [[ATOMIC_TEMP160]], align 1, !dbg [[DBG106]]
// PPC64-NEXT:    store i32 [[TMP145]], ptr [[ATOMIC_TEMP162]], align 1, !dbg [[DBG106]]
// PPC64-NEXT:    [[TMP146:%.*]] = load i32, ptr [[ATOMIC_TEMP160]], align 1, !dbg [[DBG106]]
// PPC64-NEXT:    store i32 [[TMP146]], ptr [[ATOMIC_TEMP163]], align 4, !dbg [[DBG106]]
// PPC64-NEXT:    [[BF_LOAD164:%.*]] = load i32, ptr [[ATOMIC_TEMP163]], align 1, !dbg [[DBG106]]
// PPC64-NEXT:    [[BF_ASHR165:%.*]] = ashr i32 [[BF_LOAD164]], 1, !dbg [[DBG106]]
// PPC64-NEXT:    [[CONV166:%.*]] = sitofp i32 [[BF_ASHR165]] to ppc_fp128, !dbg [[DBG107:![0-9]+]]
// PPC64-NEXT:    [[MUL167:%.*]] = fmul ppc_fp128 [[CONV166]], [[TMP144]], !dbg [[DBG108:![0-9]+]]
// PPC64-NEXT:    [[CONV168:%.*]] = fptosi ppc_fp128 [[MUL167]] to i32, !dbg [[DBG107]]
// PPC64-NEXT:    [[BF_LOAD169:%.*]] = load i32, ptr [[ATOMIC_TEMP162]], align 1, !dbg [[DBG106]]
// PPC64-NEXT:    [[BF_VALUE170:%.*]] = and i32 [[CONV168]], 2147483647, !dbg [[DBG106]]
// PPC64-NEXT:    [[BF_SHL171:%.*]] = shl i32 [[BF_VALUE170]], 1, !dbg [[DBG106]]
// PPC64-NEXT:    [[BF_CLEAR172:%.*]] = and i32 [[BF_LOAD169]], 1, !dbg [[DBG106]]
// PPC64-NEXT:    [[BF_SET173:%.*]] = or i32 [[BF_CLEAR172]], [[BF_SHL171]], !dbg [[DBG106]]
// PPC64-NEXT:    store i32 [[BF_SET173]], ptr [[ATOMIC_TEMP162]], align 1, !dbg [[DBG106]]
// PPC64-NEXT:    [[CALL174:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 4, ptr noundef @bfx_packed, ptr noundef [[ATOMIC_TEMP160]], ptr noundef [[ATOMIC_TEMP162]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG106]]
// PPC64-NEXT:    br i1 [[CALL174]], label [[ATOMIC_EXIT175:%.*]], label [[ATOMIC_CONT161]], !dbg [[DBG106]]
// PPC64:       atomic_exit175:
// PPC64-NEXT:    [[TMP147:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG109:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD176:%.*]] = load atomic i32, ptr @bfx2 monotonic, align 4, !dbg [[DBG110:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT177:%.*]], !dbg [[DBG110]]
// PPC64:       atomic_cont177:
// PPC64-NEXT:    [[TMP148:%.*]] = phi i32 [ [[ATOMIC_LOAD176]], [[ATOMIC_EXIT175]] ], [ [[TMP151:%.*]], [[ATOMIC_CONT177]] ], !dbg [[DBG110]]
// PPC64-NEXT:    store i32 [[TMP148]], ptr [[ATOMIC_TEMP178]], align 4, !dbg [[DBG110]]
// PPC64-NEXT:    store i32 [[TMP148]], ptr [[ATOMIC_TEMP179]], align 4, !dbg [[DBG110]]
// PPC64-NEXT:    [[BF_LOAD180:%.*]] = load i32, ptr [[ATOMIC_TEMP179]], align 4, !dbg [[DBG110]]
// PPC64-NEXT:    [[BF_SHL181:%.*]] = shl i32 [[BF_LOAD180]], 31, !dbg [[DBG110]]
// PPC64-NEXT:    [[BF_ASHR182:%.*]] = ashr i32 [[BF_SHL181]], 31, !dbg [[DBG110]]
// PPC64-NEXT:    [[CONV183:%.*]] = sitofp i32 [[BF_ASHR182]] to ppc_fp128, !dbg [[DBG111:![0-9]+]]
// PPC64-NEXT:    [[SUB184:%.*]] = fsub ppc_fp128 [[CONV183]], [[TMP147]], !dbg [[DBG112:![0-9]+]]
// PPC64-NEXT:    [[CONV185:%.*]] = fptosi ppc_fp128 [[SUB184]] to i32, !dbg [[DBG111]]
// PPC64-NEXT:    [[BF_LOAD186:%.*]] = load i32, ptr [[ATOMIC_TEMP178]], align 4, !dbg [[DBG110]]
// PPC64-NEXT:    [[BF_VALUE187:%.*]] = and i32 [[CONV185]], 1, !dbg [[DBG110]]
// PPC64-NEXT:    [[BF_CLEAR188:%.*]] = and i32 [[BF_LOAD186]], -2, !dbg [[DBG110]]
// PPC64-NEXT:    [[BF_SET189:%.*]] = or i32 [[BF_CLEAR188]], [[BF_VALUE187]], !dbg [[DBG110]]
// PPC64-NEXT:    store i32 [[BF_SET189]], ptr [[ATOMIC_TEMP178]], align 4, !dbg [[DBG110]]
// PPC64-NEXT:    [[TMP149:%.*]] = load i32, ptr [[ATOMIC_TEMP178]], align 4, !dbg [[DBG110]]
// PPC64-NEXT:    [[TMP150:%.*]] = cmpxchg ptr @bfx2, i32 [[TMP148]], i32 [[TMP149]] monotonic monotonic, align 4, !dbg [[DBG110]]
// PPC64-NEXT:    [[TMP151]] = extractvalue { i32, i1 } [[TMP150]], 0, !dbg [[DBG110]]
// PPC64-NEXT:    [[TMP152:%.*]] = extractvalue { i32, i1 } [[TMP150]], 1, !dbg [[DBG110]]
// PPC64-NEXT:    br i1 [[TMP152]], label [[ATOMIC_EXIT190:%.*]], label [[ATOMIC_CONT177]], !dbg [[DBG110]]
// PPC64:       atomic_exit190:
// PPC64-NEXT:    [[TMP153:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG113:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD191:%.*]] = load atomic i8, ptr @bfx2_packed monotonic, align 1, !dbg [[DBG114:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT192:%.*]], !dbg [[DBG114]]
// PPC64:       atomic_cont192:
// PPC64-NEXT:    [[TMP154:%.*]] = phi i8 [ [[ATOMIC_LOAD191]], [[ATOMIC_EXIT190]] ], [ [[TMP158:%.*]], [[ATOMIC_CONT192]] ], !dbg [[DBG114]]
// PPC64-NEXT:    store i8 [[TMP154]], ptr [[ATOMIC_TEMP193]], align 1, !dbg [[DBG114]]
// PPC64-NEXT:    store i8 [[TMP154]], ptr [[ATOMIC_TEMP194]], align 1, !dbg [[DBG114]]
// PPC64-NEXT:    [[BF_LOAD195:%.*]] = load i8, ptr [[ATOMIC_TEMP194]], align 1, !dbg [[DBG114]]
// PPC64-NEXT:    [[BF_SHL196:%.*]] = shl i8 [[BF_LOAD195]], 7, !dbg [[DBG114]]
// PPC64-NEXT:    [[BF_ASHR197:%.*]] = ashr i8 [[BF_SHL196]], 7, !dbg [[DBG114]]
// PPC64-NEXT:    [[BF_CAST:%.*]] = sext i8 [[BF_ASHR197]] to i32, !dbg [[DBG114]]
// PPC64-NEXT:    [[CONV198:%.*]] = sitofp i32 [[BF_CAST]] to ppc_fp128, !dbg [[DBG115:![0-9]+]]
// PPC64-NEXT:    [[DIV199:%.*]] = fdiv ppc_fp128 [[TMP153]], [[CONV198]], !dbg [[DBG116:![0-9]+]]
// PPC64-NEXT:    [[CONV200:%.*]] = fptosi ppc_fp128 [[DIV199]] to i32, !dbg [[DBG113]]
// PPC64-NEXT:    [[TMP155:%.*]] = trunc i32 [[CONV200]] to i8, !dbg [[DBG114]]
// PPC64-NEXT:    [[BF_LOAD201:%.*]] = load i8, ptr [[ATOMIC_TEMP193]], align 1, !dbg [[DBG114]]
// PPC64-NEXT:    [[BF_VALUE202:%.*]] = and i8 [[TMP155]], 1, !dbg [[DBG114]]
// PPC64-NEXT:    [[BF_CLEAR203:%.*]] = and i8 [[BF_LOAD201]], -2, !dbg [[DBG114]]
// PPC64-NEXT:    [[BF_SET204:%.*]] = or i8 [[BF_CLEAR203]], [[BF_VALUE202]], !dbg [[DBG114]]
// PPC64-NEXT:    store i8 [[BF_SET204]], ptr [[ATOMIC_TEMP193]], align 1, !dbg [[DBG114]]
// PPC64-NEXT:    [[TMP156:%.*]] = load i8, ptr [[ATOMIC_TEMP193]], align 1, !dbg [[DBG114]]
// PPC64-NEXT:    [[TMP157:%.*]] = cmpxchg ptr @bfx2_packed, i8 [[TMP154]], i8 [[TMP156]] monotonic monotonic, align 1, !dbg [[DBG114]]
// PPC64-NEXT:    [[TMP158]] = extractvalue { i8, i1 } [[TMP157]], 0, !dbg [[DBG114]]
// PPC64-NEXT:    [[TMP159:%.*]] = extractvalue { i8, i1 } [[TMP157]], 1, !dbg [[DBG114]]
// PPC64-NEXT:    br i1 [[TMP159]], label [[ATOMIC_EXIT205:%.*]], label [[ATOMIC_CONT192]], !dbg [[DBG114]]
// PPC64:       atomic_exit205:
// PPC64-NEXT:    [[TMP160:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG117:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD206:%.*]] = load atomic i32, ptr @bfx3 monotonic, align 4, !dbg [[DBG118:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT207:%.*]], !dbg [[DBG118]]
// PPC64:       atomic_cont207:
// PPC64-NEXT:    [[TMP161:%.*]] = phi i32 [ [[ATOMIC_LOAD206]], [[ATOMIC_EXIT205]] ], [ [[TMP164:%.*]], [[ATOMIC_CONT207]] ], !dbg [[DBG118]]
// PPC64-NEXT:    store i32 [[TMP161]], ptr [[ATOMIC_TEMP208]], align 4, !dbg [[DBG118]]
// PPC64-NEXT:    store i32 [[TMP161]], ptr [[ATOMIC_TEMP209]], align 4, !dbg [[DBG118]]
// PPC64-NEXT:    [[BF_LOAD210:%.*]] = load i32, ptr [[ATOMIC_TEMP209]], align 4, !dbg [[DBG118]]
// PPC64-NEXT:    [[BF_SHL211:%.*]] = shl i32 [[BF_LOAD210]], 11, !dbg [[DBG118]]
// PPC64-NEXT:    [[BF_ASHR212:%.*]] = ashr i32 [[BF_SHL211]], 18, !dbg [[DBG118]]
// PPC64-NEXT:    [[CONV213:%.*]] = sitofp i32 [[BF_ASHR212]] to ppc_fp128, !dbg [[DBG119:![0-9]+]]
// PPC64-NEXT:    [[DIV214:%.*]] = fdiv ppc_fp128 [[CONV213]], [[TMP160]], !dbg [[DBG120:![0-9]+]]
// PPC64-NEXT:    [[CONV215:%.*]] = fptosi ppc_fp128 [[DIV214]] to i32, !dbg [[DBG119]]
// PPC64-NEXT:    [[BF_LOAD216:%.*]] = load i32, ptr [[ATOMIC_TEMP208]], align 4, !dbg [[DBG118]]
// PPC64-NEXT:    [[BF_VALUE217:%.*]] = and i32 [[CONV215]], 16383, !dbg [[DBG118]]
// PPC64-NEXT:    [[BF_SHL218:%.*]] = shl i32 [[BF_VALUE217]], 7, !dbg [[DBG118]]
// PPC64-NEXT:    [[BF_CLEAR219:%.*]] = and i32 [[BF_LOAD216]], -2097025, !dbg [[DBG118]]
// PPC64-NEXT:    [[BF_SET220:%.*]] = or i32 [[BF_CLEAR219]], [[BF_SHL218]], !dbg [[DBG118]]
// PPC64-NEXT:    store i32 [[BF_SET220]], ptr [[ATOMIC_TEMP208]], align 4, !dbg [[DBG118]]
// PPC64-NEXT:    [[TMP162:%.*]] = load i32, ptr [[ATOMIC_TEMP208]], align 4, !dbg [[DBG118]]
// PPC64-NEXT:    [[TMP163:%.*]] = cmpxchg ptr @bfx3, i32 [[TMP161]], i32 [[TMP162]] monotonic monotonic, align 4, !dbg [[DBG118]]
// PPC64-NEXT:    [[TMP164]] = extractvalue { i32, i1 } [[TMP163]], 0, !dbg [[DBG118]]
// PPC64-NEXT:    [[TMP165:%.*]] = extractvalue { i32, i1 } [[TMP163]], 1, !dbg [[DBG118]]
// PPC64-NEXT:    br i1 [[TMP165]], label [[ATOMIC_EXIT221:%.*]], label [[ATOMIC_CONT207]], !dbg [[DBG118]]
// PPC64:       atomic_exit221:
// PPC64-NEXT:    [[TMP166:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG121:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 3, ptr noundef @bfx3_packed, ptr noundef [[ATOMIC_TEMP222]], i32 noundef signext 0), !dbg [[DBG122:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT223:%.*]], !dbg [[DBG122]]
// PPC64:       atomic_cont223:
// PPC64-NEXT:    [[TMP167:%.*]] = load i24, ptr [[ATOMIC_TEMP222]], align 1, !dbg [[DBG122]]
// PPC64-NEXT:    store i24 [[TMP167]], ptr [[ATOMIC_TEMP224]], align 1, !dbg [[DBG122]]
// PPC64-NEXT:    [[TMP168:%.*]] = load i24, ptr [[ATOMIC_TEMP222]], align 1, !dbg [[DBG122]]
// PPC64-NEXT:    store i24 [[TMP168]], ptr [[ATOMIC_TEMP225]], align 1, !dbg [[DBG122]]
// PPC64-NEXT:    [[BF_LOAD226:%.*]] = load i24, ptr [[ATOMIC_TEMP225]], align 1, !dbg [[DBG122]]
// PPC64-NEXT:    [[BF_SHL227:%.*]] = shl i24 [[BF_LOAD226]], 3, !dbg [[DBG122]]
// PPC64-NEXT:    [[BF_ASHR228:%.*]] = ashr i24 [[BF_SHL227]], 10, !dbg [[DBG122]]
// PPC64-NEXT:    [[BF_CAST229:%.*]] = sext i24 [[BF_ASHR228]] to i32, !dbg [[DBG122]]
// PPC64-NEXT:    [[CONV230:%.*]] = sitofp i32 [[BF_CAST229]] to ppc_fp128, !dbg [[DBG123:![0-9]+]]
// PPC64-NEXT:    [[ADD231:%.*]] = fadd ppc_fp128 [[CONV230]], [[TMP166]], !dbg [[DBG124:![0-9]+]]
// PPC64-NEXT:    [[CONV232:%.*]] = fptosi ppc_fp128 [[ADD231]] to i32, !dbg [[DBG123]]
// PPC64-NEXT:    [[TMP169:%.*]] = trunc i32 [[CONV232]] to i24, !dbg [[DBG122]]
// PPC64-NEXT:    [[BF_LOAD233:%.*]] = load i24, ptr [[ATOMIC_TEMP224]], align 1, !dbg [[DBG122]]
// PPC64-NEXT:    [[BF_VALUE234:%.*]] = and i24 [[TMP169]], 16383, !dbg [[DBG122]]
// PPC64-NEXT:    [[BF_SHL235:%.*]] = shl i24 [[BF_VALUE234]], 7, !dbg [[DBG122]]
// PPC64-NEXT:    [[BF_CLEAR236:%.*]] = and i24 [[BF_LOAD233]], -2097025, !dbg [[DBG122]]
// PPC64-NEXT:    [[BF_SET237:%.*]] = or i24 [[BF_CLEAR236]], [[BF_SHL235]], !dbg [[DBG122]]
// PPC64-NEXT:    store i24 [[BF_SET237]], ptr [[ATOMIC_TEMP224]], align 1, !dbg [[DBG122]]
// PPC64-NEXT:    [[CALL238:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 3, ptr noundef @bfx3_packed, ptr noundef [[ATOMIC_TEMP222]], ptr noundef [[ATOMIC_TEMP224]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG122]]
// PPC64-NEXT:    br i1 [[CALL238]], label [[ATOMIC_EXIT239:%.*]], label [[ATOMIC_CONT223]], !dbg [[DBG122]]
// PPC64:       atomic_exit239:
// PPC64-NEXT:    [[TMP170:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG125:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD240:%.*]] = load atomic i64, ptr @bfx4 monotonic, align 8, !dbg [[DBG126:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT241:%.*]], !dbg [[DBG126]]
// PPC64:       atomic_cont241:
// PPC64-NEXT:    [[TMP171:%.*]] = phi i64 [ [[ATOMIC_LOAD240]], [[ATOMIC_EXIT239]] ], [ [[TMP175:%.*]], [[ATOMIC_CONT241]] ], !dbg [[DBG126]]
// PPC64-NEXT:    store i64 [[TMP171]], ptr [[ATOMIC_TEMP242]], align 8, !dbg [[DBG126]]
// PPC64-NEXT:    store i64 [[TMP171]], ptr [[ATOMIC_TEMP243]], align 8, !dbg [[DBG126]]
// PPC64-NEXT:    [[BF_LOAD244:%.*]] = load i64, ptr [[ATOMIC_TEMP243]], align 8, !dbg [[DBG126]]
// PPC64-NEXT:    [[BF_SHL245:%.*]] = shl i64 [[BF_LOAD244]], 48, !dbg [[DBG126]]
// PPC64-NEXT:    [[BF_ASHR246:%.*]] = ashr i64 [[BF_SHL245]], 63, !dbg [[DBG126]]
// PPC64-NEXT:    [[BF_CAST247:%.*]] = trunc i64 [[BF_ASHR246]] to i32, !dbg [[DBG126]]
// PPC64-NEXT:    [[CONV248:%.*]] = sitofp i32 [[BF_CAST247]] to ppc_fp128, !dbg [[DBG127:![0-9]+]]
// PPC64-NEXT:    [[MUL249:%.*]] = fmul ppc_fp128 [[CONV248]], [[TMP170]], !dbg [[DBG128:![0-9]+]]
// PPC64-NEXT:    [[CONV250:%.*]] = fptosi ppc_fp128 [[MUL249]] to i32, !dbg [[DBG127]]
// PPC64-NEXT:    [[TMP172:%.*]] = zext i32 [[CONV250]] to i64, !dbg [[DBG126]]
// PPC64-NEXT:    [[BF_LOAD251:%.*]] = load i64, ptr [[ATOMIC_TEMP242]], align 8, !dbg [[DBG126]]
// PPC64-NEXT:    [[BF_VALUE252:%.*]] = and i64 [[TMP172]], 1, !dbg [[DBG126]]
// PPC64-NEXT:    [[BF_SHL253:%.*]] = shl i64 [[BF_VALUE252]], 15, !dbg [[DBG126]]
// PPC64-NEXT:    [[BF_CLEAR254:%.*]] = and i64 [[BF_LOAD251]], -32769, !dbg [[DBG126]]
// PPC64-NEXT:    [[BF_SET255:%.*]] = or i64 [[BF_CLEAR254]], [[BF_SHL253]], !dbg [[DBG126]]
// PPC64-NEXT:    store i64 [[BF_SET255]], ptr [[ATOMIC_TEMP242]], align 8, !dbg [[DBG126]]
// PPC64-NEXT:    [[TMP173:%.*]] = load i64, ptr [[ATOMIC_TEMP242]], align 8, !dbg [[DBG126]]
// PPC64-NEXT:    [[TMP174:%.*]] = cmpxchg ptr @bfx4, i64 [[TMP171]], i64 [[TMP173]] monotonic monotonic, align 8, !dbg [[DBG126]]
// PPC64-NEXT:    [[TMP175]] = extractvalue { i64, i1 } [[TMP174]], 0, !dbg [[DBG126]]
// PPC64-NEXT:    [[TMP176:%.*]] = extractvalue { i64, i1 } [[TMP174]], 1, !dbg [[DBG126]]
// PPC64-NEXT:    br i1 [[TMP176]], label [[ATOMIC_EXIT256:%.*]], label [[ATOMIC_CONT241]], !dbg [[DBG126]]
// PPC64:       atomic_exit256:
// PPC64-NEXT:    [[TMP177:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG129:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD257:%.*]] = load atomic i8, ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED:%.*]], ptr @bfx4_packed, i32 0, i32 1) monotonic, align 1, !dbg [[DBG130:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT258:%.*]], !dbg [[DBG130]]
// PPC64:       atomic_cont258:
// PPC64-NEXT:    [[TMP178:%.*]] = phi i8 [ [[ATOMIC_LOAD257]], [[ATOMIC_EXIT256]] ], [ [[TMP182:%.*]], [[ATOMIC_CONT258]] ], !dbg [[DBG130]]
// PPC64-NEXT:    store i8 [[TMP178]], ptr [[ATOMIC_TEMP259]], align 1, !dbg [[DBG130]]
// PPC64-NEXT:    store i8 [[TMP178]], ptr [[ATOMIC_TEMP260]], align 1, !dbg [[DBG130]]
// PPC64-NEXT:    [[BF_LOAD261:%.*]] = load i8, ptr [[ATOMIC_TEMP260]], align 1, !dbg [[DBG130]]
// PPC64-NEXT:    [[BF_ASHR262:%.*]] = ashr i8 [[BF_LOAD261]], 7, !dbg [[DBG130]]
// PPC64-NEXT:    [[BF_CAST263:%.*]] = sext i8 [[BF_ASHR262]] to i32, !dbg [[DBG130]]
// PPC64-NEXT:    [[CONV264:%.*]] = sitofp i32 [[BF_CAST263]] to ppc_fp128, !dbg [[DBG131:![0-9]+]]
// PPC64-NEXT:    [[SUB265:%.*]] = fsub ppc_fp128 [[CONV264]], [[TMP177]], !dbg [[DBG132:![0-9]+]]
// PPC64-NEXT:    [[CONV266:%.*]] = fptosi ppc_fp128 [[SUB265]] to i32, !dbg [[DBG131]]
// PPC64-NEXT:    [[TMP179:%.*]] = trunc i32 [[CONV266]] to i8, !dbg [[DBG130]]
// PPC64-NEXT:    [[BF_LOAD267:%.*]] = load i8, ptr [[ATOMIC_TEMP259]], align 1, !dbg [[DBG130]]
// PPC64-NEXT:    [[BF_VALUE268:%.*]] = and i8 [[TMP179]], 1, !dbg [[DBG130]]
// PPC64-NEXT:    [[BF_SHL269:%.*]] = shl i8 [[BF_VALUE268]], 7, !dbg [[DBG130]]
// PPC64-NEXT:    [[BF_CLEAR270:%.*]] = and i8 [[BF_LOAD267]], 127, !dbg [[DBG130]]
// PPC64-NEXT:    [[BF_SET271:%.*]] = or i8 [[BF_CLEAR270]], [[BF_SHL269]], !dbg [[DBG130]]
// PPC64-NEXT:    store i8 [[BF_SET271]], ptr [[ATOMIC_TEMP259]], align 1, !dbg [[DBG130]]
// PPC64-NEXT:    [[TMP180:%.*]] = load i8, ptr [[ATOMIC_TEMP259]], align 1, !dbg [[DBG130]]
// PPC64-NEXT:    [[TMP181:%.*]] = cmpxchg ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1), i8 [[TMP178]], i8 [[TMP180]] monotonic monotonic, align 1, !dbg [[DBG130]]
// PPC64-NEXT:    [[TMP182]] = extractvalue { i8, i1 } [[TMP181]], 0, !dbg [[DBG130]]
// PPC64-NEXT:    [[TMP183:%.*]] = extractvalue { i8, i1 } [[TMP181]], 1, !dbg [[DBG130]]
// PPC64-NEXT:    br i1 [[TMP183]], label [[ATOMIC_EXIT272:%.*]], label [[ATOMIC_CONT258]], !dbg [[DBG130]]
// PPC64:       atomic_exit272:
// PPC64-NEXT:    [[TMP184:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG133:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD273:%.*]] = load atomic i64, ptr @bfx4 monotonic, align 8, !dbg [[DBG134:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT274:%.*]], !dbg [[DBG134]]
// PPC64:       atomic_cont274:
// PPC64-NEXT:    [[TMP185:%.*]] = phi i64 [ [[ATOMIC_LOAD273]], [[ATOMIC_EXIT272]] ], [ [[TMP188:%.*]], [[ATOMIC_CONT274]] ], !dbg [[DBG134]]
// PPC64-NEXT:    store i64 [[TMP185]], ptr [[ATOMIC_TEMP275]], align 8, !dbg [[DBG134]]
// PPC64-NEXT:    store i64 [[TMP185]], ptr [[ATOMIC_TEMP276]], align 8, !dbg [[DBG134]]
// PPC64-NEXT:    [[BF_LOAD277:%.*]] = load i64, ptr [[ATOMIC_TEMP276]], align 8, !dbg [[DBG134]]
// PPC64-NEXT:    [[BF_SHL278:%.*]] = shl i64 [[BF_LOAD277]], 49, !dbg [[DBG134]]
// PPC64-NEXT:    [[BF_ASHR279:%.*]] = ashr i64 [[BF_SHL278]], 57, !dbg [[DBG134]]
// PPC64-NEXT:    [[CONV280:%.*]] = sitofp i64 [[BF_ASHR279]] to ppc_fp128, !dbg [[DBG135:![0-9]+]]
// PPC64-NEXT:    [[DIV281:%.*]] = fdiv ppc_fp128 [[CONV280]], [[TMP184]], !dbg [[DBG136:![0-9]+]]
// PPC64-NEXT:    [[CONV282:%.*]] = fptosi ppc_fp128 [[DIV281]] to i64, !dbg [[DBG135]]
// PPC64-NEXT:    [[BF_LOAD283:%.*]] = load i64, ptr [[ATOMIC_TEMP275]], align 8, !dbg [[DBG134]]
// PPC64-NEXT:    [[BF_VALUE284:%.*]] = and i64 [[CONV282]], 127, !dbg [[DBG134]]
// PPC64-NEXT:    [[BF_SHL285:%.*]] = shl i64 [[BF_VALUE284]], 8, !dbg [[DBG134]]
// PPC64-NEXT:    [[BF_CLEAR286:%.*]] = and i64 [[BF_LOAD283]], -32513, !dbg [[DBG134]]
// PPC64-NEXT:    [[BF_SET287:%.*]] = or i64 [[BF_CLEAR286]], [[BF_SHL285]], !dbg [[DBG134]]
// PPC64-NEXT:    store i64 [[BF_SET287]], ptr [[ATOMIC_TEMP275]], align 8, !dbg [[DBG134]]
// PPC64-NEXT:    [[TMP186:%.*]] = load i64, ptr [[ATOMIC_TEMP275]], align 8, !dbg [[DBG134]]
// PPC64-NEXT:    [[TMP187:%.*]] = cmpxchg ptr @bfx4, i64 [[TMP185]], i64 [[TMP186]] monotonic monotonic, align 8, !dbg [[DBG134]]
// PPC64-NEXT:    [[TMP188]] = extractvalue { i64, i1 } [[TMP187]], 0, !dbg [[DBG134]]
// PPC64-NEXT:    [[TMP189:%.*]] = extractvalue { i64, i1 } [[TMP187]], 1, !dbg [[DBG134]]
// PPC64-NEXT:    br i1 [[TMP189]], label [[ATOMIC_EXIT288:%.*]], label [[ATOMIC_CONT274]], !dbg [[DBG134]]
// PPC64:       atomic_exit288:
// PPC64-NEXT:    [[TMP190:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG137:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD289:%.*]] = load atomic i8, ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1) monotonic, align 1, !dbg [[DBG138:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT290:%.*]], !dbg [[DBG138]]
// PPC64:       atomic_cont290:
// PPC64-NEXT:    [[TMP191:%.*]] = phi i8 [ [[ATOMIC_LOAD289]], [[ATOMIC_EXIT288]] ], [ [[TMP195:%.*]], [[ATOMIC_CONT290]] ], !dbg [[DBG138]]
// PPC64-NEXT:    store i8 [[TMP191]], ptr [[ATOMIC_TEMP291]], align 1, !dbg [[DBG138]]
// PPC64-NEXT:    store i8 [[TMP191]], ptr [[ATOMIC_TEMP292]], align 1, !dbg [[DBG138]]
// PPC64-NEXT:    [[BF_LOAD293:%.*]] = load i8, ptr [[ATOMIC_TEMP292]], align 1, !dbg [[DBG138]]
// PPC64-NEXT:    [[BF_SHL294:%.*]] = shl i8 [[BF_LOAD293]], 1, !dbg [[DBG138]]
// PPC64-NEXT:    [[BF_ASHR295:%.*]] = ashr i8 [[BF_SHL294]], 1, !dbg [[DBG138]]
// PPC64-NEXT:    [[BF_CAST296:%.*]] = sext i8 [[BF_ASHR295]] to i64, !dbg [[DBG138]]
// PPC64-NEXT:    [[CONV297:%.*]] = sitofp i64 [[BF_CAST296]] to ppc_fp128, !dbg [[DBG139:![0-9]+]]
// PPC64-NEXT:    [[ADD298:%.*]] = fadd ppc_fp128 [[CONV297]], [[TMP190]], !dbg [[DBG140:![0-9]+]]
// PPC64-NEXT:    [[CONV299:%.*]] = fptosi ppc_fp128 [[ADD298]] to i64, !dbg [[DBG139]]
// PPC64-NEXT:    [[TMP192:%.*]] = trunc i64 [[CONV299]] to i8, !dbg [[DBG138]]
// PPC64-NEXT:    [[BF_LOAD300:%.*]] = load i8, ptr [[ATOMIC_TEMP291]], align 1, !dbg [[DBG138]]
// PPC64-NEXT:    [[BF_VALUE301:%.*]] = and i8 [[TMP192]], 127, !dbg [[DBG138]]
// PPC64-NEXT:    [[BF_CLEAR302:%.*]] = and i8 [[BF_LOAD300]], -128, !dbg [[DBG138]]
// PPC64-NEXT:    [[BF_SET303:%.*]] = or i8 [[BF_CLEAR302]], [[BF_VALUE301]], !dbg [[DBG138]]
// PPC64-NEXT:    store i8 [[BF_SET303]], ptr [[ATOMIC_TEMP291]], align 1, !dbg [[DBG138]]
// PPC64-NEXT:    [[TMP193:%.*]] = load i8, ptr [[ATOMIC_TEMP291]], align 1, !dbg [[DBG138]]
// PPC64-NEXT:    [[TMP194:%.*]] = cmpxchg ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1), i8 [[TMP191]], i8 [[TMP193]] monotonic monotonic, align 1, !dbg [[DBG138]]
// PPC64-NEXT:    [[TMP195]] = extractvalue { i8, i1 } [[TMP194]], 0, !dbg [[DBG138]]
// PPC64-NEXT:    [[TMP196:%.*]] = extractvalue { i8, i1 } [[TMP194]], 1, !dbg [[DBG138]]
// PPC64-NEXT:    br i1 [[TMP196]], label [[ATOMIC_EXIT304:%.*]], label [[ATOMIC_CONT290]], !dbg [[DBG138]]
// PPC64:       atomic_exit304:
// PPC64-NEXT:    [[TMP197:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG141:![0-9]+]]
// PPC64-NEXT:    [[CONV305:%.*]] = uitofp i64 [[TMP197]] to float, !dbg [[DBG141]]
// PPC64-NEXT:    [[ATOMIC_LOAD306:%.*]] = load atomic i64, ptr @float2x monotonic, align 8, !dbg [[DBG142:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT307:%.*]], !dbg [[DBG142]]
// PPC64:       atomic_cont307:
// PPC64-NEXT:    [[TMP198:%.*]] = phi i64 [ [[ATOMIC_LOAD306]], [[ATOMIC_EXIT304]] ], [ [[TMP206:%.*]], [[ATOMIC_CONT307]] ], !dbg [[DBG142]]
// PPC64-NEXT:    store i64 [[TMP198]], ptr [[ATOMIC_TEMP308]], align 8, !dbg [[DBG142]]
// PPC64-NEXT:    [[TMP199:%.*]] = bitcast i64 [[TMP198]] to <2 x float>, !dbg [[DBG142]]
// PPC64-NEXT:    store <2 x float> [[TMP199]], ptr [[ATOMIC_TEMP309]], align 8, !dbg [[DBG142]]
// PPC64-NEXT:    [[TMP200:%.*]] = load <2 x float>, ptr [[ATOMIC_TEMP309]], align 8, !dbg [[DBG142]]
// PPC64-NEXT:    [[TMP201:%.*]] = extractelement <2 x float> [[TMP200]], i64 0, !dbg [[DBG142]]
// PPC64-NEXT:    [[SUB310:%.*]] = fsub float [[CONV305]], [[TMP201]], !dbg [[DBG143:![0-9]+]]
// PPC64-NEXT:    [[TMP202:%.*]] = load <2 x float>, ptr [[ATOMIC_TEMP308]], align 8, !dbg [[DBG142]]
// PPC64-NEXT:    [[TMP203:%.*]] = insertelement <2 x float> [[TMP202]], float [[SUB310]], i64 0, !dbg [[DBG142]]
// PPC64-NEXT:    store <2 x float> [[TMP203]], ptr [[ATOMIC_TEMP308]], align 8, !dbg [[DBG142]]
// PPC64-NEXT:    [[TMP204:%.*]] = load i64, ptr [[ATOMIC_TEMP308]], align 8, !dbg [[DBG142]]
// PPC64-NEXT:    [[TMP205:%.*]] = cmpxchg ptr @float2x, i64 [[TMP198]], i64 [[TMP204]] monotonic monotonic, align 8, !dbg [[DBG142]]
// PPC64-NEXT:    [[TMP206]] = extractvalue { i64, i1 } [[TMP205]], 0, !dbg [[DBG142]]
// PPC64-NEXT:    [[TMP207:%.*]] = extractvalue { i64, i1 } [[TMP205]], 1, !dbg [[DBG142]]
// PPC64-NEXT:    br i1 [[TMP207]], label [[ATOMIC_EXIT311:%.*]], label [[ATOMIC_CONT307]], !dbg [[DBG142]]
// PPC64:       atomic_exit311:
// PPC64-NEXT:    ret i32 0, !dbg [[DBG144:![0-9]+]]
//
//
// AARCH64-LABEL: define {{[^@]+}}@main
// AARCH64-SAME: () #[[ATTR0:[0-9]+]] !dbg [[DBG5:![0-9]+]] {
// AARCH64-NEXT:  entry:
// AARCH64-NEXT:    [[RETVAL:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca i16, align 2
// AARCH64-NEXT:    [[ATOMIC_TEMP5:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP9:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP13:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP17:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP21:%.*]] = alloca double, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP25:%.*]] = alloca fp128, align 16
// AARCH64-NEXT:    [[ATOMIC_TEMP28:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP30:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP32:%.*]] = alloca { float, float }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP34:%.*]] = alloca { float, float }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP37:%.*]] = alloca { double, double }, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP39:%.*]] = alloca { double, double }, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP46:%.*]] = alloca i8, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP53:%.*]] = alloca i8, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP61:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP68:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP70:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP72:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP84:%.*]] = alloca float, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP90:%.*]] = alloca double, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP94:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP96:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP106:%.*]] = alloca i16, align 2
// AARCH64-NEXT:    [[ATOMIC_TEMP114:%.*]] = alloca i8, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP126:%.*]] = alloca i8, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP140:%.*]] = alloca <4 x i32>, align 16
// AARCH64-NEXT:    [[ATOMIC_TEMP141:%.*]] = alloca <4 x i32>, align 16
// AARCH64-NEXT:    [[ATOMIC_TEMP145:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP146:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP152:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP154:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP155:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP170:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP171:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP185:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP186:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP200:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP201:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP214:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP216:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP217:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP234:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP235:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP251:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP252:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP267:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP268:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP283:%.*]] = alloca i64, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP284:%.*]] = alloca i64, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP300:%.*]] = alloca <2 x float>, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP301:%.*]] = alloca <2 x float>, align 8
// AARCH64-NEXT:    store i32 0, ptr [[RETVAL]], align 4
// AARCH64-NEXT:    [[TMP0:%.*]] = atomicrmw fadd ptr @dv, double 1.000000e+00 monotonic, align 8, !dbg [[DBG9:![0-9]+]]
// AARCH64-NEXT:    [[TMP1:%.*]] = atomicrmw add ptr @bx, i8 1 monotonic, align 1, !dbg [[DBG10:![0-9]+]]
// AARCH64-NEXT:    [[TMP2:%.*]] = atomicrmw add ptr @cx, i8 1 monotonic, align 1, !dbg [[DBG11:![0-9]+]]
// AARCH64-NEXT:    [[TMP3:%.*]] = atomicrmw sub ptr @ucx, i8 1 monotonic, align 1, !dbg [[DBG12:![0-9]+]]
// AARCH64-NEXT:    [[TMP4:%.*]] = atomicrmw sub ptr @sx, i16 1 monotonic, align 2, !dbg [[DBG13:![0-9]+]]
// AARCH64-NEXT:    [[TMP5:%.*]] = load i16, ptr @usv, align 2, !dbg [[DBG14:![0-9]+]]
// AARCH64-NEXT:    [[CONV:%.*]] = zext i16 [[TMP5]] to i32, !dbg [[DBG14]]
// AARCH64-NEXT:    [[ATOMIC_LOAD:%.*]] = load atomic i16, ptr @usx monotonic, align 2, !dbg [[DBG15:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT:%.*]], !dbg [[DBG15]]
// AARCH64:       atomic_cont:
// AARCH64-NEXT:    [[TMP6:%.*]] = phi i16 [ [[ATOMIC_LOAD]], [[ENTRY:%.*]] ], [ [[TMP9:%.*]], [[ATOMIC_CONT]] ], !dbg [[DBG15]]
// AARCH64-NEXT:    [[CONV1:%.*]] = zext i16 [[TMP6]] to i32, !dbg [[DBG15]]
// AARCH64-NEXT:    [[ADD:%.*]] = add nsw i32 [[CONV1]], [[CONV]], !dbg [[DBG16:![0-9]+]]
// AARCH64-NEXT:    [[CONV2:%.*]] = trunc i32 [[ADD]] to i16, !dbg [[DBG15]]
// AARCH64-NEXT:    store i16 [[CONV2]], ptr [[ATOMIC_TEMP]], align 2, !dbg [[DBG15]]
// AARCH64-NEXT:    [[TMP7:%.*]] = load i16, ptr [[ATOMIC_TEMP]], align 2, !dbg [[DBG15]]
// AARCH64-NEXT:    [[TMP8:%.*]] = cmpxchg ptr @usx, i16 [[TMP6]], i16 [[TMP7]] monotonic monotonic, align 2, !dbg [[DBG15]]
// AARCH64-NEXT:    [[TMP9]] = extractvalue { i16, i1 } [[TMP8]], 0, !dbg [[DBG15]]
// AARCH64-NEXT:    [[TMP10:%.*]] = extractvalue { i16, i1 } [[TMP8]], 1, !dbg [[DBG15]]
// AARCH64-NEXT:    br i1 [[TMP10]], label [[ATOMIC_EXIT:%.*]], label [[ATOMIC_CONT]], !dbg [[DBG15]]
// AARCH64:       atomic_exit:
// AARCH64-NEXT:    [[TMP11:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG17:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD3:%.*]] = load atomic i32, ptr @ix monotonic, align 4, !dbg [[DBG18:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT4:%.*]], !dbg [[DBG18]]
// AARCH64:       atomic_cont4:
// AARCH64-NEXT:    [[TMP12:%.*]] = phi i32 [ [[ATOMIC_LOAD3]], [[ATOMIC_EXIT]] ], [ [[TMP15:%.*]], [[ATOMIC_CONT4]] ], !dbg [[DBG18]]
// AARCH64-NEXT:    [[MUL:%.*]] = mul nsw i32 [[TMP12]], [[TMP11]], !dbg [[DBG19:![0-9]+]]
// AARCH64-NEXT:    store i32 [[MUL]], ptr [[ATOMIC_TEMP5]], align 4, !dbg [[DBG18]]
// AARCH64-NEXT:    [[TMP13:%.*]] = load i32, ptr [[ATOMIC_TEMP5]], align 4, !dbg [[DBG18]]
// AARCH64-NEXT:    [[TMP14:%.*]] = cmpxchg ptr @ix, i32 [[TMP12]], i32 [[TMP13]] monotonic monotonic, align 4, !dbg [[DBG18]]
// AARCH64-NEXT:    [[TMP15]] = extractvalue { i32, i1 } [[TMP14]], 0, !dbg [[DBG18]]
// AARCH64-NEXT:    [[TMP16:%.*]] = extractvalue { i32, i1 } [[TMP14]], 1, !dbg [[DBG18]]
// AARCH64-NEXT:    br i1 [[TMP16]], label [[ATOMIC_EXIT6:%.*]], label [[ATOMIC_CONT4]], !dbg [[DBG18]]
// AARCH64:       atomic_exit6:
// AARCH64-NEXT:    [[TMP17:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG20:![0-9]+]]
// AARCH64-NEXT:    [[TMP18:%.*]] = atomicrmw sub ptr @uix, i32 [[TMP17]] monotonic, align 4, !dbg [[DBG21:![0-9]+]]
// AARCH64-NEXT:    [[TMP19:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG22:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD7:%.*]] = load atomic i32, ptr @ix monotonic, align 4, !dbg [[DBG23:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT8:%.*]], !dbg [[DBG23]]
// AARCH64:       atomic_cont8:
// AARCH64-NEXT:    [[TMP20:%.*]] = phi i32 [ [[ATOMIC_LOAD7]], [[ATOMIC_EXIT6]] ], [ [[TMP23:%.*]], [[ATOMIC_CONT8]] ], !dbg [[DBG23]]
// AARCH64-NEXT:    [[SHL:%.*]] = shl i32 [[TMP20]], [[TMP19]], !dbg [[DBG24:![0-9]+]]
// AARCH64-NEXT:    store i32 [[SHL]], ptr [[ATOMIC_TEMP9]], align 4, !dbg [[DBG23]]
// AARCH64-NEXT:    [[TMP21:%.*]] = load i32, ptr [[ATOMIC_TEMP9]], align 4, !dbg [[DBG23]]
// AARCH64-NEXT:    [[TMP22:%.*]] = cmpxchg ptr @ix, i32 [[TMP20]], i32 [[TMP21]] monotonic monotonic, align 4, !dbg [[DBG23]]
// AARCH64-NEXT:    [[TMP23]] = extractvalue { i32, i1 } [[TMP22]], 0, !dbg [[DBG23]]
// AARCH64-NEXT:    [[TMP24:%.*]] = extractvalue { i32, i1 } [[TMP22]], 1, !dbg [[DBG23]]
// AARCH64-NEXT:    br i1 [[TMP24]], label [[ATOMIC_EXIT10:%.*]], label [[ATOMIC_CONT8]], !dbg [[DBG23]]
// AARCH64:       atomic_exit10:
// AARCH64-NEXT:    [[TMP25:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG25:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD11:%.*]] = load atomic i32, ptr @uix monotonic, align 4, !dbg [[DBG26:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT12:%.*]], !dbg [[DBG26]]
// AARCH64:       atomic_cont12:
// AARCH64-NEXT:    [[TMP26:%.*]] = phi i32 [ [[ATOMIC_LOAD11]], [[ATOMIC_EXIT10]] ], [ [[TMP29:%.*]], [[ATOMIC_CONT12]] ], !dbg [[DBG26]]
// AARCH64-NEXT:    [[SHR:%.*]] = lshr i32 [[TMP26]], [[TMP25]], !dbg [[DBG27:![0-9]+]]
// AARCH64-NEXT:    store i32 [[SHR]], ptr [[ATOMIC_TEMP13]], align 4, !dbg [[DBG26]]
// AARCH64-NEXT:    [[TMP27:%.*]] = load i32, ptr [[ATOMIC_TEMP13]], align 4, !dbg [[DBG26]]
// AARCH64-NEXT:    [[TMP28:%.*]] = cmpxchg ptr @uix, i32 [[TMP26]], i32 [[TMP27]] monotonic monotonic, align 4, !dbg [[DBG26]]
// AARCH64-NEXT:    [[TMP29]] = extractvalue { i32, i1 } [[TMP28]], 0, !dbg [[DBG26]]
// AARCH64-NEXT:    [[TMP30:%.*]] = extractvalue { i32, i1 } [[TMP28]], 1, !dbg [[DBG26]]
// AARCH64-NEXT:    br i1 [[TMP30]], label [[ATOMIC_EXIT14:%.*]], label [[ATOMIC_CONT12]], !dbg [[DBG26]]
// AARCH64:       atomic_exit14:
// AARCH64-NEXT:    [[TMP31:%.*]] = load i64, ptr @lv, align 8, !dbg [[DBG28:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD15:%.*]] = load atomic i64, ptr @lx monotonic, align 8, !dbg [[DBG29:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT16:%.*]], !dbg [[DBG29]]
// AARCH64:       atomic_cont16:
// AARCH64-NEXT:    [[TMP32:%.*]] = phi i64 [ [[ATOMIC_LOAD15]], [[ATOMIC_EXIT14]] ], [ [[TMP35:%.*]], [[ATOMIC_CONT16]] ], !dbg [[DBG29]]
// AARCH64-NEXT:    [[DIV:%.*]] = sdiv i64 [[TMP32]], [[TMP31]], !dbg [[DBG30:![0-9]+]]
// AARCH64-NEXT:    store i64 [[DIV]], ptr [[ATOMIC_TEMP17]], align 8, !dbg [[DBG29]]
// AARCH64-NEXT:    [[TMP33:%.*]] = load i64, ptr [[ATOMIC_TEMP17]], align 8, !dbg [[DBG29]]
// AARCH64-NEXT:    [[TMP34:%.*]] = cmpxchg ptr @lx, i64 [[TMP32]], i64 [[TMP33]] monotonic monotonic, align 8, !dbg [[DBG29]]
// AARCH64-NEXT:    [[TMP35]] = extractvalue { i64, i1 } [[TMP34]], 0, !dbg [[DBG29]]
// AARCH64-NEXT:    [[TMP36:%.*]] = extractvalue { i64, i1 } [[TMP34]], 1, !dbg [[DBG29]]
// AARCH64-NEXT:    br i1 [[TMP36]], label [[ATOMIC_EXIT18:%.*]], label [[ATOMIC_CONT16]], !dbg [[DBG29]]
// AARCH64:       atomic_exit18:
// AARCH64-NEXT:    [[TMP37:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG31:![0-9]+]]
// AARCH64-NEXT:    [[TMP38:%.*]] = atomicrmw and ptr @ulx, i64 [[TMP37]] monotonic, align 8, !dbg [[DBG32:![0-9]+]]
// AARCH64-NEXT:    [[TMP39:%.*]] = load i64, ptr @llv, align 8, !dbg [[DBG33:![0-9]+]]
// AARCH64-NEXT:    [[TMP40:%.*]] = atomicrmw xor ptr @llx, i64 [[TMP39]] monotonic, align 8, !dbg [[DBG34:![0-9]+]]
// AARCH64-NEXT:    [[TMP41:%.*]] = load i64, ptr @ullv, align 8, !dbg [[DBG35:![0-9]+]]
// AARCH64-NEXT:    [[TMP42:%.*]] = atomicrmw or ptr @ullx, i64 [[TMP41]] monotonic, align 8, !dbg [[DBG36:![0-9]+]]
// AARCH64-NEXT:    [[TMP43:%.*]] = load float, ptr @fv, align 4, !dbg [[DBG37:![0-9]+]]
// AARCH64-NEXT:    [[TMP44:%.*]] = atomicrmw fadd ptr @fx, float [[TMP43]] monotonic, align 4, !dbg [[DBG38:![0-9]+]]
// AARCH64-NEXT:    [[TMP45:%.*]] = load double, ptr @dv, align 8, !dbg [[DBG39:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD19:%.*]] = load atomic i64, ptr @dx monotonic, align 8, !dbg [[DBG40:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT20:%.*]], !dbg [[DBG40]]
// AARCH64:       atomic_cont20:
// AARCH64-NEXT:    [[TMP46:%.*]] = phi i64 [ [[ATOMIC_LOAD19]], [[ATOMIC_EXIT18]] ], [ [[TMP50:%.*]], [[ATOMIC_CONT20]] ], !dbg [[DBG40]]
// AARCH64-NEXT:    [[TMP47:%.*]] = bitcast i64 [[TMP46]] to double, !dbg [[DBG40]]
// AARCH64-NEXT:    [[SUB:%.*]] = fsub double [[TMP45]], [[TMP47]], !dbg [[DBG41:![0-9]+]]
// AARCH64-NEXT:    store double [[SUB]], ptr [[ATOMIC_TEMP21]], align 8, !dbg [[DBG40]]
// AARCH64-NEXT:    [[TMP48:%.*]] = load i64, ptr [[ATOMIC_TEMP21]], align 8, !dbg [[DBG40]]
// AARCH64-NEXT:    [[TMP49:%.*]] = cmpxchg ptr @dx, i64 [[TMP46]], i64 [[TMP48]] monotonic monotonic, align 8, !dbg [[DBG40]]
// AARCH64-NEXT:    [[TMP50]] = extractvalue { i64, i1 } [[TMP49]], 0, !dbg [[DBG40]]
// AARCH64-NEXT:    [[TMP51:%.*]] = extractvalue { i64, i1 } [[TMP49]], 1, !dbg [[DBG40]]
// AARCH64-NEXT:    br i1 [[TMP51]], label [[ATOMIC_EXIT22:%.*]], label [[ATOMIC_CONT20]], !dbg [[DBG40]]
// AARCH64:       atomic_exit22:
// AARCH64-NEXT:    [[TMP52:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG42:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD23:%.*]] = load atomic i128, ptr @ldx monotonic, align 16, !dbg [[DBG43:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT24:%.*]], !dbg [[DBG43]]
// AARCH64:       atomic_cont24:
// AARCH64-NEXT:    [[TMP53:%.*]] = phi i128 [ [[ATOMIC_LOAD23]], [[ATOMIC_EXIT22]] ], [ [[TMP57:%.*]], [[ATOMIC_CONT24]] ], !dbg [[DBG43]]
// AARCH64-NEXT:    [[TMP54:%.*]] = bitcast i128 [[TMP53]] to fp128, !dbg [[DBG43]]
// AARCH64-NEXT:    [[MUL26:%.*]] = fmul fp128 [[TMP54]], [[TMP52]], !dbg [[DBG44:![0-9]+]]
// AARCH64-NEXT:    store fp128 [[MUL26]], ptr [[ATOMIC_TEMP25]], align 16, !dbg [[DBG43]]
// AARCH64-NEXT:    [[TMP55:%.*]] = load i128, ptr [[ATOMIC_TEMP25]], align 16, !dbg [[DBG43]]
// AARCH64-NEXT:    [[TMP56:%.*]] = cmpxchg ptr @ldx, i128 [[TMP53]], i128 [[TMP55]] monotonic monotonic, align 16, !dbg [[DBG43]]
// AARCH64-NEXT:    [[TMP57]] = extractvalue { i128, i1 } [[TMP56]], 0, !dbg [[DBG43]]
// AARCH64-NEXT:    [[TMP58:%.*]] = extractvalue { i128, i1 } [[TMP56]], 1, !dbg [[DBG43]]
// AARCH64-NEXT:    br i1 [[TMP58]], label [[ATOMIC_EXIT27:%.*]], label [[ATOMIC_CONT24]], !dbg [[DBG43]]
// AARCH64:       atomic_exit27:
// AARCH64-NEXT:    [[CIV_REAL:%.*]] = load i32, ptr @civ, align 4, !dbg [[DBG45:![0-9]+]]
// AARCH64-NEXT:    [[CIV_IMAG:%.*]] = load i32, ptr getelementptr inbounds nuw ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG45]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP28]], i32 noundef 0), !dbg [[DBG46:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT29:%.*]], !dbg [[DBG46]]
// AARCH64:       atomic_cont29:
// AARCH64-NEXT:    [[ATOMIC_TEMP28_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP28]], i32 0, i32 0, !dbg [[DBG46]]
// AARCH64-NEXT:    [[ATOMIC_TEMP28_REAL:%.*]] = load i32, ptr [[ATOMIC_TEMP28_REALP]], align 4, !dbg [[DBG46]]
// AARCH64-NEXT:    [[ATOMIC_TEMP28_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP28]], i32 0, i32 1, !dbg [[DBG46]]
// AARCH64-NEXT:    [[ATOMIC_TEMP28_IMAG:%.*]] = load i32, ptr [[ATOMIC_TEMP28_IMAGP]], align 4, !dbg [[DBG46]]
// AARCH64-NEXT:    [[TMP59:%.*]] = mul i32 [[CIV_REAL]], [[ATOMIC_TEMP28_REAL]], !dbg [[DBG47:![0-9]+]]
// AARCH64-NEXT:    [[TMP60:%.*]] = mul i32 [[CIV_IMAG]], [[ATOMIC_TEMP28_IMAG]], !dbg [[DBG47]]
// AARCH64-NEXT:    [[TMP61:%.*]] = add i32 [[TMP59]], [[TMP60]], !dbg [[DBG47]]
// AARCH64-NEXT:    [[TMP62:%.*]] = mul i32 [[ATOMIC_TEMP28_REAL]], [[ATOMIC_TEMP28_REAL]], !dbg [[DBG47]]
// AARCH64-NEXT:    [[TMP63:%.*]] = mul i32 [[ATOMIC_TEMP28_IMAG]], [[ATOMIC_TEMP28_IMAG]], !dbg [[DBG47]]
// AARCH64-NEXT:    [[TMP64:%.*]] = add i32 [[TMP62]], [[TMP63]], !dbg [[DBG47]]
// AARCH64-NEXT:    [[TMP65:%.*]] = mul i32 [[CIV_IMAG]], [[ATOMIC_TEMP28_REAL]], !dbg [[DBG47]]
// AARCH64-NEXT:    [[TMP66:%.*]] = mul i32 [[CIV_REAL]], [[ATOMIC_TEMP28_IMAG]], !dbg [[DBG47]]
// AARCH64-NEXT:    [[TMP67:%.*]] = sub i32 [[TMP65]], [[TMP66]], !dbg [[DBG47]]
// AARCH64-NEXT:    [[TMP68:%.*]] = sdiv i32 [[TMP61]], [[TMP64]], !dbg [[DBG47]]
// AARCH64-NEXT:    [[TMP69:%.*]] = sdiv i32 [[TMP67]], [[TMP64]], !dbg [[DBG47]]
// AARCH64-NEXT:    [[ATOMIC_TEMP30_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP30]], i32 0, i32 0, !dbg [[DBG46]]
// AARCH64-NEXT:    [[ATOMIC_TEMP30_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP30]], i32 0, i32 1, !dbg [[DBG46]]
// AARCH64-NEXT:    store i32 [[TMP68]], ptr [[ATOMIC_TEMP30_REALP]], align 4, !dbg [[DBG46]]
// AARCH64-NEXT:    store i32 [[TMP69]], ptr [[ATOMIC_TEMP30_IMAGP]], align 4, !dbg [[DBG46]]
// AARCH64-NEXT:    [[CALL:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP28]], ptr noundef [[ATOMIC_TEMP30]], i32 noundef 0, i32 noundef 0), !dbg [[DBG46]]
// AARCH64-NEXT:    br i1 [[CALL]], label [[ATOMIC_EXIT31:%.*]], label [[ATOMIC_CONT29]], !dbg [[DBG46]]
// AARCH64:       atomic_exit31:
// AARCH64-NEXT:    [[CFV_REAL:%.*]] = load float, ptr @cfv, align 4, !dbg [[DBG48:![0-9]+]]
// AARCH64-NEXT:    [[CFV_IMAG:%.*]] = load float, ptr getelementptr inbounds nuw ({ float, float }, ptr @cfv, i32 0, i32 1), align 4, !dbg [[DBG48]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cfx, ptr noundef [[ATOMIC_TEMP32]], i32 noundef 0), !dbg [[DBG49:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT33:%.*]], !dbg [[DBG49]]
// AARCH64:       atomic_cont33:
// AARCH64-NEXT:    [[ATOMIC_TEMP32_REALP:%.*]] = getelementptr inbounds nuw { float, float }, ptr [[ATOMIC_TEMP32]], i32 0, i32 0, !dbg [[DBG49]]
// AARCH64-NEXT:    [[ATOMIC_TEMP32_REAL:%.*]] = load float, ptr [[ATOMIC_TEMP32_REALP]], align 4, !dbg [[DBG49]]
// AARCH64-NEXT:    [[ATOMIC_TEMP32_IMAGP:%.*]] = getelementptr inbounds nuw { float, float }, ptr [[ATOMIC_TEMP32]], i32 0, i32 1, !dbg [[DBG49]]
// AARCH64-NEXT:    [[ATOMIC_TEMP32_IMAG:%.*]] = load float, ptr [[ATOMIC_TEMP32_IMAGP]], align 4, !dbg [[DBG49]]
// AARCH64-NEXT:    [[ADD_R:%.*]] = fadd float [[CFV_REAL]], [[ATOMIC_TEMP32_REAL]], !dbg [[DBG50:![0-9]+]]
// AARCH64-NEXT:    [[ADD_I:%.*]] = fadd float [[CFV_IMAG]], [[ATOMIC_TEMP32_IMAG]], !dbg [[DBG50]]
// AARCH64-NEXT:    [[ATOMIC_TEMP34_REALP:%.*]] = getelementptr inbounds nuw { float, float }, ptr [[ATOMIC_TEMP34]], i32 0, i32 0, !dbg [[DBG49]]
// AARCH64-NEXT:    [[ATOMIC_TEMP34_IMAGP:%.*]] = getelementptr inbounds nuw { float, float }, ptr [[ATOMIC_TEMP34]], i32 0, i32 1, !dbg [[DBG49]]
// AARCH64-NEXT:    store float [[ADD_R]], ptr [[ATOMIC_TEMP34_REALP]], align 4, !dbg [[DBG49]]
// AARCH64-NEXT:    store float [[ADD_I]], ptr [[ATOMIC_TEMP34_IMAGP]], align 4, !dbg [[DBG49]]
// AARCH64-NEXT:    [[CALL35:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cfx, ptr noundef [[ATOMIC_TEMP32]], ptr noundef [[ATOMIC_TEMP34]], i32 noundef 0, i32 noundef 0), !dbg [[DBG49]]
// AARCH64-NEXT:    br i1 [[CALL35]], label [[ATOMIC_EXIT36:%.*]], label [[ATOMIC_CONT33]], !dbg [[DBG49]]
// AARCH64:       atomic_exit36:
// AARCH64-NEXT:    [[CDV_REAL:%.*]] = load double, ptr @cdv, align 8, !dbg [[DBG51:![0-9]+]]
// AARCH64-NEXT:    [[CDV_IMAG:%.*]] = load double, ptr getelementptr inbounds nuw ({ double, double }, ptr @cdv, i32 0, i32 1), align 8, !dbg [[DBG51]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 16, ptr noundef @cdx, ptr noundef [[ATOMIC_TEMP37]], i32 noundef 5), !dbg [[DBG52:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT38:%.*]], !dbg [[DBG52]]
// AARCH64:       atomic_cont38:
// AARCH64-NEXT:    [[ATOMIC_TEMP37_REALP:%.*]] = getelementptr inbounds nuw { double, double }, ptr [[ATOMIC_TEMP37]], i32 0, i32 0, !dbg [[DBG52]]
// AARCH64-NEXT:    [[ATOMIC_TEMP37_REAL:%.*]] = load double, ptr [[ATOMIC_TEMP37_REALP]], align 8, !dbg [[DBG52]]
// AARCH64-NEXT:    [[ATOMIC_TEMP37_IMAGP:%.*]] = getelementptr inbounds nuw { double, double }, ptr [[ATOMIC_TEMP37]], i32 0, i32 1, !dbg [[DBG52]]
// AARCH64-NEXT:    [[ATOMIC_TEMP37_IMAG:%.*]] = load double, ptr [[ATOMIC_TEMP37_IMAGP]], align 8, !dbg [[DBG52]]
// AARCH64-NEXT:    [[SUB_R:%.*]] = fsub double [[ATOMIC_TEMP37_REAL]], [[CDV_REAL]], !dbg [[DBG53:![0-9]+]]
// AARCH64-NEXT:    [[SUB_I:%.*]] = fsub double [[ATOMIC_TEMP37_IMAG]], [[CDV_IMAG]], !dbg [[DBG53]]
// AARCH64-NEXT:    [[ATOMIC_TEMP39_REALP:%.*]] = getelementptr inbounds nuw { double, double }, ptr [[ATOMIC_TEMP39]], i32 0, i32 0, !dbg [[DBG52]]
// AARCH64-NEXT:    [[ATOMIC_TEMP39_IMAGP:%.*]] = getelementptr inbounds nuw { double, double }, ptr [[ATOMIC_TEMP39]], i32 0, i32 1, !dbg [[DBG52]]
// AARCH64-NEXT:    store double [[SUB_R]], ptr [[ATOMIC_TEMP39_REALP]], align 8, !dbg [[DBG52]]
// AARCH64-NEXT:    store double [[SUB_I]], ptr [[ATOMIC_TEMP39_IMAGP]], align 8, !dbg [[DBG52]]
// AARCH64-NEXT:    [[CALL40:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 16, ptr noundef @cdx, ptr noundef [[ATOMIC_TEMP37]], ptr noundef [[ATOMIC_TEMP39]], i32 noundef 5, i32 noundef 5), !dbg [[DBG52]]
// AARCH64-NEXT:    br i1 [[CALL40]], label [[ATOMIC_EXIT41:%.*]], label [[ATOMIC_CONT38]], !dbg [[DBG52]]
// AARCH64:       atomic_exit41:
// AARCH64-NEXT:    fence release
// AARCH64-NEXT:    [[TMP70:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG54:![0-9]+]]
// AARCH64-NEXT:    [[LOADEDV:%.*]] = trunc i8 [[TMP70]] to i1, !dbg [[DBG54]]
// AARCH64-NEXT:    [[CONV42:%.*]] = zext i1 [[LOADEDV]] to i64, !dbg [[DBG54]]
// AARCH64-NEXT:    [[TMP71:%.*]] = atomicrmw and ptr @ulx, i64 [[CONV42]] monotonic, align 8, !dbg [[DBG55:![0-9]+]]
// AARCH64-NEXT:    [[TMP72:%.*]] = load i8, ptr @cv, align 1, !dbg [[DBG56:![0-9]+]]
// AARCH64-NEXT:    [[CONV43:%.*]] = sext i8 [[TMP72]] to i32, !dbg [[DBG56]]
// AARCH64-NEXT:    [[ATOMIC_LOAD44:%.*]] = load atomic i8, ptr @bx monotonic, align 1, !dbg [[DBG57:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT45:%.*]], !dbg [[DBG57]]
// AARCH64:       atomic_cont45:
// AARCH64-NEXT:    [[TMP73:%.*]] = phi i8 [ [[ATOMIC_LOAD44]], [[ATOMIC_EXIT41]] ], [ [[TMP76:%.*]], [[ATOMIC_CONT45]] ], !dbg [[DBG57]]
// AARCH64-NEXT:    [[LOADEDV47:%.*]] = trunc i8 [[TMP73]] to i1, !dbg [[DBG57]]
// AARCH64-NEXT:    [[CONV48:%.*]] = zext i1 [[LOADEDV47]] to i32, !dbg [[DBG57]]
// AARCH64-NEXT:    [[AND:%.*]] = and i32 [[CONV43]], [[CONV48]], !dbg [[DBG58:![0-9]+]]
// AARCH64-NEXT:    [[TOBOOL:%.*]] = icmp ne i32 [[AND]], 0, !dbg [[DBG56]]
// AARCH64-NEXT:    [[STOREDV:%.*]] = zext i1 [[TOBOOL]] to i8, !dbg [[DBG57]]
// AARCH64-NEXT:    store i8 [[STOREDV]], ptr [[ATOMIC_TEMP46]], align 1, !dbg [[DBG57]]
// AARCH64-NEXT:    [[TMP74:%.*]] = load i8, ptr [[ATOMIC_TEMP46]], align 1, !dbg [[DBG57]]
// AARCH64-NEXT:    [[TMP75:%.*]] = cmpxchg ptr @bx, i8 [[TMP73]], i8 [[TMP74]] monotonic monotonic, align 1, !dbg [[DBG57]]
// AARCH64-NEXT:    [[TMP76]] = extractvalue { i8, i1 } [[TMP75]], 0, !dbg [[DBG57]]
// AARCH64-NEXT:    [[TMP77:%.*]] = extractvalue { i8, i1 } [[TMP75]], 1, !dbg [[DBG57]]
// AARCH64-NEXT:    br i1 [[TMP77]], label [[ATOMIC_EXIT49:%.*]], label [[ATOMIC_CONT45]], !dbg [[DBG57]]
// AARCH64:       atomic_exit49:
// AARCH64-NEXT:    [[TMP78:%.*]] = load i8, ptr @ucv, align 1, !dbg [[DBG59:![0-9]+]]
// AARCH64-NEXT:    [[CONV50:%.*]] = zext i8 [[TMP78]] to i32, !dbg [[DBG59]]
// AARCH64-NEXT:    [[ATOMIC_LOAD51:%.*]] = load atomic i8, ptr @cx seq_cst, align 1, !dbg [[DBG60:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT52:%.*]], !dbg [[DBG60]]
// AARCH64:       atomic_cont52:
// AARCH64-NEXT:    [[TMP79:%.*]] = phi i8 [ [[ATOMIC_LOAD51]], [[ATOMIC_EXIT49]] ], [ [[TMP82:%.*]], [[ATOMIC_CONT52]] ], !dbg [[DBG60]]
// AARCH64-NEXT:    [[CONV54:%.*]] = sext i8 [[TMP79]] to i32, !dbg [[DBG60]]
// AARCH64-NEXT:    [[SHR55:%.*]] = ashr i32 [[CONV54]], [[CONV50]], !dbg [[DBG61:![0-9]+]]
// AARCH64-NEXT:    [[CONV56:%.*]] = trunc i32 [[SHR55]] to i8, !dbg [[DBG60]]
// AARCH64-NEXT:    store i8 [[CONV56]], ptr [[ATOMIC_TEMP53]], align 1, !dbg [[DBG60]]
// AARCH64-NEXT:    [[TMP80:%.*]] = load i8, ptr [[ATOMIC_TEMP53]], align 1, !dbg [[DBG60]]
// AARCH64-NEXT:    [[TMP81:%.*]] = cmpxchg ptr @cx, i8 [[TMP79]], i8 [[TMP80]] seq_cst seq_cst, align 1, !dbg [[DBG60]]
// AARCH64-NEXT:    [[TMP82]] = extractvalue { i8, i1 } [[TMP81]], 0, !dbg [[DBG60]]
// AARCH64-NEXT:    [[TMP83:%.*]] = extractvalue { i8, i1 } [[TMP81]], 1, !dbg [[DBG60]]
// AARCH64-NEXT:    br i1 [[TMP83]], label [[ATOMIC_EXIT57:%.*]], label [[ATOMIC_CONT52]], !dbg [[DBG60]]
// AARCH64:       atomic_exit57:
// AARCH64-NEXT:    fence release
// AARCH64-NEXT:    [[TMP84:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG62:![0-9]+]]
// AARCH64-NEXT:    [[CONV58:%.*]] = sext i16 [[TMP84]] to i32, !dbg [[DBG62]]
// AARCH64-NEXT:    [[ATOMIC_LOAD59:%.*]] = load atomic i64, ptr @ulx monotonic, align 8, !dbg [[DBG63:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT60:%.*]], !dbg [[DBG63]]
// AARCH64:       atomic_cont60:
// AARCH64-NEXT:    [[TMP85:%.*]] = phi i64 [ [[ATOMIC_LOAD59]], [[ATOMIC_EXIT57]] ], [ [[TMP88:%.*]], [[ATOMIC_CONT60]] ], !dbg [[DBG63]]
// AARCH64-NEXT:    [[SH_PROM:%.*]] = trunc i64 [[TMP85]] to i32, !dbg [[DBG64:![0-9]+]]
// AARCH64-NEXT:    [[SHL62:%.*]] = shl i32 [[CONV58]], [[SH_PROM]], !dbg [[DBG64]]
// AARCH64-NEXT:    [[CONV63:%.*]] = sext i32 [[SHL62]] to i64, !dbg [[DBG62]]
// AARCH64-NEXT:    store i64 [[CONV63]], ptr [[ATOMIC_TEMP61]], align 8, !dbg [[DBG63]]
// AARCH64-NEXT:    [[TMP86:%.*]] = load i64, ptr [[ATOMIC_TEMP61]], align 8, !dbg [[DBG63]]
// AARCH64-NEXT:    [[TMP87:%.*]] = cmpxchg ptr @ulx, i64 [[TMP85]], i64 [[TMP86]] monotonic monotonic, align 8, !dbg [[DBG63]]
// AARCH64-NEXT:    [[TMP88]] = extractvalue { i64, i1 } [[TMP87]], 0, !dbg [[DBG63]]
// AARCH64-NEXT:    [[TMP89:%.*]] = extractvalue { i64, i1 } [[TMP87]], 1, !dbg [[DBG63]]
// AARCH64-NEXT:    br i1 [[TMP89]], label [[ATOMIC_EXIT64:%.*]], label [[ATOMIC_CONT60]], !dbg [[DBG63]]
// AARCH64:       atomic_exit64:
// AARCH64-NEXT:    [[TMP90:%.*]] = load i16, ptr @usv, align 2, !dbg [[DBG65:![0-9]+]]
// AARCH64-NEXT:    [[CONV65:%.*]] = zext i16 [[TMP90]] to i64, !dbg [[DBG65]]
// AARCH64-NEXT:    [[ATOMIC_LOAD66:%.*]] = load atomic i64, ptr @lx monotonic, align 8, !dbg [[DBG66:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT67:%.*]], !dbg [[DBG66]]
// AARCH64:       atomic_cont67:
// AARCH64-NEXT:    [[TMP91:%.*]] = phi i64 [ [[ATOMIC_LOAD66]], [[ATOMIC_EXIT64]] ], [ [[TMP94:%.*]], [[ATOMIC_CONT67]] ], !dbg [[DBG66]]
// AARCH64-NEXT:    [[REM:%.*]] = srem i64 [[TMP91]], [[CONV65]], !dbg [[DBG67:![0-9]+]]
// AARCH64-NEXT:    store i64 [[REM]], ptr [[ATOMIC_TEMP68]], align 8, !dbg [[DBG66]]
// AARCH64-NEXT:    [[TMP92:%.*]] = load i64, ptr [[ATOMIC_TEMP68]], align 8, !dbg [[DBG66]]
// AARCH64-NEXT:    [[TMP93:%.*]] = cmpxchg ptr @lx, i64 [[TMP91]], i64 [[TMP92]] monotonic monotonic, align 8, !dbg [[DBG66]]
// AARCH64-NEXT:    [[TMP94]] = extractvalue { i64, i1 } [[TMP93]], 0, !dbg [[DBG66]]
// AARCH64-NEXT:    [[TMP95:%.*]] = extractvalue { i64, i1 } [[TMP93]], 1, !dbg [[DBG66]]
// AARCH64-NEXT:    br i1 [[TMP95]], label [[ATOMIC_EXIT69:%.*]], label [[ATOMIC_CONT67]], !dbg [[DBG66]]
// AARCH64:       atomic_exit69:
// AARCH64-NEXT:    [[TMP96:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG68:![0-9]+]]
// AARCH64-NEXT:    [[TMP97:%.*]] = atomicrmw or ptr @uix, i32 [[TMP96]] seq_cst, align 4, !dbg [[DBG69:![0-9]+]]
// AARCH64-NEXT:    fence release
// AARCH64-NEXT:    [[TMP98:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG70:![0-9]+]]
// AARCH64-NEXT:    [[TMP99:%.*]] = atomicrmw and ptr @ix, i32 [[TMP98]] monotonic, align 4, !dbg [[DBG71:![0-9]+]]
// AARCH64-NEXT:    [[TMP100:%.*]] = load i64, ptr @lv, align 8, !dbg [[DBG72:![0-9]+]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP70]], i32 noundef 0), !dbg [[DBG73:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT71:%.*]], !dbg [[DBG73]]
// AARCH64:       atomic_cont71:
// AARCH64-NEXT:    [[ATOMIC_TEMP70_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP70]], i32 0, i32 0, !dbg [[DBG73]]
// AARCH64-NEXT:    [[ATOMIC_TEMP70_REAL:%.*]] = load i32, ptr [[ATOMIC_TEMP70_REALP]], align 4, !dbg [[DBG73]]
// AARCH64-NEXT:    [[ATOMIC_TEMP70_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP70]], i32 0, i32 1, !dbg [[DBG73]]
// AARCH64-NEXT:    [[ATOMIC_TEMP70_IMAG:%.*]] = load i32, ptr [[ATOMIC_TEMP70_IMAGP]], align 4, !dbg [[DBG73]]
// AARCH64-NEXT:    [[CONV73:%.*]] = sext i32 [[ATOMIC_TEMP70_REAL]] to i64, !dbg [[DBG73]]
// AARCH64-NEXT:    [[CONV74:%.*]] = sext i32 [[ATOMIC_TEMP70_IMAG]] to i64, !dbg [[DBG73]]
// AARCH64-NEXT:    [[ADD_R75:%.*]] = add i64 [[TMP100]], [[CONV73]], !dbg [[DBG74:![0-9]+]]
// AARCH64-NEXT:    [[ADD_I76:%.*]] = add i64 0, [[CONV74]], !dbg [[DBG74]]
// AARCH64-NEXT:    [[CONV77:%.*]] = trunc i64 [[ADD_R75]] to i32, !dbg [[DBG72]]
// AARCH64-NEXT:    [[CONV78:%.*]] = trunc i64 [[ADD_I76]] to i32, !dbg [[DBG72]]
// AARCH64-NEXT:    [[ATOMIC_TEMP72_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP72]], i32 0, i32 0, !dbg [[DBG73]]
// AARCH64-NEXT:    [[ATOMIC_TEMP72_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP72]], i32 0, i32 1, !dbg [[DBG73]]
// AARCH64-NEXT:    store i32 [[CONV77]], ptr [[ATOMIC_TEMP72_REALP]], align 4, !dbg [[DBG73]]
// AARCH64-NEXT:    store i32 [[CONV78]], ptr [[ATOMIC_TEMP72_IMAGP]], align 4, !dbg [[DBG73]]
// AARCH64-NEXT:    [[CALL79:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP70]], ptr noundef [[ATOMIC_TEMP72]], i32 noundef 0, i32 noundef 0), !dbg [[DBG73]]
// AARCH64-NEXT:    br i1 [[CALL79]], label [[ATOMIC_EXIT80:%.*]], label [[ATOMIC_CONT71]], !dbg [[DBG73]]
// AARCH64:       atomic_exit80:
// AARCH64-NEXT:    [[TMP101:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG75:![0-9]+]]
// AARCH64-NEXT:    [[CONV81:%.*]] = uitofp i64 [[TMP101]] to float, !dbg [[DBG75]]
// AARCH64-NEXT:    [[ATOMIC_LOAD82:%.*]] = load atomic i32, ptr @fx monotonic, align 4, !dbg [[DBG76:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT83:%.*]], !dbg [[DBG76]]
// AARCH64:       atomic_cont83:
// AARCH64-NEXT:    [[TMP102:%.*]] = phi i32 [ [[ATOMIC_LOAD82]], [[ATOMIC_EXIT80]] ], [ [[TMP106:%.*]], [[ATOMIC_CONT83]] ], !dbg [[DBG76]]
// AARCH64-NEXT:    [[TMP103:%.*]] = bitcast i32 [[TMP102]] to float, !dbg [[DBG76]]
// AARCH64-NEXT:    [[MUL85:%.*]] = fmul float [[TMP103]], [[CONV81]], !dbg [[DBG77:![0-9]+]]
// AARCH64-NEXT:    store float [[MUL85]], ptr [[ATOMIC_TEMP84]], align 4, !dbg [[DBG76]]
// AARCH64-NEXT:    [[TMP104:%.*]] = load i32, ptr [[ATOMIC_TEMP84]], align 4, !dbg [[DBG76]]
// AARCH64-NEXT:    [[TMP105:%.*]] = cmpxchg ptr @fx, i32 [[TMP102]], i32 [[TMP104]] monotonic monotonic, align 4, !dbg [[DBG76]]
// AARCH64-NEXT:    [[TMP106]] = extractvalue { i32, i1 } [[TMP105]], 0, !dbg [[DBG76]]
// AARCH64-NEXT:    [[TMP107:%.*]] = extractvalue { i32, i1 } [[TMP105]], 1, !dbg [[DBG76]]
// AARCH64-NEXT:    br i1 [[TMP107]], label [[ATOMIC_EXIT86:%.*]], label [[ATOMIC_CONT83]], !dbg [[DBG76]]
// AARCH64:       atomic_exit86:
// AARCH64-NEXT:    [[TMP108:%.*]] = load i64, ptr @llv, align 8, !dbg [[DBG78:![0-9]+]]
// AARCH64-NEXT:    [[CONV87:%.*]] = sitofp i64 [[TMP108]] to double, !dbg [[DBG78]]
// AARCH64-NEXT:    [[ATOMIC_LOAD88:%.*]] = load atomic i64, ptr @dx monotonic, align 8, !dbg [[DBG79:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT89:%.*]], !dbg [[DBG79]]
// AARCH64:       atomic_cont89:
// AARCH64-NEXT:    [[TMP109:%.*]] = phi i64 [ [[ATOMIC_LOAD88]], [[ATOMIC_EXIT86]] ], [ [[TMP113:%.*]], [[ATOMIC_CONT89]] ], !dbg [[DBG79]]
// AARCH64-NEXT:    [[TMP110:%.*]] = bitcast i64 [[TMP109]] to double, !dbg [[DBG79]]
// AARCH64-NEXT:    [[DIV91:%.*]] = fdiv double [[TMP110]], [[CONV87]], !dbg [[DBG80:![0-9]+]]
// AARCH64-NEXT:    store double [[DIV91]], ptr [[ATOMIC_TEMP90]], align 8, !dbg [[DBG79]]
// AARCH64-NEXT:    [[TMP111:%.*]] = load i64, ptr [[ATOMIC_TEMP90]], align 8, !dbg [[DBG79]]
// AARCH64-NEXT:    [[TMP112:%.*]] = cmpxchg ptr @dx, i64 [[TMP109]], i64 [[TMP111]] monotonic monotonic, align 8, !dbg [[DBG79]]
// AARCH64-NEXT:    [[TMP113]] = extractvalue { i64, i1 } [[TMP112]], 0, !dbg [[DBG79]]
// AARCH64-NEXT:    [[TMP114:%.*]] = extractvalue { i64, i1 } [[TMP112]], 1, !dbg [[DBG79]]
// AARCH64-NEXT:    br i1 [[TMP114]], label [[ATOMIC_EXIT92:%.*]], label [[ATOMIC_CONT89]], !dbg [[DBG79]]
// AARCH64:       atomic_exit92:
// AARCH64-NEXT:    [[TMP115:%.*]] = load i64, ptr @ullv, align 8, !dbg [[DBG81:![0-9]+]]
// AARCH64-NEXT:    [[CONV93:%.*]] = uitofp i64 [[TMP115]] to fp128, !dbg [[DBG81]]
// AARCH64-NEXT:    [[TMP116:%.*]] = atomicrmw fsub ptr @ldx, fp128 [[CONV93]] monotonic, align 16, !dbg [[DBG82:![0-9]+]]
// AARCH64-NEXT:    [[TMP117:%.*]] = load float, ptr @fv, align 4, !dbg [[DBG83:![0-9]+]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP94]], i32 noundef 0), !dbg [[DBG84:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT95:%.*]], !dbg [[DBG84]]
// AARCH64:       atomic_cont95:
// AARCH64-NEXT:    [[ATOMIC_TEMP94_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP94]], i32 0, i32 0, !dbg [[DBG84]]
// AARCH64-NEXT:    [[ATOMIC_TEMP94_REAL:%.*]] = load i32, ptr [[ATOMIC_TEMP94_REALP]], align 4, !dbg [[DBG84]]
// AARCH64-NEXT:    [[ATOMIC_TEMP94_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP94]], i32 0, i32 1, !dbg [[DBG84]]
// AARCH64-NEXT:    [[ATOMIC_TEMP94_IMAG:%.*]] = load i32, ptr [[ATOMIC_TEMP94_IMAGP]], align 4, !dbg [[DBG84]]
// AARCH64-NEXT:    [[CONV97:%.*]] = sitofp i32 [[ATOMIC_TEMP94_REAL]] to float, !dbg [[DBG84]]
// AARCH64-NEXT:    [[CONV98:%.*]] = sitofp i32 [[ATOMIC_TEMP94_IMAG]] to float, !dbg [[DBG84]]
// AARCH64-NEXT:    [[CALL99:%.*]] = call { float, float } @__divsc3(float noundef [[TMP117]], float noundef 0.000000e+00, float noundef [[CONV97]], float noundef [[CONV98]]) #[[ATTR2:[0-9]+]], !dbg [[DBG85:![0-9]+]]
// AARCH64-NEXT:    [[TMP118:%.*]] = extractvalue { float, float } [[CALL99]], 0, !dbg [[DBG85]]
// AARCH64-NEXT:    [[TMP119:%.*]] = extractvalue { float, float } [[CALL99]], 1, !dbg [[DBG85]]
// AARCH64-NEXT:    [[CONV100:%.*]] = fptosi float [[TMP118]] to i32, !dbg [[DBG83]]
// AARCH64-NEXT:    [[CONV101:%.*]] = fptosi float [[TMP119]] to i32, !dbg [[DBG83]]
// AARCH64-NEXT:    [[ATOMIC_TEMP96_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP96]], i32 0, i32 0, !dbg [[DBG84]]
// AARCH64-NEXT:    [[ATOMIC_TEMP96_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP96]], i32 0, i32 1, !dbg [[DBG84]]
// AARCH64-NEXT:    store i32 [[CONV100]], ptr [[ATOMIC_TEMP96_REALP]], align 4, !dbg [[DBG84]]
// AARCH64-NEXT:    store i32 [[CONV101]], ptr [[ATOMIC_TEMP96_IMAGP]], align 4, !dbg [[DBG84]]
// AARCH64-NEXT:    [[CALL102:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP94]], ptr noundef [[ATOMIC_TEMP96]], i32 noundef 0, i32 noundef 0), !dbg [[DBG84]]
// AARCH64-NEXT:    br i1 [[CALL102]], label [[ATOMIC_EXIT103:%.*]], label [[ATOMIC_CONT95]], !dbg [[DBG84]]
// AARCH64:       atomic_exit103:
// AARCH64-NEXT:    [[TMP120:%.*]] = load double, ptr @dv, align 8, !dbg [[DBG86:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD104:%.*]] = load atomic i16, ptr @sx monotonic, align 2, !dbg [[DBG87:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT105:%.*]], !dbg [[DBG87]]
// AARCH64:       atomic_cont105:
// AARCH64-NEXT:    [[TMP121:%.*]] = phi i16 [ [[ATOMIC_LOAD104]], [[ATOMIC_EXIT103]] ], [ [[TMP124:%.*]], [[ATOMIC_CONT105]] ], !dbg [[DBG87]]
// AARCH64-NEXT:    [[CONV107:%.*]] = sext i16 [[TMP121]] to i32, !dbg [[DBG87]]
// AARCH64-NEXT:    [[CONV108:%.*]] = sitofp i32 [[CONV107]] to double, !dbg [[DBG87]]
// AARCH64-NEXT:    [[ADD109:%.*]] = fadd double [[CONV108]], [[TMP120]], !dbg [[DBG88:![0-9]+]]
// AARCH64-NEXT:    [[CONV110:%.*]] = fptosi double [[ADD109]] to i16, !dbg [[DBG87]]
// AARCH64-NEXT:    store i16 [[CONV110]], ptr [[ATOMIC_TEMP106]], align 2, !dbg [[DBG87]]
// AARCH64-NEXT:    [[TMP122:%.*]] = load i16, ptr [[ATOMIC_TEMP106]], align 2, !dbg [[DBG87]]
// AARCH64-NEXT:    [[TMP123:%.*]] = cmpxchg ptr @sx, i16 [[TMP121]], i16 [[TMP122]] monotonic monotonic, align 2, !dbg [[DBG87]]
// AARCH64-NEXT:    [[TMP124]] = extractvalue { i16, i1 } [[TMP123]], 0, !dbg [[DBG87]]
// AARCH64-NEXT:    [[TMP125:%.*]] = extractvalue { i16, i1 } [[TMP123]], 1, !dbg [[DBG87]]
// AARCH64-NEXT:    br i1 [[TMP125]], label [[ATOMIC_EXIT111:%.*]], label [[ATOMIC_CONT105]], !dbg [[DBG87]]
// AARCH64:       atomic_exit111:
// AARCH64-NEXT:    [[TMP126:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG89:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD112:%.*]] = load atomic i8, ptr @bx monotonic, align 1, !dbg [[DBG90:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT113:%.*]], !dbg [[DBG90]]
// AARCH64:       atomic_cont113:
// AARCH64-NEXT:    [[TMP127:%.*]] = phi i8 [ [[ATOMIC_LOAD112]], [[ATOMIC_EXIT111]] ], [ [[TMP130:%.*]], [[ATOMIC_CONT113]] ], !dbg [[DBG90]]
// AARCH64-NEXT:    [[LOADEDV115:%.*]] = trunc i8 [[TMP127]] to i1, !dbg [[DBG90]]
// AARCH64-NEXT:    [[CONV116:%.*]] = zext i1 [[LOADEDV115]] to i32, !dbg [[DBG90]]
// AARCH64-NEXT:    [[CONV117:%.*]] = sitofp i32 [[CONV116]] to fp128, !dbg [[DBG90]]
// AARCH64-NEXT:    [[MUL118:%.*]] = fmul fp128 [[TMP126]], [[CONV117]], !dbg [[DBG91:![0-9]+]]
// AARCH64-NEXT:    [[TOBOOL119:%.*]] = fcmp une fp128 [[MUL118]], 0xL00000000000000000000000000000000, !dbg [[DBG89]]
// AARCH64-NEXT:    [[STOREDV120:%.*]] = zext i1 [[TOBOOL119]] to i8, !dbg [[DBG90]]
// AARCH64-NEXT:    store i8 [[STOREDV120]], ptr [[ATOMIC_TEMP114]], align 1, !dbg [[DBG90]]
// AARCH64-NEXT:    [[TMP128:%.*]] = load i8, ptr [[ATOMIC_TEMP114]], align 1, !dbg [[DBG90]]
// AARCH64-NEXT:    [[TMP129:%.*]] = cmpxchg ptr @bx, i8 [[TMP127]], i8 [[TMP128]] release monotonic, align 1, !dbg [[DBG90]]
// AARCH64-NEXT:    [[TMP130]] = extractvalue { i8, i1 } [[TMP129]], 0, !dbg [[DBG90]]
// AARCH64-NEXT:    [[TMP131:%.*]] = extractvalue { i8, i1 } [[TMP129]], 1, !dbg [[DBG90]]
// AARCH64-NEXT:    br i1 [[TMP131]], label [[ATOMIC_EXIT121:%.*]], label [[ATOMIC_CONT113]], !dbg [[DBG90]]
// AARCH64:       atomic_exit121:
// AARCH64-NEXT:    fence release
// AARCH64-NEXT:    [[CIV_REAL122:%.*]] = load i32, ptr @civ, align 4, !dbg [[DBG92:![0-9]+]]
// AARCH64-NEXT:    [[CIV_IMAG123:%.*]] = load i32, ptr getelementptr inbounds nuw ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG92]]
// AARCH64-NEXT:    [[ATOMIC_LOAD124:%.*]] = load atomic i8, ptr @bx monotonic, align 1, !dbg [[DBG93:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT125:%.*]], !dbg [[DBG93]]
// AARCH64:       atomic_cont125:
// AARCH64-NEXT:    [[TMP132:%.*]] = phi i8 [ [[ATOMIC_LOAD124]], [[ATOMIC_EXIT121]] ], [ [[TMP135:%.*]], [[ATOMIC_CONT125]] ], !dbg [[DBG93]]
// AARCH64-NEXT:    [[LOADEDV127:%.*]] = trunc i8 [[TMP132]] to i1, !dbg [[DBG93]]
// AARCH64-NEXT:    [[CONV128:%.*]] = zext i1 [[LOADEDV127]] to i32, !dbg [[DBG93]]
// AARCH64-NEXT:    [[SUB_R129:%.*]] = sub i32 [[CIV_REAL122]], [[CONV128]], !dbg [[DBG94:![0-9]+]]
// AARCH64-NEXT:    [[SUB_I130:%.*]] = sub i32 [[CIV_IMAG123]], 0, !dbg [[DBG94]]
// AARCH64-NEXT:    [[TOBOOL131:%.*]] = icmp ne i32 [[SUB_R129]], 0, !dbg [[DBG92]]
// AARCH64-NEXT:    [[TOBOOL132:%.*]] = icmp ne i32 [[SUB_I130]], 0, !dbg [[DBG92]]
// AARCH64-NEXT:    [[TOBOOL133:%.*]] = or i1 [[TOBOOL131]], [[TOBOOL132]], !dbg [[DBG92]]
// AARCH64-NEXT:    [[STOREDV134:%.*]] = zext i1 [[TOBOOL133]] to i8, !dbg [[DBG93]]
// AARCH64-NEXT:    store i8 [[STOREDV134]], ptr [[ATOMIC_TEMP126]], align 1, !dbg [[DBG93]]
// AARCH64-NEXT:    [[TMP133:%.*]] = load i8, ptr [[ATOMIC_TEMP126]], align 1, !dbg [[DBG93]]
// AARCH64-NEXT:    [[TMP134:%.*]] = cmpxchg ptr @bx, i8 [[TMP132]], i8 [[TMP133]] monotonic monotonic, align 1, !dbg [[DBG93]]
// AARCH64-NEXT:    [[TMP135]] = extractvalue { i8, i1 } [[TMP134]], 0, !dbg [[DBG93]]
// AARCH64-NEXT:    [[TMP136:%.*]] = extractvalue { i8, i1 } [[TMP134]], 1, !dbg [[DBG93]]
// AARCH64-NEXT:    br i1 [[TMP136]], label [[ATOMIC_EXIT135:%.*]], label [[ATOMIC_CONT125]], !dbg [[DBG93]]
// AARCH64:       atomic_exit135:
// AARCH64-NEXT:    [[TMP137:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG95:![0-9]+]]
// AARCH64-NEXT:    [[TMP138:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG96:![0-9]+]]
// AARCH64-NEXT:    [[LOADEDV136:%.*]] = trunc i8 [[TMP138]] to i1, !dbg [[DBG96]]
// AARCH64-NEXT:    [[CONV137:%.*]] = zext i1 [[LOADEDV136]] to i32, !dbg [[DBG96]]
// AARCH64-NEXT:    [[ATOMIC_LOAD138:%.*]] = load atomic i128, ptr @int4x monotonic, align 16, !dbg [[DBG97:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT139:%.*]], !dbg [[DBG97]]
// AARCH64:       atomic_cont139:
// AARCH64-NEXT:    [[TMP139:%.*]] = phi i128 [ [[ATOMIC_LOAD138]], [[ATOMIC_EXIT135]] ], [ [[TMP145:%.*]], [[ATOMIC_CONT139]] ], !dbg [[DBG97]]
// AARCH64-NEXT:    store i128 [[TMP139]], ptr [[ATOMIC_TEMP140]], align 16, !dbg [[DBG97]]
// AARCH64-NEXT:    [[TMP140:%.*]] = bitcast i128 [[TMP139]] to <4 x i32>, !dbg [[DBG97]]
// AARCH64-NEXT:    store <4 x i32> [[TMP140]], ptr [[ATOMIC_TEMP141]], align 16, !dbg [[DBG97]]
// AARCH64-NEXT:    [[TMP141:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP141]], align 16, !dbg [[DBG97]]
// AARCH64-NEXT:    [[VECEXT:%.*]] = extractelement <4 x i32> [[TMP141]], i16 [[TMP137]], !dbg [[DBG97]]
// AARCH64-NEXT:    [[OR:%.*]] = or i32 [[VECEXT]], [[CONV137]], !dbg [[DBG98:![0-9]+]]
// AARCH64-NEXT:    [[TMP142:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP140]], align 16, !dbg [[DBG97]]
// AARCH64-NEXT:    [[VECINS:%.*]] = insertelement <4 x i32> [[TMP142]], i32 [[OR]], i16 [[TMP137]], !dbg [[DBG97]]
// AARCH64-NEXT:    store <4 x i32> [[VECINS]], ptr [[ATOMIC_TEMP140]], align 16, !dbg [[DBG97]]
// AARCH64-NEXT:    [[TMP143:%.*]] = load i128, ptr [[ATOMIC_TEMP140]], align 16, !dbg [[DBG97]]
// AARCH64-NEXT:    [[TMP144:%.*]] = cmpxchg ptr @int4x, i128 [[TMP139]], i128 [[TMP143]] monotonic monotonic, align 16, !dbg [[DBG97]]
// AARCH64-NEXT:    [[TMP145]] = extractvalue { i128, i1 } [[TMP144]], 0, !dbg [[DBG97]]
// AARCH64-NEXT:    [[TMP146:%.*]] = extractvalue { i128, i1 } [[TMP144]], 1, !dbg [[DBG97]]
// AARCH64-NEXT:    br i1 [[TMP146]], label [[ATOMIC_EXIT142:%.*]], label [[ATOMIC_CONT139]], !dbg [[DBG97]]
// AARCH64:       atomic_exit142:
// AARCH64-NEXT:    [[TMP147:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG99:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD143:%.*]] = load atomic i32, ptr getelementptr (i8, ptr @bfx, i64 4) monotonic, align 4, !dbg [[DBG100:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT144:%.*]], !dbg [[DBG100]]
// AARCH64:       atomic_cont144:
// AARCH64-NEXT:    [[TMP148:%.*]] = phi i32 [ [[ATOMIC_LOAD143]], [[ATOMIC_EXIT142]] ], [ [[TMP151:%.*]], [[ATOMIC_CONT144]] ], !dbg [[DBG100]]
// AARCH64-NEXT:    store i32 [[TMP148]], ptr [[ATOMIC_TEMP145]], align 4, !dbg [[DBG100]]
// AARCH64-NEXT:    store i32 [[TMP148]], ptr [[ATOMIC_TEMP146]], align 4, !dbg [[DBG100]]
// AARCH64-NEXT:    [[BF_LOAD:%.*]] = load i32, ptr [[ATOMIC_TEMP146]], align 4, !dbg [[DBG100]]
// AARCH64-NEXT:    [[BF_SHL:%.*]] = shl i32 [[BF_LOAD]], 1, !dbg [[DBG100]]
// AARCH64-NEXT:    [[BF_ASHR:%.*]] = ashr i32 [[BF_SHL]], 1, !dbg [[DBG100]]
// AARCH64-NEXT:    [[CONV147:%.*]] = sitofp i32 [[BF_ASHR]] to fp128, !dbg [[DBG101:![0-9]+]]
// AARCH64-NEXT:    [[SUB148:%.*]] = fsub fp128 [[CONV147]], [[TMP147]], !dbg [[DBG102:![0-9]+]]
// AARCH64-NEXT:    [[CONV149:%.*]] = fptosi fp128 [[SUB148]] to i32, !dbg [[DBG101]]
// AARCH64-NEXT:    [[BF_LOAD150:%.*]] = load i32, ptr [[ATOMIC_TEMP145]], align 4, !dbg [[DBG100]]
// AARCH64-NEXT:    [[BF_VALUE:%.*]] = and i32 [[CONV149]], 2147483647, !dbg [[DBG100]]
// AARCH64-NEXT:    [[BF_CLEAR:%.*]] = and i32 [[BF_LOAD150]], -2147483648, !dbg [[DBG100]]
// AARCH64-NEXT:    [[BF_SET:%.*]] = or i32 [[BF_CLEAR]], [[BF_VALUE]], !dbg [[DBG100]]
// AARCH64-NEXT:    store i32 [[BF_SET]], ptr [[ATOMIC_TEMP145]], align 4, !dbg [[DBG100]]
// AARCH64-NEXT:    [[TMP149:%.*]] = load i32, ptr [[ATOMIC_TEMP145]], align 4, !dbg [[DBG100]]
// AARCH64-NEXT:    [[TMP150:%.*]] = cmpxchg ptr getelementptr (i8, ptr @bfx, i64 4), i32 [[TMP148]], i32 [[TMP149]] monotonic monotonic, align 4, !dbg [[DBG100]]
// AARCH64-NEXT:    [[TMP151]] = extractvalue { i32, i1 } [[TMP150]], 0, !dbg [[DBG100]]
// AARCH64-NEXT:    [[TMP152:%.*]] = extractvalue { i32, i1 } [[TMP150]], 1, !dbg [[DBG100]]
// AARCH64-NEXT:    br i1 [[TMP152]], label [[ATOMIC_EXIT151:%.*]], label [[ATOMIC_CONT144]], !dbg [[DBG100]]
// AARCH64:       atomic_exit151:
// AARCH64-NEXT:    [[TMP153:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG103:![0-9]+]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 4, ptr noundef getelementptr (i8, ptr @bfx_packed, i64 4), ptr noundef [[ATOMIC_TEMP152]], i32 noundef 0), !dbg [[DBG104:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT153:%.*]], !dbg [[DBG104]]
// AARCH64:       atomic_cont153:
// AARCH64-NEXT:    [[TMP154:%.*]] = load i32, ptr [[ATOMIC_TEMP152]], align 1, !dbg [[DBG104]]
// AARCH64-NEXT:    store i32 [[TMP154]], ptr [[ATOMIC_TEMP154]], align 1, !dbg [[DBG104]]
// AARCH64-NEXT:    [[TMP155:%.*]] = load i32, ptr [[ATOMIC_TEMP152]], align 1, !dbg [[DBG104]]
// AARCH64-NEXT:    store i32 [[TMP155]], ptr [[ATOMIC_TEMP155]], align 4, !dbg [[DBG104]]
// AARCH64-NEXT:    [[BF_LOAD156:%.*]] = load i32, ptr [[ATOMIC_TEMP155]], align 1, !dbg [[DBG104]]
// AARCH64-NEXT:    [[BF_SHL157:%.*]] = shl i32 [[BF_LOAD156]], 1, !dbg [[DBG104]]
// AARCH64-NEXT:    [[BF_ASHR158:%.*]] = ashr i32 [[BF_SHL157]], 1, !dbg [[DBG104]]
// AARCH64-NEXT:    [[CONV159:%.*]] = sitofp i32 [[BF_ASHR158]] to fp128, !dbg [[DBG105:![0-9]+]]
// AARCH64-NEXT:    [[MUL160:%.*]] = fmul fp128 [[CONV159]], [[TMP153]], !dbg [[DBG106:![0-9]+]]
// AARCH64-NEXT:    [[CONV161:%.*]] = fptosi fp128 [[MUL160]] to i32, !dbg [[DBG105]]
// AARCH64-NEXT:    [[BF_LOAD162:%.*]] = load i32, ptr [[ATOMIC_TEMP154]], align 1, !dbg [[DBG104]]
// AARCH64-NEXT:    [[BF_VALUE163:%.*]] = and i32 [[CONV161]], 2147483647, !dbg [[DBG104]]
// AARCH64-NEXT:    [[BF_CLEAR164:%.*]] = and i32 [[BF_LOAD162]], -2147483648, !dbg [[DBG104]]
// AARCH64-NEXT:    [[BF_SET165:%.*]] = or i32 [[BF_CLEAR164]], [[BF_VALUE163]], !dbg [[DBG104]]
// AARCH64-NEXT:    store i32 [[BF_SET165]], ptr [[ATOMIC_TEMP154]], align 1, !dbg [[DBG104]]
// AARCH64-NEXT:    [[CALL166:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 4, ptr noundef getelementptr (i8, ptr @bfx_packed, i64 4), ptr noundef [[ATOMIC_TEMP152]], ptr noundef [[ATOMIC_TEMP154]], i32 noundef 0, i32 noundef 0), !dbg [[DBG104]]
// AARCH64-NEXT:    br i1 [[CALL166]], label [[ATOMIC_EXIT167:%.*]], label [[ATOMIC_CONT153]], !dbg [[DBG104]]
// AARCH64:       atomic_exit167:
// AARCH64-NEXT:    [[TMP156:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG107:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD168:%.*]] = load atomic i32, ptr @bfx2 monotonic, align 4, !dbg [[DBG108:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT169:%.*]], !dbg [[DBG108]]
// AARCH64:       atomic_cont169:
// AARCH64-NEXT:    [[TMP157:%.*]] = phi i32 [ [[ATOMIC_LOAD168]], [[ATOMIC_EXIT167]] ], [ [[TMP160:%.*]], [[ATOMIC_CONT169]] ], !dbg [[DBG108]]
// AARCH64-NEXT:    store i32 [[TMP157]], ptr [[ATOMIC_TEMP170]], align 4, !dbg [[DBG108]]
// AARCH64-NEXT:    store i32 [[TMP157]], ptr [[ATOMIC_TEMP171]], align 4, !dbg [[DBG108]]
// AARCH64-NEXT:    [[BF_LOAD172:%.*]] = load i32, ptr [[ATOMIC_TEMP171]], align 4, !dbg [[DBG108]]
// AARCH64-NEXT:    [[BF_ASHR173:%.*]] = ashr i32 [[BF_LOAD172]], 31, !dbg [[DBG108]]
// AARCH64-NEXT:    [[CONV174:%.*]] = sitofp i32 [[BF_ASHR173]] to fp128, !dbg [[DBG109:![0-9]+]]
// AARCH64-NEXT:    [[SUB175:%.*]] = fsub fp128 [[CONV174]], [[TMP156]], !dbg [[DBG110:![0-9]+]]
// AARCH64-NEXT:    [[CONV176:%.*]] = fptosi fp128 [[SUB175]] to i32, !dbg [[DBG109]]
// AARCH64-NEXT:    [[BF_LOAD177:%.*]] = load i32, ptr [[ATOMIC_TEMP170]], align 4, !dbg [[DBG108]]
// AARCH64-NEXT:    [[BF_VALUE178:%.*]] = and i32 [[CONV176]], 1, !dbg [[DBG108]]
// AARCH64-NEXT:    [[BF_SHL179:%.*]] = shl i32 [[BF_VALUE178]], 31, !dbg [[DBG108]]
// AARCH64-NEXT:    [[BF_CLEAR180:%.*]] = and i32 [[BF_LOAD177]], 2147483647, !dbg [[DBG108]]
// AARCH64-NEXT:    [[BF_SET181:%.*]] = or i32 [[BF_CLEAR180]], [[BF_SHL179]], !dbg [[DBG108]]
// AARCH64-NEXT:    store i32 [[BF_SET181]], ptr [[ATOMIC_TEMP170]], align 4, !dbg [[DBG108]]
// AARCH64-NEXT:    [[TMP158:%.*]] = load i32, ptr [[ATOMIC_TEMP170]], align 4, !dbg [[DBG108]]
// AARCH64-NEXT:    [[TMP159:%.*]] = cmpxchg ptr @bfx2, i32 [[TMP157]], i32 [[TMP158]] monotonic monotonic, align 4, !dbg [[DBG108]]
// AARCH64-NEXT:    [[TMP160]] = extractvalue { i32, i1 } [[TMP159]], 0, !dbg [[DBG108]]
// AARCH64-NEXT:    [[TMP161:%.*]] = extractvalue { i32, i1 } [[TMP159]], 1, !dbg [[DBG108]]
// AARCH64-NEXT:    br i1 [[TMP161]], label [[ATOMIC_EXIT182:%.*]], label [[ATOMIC_CONT169]], !dbg [[DBG108]]
// AARCH64:       atomic_exit182:
// AARCH64-NEXT:    [[TMP162:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG111:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD183:%.*]] = load atomic i8, ptr getelementptr (i8, ptr @bfx2_packed, i64 3) monotonic, align 1, !dbg [[DBG112:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT184:%.*]], !dbg [[DBG112]]
// AARCH64:       atomic_cont184:
// AARCH64-NEXT:    [[TMP163:%.*]] = phi i8 [ [[ATOMIC_LOAD183]], [[ATOMIC_EXIT182]] ], [ [[TMP167:%.*]], [[ATOMIC_CONT184]] ], !dbg [[DBG112]]
// AARCH64-NEXT:    store i8 [[TMP163]], ptr [[ATOMIC_TEMP185]], align 1, !dbg [[DBG112]]
// AARCH64-NEXT:    store i8 [[TMP163]], ptr [[ATOMIC_TEMP186]], align 1, !dbg [[DBG112]]
// AARCH64-NEXT:    [[BF_LOAD187:%.*]] = load i8, ptr [[ATOMIC_TEMP186]], align 1, !dbg [[DBG112]]
// AARCH64-NEXT:    [[BF_ASHR188:%.*]] = ashr i8 [[BF_LOAD187]], 7, !dbg [[DBG112]]
// AARCH64-NEXT:    [[BF_CAST:%.*]] = sext i8 [[BF_ASHR188]] to i32, !dbg [[DBG112]]
// AARCH64-NEXT:    [[CONV189:%.*]] = sitofp i32 [[BF_CAST]] to fp128, !dbg [[DBG113:![0-9]+]]
// AARCH64-NEXT:    [[DIV190:%.*]] = fdiv fp128 [[TMP162]], [[CONV189]], !dbg [[DBG114:![0-9]+]]
// AARCH64-NEXT:    [[CONV191:%.*]] = fptosi fp128 [[DIV190]] to i32, !dbg [[DBG111]]
// AARCH64-NEXT:    [[TMP164:%.*]] = trunc i32 [[CONV191]] to i8, !dbg [[DBG112]]
// AARCH64-NEXT:    [[BF_LOAD192:%.*]] = load i8, ptr [[ATOMIC_TEMP185]], align 1, !dbg [[DBG112]]
// AARCH64-NEXT:    [[BF_VALUE193:%.*]] = and i8 [[TMP164]], 1, !dbg [[DBG112]]
// AARCH64-NEXT:    [[BF_SHL194:%.*]] = shl i8 [[BF_VALUE193]], 7, !dbg [[DBG112]]
// AARCH64-NEXT:    [[BF_CLEAR195:%.*]] = and i8 [[BF_LOAD192]], 127, !dbg [[DBG112]]
// AARCH64-NEXT:    [[BF_SET196:%.*]] = or i8 [[BF_CLEAR195]], [[BF_SHL194]], !dbg [[DBG112]]
// AARCH64-NEXT:    store i8 [[BF_SET196]], ptr [[ATOMIC_TEMP185]], align 1, !dbg [[DBG112]]
// AARCH64-NEXT:    [[TMP165:%.*]] = load i8, ptr [[ATOMIC_TEMP185]], align 1, !dbg [[DBG112]]
// AARCH64-NEXT:    [[TMP166:%.*]] = cmpxchg ptr getelementptr (i8, ptr @bfx2_packed, i64 3), i8 [[TMP163]], i8 [[TMP165]] monotonic monotonic, align 1, !dbg [[DBG112]]
// AARCH64-NEXT:    [[TMP167]] = extractvalue { i8, i1 } [[TMP166]], 0, !dbg [[DBG112]]
// AARCH64-NEXT:    [[TMP168:%.*]] = extractvalue { i8, i1 } [[TMP166]], 1, !dbg [[DBG112]]
// AARCH64-NEXT:    br i1 [[TMP168]], label [[ATOMIC_EXIT197:%.*]], label [[ATOMIC_CONT184]], !dbg [[DBG112]]
// AARCH64:       atomic_exit197:
// AARCH64-NEXT:    [[TMP169:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG115:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD198:%.*]] = load atomic i32, ptr @bfx3 monotonic, align 4, !dbg [[DBG116:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT199:%.*]], !dbg [[DBG116]]
// AARCH64:       atomic_cont199:
// AARCH64-NEXT:    [[TMP170:%.*]] = phi i32 [ [[ATOMIC_LOAD198]], [[ATOMIC_EXIT197]] ], [ [[TMP173:%.*]], [[ATOMIC_CONT199]] ], !dbg [[DBG116]]
// AARCH64-NEXT:    store i32 [[TMP170]], ptr [[ATOMIC_TEMP200]], align 4, !dbg [[DBG116]]
// AARCH64-NEXT:    store i32 [[TMP170]], ptr [[ATOMIC_TEMP201]], align 4, !dbg [[DBG116]]
// AARCH64-NEXT:    [[BF_LOAD202:%.*]] = load i32, ptr [[ATOMIC_TEMP201]], align 4, !dbg [[DBG116]]
// AARCH64-NEXT:    [[BF_SHL203:%.*]] = shl i32 [[BF_LOAD202]], 7, !dbg [[DBG116]]
// AARCH64-NEXT:    [[BF_ASHR204:%.*]] = ashr i32 [[BF_SHL203]], 18, !dbg [[DBG116]]
// AARCH64-NEXT:    [[CONV205:%.*]] = sitofp i32 [[BF_ASHR204]] to fp128, !dbg [[DBG117:![0-9]+]]
// AARCH64-NEXT:    [[DIV206:%.*]] = fdiv fp128 [[CONV205]], [[TMP169]], !dbg [[DBG118:![0-9]+]]
// AARCH64-NEXT:    [[CONV207:%.*]] = fptosi fp128 [[DIV206]] to i32, !dbg [[DBG117]]
// AARCH64-NEXT:    [[BF_LOAD208:%.*]] = load i32, ptr [[ATOMIC_TEMP200]], align 4, !dbg [[DBG116]]
// AARCH64-NEXT:    [[BF_VALUE209:%.*]] = and i32 [[CONV207]], 16383, !dbg [[DBG116]]
// AARCH64-NEXT:    [[BF_SHL210:%.*]] = shl i32 [[BF_VALUE209]], 11, !dbg [[DBG116]]
// AARCH64-NEXT:    [[BF_CLEAR211:%.*]] = and i32 [[BF_LOAD208]], -33552385, !dbg [[DBG116]]
// AARCH64-NEXT:    [[BF_SET212:%.*]] = or i32 [[BF_CLEAR211]], [[BF_SHL210]], !dbg [[DBG116]]
// AARCH64-NEXT:    store i32 [[BF_SET212]], ptr [[ATOMIC_TEMP200]], align 4, !dbg [[DBG116]]
// AARCH64-NEXT:    [[TMP171:%.*]] = load i32, ptr [[ATOMIC_TEMP200]], align 4, !dbg [[DBG116]]
// AARCH64-NEXT:    [[TMP172:%.*]] = cmpxchg ptr @bfx3, i32 [[TMP170]], i32 [[TMP171]] monotonic monotonic, align 4, !dbg [[DBG116]]
// AARCH64-NEXT:    [[TMP173]] = extractvalue { i32, i1 } [[TMP172]], 0, !dbg [[DBG116]]
// AARCH64-NEXT:    [[TMP174:%.*]] = extractvalue { i32, i1 } [[TMP172]], 1, !dbg [[DBG116]]
// AARCH64-NEXT:    br i1 [[TMP174]], label [[ATOMIC_EXIT213:%.*]], label [[ATOMIC_CONT199]], !dbg [[DBG116]]
// AARCH64:       atomic_exit213:
// AARCH64-NEXT:    [[TMP175:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG119:![0-9]+]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 3, ptr noundef getelementptr (i8, ptr @bfx3_packed, i64 1), ptr noundef [[ATOMIC_TEMP214]], i32 noundef 0), !dbg [[DBG120:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT215:%.*]], !dbg [[DBG120]]
// AARCH64:       atomic_cont215:
// AARCH64-NEXT:    [[TMP176:%.*]] = load i24, ptr [[ATOMIC_TEMP214]], align 1, !dbg [[DBG120]]
// AARCH64-NEXT:    store i24 [[TMP176]], ptr [[ATOMIC_TEMP216]], align 1, !dbg [[DBG120]]
// AARCH64-NEXT:    [[TMP177:%.*]] = load i24, ptr [[ATOMIC_TEMP214]], align 1, !dbg [[DBG120]]
// AARCH64-NEXT:    store i24 [[TMP177]], ptr [[ATOMIC_TEMP217]], align 1, !dbg [[DBG120]]
// AARCH64-NEXT:    [[BF_LOAD218:%.*]] = load i24, ptr [[ATOMIC_TEMP217]], align 1, !dbg [[DBG120]]
// AARCH64-NEXT:    [[BF_SHL219:%.*]] = shl i24 [[BF_LOAD218]], 7, !dbg [[DBG120]]
// AARCH64-NEXT:    [[BF_ASHR220:%.*]] = ashr i24 [[BF_SHL219]], 10, !dbg [[DBG120]]
// AARCH64-NEXT:    [[BF_CAST221:%.*]] = sext i24 [[BF_ASHR220]] to i32, !dbg [[DBG120]]
// AARCH64-NEXT:    [[CONV222:%.*]] = sitofp i32 [[BF_CAST221]] to fp128, !dbg [[DBG121:![0-9]+]]
// AARCH64-NEXT:    [[ADD223:%.*]] = fadd fp128 [[CONV222]], [[TMP175]], !dbg [[DBG122:![0-9]+]]
// AARCH64-NEXT:    [[CONV224:%.*]] = fptosi fp128 [[ADD223]] to i32, !dbg [[DBG121]]
// AARCH64-NEXT:    [[TMP178:%.*]] = trunc i32 [[CONV224]] to i24, !dbg [[DBG120]]
// AARCH64-NEXT:    [[BF_LOAD225:%.*]] = load i24, ptr [[ATOMIC_TEMP216]], align 1, !dbg [[DBG120]]
// AARCH64-NEXT:    [[BF_VALUE226:%.*]] = and i24 [[TMP178]], 16383, !dbg [[DBG120]]
// AARCH64-NEXT:    [[BF_SHL227:%.*]] = shl i24 [[BF_VALUE226]], 3, !dbg [[DBG120]]
// AARCH64-NEXT:    [[BF_CLEAR228:%.*]] = and i24 [[BF_LOAD225]], -131065, !dbg [[DBG120]]
// AARCH64-NEXT:    [[BF_SET229:%.*]] = or i24 [[BF_CLEAR228]], [[BF_SHL227]], !dbg [[DBG120]]
// AARCH64-NEXT:    store i24 [[BF_SET229]], ptr [[ATOMIC_TEMP216]], align 1, !dbg [[DBG120]]
// AARCH64-NEXT:    [[CALL230:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 3, ptr noundef getelementptr (i8, ptr @bfx3_packed, i64 1), ptr noundef [[ATOMIC_TEMP214]], ptr noundef [[ATOMIC_TEMP216]], i32 noundef 0, i32 noundef 0), !dbg [[DBG120]]
// AARCH64-NEXT:    br i1 [[CALL230]], label [[ATOMIC_EXIT231:%.*]], label [[ATOMIC_CONT215]], !dbg [[DBG120]]
// AARCH64:       atomic_exit231:
// AARCH64-NEXT:    [[TMP179:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG123:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD232:%.*]] = load atomic i64, ptr @bfx4 monotonic, align 8, !dbg [[DBG124:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT233:%.*]], !dbg [[DBG124]]
// AARCH64:       atomic_cont233:
// AARCH64-NEXT:    [[TMP180:%.*]] = phi i64 [ [[ATOMIC_LOAD232]], [[ATOMIC_EXIT231]] ], [ [[TMP184:%.*]], [[ATOMIC_CONT233]] ], !dbg [[DBG124]]
// AARCH64-NEXT:    store i64 [[TMP180]], ptr [[ATOMIC_TEMP234]], align 8, !dbg [[DBG124]]
// AARCH64-NEXT:    store i64 [[TMP180]], ptr [[ATOMIC_TEMP235]], align 8, !dbg [[DBG124]]
// AARCH64-NEXT:    [[BF_LOAD236:%.*]] = load i64, ptr [[ATOMIC_TEMP235]], align 8, !dbg [[DBG124]]
// AARCH64-NEXT:    [[BF_SHL237:%.*]] = shl i64 [[BF_LOAD236]], 47, !dbg [[DBG124]]
// AARCH64-NEXT:    [[BF_ASHR238:%.*]] = ashr i64 [[BF_SHL237]], 63, !dbg [[DBG124]]
// AARCH64-NEXT:    [[BF_CAST239:%.*]] = trunc i64 [[BF_ASHR238]] to i32, !dbg [[DBG124]]
// AARCH64-NEXT:    [[CONV240:%.*]] = sitofp i32 [[BF_CAST239]] to fp128, !dbg [[DBG125:![0-9]+]]
// AARCH64-NEXT:    [[MUL241:%.*]] = fmul fp128 [[CONV240]], [[TMP179]], !dbg [[DBG126:![0-9]+]]
// AARCH64-NEXT:    [[CONV242:%.*]] = fptosi fp128 [[MUL241]] to i32, !dbg [[DBG125]]
// AARCH64-NEXT:    [[TMP181:%.*]] = zext i32 [[CONV242]] to i64, !dbg [[DBG124]]
// AARCH64-NEXT:    [[BF_LOAD243:%.*]] = load i64, ptr [[ATOMIC_TEMP234]], align 8, !dbg [[DBG124]]
// AARCH64-NEXT:    [[BF_VALUE244:%.*]] = and i64 [[TMP181]], 1, !dbg [[DBG124]]
// AARCH64-NEXT:    [[BF_SHL245:%.*]] = shl i64 [[BF_VALUE244]], 16, !dbg [[DBG124]]
// AARCH64-NEXT:    [[BF_CLEAR246:%.*]] = and i64 [[BF_LOAD243]], -65537, !dbg [[DBG124]]
// AARCH64-NEXT:    [[BF_SET247:%.*]] = or i64 [[BF_CLEAR246]], [[BF_SHL245]], !dbg [[DBG124]]
// AARCH64-NEXT:    store i64 [[BF_SET247]], ptr [[ATOMIC_TEMP234]], align 8, !dbg [[DBG124]]
// AARCH64-NEXT:    [[TMP182:%.*]] = load i64, ptr [[ATOMIC_TEMP234]], align 8, !dbg [[DBG124]]
// AARCH64-NEXT:    [[TMP183:%.*]] = cmpxchg ptr @bfx4, i64 [[TMP180]], i64 [[TMP182]] monotonic monotonic, align 8, !dbg [[DBG124]]
// AARCH64-NEXT:    [[TMP184]] = extractvalue { i64, i1 } [[TMP183]], 0, !dbg [[DBG124]]
// AARCH64-NEXT:    [[TMP185:%.*]] = extractvalue { i64, i1 } [[TMP183]], 1, !dbg [[DBG124]]
// AARCH64-NEXT:    br i1 [[TMP185]], label [[ATOMIC_EXIT248:%.*]], label [[ATOMIC_CONT233]], !dbg [[DBG124]]
// AARCH64:       atomic_exit248:
// AARCH64-NEXT:    [[TMP186:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG127:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD249:%.*]] = load atomic i8, ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED:%.*]], ptr @bfx4_packed, i32 0, i32 1) monotonic, align 1, !dbg [[DBG128:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT250:%.*]], !dbg [[DBG128]]
// AARCH64:       atomic_cont250:
// AARCH64-NEXT:    [[TMP187:%.*]] = phi i8 [ [[ATOMIC_LOAD249]], [[ATOMIC_EXIT248]] ], [ [[TMP191:%.*]], [[ATOMIC_CONT250]] ], !dbg [[DBG128]]
// AARCH64-NEXT:    store i8 [[TMP187]], ptr [[ATOMIC_TEMP251]], align 1, !dbg [[DBG128]]
// AARCH64-NEXT:    store i8 [[TMP187]], ptr [[ATOMIC_TEMP252]], align 1, !dbg [[DBG128]]
// AARCH64-NEXT:    [[BF_LOAD253:%.*]] = load i8, ptr [[ATOMIC_TEMP252]], align 1, !dbg [[DBG128]]
// AARCH64-NEXT:    [[BF_SHL254:%.*]] = shl i8 [[BF_LOAD253]], 7, !dbg [[DBG128]]
// AARCH64-NEXT:    [[BF_ASHR255:%.*]] = ashr i8 [[BF_SHL254]], 7, !dbg [[DBG128]]
// AARCH64-NEXT:    [[BF_CAST256:%.*]] = sext i8 [[BF_ASHR255]] to i32, !dbg [[DBG128]]
// AARCH64-NEXT:    [[CONV257:%.*]] = sitofp i32 [[BF_CAST256]] to fp128, !dbg [[DBG129:![0-9]+]]
// AARCH64-NEXT:    [[SUB258:%.*]] = fsub fp128 [[CONV257]], [[TMP186]], !dbg [[DBG130:![0-9]+]]
// AARCH64-NEXT:    [[CONV259:%.*]] = fptosi fp128 [[SUB258]] to i32, !dbg [[DBG129]]
// AARCH64-NEXT:    [[TMP188:%.*]] = trunc i32 [[CONV259]] to i8, !dbg [[DBG128]]
// AARCH64-NEXT:    [[BF_LOAD260:%.*]] = load i8, ptr [[ATOMIC_TEMP251]], align 1, !dbg [[DBG128]]
// AARCH64-NEXT:    [[BF_VALUE261:%.*]] = and i8 [[TMP188]], 1, !dbg [[DBG128]]
// AARCH64-NEXT:    [[BF_CLEAR262:%.*]] = and i8 [[BF_LOAD260]], -2, !dbg [[DBG128]]
// AARCH64-NEXT:    [[BF_SET263:%.*]] = or i8 [[BF_CLEAR262]], [[BF_VALUE261]], !dbg [[DBG128]]
// AARCH64-NEXT:    store i8 [[BF_SET263]], ptr [[ATOMIC_TEMP251]], align 1, !dbg [[DBG128]]
// AARCH64-NEXT:    [[TMP189:%.*]] = load i8, ptr [[ATOMIC_TEMP251]], align 1, !dbg [[DBG128]]
// AARCH64-NEXT:    [[TMP190:%.*]] = cmpxchg ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1), i8 [[TMP187]], i8 [[TMP189]] monotonic monotonic, align 1, !dbg [[DBG128]]
// AARCH64-NEXT:    [[TMP191]] = extractvalue { i8, i1 } [[TMP190]], 0, !dbg [[DBG128]]
// AARCH64-NEXT:    [[TMP192:%.*]] = extractvalue { i8, i1 } [[TMP190]], 1, !dbg [[DBG128]]
// AARCH64-NEXT:    br i1 [[TMP192]], label [[ATOMIC_EXIT264:%.*]], label [[ATOMIC_CONT250]], !dbg [[DBG128]]
// AARCH64:       atomic_exit264:
// AARCH64-NEXT:    [[TMP193:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG131:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD265:%.*]] = load atomic i64, ptr @bfx4 monotonic, align 8, !dbg [[DBG132:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT266:%.*]], !dbg [[DBG132]]
// AARCH64:       atomic_cont266:
// AARCH64-NEXT:    [[TMP194:%.*]] = phi i64 [ [[ATOMIC_LOAD265]], [[ATOMIC_EXIT264]] ], [ [[TMP197:%.*]], [[ATOMIC_CONT266]] ], !dbg [[DBG132]]
// AARCH64-NEXT:    store i64 [[TMP194]], ptr [[ATOMIC_TEMP267]], align 8, !dbg [[DBG132]]
// AARCH64-NEXT:    store i64 [[TMP194]], ptr [[ATOMIC_TEMP268]], align 8, !dbg [[DBG132]]
// AARCH64-NEXT:    [[BF_LOAD269:%.*]] = load i64, ptr [[ATOMIC_TEMP268]], align 8, !dbg [[DBG132]]
// AARCH64-NEXT:    [[BF_SHL270:%.*]] = shl i64 [[BF_LOAD269]], 40, !dbg [[DBG132]]
// AARCH64-NEXT:    [[BF_ASHR271:%.*]] = ashr i64 [[BF_SHL270]], 57, !dbg [[DBG132]]
// AARCH64-NEXT:    [[CONV272:%.*]] = sitofp i64 [[BF_ASHR271]] to fp128, !dbg [[DBG133:![0-9]+]]
// AARCH64-NEXT:    [[DIV273:%.*]] = fdiv fp128 [[CONV272]], [[TMP193]], !dbg [[DBG134:![0-9]+]]
// AARCH64-NEXT:    [[CONV274:%.*]] = fptosi fp128 [[DIV273]] to i64, !dbg [[DBG133]]
// AARCH64-NEXT:    [[BF_LOAD275:%.*]] = load i64, ptr [[ATOMIC_TEMP267]], align 8, !dbg [[DBG132]]
// AARCH64-NEXT:    [[BF_VALUE276:%.*]] = and i64 [[CONV274]], 127, !dbg [[DBG132]]
// AARCH64-NEXT:    [[BF_SHL277:%.*]] = shl i64 [[BF_VALUE276]], 17, !dbg [[DBG132]]
// AARCH64-NEXT:    [[BF_CLEAR278:%.*]] = and i64 [[BF_LOAD275]], -16646145, !dbg [[DBG132]]
// AARCH64-NEXT:    [[BF_SET279:%.*]] = or i64 [[BF_CLEAR278]], [[BF_SHL277]], !dbg [[DBG132]]
// AARCH64-NEXT:    store i64 [[BF_SET279]], ptr [[ATOMIC_TEMP267]], align 8, !dbg [[DBG132]]
// AARCH64-NEXT:    [[TMP195:%.*]] = load i64, ptr [[ATOMIC_TEMP267]], align 8, !dbg [[DBG132]]
// AARCH64-NEXT:    [[TMP196:%.*]] = cmpxchg ptr @bfx4, i64 [[TMP194]], i64 [[TMP195]] monotonic monotonic, align 8, !dbg [[DBG132]]
// AARCH64-NEXT:    [[TMP197]] = extractvalue { i64, i1 } [[TMP196]], 0, !dbg [[DBG132]]
// AARCH64-NEXT:    [[TMP198:%.*]] = extractvalue { i64, i1 } [[TMP196]], 1, !dbg [[DBG132]]
// AARCH64-NEXT:    br i1 [[TMP198]], label [[ATOMIC_EXIT280:%.*]], label [[ATOMIC_CONT266]], !dbg [[DBG132]]
// AARCH64:       atomic_exit280:
// AARCH64-NEXT:    [[TMP199:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG135:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD281:%.*]] = load atomic i8, ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1) monotonic, align 1, !dbg [[DBG136:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT282:%.*]], !dbg [[DBG136]]
// AARCH64:       atomic_cont282:
// AARCH64-NEXT:    [[TMP200:%.*]] = phi i8 [ [[ATOMIC_LOAD281]], [[ATOMIC_EXIT280]] ], [ [[TMP204:%.*]], [[ATOMIC_CONT282]] ], !dbg [[DBG136]]
// AARCH64-NEXT:    store i8 [[TMP200]], ptr [[ATOMIC_TEMP283]], align 1, !dbg [[DBG136]]
// AARCH64-NEXT:    store i8 [[TMP200]], ptr [[ATOMIC_TEMP284]], align 1, !dbg [[DBG136]]
// AARCH64-NEXT:    [[BF_LOAD285:%.*]] = load i8, ptr [[ATOMIC_TEMP284]], align 1, !dbg [[DBG136]]
// AARCH64-NEXT:    [[BF_ASHR286:%.*]] = ashr i8 [[BF_LOAD285]], 1, !dbg [[DBG136]]
// AARCH64-NEXT:    [[BF_CAST287:%.*]] = sext i8 [[BF_ASHR286]] to i64, !dbg [[DBG136]]
// AARCH64-NEXT:    [[CONV288:%.*]] = sitofp i64 [[BF_CAST287]] to fp128, !dbg [[DBG137:![0-9]+]]
// AARCH64-NEXT:    [[ADD289:%.*]] = fadd fp128 [[CONV288]], [[TMP199]], !dbg [[DBG138:![0-9]+]]
// AARCH64-NEXT:    [[CONV290:%.*]] = fptosi fp128 [[ADD289]] to i64, !dbg [[DBG137]]
// AARCH64-NEXT:    [[TMP201:%.*]] = trunc i64 [[CONV290]] to i8, !dbg [[DBG136]]
// AARCH64-NEXT:    [[BF_LOAD291:%.*]] = load i8, ptr [[ATOMIC_TEMP283]], align 1, !dbg [[DBG136]]
// AARCH64-NEXT:    [[BF_VALUE292:%.*]] = and i8 [[TMP201]], 127, !dbg [[DBG136]]
// AARCH64-NEXT:    [[BF_SHL293:%.*]] = shl i8 [[BF_VALUE292]], 1, !dbg [[DBG136]]
// AARCH64-NEXT:    [[BF_CLEAR294:%.*]] = and i8 [[BF_LOAD291]], 1, !dbg [[DBG136]]
// AARCH64-NEXT:    [[BF_SET295:%.*]] = or i8 [[BF_CLEAR294]], [[BF_SHL293]], !dbg [[DBG136]]
// AARCH64-NEXT:    store i8 [[BF_SET295]], ptr [[ATOMIC_TEMP283]], align 1, !dbg [[DBG136]]
// AARCH64-NEXT:    [[TMP202:%.*]] = load i8, ptr [[ATOMIC_TEMP283]], align 1, !dbg [[DBG136]]
// AARCH64-NEXT:    [[TMP203:%.*]] = cmpxchg ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1), i8 [[TMP200]], i8 [[TMP202]] monotonic monotonic, align 1, !dbg [[DBG136]]
// AARCH64-NEXT:    [[TMP204]] = extractvalue { i8, i1 } [[TMP203]], 0, !dbg [[DBG136]]
// AARCH64-NEXT:    [[TMP205:%.*]] = extractvalue { i8, i1 } [[TMP203]], 1, !dbg [[DBG136]]
// AARCH64-NEXT:    br i1 [[TMP205]], label [[ATOMIC_EXIT296:%.*]], label [[ATOMIC_CONT282]], !dbg [[DBG136]]
// AARCH64:       atomic_exit296:
// AARCH64-NEXT:    [[TMP206:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG139:![0-9]+]]
// AARCH64-NEXT:    [[CONV297:%.*]] = uitofp i64 [[TMP206]] to float, !dbg [[DBG139]]
// AARCH64-NEXT:    [[ATOMIC_LOAD298:%.*]] = load atomic i64, ptr @float2x monotonic, align 8, !dbg [[DBG140:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT299:%.*]], !dbg [[DBG140]]
// AARCH64:       atomic_cont299:
// AARCH64-NEXT:    [[TMP207:%.*]] = phi i64 [ [[ATOMIC_LOAD298]], [[ATOMIC_EXIT296]] ], [ [[TMP215:%.*]], [[ATOMIC_CONT299]] ], !dbg [[DBG140]]
// AARCH64-NEXT:    store i64 [[TMP207]], ptr [[ATOMIC_TEMP300]], align 8, !dbg [[DBG140]]
// AARCH64-NEXT:    [[TMP208:%.*]] = bitcast i64 [[TMP207]] to <2 x float>, !dbg [[DBG140]]
// AARCH64-NEXT:    store <2 x float> [[TMP208]], ptr [[ATOMIC_TEMP301]], align 8, !dbg [[DBG140]]
// AARCH64-NEXT:    [[TMP209:%.*]] = load <2 x float>, ptr [[ATOMIC_TEMP301]], align 8, !dbg [[DBG140]]
// AARCH64-NEXT:    [[TMP210:%.*]] = extractelement <2 x float> [[TMP209]], i64 0, !dbg [[DBG140]]
// AARCH64-NEXT:    [[SUB302:%.*]] = fsub float [[CONV297]], [[TMP210]], !dbg [[DBG141:![0-9]+]]
// AARCH64-NEXT:    [[TMP211:%.*]] = load <2 x float>, ptr [[ATOMIC_TEMP300]], align 8, !dbg [[DBG140]]
// AARCH64-NEXT:    [[TMP212:%.*]] = insertelement <2 x float> [[TMP211]], float [[SUB302]], i64 0, !dbg [[DBG140]]
// AARCH64-NEXT:    store <2 x float> [[TMP212]], ptr [[ATOMIC_TEMP300]], align 8, !dbg [[DBG140]]
// AARCH64-NEXT:    [[TMP213:%.*]] = load i64, ptr [[ATOMIC_TEMP300]], align 8, !dbg [[DBG140]]
// AARCH64-NEXT:    [[TMP214:%.*]] = cmpxchg ptr @float2x, i64 [[TMP207]], i64 [[TMP213]] monotonic monotonic, align 8, !dbg [[DBG140]]
// AARCH64-NEXT:    [[TMP215]] = extractvalue { i64, i1 } [[TMP214]], 0, !dbg [[DBG140]]
// AARCH64-NEXT:    [[TMP216:%.*]] = extractvalue { i64, i1 } [[TMP214]], 1, !dbg [[DBG140]]
// AARCH64-NEXT:    br i1 [[TMP216]], label [[ATOMIC_EXIT303:%.*]], label [[ATOMIC_CONT299]], !dbg [[DBG140]]
// AARCH64:       atomic_exit303:
// AARCH64-NEXT:    ret i32 0, !dbg [[DBG142:![0-9]+]]
//
