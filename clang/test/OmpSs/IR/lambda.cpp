// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --include-generated-funcs
// RUN: %clang_cc1 -triple x86_64-gnu-linux -x c++ -fompss-2 -disable-llvm-passes %s -emit-llvm -o - | FileCheck %s --check-prefixes=LIN64
// RUN: %clang_cc1 -triple ppc64 -x c++ -fompss-2 -disable-llvm-passes %s -emit-llvm -o - | FileCheck %s --check-prefixes=PPC64
// RUN: %clang_cc1 -triple aarch64 -x c++ -fompss-2 -disable-llvm-passes %s -emit-llvm -o - | FileCheck %s --check-prefixes=AARCH64
// expected-no-diagnostics

void bar(int x) {
    auto foo = [&x]() {
      #pragma oss task in(x)
      x++;
    };
    foo();
    #pragma oss task cost([&x]() { return x; }())
    {}
}

// LIN64-LABEL: @_Z3bari(
// LIN64-NEXT:  entry:
// LIN64-NEXT:    [[X_ADDR:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[FOO:%.*]] = alloca [[CLASS_ANON:%.*]], align 8
// LIN64-NEXT:    store i32 [[X:%.*]], ptr [[X_ADDR]], align 4
// LIN64-NEXT:    [[TMP0:%.*]] = getelementptr inbounds nuw [[CLASS_ANON]], ptr [[FOO]], i32 0, i32 0, !dbg [[DBG9:![0-9]+]]
// LIN64-NEXT:    store ptr [[X_ADDR]], ptr [[TMP0]], align 8, !dbg [[DBG9]]
// LIN64-NEXT:    call void @"_ZZ3bariENK3$_0clEv"(ptr noundef nonnull align 8 dereferenceable(8) [[FOO]]), !dbg [[DBG10:![0-9]+]]
// LIN64-NEXT:    [[TMP1:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OSS"([5 x i8] c"TASK\00"), "QUAL.OSS.FIRSTPRIVATE"(ptr [[X_ADDR]], i32 undef), "QUAL.OSS.COST"(ptr @compute_cost, ptr [[X_ADDR]]) ], !dbg [[DBG11:![0-9]+]]
// LIN64-NEXT:    call void @llvm.directive.region.exit(token [[TMP1]]), !dbg [[DBG12:![0-9]+]]
// LIN64-NEXT:    ret void, !dbg [[DBG13:![0-9]+]]
//
//
// LIN64-LABEL: @compute_cost(
// LIN64-NEXT:  entry:
// LIN64-NEXT:    [[X_ADDR:%.*]] = alloca ptr, align 8
// LIN64-NEXT:    [[REF_TMP:%.*]] = alloca [[CLASS_ANON_0:%.*]], align 8
// LIN64-NEXT:    store ptr [[X:%.*]], ptr [[X_ADDR]], align 8
// LIN64-NEXT:    [[TMP0:%.*]] = getelementptr inbounds nuw [[CLASS_ANON_0]], ptr [[REF_TMP]], i32 0, i32 0, !dbg [[DBG21:![0-9]+]]
// LIN64-NEXT:    store ptr [[X]], ptr [[TMP0]], align 8, !dbg [[DBG21]]
// LIN64-NEXT:    [[CALL:%.*]] = call noundef i32 @"_ZZ3bariENK3$_1clEv"(ptr noundef nonnull align 8 dereferenceable(8) [[REF_TMP]]), !dbg [[DBG21]]
// LIN64-NEXT:    ret i32 [[CALL]], !dbg [[DBG23:![0-9]+]]
//
//
// LIN64-LABEL: @compute_dep(
// LIN64-NEXT:  entry:
// LIN64-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T:%.*]], align 8
// LIN64-NEXT:    [[X_ADDR:%.*]] = alloca ptr, align 8
// LIN64-NEXT:    store ptr [[X:%.*]], ptr [[X_ADDR]], align 8
// LIN64-NEXT:    [[TMP0:%.*]] = getelementptr inbounds nuw [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 0
// LIN64-NEXT:    store ptr [[X]], ptr [[TMP0]], align 8
// LIN64-NEXT:    [[TMP1:%.*]] = getelementptr inbounds nuw [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 1
// LIN64-NEXT:    store i64 4, ptr [[TMP1]], align 8
// LIN64-NEXT:    [[TMP2:%.*]] = getelementptr inbounds nuw [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 2
// LIN64-NEXT:    store i64 0, ptr [[TMP2]], align 8
// LIN64-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 3
// LIN64-NEXT:    store i64 4, ptr [[TMP3]], align 8
// LIN64-NEXT:    [[TMP4:%.*]] = load [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], align 8
// LIN64-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T]] [[TMP4]]
//
//
// PPC64-LABEL: @_Z3bari(
// PPC64-NEXT:  entry:
// PPC64-NEXT:    [[X_ADDR:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[FOO:%.*]] = alloca [[CLASS_ANON:%.*]], align 8
// PPC64-NEXT:    store i32 [[X:%.*]], ptr [[X_ADDR]], align 4
// PPC64-NEXT:    [[TMP0:%.*]] = getelementptr inbounds nuw [[CLASS_ANON]], ptr [[FOO]], i32 0, i32 0, !dbg [[DBG9:![0-9]+]]
// PPC64-NEXT:    store ptr [[X_ADDR]], ptr [[TMP0]], align 8, !dbg [[DBG9]]
// PPC64-NEXT:    call void @"_ZZ3bariENK3$_0clEv"(ptr noundef nonnull align 8 dereferenceable(8) [[FOO]]), !dbg [[DBG10:![0-9]+]]
// PPC64-NEXT:    [[TMP1:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OSS"([5 x i8] c"TASK\00"), "QUAL.OSS.FIRSTPRIVATE"(ptr [[X_ADDR]], i32 undef), "QUAL.OSS.COST"(ptr @compute_cost, ptr [[X_ADDR]]) ], !dbg [[DBG11:![0-9]+]]
// PPC64-NEXT:    call void @llvm.directive.region.exit(token [[TMP1]]), !dbg [[DBG12:![0-9]+]]
// PPC64-NEXT:    ret void, !dbg [[DBG13:![0-9]+]]
//
//
// PPC64-LABEL: @compute_cost(
// PPC64-NEXT:  entry:
// PPC64-NEXT:    [[X_ADDR:%.*]] = alloca ptr, align 8
// PPC64-NEXT:    [[REF_TMP:%.*]] = alloca [[CLASS_ANON_0:%.*]], align 8
// PPC64-NEXT:    store ptr [[X:%.*]], ptr [[X_ADDR]], align 8
// PPC64-NEXT:    [[TMP0:%.*]] = getelementptr inbounds nuw [[CLASS_ANON_0]], ptr [[REF_TMP]], i32 0, i32 0, !dbg [[DBG21:![0-9]+]]
// PPC64-NEXT:    store ptr [[X]], ptr [[TMP0]], align 8, !dbg [[DBG21]]
// PPC64-NEXT:    [[CALL:%.*]] = call noundef signext i32 @"_ZZ3bariENK3$_1clEv"(ptr noundef nonnull align 8 dereferenceable(8) [[REF_TMP]]), !dbg [[DBG21]]
// PPC64-NEXT:    ret i32 [[CALL]], !dbg [[DBG23:![0-9]+]]
//
//
// PPC64-LABEL: @compute_dep(
// PPC64-NEXT:  entry:
// PPC64-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T:%.*]], align 8
// PPC64-NEXT:    [[X_ADDR:%.*]] = alloca ptr, align 8
// PPC64-NEXT:    store ptr [[X:%.*]], ptr [[X_ADDR]], align 8
// PPC64-NEXT:    [[TMP0:%.*]] = getelementptr inbounds nuw [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 0
// PPC64-NEXT:    store ptr [[X]], ptr [[TMP0]], align 8
// PPC64-NEXT:    [[TMP1:%.*]] = getelementptr inbounds nuw [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 1
// PPC64-NEXT:    store i64 4, ptr [[TMP1]], align 8
// PPC64-NEXT:    [[TMP2:%.*]] = getelementptr inbounds nuw [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 2
// PPC64-NEXT:    store i64 0, ptr [[TMP2]], align 8
// PPC64-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 3
// PPC64-NEXT:    store i64 4, ptr [[TMP3]], align 8
// PPC64-NEXT:    [[TMP4:%.*]] = load [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], align 8
// PPC64-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T]] [[TMP4]]
//
//
// AARCH64-LABEL: @_Z3bari(
// AARCH64-NEXT:  entry:
// AARCH64-NEXT:    [[X_ADDR:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[FOO:%.*]] = alloca [[CLASS_ANON:%.*]], align 8
// AARCH64-NEXT:    store i32 [[X:%.*]], ptr [[X_ADDR]], align 4
// AARCH64-NEXT:    [[TMP0:%.*]] = getelementptr inbounds nuw [[CLASS_ANON]], ptr [[FOO]], i32 0, i32 0, !dbg [[DBG9:![0-9]+]]
// AARCH64-NEXT:    store ptr [[X_ADDR]], ptr [[TMP0]], align 8, !dbg [[DBG9]]
// AARCH64-NEXT:    call void @"_ZZ3bariENK3$_0clEv"(ptr noundef nonnull align 8 dereferenceable(8) [[FOO]]), !dbg [[DBG10:![0-9]+]]
// AARCH64-NEXT:    [[TMP1:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OSS"([5 x i8] c"TASK\00"), "QUAL.OSS.FIRSTPRIVATE"(ptr [[X_ADDR]], i32 undef), "QUAL.OSS.COST"(ptr @compute_cost, ptr [[X_ADDR]]) ], !dbg [[DBG11:![0-9]+]]
// AARCH64-NEXT:    call void @llvm.directive.region.exit(token [[TMP1]]), !dbg [[DBG12:![0-9]+]]
// AARCH64-NEXT:    ret void, !dbg [[DBG13:![0-9]+]]
//
//
// AARCH64-LABEL: @compute_cost(
// AARCH64-NEXT:  entry:
// AARCH64-NEXT:    [[X_ADDR:%.*]] = alloca ptr, align 8
// AARCH64-NEXT:    [[REF_TMP:%.*]] = alloca [[CLASS_ANON_0:%.*]], align 8
// AARCH64-NEXT:    store ptr [[X:%.*]], ptr [[X_ADDR]], align 8
// AARCH64-NEXT:    [[TMP0:%.*]] = getelementptr inbounds nuw [[CLASS_ANON_0]], ptr [[REF_TMP]], i32 0, i32 0, !dbg [[DBG21:![0-9]+]]
// AARCH64-NEXT:    store ptr [[X]], ptr [[TMP0]], align 8, !dbg [[DBG21]]
// AARCH64-NEXT:    [[CALL:%.*]] = call noundef i32 @"_ZZ3bariENK3$_1clEv"(ptr noundef nonnull align 8 dereferenceable(8) [[REF_TMP]]), !dbg [[DBG21]]
// AARCH64-NEXT:    ret i32 [[CALL]], !dbg [[DBG23:![0-9]+]]
//
//
// AARCH64-LABEL: @compute_dep(
// AARCH64-NEXT:  entry:
// AARCH64-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT__DEPEND_UNPACK_T:%.*]], align 8
// AARCH64-NEXT:    [[X_ADDR:%.*]] = alloca ptr, align 8
// AARCH64-NEXT:    store ptr [[X:%.*]], ptr [[X_ADDR]], align 8
// AARCH64-NEXT:    [[TMP0:%.*]] = getelementptr inbounds nuw [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 0
// AARCH64-NEXT:    store ptr [[X]], ptr [[TMP0]], align 8
// AARCH64-NEXT:    [[TMP1:%.*]] = getelementptr inbounds nuw [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 1
// AARCH64-NEXT:    store i64 4, ptr [[TMP1]], align 8
// AARCH64-NEXT:    [[TMP2:%.*]] = getelementptr inbounds nuw [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 2
// AARCH64-NEXT:    store i64 0, ptr [[TMP2]], align 8
// AARCH64-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], i32 0, i32 3
// AARCH64-NEXT:    store i64 4, ptr [[TMP3]], align 8
// AARCH64-NEXT:    [[TMP4:%.*]] = load [[STRUCT__DEPEND_UNPACK_T]], ptr [[RETVAL]], align 8
// AARCH64-NEXT:    ret [[STRUCT__DEPEND_UNPACK_T]] [[TMP4]]
//
