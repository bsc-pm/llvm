// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// RUN: %clang_cc1 -no-opaque-pointers -verify -disable-llvm-passes -fompss-2 -x c -S -emit-llvm %s -o - | FileCheck %s
// expected-no-diagnostics
#ifndef HEADER
#define HEADER

_Bool bv, bx;
char cv, cx;
unsigned char ucv, ucx;
short sv, sx;
unsigned short usv, usx;
int iv, ix;
unsigned int uiv, uix;
long lv, lx;
unsigned long ulv, ulx;
long long llv, llx;
unsigned long long ullv, ullx;
float fv, fx;
double dv, dx;
long double ldv, ldx;
_Complex int civ, cix;
_Complex float cfv, cfx;
_Complex double cdv, cdx;

typedef int int4 __attribute__((__vector_size__(16)));
int4 int4x;

struct BitFields {
  int : 32;
  int a : 31;
} bfx;

struct BitFields_packed {
  int : 32;
  int a : 31;
} __attribute__ ((__packed__)) bfx_packed;

struct BitFields2 {
  int : 31;
  int a : 1;
} bfx2;

struct BitFields2_packed {
  int : 31;
  int a : 1;
} __attribute__ ((__packed__)) bfx2_packed;

struct BitFields3 {
  int : 11;
  int a : 14;
} bfx3;

struct BitFields3_packed {
  int : 11;
  int a : 14;
} __attribute__ ((__packed__)) bfx3_packed;

struct BitFields4 {
  short : 16;
  int a: 1;
  long b : 7;
} bfx4;

struct BitFields4_packed {
  short : 16;
  int a: 1;
  long b : 7;
} __attribute__ ((__packed__)) bfx4_packed;

typedef float float2 __attribute__((ext_vector_type(2)));
float2 float2x;

#ifdef __x86_64__
// Register "0" is currently an invalid register for global register variables.
// Use "esp" instead of "0".
// register int rix __asm__("0");
register int rix __asm__("esp");
#endif

// CHECK-LABEL: @main(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[RETVAL:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca x86_fp80, align 16
// CHECK-NEXT:    [[ATOMIC_TEMP1:%.*]] = alloca { i32, i32 }, align 4
// CHECK-NEXT:    [[ATOMIC_TEMP2:%.*]] = alloca { float, float }, align 4
// CHECK-NEXT:    [[ATOMIC_TEMP3:%.*]] = alloca { double, double }, align 8
// CHECK-NEXT:    [[ATOMIC_TEMP10:%.*]] = alloca { i32, i32 }, align 4
// CHECK-NEXT:    [[ATOMIC_TEMP14:%.*]] = alloca x86_fp80, align 16
// CHECK-NEXT:    [[ATOMIC_TEMP16:%.*]] = alloca { i32, i32 }, align 4
// CHECK-NEXT:    [[ATOMIC_TEMP32:%.*]] = alloca <4 x i32>, align 16
// CHECK-NEXT:    [[ATOMIC_TEMP33:%.*]] = alloca <4 x i32>, align 16
// CHECK-NEXT:    [[ATOMIC_TEMP36:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[ATOMIC_TEMP39:%.*]] = alloca i32, align 1
// CHECK-NEXT:    [[ATOMIC_TEMP41:%.*]] = alloca i32, align 1
// CHECK-NEXT:    [[ATOMIC_TEMP51:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[ATOMIC_TEMP60:%.*]] = alloca i32, align 1
// CHECK-NEXT:    [[ATOMIC_TEMP70:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[ATOMIC_TEMP78:%.*]] = alloca i32, align 1
// CHECK-NEXT:    [[ATOMIC_TEMP80:%.*]] = alloca i32, align 1
// CHECK-NEXT:    [[ATOMIC_TEMP91:%.*]] = alloca i64, align 8
// CHECK-NEXT:    [[ATOMIC_TEMP101:%.*]] = alloca i32, align 1
// CHECK-NEXT:    [[ATOMIC_TEMP110:%.*]] = alloca i64, align 8
// CHECK-NEXT:    [[ATOMIC_TEMP120:%.*]] = alloca i64, align 1
// CHECK-NEXT:    [[ATOMIC_TEMP130:%.*]] = alloca <2 x float>, align 8
// CHECK-NEXT:    store i32 0, i32* [[RETVAL]], align 4
// CHECK-NEXT:    store atomic i32 1, i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 1) monotonic, align 4, !dbg [[DBG10:![0-9]+]]
// CHECK-NEXT:    [[TMP0:%.*]] = load i8, i8* @bv, align 1, !dbg [[DBG11:![0-9]+]]
// CHECK-NEXT:    [[TOBOOL:%.*]] = trunc i8 [[TMP0]] to i1, !dbg [[DBG11]]
// CHECK-NEXT:    [[FROMBOOL:%.*]] = zext i1 [[TOBOOL]] to i8, !dbg [[DBG12:![0-9]+]]
// CHECK-NEXT:    store atomic i8 [[FROMBOOL]], i8* @bx monotonic, align 1, !dbg [[DBG12]]
// CHECK-NEXT:    [[TMP1:%.*]] = load i8, i8* @cv, align 1, !dbg [[DBG13:![0-9]+]]
// CHECK-NEXT:    store atomic i8 [[TMP1]], i8* @cx release, align 1, !dbg [[DBG14:![0-9]+]]
// CHECK-NEXT:    fence release
// CHECK-NEXT:    [[TMP2:%.*]] = load i8, i8* @ucv, align 1, !dbg [[DBG15:![0-9]+]]
// CHECK-NEXT:    store atomic i8 [[TMP2]], i8* @ucx monotonic, align 1, !dbg [[DBG16:![0-9]+]]
// CHECK-NEXT:    [[TMP3:%.*]] = load i16, i16* @sv, align 2, !dbg [[DBG17:![0-9]+]]
// CHECK-NEXT:    store atomic i16 [[TMP3]], i16* @sx monotonic, align 2, !dbg [[DBG18:![0-9]+]]
// CHECK-NEXT:    [[TMP4:%.*]] = load i16, i16* @usv, align 2, !dbg [[DBG19:![0-9]+]]
// CHECK-NEXT:    store atomic i16 [[TMP4]], i16* @usx monotonic, align 2, !dbg [[DBG20:![0-9]+]]
// CHECK-NEXT:    [[TMP5:%.*]] = load i32, i32* @iv, align 4, !dbg [[DBG21:![0-9]+]]
// CHECK-NEXT:    store atomic i32 [[TMP5]], i32* @ix monotonic, align 4, !dbg [[DBG22:![0-9]+]]
// CHECK-NEXT:    [[TMP6:%.*]] = load i32, i32* @uiv, align 4, !dbg [[DBG23:![0-9]+]]
// CHECK-NEXT:    store atomic i32 [[TMP6]], i32* @uix monotonic, align 4, !dbg [[DBG24:![0-9]+]]
// CHECK-NEXT:    [[TMP7:%.*]] = load i64, i64* @lv, align 8, !dbg [[DBG25:![0-9]+]]
// CHECK-NEXT:    store atomic i64 [[TMP7]], i64* @lx monotonic, align 8, !dbg [[DBG26:![0-9]+]]
// CHECK-NEXT:    [[TMP8:%.*]] = load i64, i64* @ulv, align 8, !dbg [[DBG27:![0-9]+]]
// CHECK-NEXT:    store atomic i64 [[TMP8]], i64* @ulx monotonic, align 8, !dbg [[DBG28:![0-9]+]]
// CHECK-NEXT:    [[TMP9:%.*]] = load i64, i64* @llv, align 8, !dbg [[DBG29:![0-9]+]]
// CHECK-NEXT:    store atomic i64 [[TMP9]], i64* @llx monotonic, align 8, !dbg [[DBG30:![0-9]+]]
// CHECK-NEXT:    [[TMP10:%.*]] = load i64, i64* @ullv, align 8, !dbg [[DBG31:![0-9]+]]
// CHECK-NEXT:    store atomic i64 [[TMP10]], i64* @ullx monotonic, align 8, !dbg [[DBG32:![0-9]+]]
// CHECK-NEXT:    [[TMP11:%.*]] = load float, float* @fv, align 4, !dbg [[DBG33:![0-9]+]]
// CHECK-NEXT:    [[TMP12:%.*]] = bitcast float [[TMP11]] to i32, !dbg [[DBG34:![0-9]+]]
// CHECK-NEXT:    store atomic i32 [[TMP12]], i32* bitcast (float* @fx to i32*) monotonic, align 4, !dbg [[DBG34]]
// CHECK-NEXT:    [[TMP13:%.*]] = load double, double* @dv, align 8, !dbg [[DBG35:![0-9]+]]
// CHECK-NEXT:    [[TMP14:%.*]] = bitcast double [[TMP13]] to i64, !dbg [[DBG36:![0-9]+]]
// CHECK-NEXT:    store atomic i64 [[TMP14]], i64* bitcast (double* @dx to i64*) monotonic, align 8, !dbg [[DBG36]]
// CHECK-NEXT:    [[TMP15:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG37:![0-9]+]]
// CHECK-NEXT:    [[TMP16:%.*]] = bitcast x86_fp80* [[ATOMIC_TEMP]] to i8*, !dbg [[DBG38:![0-9]+]]
// CHECK-NEXT:    call void @llvm.memset.p0i8.i64(i8* align 16 [[TMP16]], i8 0, i64 16, i1 false), !dbg [[DBG38]]
// CHECK-NEXT:    store x86_fp80 [[TMP15]], x86_fp80* [[ATOMIC_TEMP]], align 16, !dbg [[DBG38]]
// CHECK-NEXT:    [[TMP17:%.*]] = bitcast x86_fp80* [[ATOMIC_TEMP]] to i8*, !dbg [[DBG38]]
// CHECK-NEXT:    call void @__atomic_store(i64 noundef 16, i8* noundef bitcast (x86_fp80* @ldx to i8*), i8* noundef [[TMP17]], i32 noundef 0), !dbg [[DBG38]]
// CHECK-NEXT:    [[CIV_REAL:%.*]] = load i32, i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 0), align 4, !dbg [[DBG39:![0-9]+]]
// CHECK-NEXT:    [[CIV_IMAG:%.*]] = load i32, i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 1), align 4, !dbg [[DBG39]]
// CHECK-NEXT:    [[ATOMIC_TEMP1_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP1]], i32 0, i32 0, !dbg [[DBG40:![0-9]+]]
// CHECK-NEXT:    [[ATOMIC_TEMP1_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP1]], i32 0, i32 1, !dbg [[DBG40]]
// CHECK-NEXT:    store i32 [[CIV_REAL]], i32* [[ATOMIC_TEMP1_REALP]], align 4, !dbg [[DBG40]]
// CHECK-NEXT:    store i32 [[CIV_IMAG]], i32* [[ATOMIC_TEMP1_IMAGP]], align 4, !dbg [[DBG40]]
// CHECK-NEXT:    [[TMP18:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP1]] to i8*, !dbg [[DBG40]]
// CHECK-NEXT:    call void @__atomic_store(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP18]], i32 noundef 0), !dbg [[DBG40]]
// CHECK-NEXT:    [[CFV_REAL:%.*]] = load float, float* getelementptr inbounds ({ float, float }, { float, float }* @cfv, i32 0, i32 0), align 4, !dbg [[DBG41:![0-9]+]]
// CHECK-NEXT:    [[CFV_IMAG:%.*]] = load float, float* getelementptr inbounds ({ float, float }, { float, float }* @cfv, i32 0, i32 1), align 4, !dbg [[DBG41]]
// CHECK-NEXT:    [[ATOMIC_TEMP2_REALP:%.*]] = getelementptr inbounds { float, float }, { float, float }* [[ATOMIC_TEMP2]], i32 0, i32 0, !dbg [[DBG42:![0-9]+]]
// CHECK-NEXT:    [[ATOMIC_TEMP2_IMAGP:%.*]] = getelementptr inbounds { float, float }, { float, float }* [[ATOMIC_TEMP2]], i32 0, i32 1, !dbg [[DBG42]]
// CHECK-NEXT:    store float [[CFV_REAL]], float* [[ATOMIC_TEMP2_REALP]], align 4, !dbg [[DBG42]]
// CHECK-NEXT:    store float [[CFV_IMAG]], float* [[ATOMIC_TEMP2_IMAGP]], align 4, !dbg [[DBG42]]
// CHECK-NEXT:    [[TMP19:%.*]] = bitcast { float, float }* [[ATOMIC_TEMP2]] to i8*, !dbg [[DBG42]]
// CHECK-NEXT:    call void @__atomic_store(i64 noundef 8, i8* noundef bitcast ({ float, float }* @cfx to i8*), i8* noundef [[TMP19]], i32 noundef 0), !dbg [[DBG42]]
// CHECK-NEXT:    [[CDV_REAL:%.*]] = load double, double* getelementptr inbounds ({ double, double }, { double, double }* @cdv, i32 0, i32 0), align 8, !dbg [[DBG43:![0-9]+]]
// CHECK-NEXT:    [[CDV_IMAG:%.*]] = load double, double* getelementptr inbounds ({ double, double }, { double, double }* @cdv, i32 0, i32 1), align 8, !dbg [[DBG43]]
// CHECK-NEXT:    [[ATOMIC_TEMP3_REALP:%.*]] = getelementptr inbounds { double, double }, { double, double }* [[ATOMIC_TEMP3]], i32 0, i32 0, !dbg [[DBG44:![0-9]+]]
// CHECK-NEXT:    [[ATOMIC_TEMP3_IMAGP:%.*]] = getelementptr inbounds { double, double }, { double, double }* [[ATOMIC_TEMP3]], i32 0, i32 1, !dbg [[DBG44]]
// CHECK-NEXT:    store double [[CDV_REAL]], double* [[ATOMIC_TEMP3_REALP]], align 8, !dbg [[DBG44]]
// CHECK-NEXT:    store double [[CDV_IMAG]], double* [[ATOMIC_TEMP3_IMAGP]], align 8, !dbg [[DBG44]]
// CHECK-NEXT:    [[TMP20:%.*]] = bitcast { double, double }* [[ATOMIC_TEMP3]] to i8*, !dbg [[DBG44]]
// CHECK-NEXT:    call void @__atomic_store(i64 noundef 16, i8* noundef bitcast ({ double, double }* @cdx to i8*), i8* noundef [[TMP20]], i32 noundef 5), !dbg [[DBG44]]
// CHECK-NEXT:    fence release
// CHECK-NEXT:    [[TMP21:%.*]] = load i8, i8* @bv, align 1, !dbg [[DBG45:![0-9]+]]
// CHECK-NEXT:    [[TOBOOL4:%.*]] = trunc i8 [[TMP21]] to i1, !dbg [[DBG45]]
// CHECK-NEXT:    [[CONV:%.*]] = zext i1 [[TOBOOL4]] to i64, !dbg [[DBG45]]
// CHECK-NEXT:    store atomic i64 [[CONV]], i64* @ulx monotonic, align 8, !dbg [[DBG46:![0-9]+]]
// CHECK-NEXT:    [[TMP22:%.*]] = load i8, i8* @cv, align 1, !dbg [[DBG47:![0-9]+]]
// CHECK-NEXT:    [[TOBOOL5:%.*]] = icmp ne i8 [[TMP22]], 0, !dbg [[DBG47]]
// CHECK-NEXT:    [[FROMBOOL6:%.*]] = zext i1 [[TOBOOL5]] to i8, !dbg [[DBG48:![0-9]+]]
// CHECK-NEXT:    store atomic i8 [[FROMBOOL6]], i8* @bx monotonic, align 1, !dbg [[DBG48]]
// CHECK-NEXT:    [[TMP23:%.*]] = load i8, i8* @ucv, align 1, !dbg [[DBG49:![0-9]+]]
// CHECK-NEXT:    store atomic i8 [[TMP23]], i8* @cx seq_cst, align 1, !dbg [[DBG50:![0-9]+]]
// CHECK-NEXT:    fence release
// CHECK-NEXT:    [[TMP24:%.*]] = load i16, i16* @sv, align 2, !dbg [[DBG51:![0-9]+]]
// CHECK-NEXT:    [[CONV7:%.*]] = sext i16 [[TMP24]] to i64, !dbg [[DBG51]]
// CHECK-NEXT:    store atomic i64 [[CONV7]], i64* @ulx monotonic, align 8, !dbg [[DBG52:![0-9]+]]
// CHECK-NEXT:    [[TMP25:%.*]] = load i16, i16* @usv, align 2, !dbg [[DBG53:![0-9]+]]
// CHECK-NEXT:    [[CONV8:%.*]] = zext i16 [[TMP25]] to i64, !dbg [[DBG53]]
// CHECK-NEXT:    store atomic i64 [[CONV8]], i64* @lx monotonic, align 8, !dbg [[DBG54:![0-9]+]]
// CHECK-NEXT:    [[TMP26:%.*]] = load i32, i32* @iv, align 4, !dbg [[DBG55:![0-9]+]]
// CHECK-NEXT:    store atomic i32 [[TMP26]], i32* @uix seq_cst, align 4, !dbg [[DBG56:![0-9]+]]
// CHECK-NEXT:    fence release
// CHECK-NEXT:    [[TMP27:%.*]] = load i32, i32* @uiv, align 4, !dbg [[DBG57:![0-9]+]]
// CHECK-NEXT:    store atomic i32 [[TMP27]], i32* @ix monotonic, align 4, !dbg [[DBG58:![0-9]+]]
// CHECK-NEXT:    [[TMP28:%.*]] = load i64, i64* @lv, align 8, !dbg [[DBG59:![0-9]+]]
// CHECK-NEXT:    [[CONV9:%.*]] = trunc i64 [[TMP28]] to i32, !dbg [[DBG59]]
// CHECK-NEXT:    [[ATOMIC_TEMP10_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP10]], i32 0, i32 0, !dbg [[DBG60:![0-9]+]]
// CHECK-NEXT:    [[ATOMIC_TEMP10_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP10]], i32 0, i32 1, !dbg [[DBG60]]
// CHECK-NEXT:    store i32 [[CONV9]], i32* [[ATOMIC_TEMP10_REALP]], align 4, !dbg [[DBG60]]
// CHECK-NEXT:    store i32 0, i32* [[ATOMIC_TEMP10_IMAGP]], align 4, !dbg [[DBG60]]
// CHECK-NEXT:    [[TMP29:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP10]] to i8*, !dbg [[DBG60]]
// CHECK-NEXT:    call void @__atomic_store(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP29]], i32 noundef 0), !dbg [[DBG60]]
// CHECK-NEXT:    [[TMP30:%.*]] = load i64, i64* @ulv, align 8, !dbg [[DBG61:![0-9]+]]
// CHECK-NEXT:    [[CONV11:%.*]] = uitofp i64 [[TMP30]] to float, !dbg [[DBG61]]
// CHECK-NEXT:    [[TMP31:%.*]] = bitcast float [[CONV11]] to i32, !dbg [[DBG62:![0-9]+]]
// CHECK-NEXT:    store atomic i32 [[TMP31]], i32* bitcast (float* @fx to i32*) monotonic, align 4, !dbg [[DBG62]]
// CHECK-NEXT:    [[TMP32:%.*]] = load i64, i64* @llv, align 8, !dbg [[DBG63:![0-9]+]]
// CHECK-NEXT:    [[CONV12:%.*]] = sitofp i64 [[TMP32]] to double, !dbg [[DBG63]]
// CHECK-NEXT:    [[TMP33:%.*]] = bitcast double [[CONV12]] to i64, !dbg [[DBG64:![0-9]+]]
// CHECK-NEXT:    store atomic i64 [[TMP33]], i64* bitcast (double* @dx to i64*) monotonic, align 8, !dbg [[DBG64]]
// CHECK-NEXT:    [[TMP34:%.*]] = load i64, i64* @ullv, align 8, !dbg [[DBG65:![0-9]+]]
// CHECK-NEXT:    [[CONV13:%.*]] = uitofp i64 [[TMP34]] to x86_fp80, !dbg [[DBG65]]
// CHECK-NEXT:    [[TMP35:%.*]] = bitcast x86_fp80* [[ATOMIC_TEMP14]] to i8*, !dbg [[DBG66:![0-9]+]]
// CHECK-NEXT:    call void @llvm.memset.p0i8.i64(i8* align 16 [[TMP35]], i8 0, i64 16, i1 false), !dbg [[DBG66]]
// CHECK-NEXT:    store x86_fp80 [[CONV13]], x86_fp80* [[ATOMIC_TEMP14]], align 16, !dbg [[DBG66]]
// CHECK-NEXT:    [[TMP36:%.*]] = bitcast x86_fp80* [[ATOMIC_TEMP14]] to i8*, !dbg [[DBG66]]
// CHECK-NEXT:    call void @__atomic_store(i64 noundef 16, i8* noundef bitcast (x86_fp80* @ldx to i8*), i8* noundef [[TMP36]], i32 noundef 0), !dbg [[DBG66]]
// CHECK-NEXT:    [[TMP37:%.*]] = load float, float* @fv, align 4, !dbg [[DBG67:![0-9]+]]
// CHECK-NEXT:    [[CONV15:%.*]] = fptosi float [[TMP37]] to i32, !dbg [[DBG67]]
// CHECK-NEXT:    [[ATOMIC_TEMP16_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP16]], i32 0, i32 0, !dbg [[DBG68:![0-9]+]]
// CHECK-NEXT:    [[ATOMIC_TEMP16_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP16]], i32 0, i32 1, !dbg [[DBG68]]
// CHECK-NEXT:    store i32 [[CONV15]], i32* [[ATOMIC_TEMP16_REALP]], align 4, !dbg [[DBG68]]
// CHECK-NEXT:    store i32 0, i32* [[ATOMIC_TEMP16_IMAGP]], align 4, !dbg [[DBG68]]
// CHECK-NEXT:    [[TMP38:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP16]] to i8*, !dbg [[DBG68]]
// CHECK-NEXT:    call void @__atomic_store(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP38]], i32 noundef 0), !dbg [[DBG68]]
// CHECK-NEXT:    [[TMP39:%.*]] = load double, double* @dv, align 8, !dbg [[DBG69:![0-9]+]]
// CHECK-NEXT:    [[CONV17:%.*]] = fptosi double [[TMP39]] to i16, !dbg [[DBG69]]
// CHECK-NEXT:    store atomic i16 [[CONV17]], i16* @sx monotonic, align 2, !dbg [[DBG70:![0-9]+]]
// CHECK-NEXT:    [[TMP40:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG71:![0-9]+]]
// CHECK-NEXT:    [[TOBOOL18:%.*]] = fcmp une x86_fp80 [[TMP40]], 0xK00000000000000000000, !dbg [[DBG71]]
// CHECK-NEXT:    [[FROMBOOL19:%.*]] = zext i1 [[TOBOOL18]] to i8, !dbg [[DBG72:![0-9]+]]
// CHECK-NEXT:    store atomic i8 [[FROMBOOL19]], i8* @bx monotonic, align 1, !dbg [[DBG72]]
// CHECK-NEXT:    [[CIV_REAL20:%.*]] = load i32, i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 0), align 4, !dbg [[DBG73:![0-9]+]]
// CHECK-NEXT:    [[CIV_IMAG21:%.*]] = load i32, i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 1), align 4, !dbg [[DBG73]]
// CHECK-NEXT:    [[TOBOOL22:%.*]] = icmp ne i32 [[CIV_REAL20]], 0, !dbg [[DBG73]]
// CHECK-NEXT:    [[TOBOOL23:%.*]] = icmp ne i32 [[CIV_IMAG21]], 0, !dbg [[DBG73]]
// CHECK-NEXT:    [[TOBOOL24:%.*]] = or i1 [[TOBOOL22]], [[TOBOOL23]], !dbg [[DBG73]]
// CHECK-NEXT:    [[FROMBOOL25:%.*]] = zext i1 [[TOBOOL24]] to i8, !dbg [[DBG74:![0-9]+]]
// CHECK-NEXT:    store atomic i8 [[FROMBOOL25]], i8* @bx monotonic, align 1, !dbg [[DBG74]]
// CHECK-NEXT:    [[CFV_REAL26:%.*]] = load float, float* getelementptr inbounds ({ float, float }, { float, float }* @cfv, i32 0, i32 0), align 4, !dbg [[DBG75:![0-9]+]]
// CHECK-NEXT:    [[CONV27:%.*]] = fptoui float [[CFV_REAL26]] to i16, !dbg [[DBG75]]
// CHECK-NEXT:    store atomic i16 [[CONV27]], i16* @usx monotonic, align 2, !dbg [[DBG76:![0-9]+]]
// CHECK-NEXT:    [[CDV_REAL28:%.*]] = load double, double* getelementptr inbounds ({ double, double }, { double, double }* @cdv, i32 0, i32 0), align 8, !dbg [[DBG77:![0-9]+]]
// CHECK-NEXT:    [[CONV29:%.*]] = fptosi double [[CDV_REAL28]] to i64, !dbg [[DBG77]]
// CHECK-NEXT:    store atomic i64 [[CONV29]], i64* @llx monotonic, align 8, !dbg [[DBG78:![0-9]+]]
// CHECK-NEXT:    [[TMP41:%.*]] = load i16, i16* @sv, align 2, !dbg [[DBG79:![0-9]+]]
// CHECK-NEXT:    [[TMP42:%.*]] = load i8, i8* @bv, align 1, !dbg [[DBG80:![0-9]+]]
// CHECK-NEXT:    [[TOBOOL30:%.*]] = trunc i8 [[TMP42]] to i1, !dbg [[DBG80]]
// CHECK-NEXT:    [[CONV31:%.*]] = zext i1 [[TOBOOL30]] to i32, !dbg [[DBG80]]
// CHECK-NEXT:    [[TMP43:%.*]] = bitcast <4 x i32>* [[ATOMIC_TEMP32]] to i8*, !dbg [[DBG81:![0-9]+]]
// CHECK-NEXT:    call void @__atomic_load(i64 noundef 16, i8* noundef bitcast (<4 x i32>* @int4x to i8*), i8* noundef [[TMP43]], i32 noundef 0), !dbg [[DBG81]]
// CHECK-NEXT:    br label [[ATOMIC_CONT:%.*]], !dbg [[DBG81]]
// CHECK:       atomic_cont:
// CHECK-NEXT:    [[TMP44:%.*]] = load <4 x i32>, <4 x i32>* [[ATOMIC_TEMP32]], align 16, !dbg [[DBG81]]
// CHECK-NEXT:    store <4 x i32> [[TMP44]], <4 x i32>* [[ATOMIC_TEMP33]], align 16, !dbg [[DBG81]]
// CHECK-NEXT:    [[TMP45:%.*]] = load <4 x i32>, <4 x i32>* [[ATOMIC_TEMP33]], align 16, !dbg [[DBG81]]
// CHECK-NEXT:    [[VECINS:%.*]] = insertelement <4 x i32> [[TMP45]], i32 [[CONV31]], i16 [[TMP41]], !dbg [[DBG81]]
// CHECK-NEXT:    store <4 x i32> [[VECINS]], <4 x i32>* [[ATOMIC_TEMP33]], align 16, !dbg [[DBG81]]
// CHECK-NEXT:    [[TMP46:%.*]] = bitcast <4 x i32>* [[ATOMIC_TEMP32]] to i8*, !dbg [[DBG81]]
// CHECK-NEXT:    [[TMP47:%.*]] = bitcast <4 x i32>* [[ATOMIC_TEMP33]] to i8*, !dbg [[DBG81]]
// CHECK-NEXT:    [[CALL:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, i8* noundef bitcast (<4 x i32>* @int4x to i8*), i8* noundef [[TMP46]], i8* noundef [[TMP47]], i32 noundef 0, i32 noundef 0), !dbg [[DBG81]]
// CHECK-NEXT:    br i1 [[CALL]], label [[ATOMIC_EXIT:%.*]], label [[ATOMIC_CONT]], !dbg [[DBG81]]
// CHECK:       atomic_exit:
// CHECK-NEXT:    [[TMP48:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG82:![0-9]+]]
// CHECK-NEXT:    [[CONV34:%.*]] = fptosi x86_fp80 [[TMP48]] to i32, !dbg [[DBG82]]
// CHECK-NEXT:    [[ATOMIC_LOAD:%.*]] = load atomic i32, i32* bitcast (i8* getelementptr (i8, i8* bitcast (%struct.BitFields* @bfx to i8*), i64 4) to i32*) monotonic, align 4, !dbg [[DBG83:![0-9]+]]
// CHECK-NEXT:    br label [[ATOMIC_CONT35:%.*]], !dbg [[DBG83]]
// CHECK:       atomic_cont35:
// CHECK-NEXT:    [[TMP49:%.*]] = phi i32 [ [[ATOMIC_LOAD]], [[ATOMIC_EXIT]] ], [ [[TMP52:%.*]], [[ATOMIC_CONT35]] ], !dbg [[DBG83]]
// CHECK-NEXT:    store i32 [[TMP49]], i32* [[ATOMIC_TEMP36]], align 4, !dbg [[DBG83]]
// CHECK-NEXT:    [[BF_LOAD:%.*]] = load i32, i32* [[ATOMIC_TEMP36]], align 4, !dbg [[DBG83]]
// CHECK-NEXT:    [[BF_VALUE:%.*]] = and i32 [[CONV34]], 2147483647, !dbg [[DBG83]]
// CHECK-NEXT:    [[BF_CLEAR:%.*]] = and i32 [[BF_LOAD]], -2147483648, !dbg [[DBG83]]
// CHECK-NEXT:    [[BF_SET:%.*]] = or i32 [[BF_CLEAR]], [[BF_VALUE]], !dbg [[DBG83]]
// CHECK-NEXT:    store i32 [[BF_SET]], i32* [[ATOMIC_TEMP36]], align 4, !dbg [[DBG83]]
// CHECK-NEXT:    [[TMP50:%.*]] = load i32, i32* [[ATOMIC_TEMP36]], align 4, !dbg [[DBG83]]
// CHECK-NEXT:    [[TMP51:%.*]] = cmpxchg i32* bitcast (i8* getelementptr (i8, i8* bitcast (%struct.BitFields* @bfx to i8*), i64 4) to i32*), i32 [[TMP49]], i32 [[TMP50]] monotonic monotonic, align 4, !dbg [[DBG83]]
// CHECK-NEXT:    [[TMP52]] = extractvalue { i32, i1 } [[TMP51]], 0, !dbg [[DBG83]]
// CHECK-NEXT:    [[TMP53:%.*]] = extractvalue { i32, i1 } [[TMP51]], 1, !dbg [[DBG83]]
// CHECK-NEXT:    br i1 [[TMP53]], label [[ATOMIC_EXIT37:%.*]], label [[ATOMIC_CONT35]], !dbg [[DBG83]]
// CHECK:       atomic_exit37:
// CHECK-NEXT:    [[TMP54:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG84:![0-9]+]]
// CHECK-NEXT:    [[CONV38:%.*]] = fptosi x86_fp80 [[TMP54]] to i32, !dbg [[DBG84]]
// CHECK-NEXT:    [[TMP55:%.*]] = bitcast i32* [[ATOMIC_TEMP39]] to i8*, !dbg [[DBG85:![0-9]+]]
// CHECK-NEXT:    call void @__atomic_load(i64 noundef 4, i8* noundef getelementptr (i8, i8* bitcast (%struct.BitFields_packed* @bfx_packed to i8*), i64 4), i8* noundef [[TMP55]], i32 noundef 0), !dbg [[DBG85]]
// CHECK-NEXT:    br label [[ATOMIC_CONT40:%.*]], !dbg [[DBG85]]
// CHECK:       atomic_cont40:
// CHECK-NEXT:    [[TMP56:%.*]] = load i32, i32* [[ATOMIC_TEMP39]], align 1, !dbg [[DBG85]]
// CHECK-NEXT:    store i32 [[TMP56]], i32* [[ATOMIC_TEMP41]], align 1, !dbg [[DBG85]]
// CHECK-NEXT:    [[BF_LOAD42:%.*]] = load i32, i32* [[ATOMIC_TEMP41]], align 1, !dbg [[DBG85]]
// CHECK-NEXT:    [[BF_VALUE43:%.*]] = and i32 [[CONV38]], 2147483647, !dbg [[DBG85]]
// CHECK-NEXT:    [[BF_CLEAR44:%.*]] = and i32 [[BF_LOAD42]], -2147483648, !dbg [[DBG85]]
// CHECK-NEXT:    [[BF_SET45:%.*]] = or i32 [[BF_CLEAR44]], [[BF_VALUE43]], !dbg [[DBG85]]
// CHECK-NEXT:    store i32 [[BF_SET45]], i32* [[ATOMIC_TEMP41]], align 1, !dbg [[DBG85]]
// CHECK-NEXT:    [[TMP57:%.*]] = bitcast i32* [[ATOMIC_TEMP39]] to i8*, !dbg [[DBG85]]
// CHECK-NEXT:    [[TMP58:%.*]] = bitcast i32* [[ATOMIC_TEMP41]] to i8*, !dbg [[DBG85]]
// CHECK-NEXT:    [[CALL46:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 4, i8* noundef getelementptr (i8, i8* bitcast (%struct.BitFields_packed* @bfx_packed to i8*), i64 4), i8* noundef [[TMP57]], i8* noundef [[TMP58]], i32 noundef 0, i32 noundef 0), !dbg [[DBG85]]
// CHECK-NEXT:    br i1 [[CALL46]], label [[ATOMIC_EXIT47:%.*]], label [[ATOMIC_CONT40]], !dbg [[DBG85]]
// CHECK:       atomic_exit47:
// CHECK-NEXT:    [[TMP59:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG86:![0-9]+]]
// CHECK-NEXT:    [[CONV48:%.*]] = fptosi x86_fp80 [[TMP59]] to i32, !dbg [[DBG86]]
// CHECK-NEXT:    [[ATOMIC_LOAD49:%.*]] = load atomic i32, i32* getelementptr inbounds ([[STRUCT_BITFIELDS2:%.*]], %struct.BitFields2* @bfx2, i32 0, i32 0) monotonic, align 4, !dbg [[DBG87:![0-9]+]]
// CHECK-NEXT:    br label [[ATOMIC_CONT50:%.*]], !dbg [[DBG87]]
// CHECK:       atomic_cont50:
// CHECK-NEXT:    [[TMP60:%.*]] = phi i32 [ [[ATOMIC_LOAD49]], [[ATOMIC_EXIT47]] ], [ [[TMP63:%.*]], [[ATOMIC_CONT50]] ], !dbg [[DBG87]]
// CHECK-NEXT:    store i32 [[TMP60]], i32* [[ATOMIC_TEMP51]], align 4, !dbg [[DBG87]]
// CHECK-NEXT:    [[BF_LOAD52:%.*]] = load i32, i32* [[ATOMIC_TEMP51]], align 4, !dbg [[DBG87]]
// CHECK-NEXT:    [[BF_VALUE53:%.*]] = and i32 [[CONV48]], 1, !dbg [[DBG87]]
// CHECK-NEXT:    [[BF_SHL:%.*]] = shl i32 [[BF_VALUE53]], 31, !dbg [[DBG87]]
// CHECK-NEXT:    [[BF_CLEAR54:%.*]] = and i32 [[BF_LOAD52]], 2147483647, !dbg [[DBG87]]
// CHECK-NEXT:    [[BF_SET55:%.*]] = or i32 [[BF_CLEAR54]], [[BF_SHL]], !dbg [[DBG87]]
// CHECK-NEXT:    store i32 [[BF_SET55]], i32* [[ATOMIC_TEMP51]], align 4, !dbg [[DBG87]]
// CHECK-NEXT:    [[TMP61:%.*]] = load i32, i32* [[ATOMIC_TEMP51]], align 4, !dbg [[DBG87]]
// CHECK-NEXT:    [[TMP62:%.*]] = cmpxchg i32* getelementptr inbounds ([[STRUCT_BITFIELDS2]], %struct.BitFields2* @bfx2, i32 0, i32 0), i32 [[TMP60]], i32 [[TMP61]] monotonic monotonic, align 4, !dbg [[DBG87]]
// CHECK-NEXT:    [[TMP63]] = extractvalue { i32, i1 } [[TMP62]], 0, !dbg [[DBG87]]
// CHECK-NEXT:    [[TMP64:%.*]] = extractvalue { i32, i1 } [[TMP62]], 1, !dbg [[DBG87]]
// CHECK-NEXT:    br i1 [[TMP64]], label [[ATOMIC_EXIT56:%.*]], label [[ATOMIC_CONT50]], !dbg [[DBG87]]
// CHECK:       atomic_exit56:
// CHECK-NEXT:    [[TMP65:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG88:![0-9]+]]
// CHECK-NEXT:    [[CONV57:%.*]] = fptosi x86_fp80 [[TMP65]] to i32, !dbg [[DBG88]]
// CHECK-NEXT:    [[ATOMIC_LOAD58:%.*]] = load atomic i8, i8* getelementptr (i8, i8* bitcast (%struct.BitFields2_packed* @bfx2_packed to i8*), i64 3) monotonic, align 1, !dbg [[DBG89:![0-9]+]]
// CHECK-NEXT:    br label [[ATOMIC_CONT59:%.*]], !dbg [[DBG89]]
// CHECK:       atomic_cont59:
// CHECK-NEXT:    [[TMP66:%.*]] = phi i8 [ [[ATOMIC_LOAD58]], [[ATOMIC_EXIT56]] ], [ [[TMP71:%.*]], [[ATOMIC_CONT59]] ], !dbg [[DBG89]]
// CHECK-NEXT:    [[TMP67:%.*]] = bitcast i32* [[ATOMIC_TEMP60]] to i8*, !dbg [[DBG89]]
// CHECK-NEXT:    store i8 [[TMP66]], i8* [[TMP67]], align 1, !dbg [[DBG89]]
// CHECK-NEXT:    [[TMP68:%.*]] = trunc i32 [[CONV57]] to i8, !dbg [[DBG89]]
// CHECK-NEXT:    [[BF_LOAD61:%.*]] = load i8, i8* [[TMP67]], align 1, !dbg [[DBG89]]
// CHECK-NEXT:    [[BF_VALUE62:%.*]] = and i8 [[TMP68]], 1, !dbg [[DBG89]]
// CHECK-NEXT:    [[BF_SHL63:%.*]] = shl i8 [[BF_VALUE62]], 7, !dbg [[DBG89]]
// CHECK-NEXT:    [[BF_CLEAR64:%.*]] = and i8 [[BF_LOAD61]], 127, !dbg [[DBG89]]
// CHECK-NEXT:    [[BF_SET65:%.*]] = or i8 [[BF_CLEAR64]], [[BF_SHL63]], !dbg [[DBG89]]
// CHECK-NEXT:    store i8 [[BF_SET65]], i8* [[TMP67]], align 1, !dbg [[DBG89]]
// CHECK-NEXT:    [[TMP69:%.*]] = load i8, i8* [[TMP67]], align 1, !dbg [[DBG89]]
// CHECK-NEXT:    [[TMP70:%.*]] = cmpxchg i8* getelementptr (i8, i8* bitcast (%struct.BitFields2_packed* @bfx2_packed to i8*), i64 3), i8 [[TMP66]], i8 [[TMP69]] monotonic monotonic, align 1, !dbg [[DBG89]]
// CHECK-NEXT:    [[TMP71]] = extractvalue { i8, i1 } [[TMP70]], 0, !dbg [[DBG89]]
// CHECK-NEXT:    [[TMP72:%.*]] = extractvalue { i8, i1 } [[TMP70]], 1, !dbg [[DBG89]]
// CHECK-NEXT:    br i1 [[TMP72]], label [[ATOMIC_EXIT66:%.*]], label [[ATOMIC_CONT59]], !dbg [[DBG89]]
// CHECK:       atomic_exit66:
// CHECK-NEXT:    [[TMP73:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG90:![0-9]+]]
// CHECK-NEXT:    [[CONV67:%.*]] = fptosi x86_fp80 [[TMP73]] to i32, !dbg [[DBG90]]
// CHECK-NEXT:    [[ATOMIC_LOAD68:%.*]] = load atomic i32, i32* getelementptr inbounds ([[STRUCT_BITFIELDS3:%.*]], %struct.BitFields3* @bfx3, i32 0, i32 0) monotonic, align 4, !dbg [[DBG91:![0-9]+]]
// CHECK-NEXT:    br label [[ATOMIC_CONT69:%.*]], !dbg [[DBG91]]
// CHECK:       atomic_cont69:
// CHECK-NEXT:    [[TMP74:%.*]] = phi i32 [ [[ATOMIC_LOAD68]], [[ATOMIC_EXIT66]] ], [ [[TMP77:%.*]], [[ATOMIC_CONT69]] ], !dbg [[DBG91]]
// CHECK-NEXT:    store i32 [[TMP74]], i32* [[ATOMIC_TEMP70]], align 4, !dbg [[DBG91]]
// CHECK-NEXT:    [[BF_LOAD71:%.*]] = load i32, i32* [[ATOMIC_TEMP70]], align 4, !dbg [[DBG91]]
// CHECK-NEXT:    [[BF_VALUE72:%.*]] = and i32 [[CONV67]], 16383, !dbg [[DBG91]]
// CHECK-NEXT:    [[BF_SHL73:%.*]] = shl i32 [[BF_VALUE72]], 11, !dbg [[DBG91]]
// CHECK-NEXT:    [[BF_CLEAR74:%.*]] = and i32 [[BF_LOAD71]], -33552385, !dbg [[DBG91]]
// CHECK-NEXT:    [[BF_SET75:%.*]] = or i32 [[BF_CLEAR74]], [[BF_SHL73]], !dbg [[DBG91]]
// CHECK-NEXT:    store i32 [[BF_SET75]], i32* [[ATOMIC_TEMP70]], align 4, !dbg [[DBG91]]
// CHECK-NEXT:    [[TMP75:%.*]] = load i32, i32* [[ATOMIC_TEMP70]], align 4, !dbg [[DBG91]]
// CHECK-NEXT:    [[TMP76:%.*]] = cmpxchg i32* getelementptr inbounds ([[STRUCT_BITFIELDS3]], %struct.BitFields3* @bfx3, i32 0, i32 0), i32 [[TMP74]], i32 [[TMP75]] monotonic monotonic, align 4, !dbg [[DBG91]]
// CHECK-NEXT:    [[TMP77]] = extractvalue { i32, i1 } [[TMP76]], 0, !dbg [[DBG91]]
// CHECK-NEXT:    [[TMP78:%.*]] = extractvalue { i32, i1 } [[TMP76]], 1, !dbg [[DBG91]]
// CHECK-NEXT:    br i1 [[TMP78]], label [[ATOMIC_EXIT76:%.*]], label [[ATOMIC_CONT69]], !dbg [[DBG91]]
// CHECK:       atomic_exit76:
// CHECK-NEXT:    [[TMP79:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG92:![0-9]+]]
// CHECK-NEXT:    [[CONV77:%.*]] = fptosi x86_fp80 [[TMP79]] to i32, !dbg [[DBG92]]
// CHECK-NEXT:    [[TMP80:%.*]] = bitcast i32* [[ATOMIC_TEMP78]] to i24*, !dbg [[DBG93:![0-9]+]]
// CHECK-NEXT:    [[TMP81:%.*]] = bitcast i24* [[TMP80]] to i8*, !dbg [[DBG93]]
// CHECK-NEXT:    call void @__atomic_load(i64 noundef 3, i8* noundef getelementptr (i8, i8* bitcast (%struct.BitFields3_packed* @bfx3_packed to i8*), i64 1), i8* noundef [[TMP81]], i32 noundef 0), !dbg [[DBG93]]
// CHECK-NEXT:    br label [[ATOMIC_CONT79:%.*]], !dbg [[DBG93]]
// CHECK:       atomic_cont79:
// CHECK-NEXT:    [[TMP82:%.*]] = bitcast i32* [[ATOMIC_TEMP80]] to i24*, !dbg [[DBG93]]
// CHECK-NEXT:    [[TMP83:%.*]] = load i24, i24* [[TMP80]], align 1, !dbg [[DBG93]]
// CHECK-NEXT:    store i24 [[TMP83]], i24* [[TMP82]], align 1, !dbg [[DBG93]]
// CHECK-NEXT:    [[TMP84:%.*]] = trunc i32 [[CONV77]] to i24, !dbg [[DBG93]]
// CHECK-NEXT:    [[BF_LOAD81:%.*]] = load i24, i24* [[TMP82]], align 1, !dbg [[DBG93]]
// CHECK-NEXT:    [[BF_VALUE82:%.*]] = and i24 [[TMP84]], 16383, !dbg [[DBG93]]
// CHECK-NEXT:    [[BF_SHL83:%.*]] = shl i24 [[BF_VALUE82]], 3, !dbg [[DBG93]]
// CHECK-NEXT:    [[BF_CLEAR84:%.*]] = and i24 [[BF_LOAD81]], -131065, !dbg [[DBG93]]
// CHECK-NEXT:    [[BF_SET85:%.*]] = or i24 [[BF_CLEAR84]], [[BF_SHL83]], !dbg [[DBG93]]
// CHECK-NEXT:    store i24 [[BF_SET85]], i24* [[TMP82]], align 1, !dbg [[DBG93]]
// CHECK-NEXT:    [[TMP85:%.*]] = bitcast i24* [[TMP80]] to i8*, !dbg [[DBG93]]
// CHECK-NEXT:    [[TMP86:%.*]] = bitcast i24* [[TMP82]] to i8*, !dbg [[DBG93]]
// CHECK-NEXT:    [[CALL86:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 3, i8* noundef getelementptr (i8, i8* bitcast (%struct.BitFields3_packed* @bfx3_packed to i8*), i64 1), i8* noundef [[TMP85]], i8* noundef [[TMP86]], i32 noundef 0, i32 noundef 0), !dbg [[DBG93]]
// CHECK-NEXT:    br i1 [[CALL86]], label [[ATOMIC_EXIT87:%.*]], label [[ATOMIC_CONT79]], !dbg [[DBG93]]
// CHECK:       atomic_exit87:
// CHECK-NEXT:    [[TMP87:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG94:![0-9]+]]
// CHECK-NEXT:    [[CONV88:%.*]] = fptosi x86_fp80 [[TMP87]] to i32, !dbg [[DBG94]]
// CHECK-NEXT:    [[ATOMIC_LOAD89:%.*]] = load atomic i64, i64* bitcast (%struct.BitFields4* @bfx4 to i64*) monotonic, align 8, !dbg [[DBG95:![0-9]+]]
// CHECK-NEXT:    br label [[ATOMIC_CONT90:%.*]], !dbg [[DBG95]]
// CHECK:       atomic_cont90:
// CHECK-NEXT:    [[TMP88:%.*]] = phi i64 [ [[ATOMIC_LOAD89]], [[ATOMIC_EXIT87]] ], [ [[TMP92:%.*]], [[ATOMIC_CONT90]] ], !dbg [[DBG95]]
// CHECK-NEXT:    store i64 [[TMP88]], i64* [[ATOMIC_TEMP91]], align 8, !dbg [[DBG95]]
// CHECK-NEXT:    [[TMP89:%.*]] = zext i32 [[CONV88]] to i64, !dbg [[DBG95]]
// CHECK-NEXT:    [[BF_LOAD92:%.*]] = load i64, i64* [[ATOMIC_TEMP91]], align 8, !dbg [[DBG95]]
// CHECK-NEXT:    [[BF_VALUE93:%.*]] = and i64 [[TMP89]], 1, !dbg [[DBG95]]
// CHECK-NEXT:    [[BF_SHL94:%.*]] = shl i64 [[BF_VALUE93]], 16, !dbg [[DBG95]]
// CHECK-NEXT:    [[BF_CLEAR95:%.*]] = and i64 [[BF_LOAD92]], -65537, !dbg [[DBG95]]
// CHECK-NEXT:    [[BF_SET96:%.*]] = or i64 [[BF_CLEAR95]], [[BF_SHL94]], !dbg [[DBG95]]
// CHECK-NEXT:    store i64 [[BF_SET96]], i64* [[ATOMIC_TEMP91]], align 8, !dbg [[DBG95]]
// CHECK-NEXT:    [[TMP90:%.*]] = load i64, i64* [[ATOMIC_TEMP91]], align 8, !dbg [[DBG95]]
// CHECK-NEXT:    [[TMP91:%.*]] = cmpxchg i64* bitcast (%struct.BitFields4* @bfx4 to i64*), i64 [[TMP88]], i64 [[TMP90]] monotonic monotonic, align 8, !dbg [[DBG95]]
// CHECK-NEXT:    [[TMP92]] = extractvalue { i64, i1 } [[TMP91]], 0, !dbg [[DBG95]]
// CHECK-NEXT:    [[TMP93:%.*]] = extractvalue { i64, i1 } [[TMP91]], 1, !dbg [[DBG95]]
// CHECK-NEXT:    br i1 [[TMP93]], label [[ATOMIC_EXIT97:%.*]], label [[ATOMIC_CONT90]], !dbg [[DBG95]]
// CHECK:       atomic_exit97:
// CHECK-NEXT:    [[TMP94:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG96:![0-9]+]]
// CHECK-NEXT:    [[CONV98:%.*]] = fptosi x86_fp80 [[TMP94]] to i32, !dbg [[DBG96]]
// CHECK-NEXT:    [[ATOMIC_LOAD99:%.*]] = load atomic i8, i8* getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED:%.*]], %struct.BitFields4_packed* @bfx4_packed, i32 0, i32 0, i64 2) monotonic, align 1, !dbg [[DBG97:![0-9]+]]
// CHECK-NEXT:    br label [[ATOMIC_CONT100:%.*]], !dbg [[DBG97]]
// CHECK:       atomic_cont100:
// CHECK-NEXT:    [[TMP95:%.*]] = phi i8 [ [[ATOMIC_LOAD99]], [[ATOMIC_EXIT97]] ], [ [[TMP100:%.*]], [[ATOMIC_CONT100]] ], !dbg [[DBG97]]
// CHECK-NEXT:    [[TMP96:%.*]] = bitcast i32* [[ATOMIC_TEMP101]] to i8*, !dbg [[DBG97]]
// CHECK-NEXT:    store i8 [[TMP95]], i8* [[TMP96]], align 1, !dbg [[DBG97]]
// CHECK-NEXT:    [[TMP97:%.*]] = trunc i32 [[CONV98]] to i8, !dbg [[DBG97]]
// CHECK-NEXT:    [[BF_LOAD102:%.*]] = load i8, i8* [[TMP96]], align 1, !dbg [[DBG97]]
// CHECK-NEXT:    [[BF_VALUE103:%.*]] = and i8 [[TMP97]], 1, !dbg [[DBG97]]
// CHECK-NEXT:    [[BF_CLEAR104:%.*]] = and i8 [[BF_LOAD102]], -2, !dbg [[DBG97]]
// CHECK-NEXT:    [[BF_SET105:%.*]] = or i8 [[BF_CLEAR104]], [[BF_VALUE103]], !dbg [[DBG97]]
// CHECK-NEXT:    store i8 [[BF_SET105]], i8* [[TMP96]], align 1, !dbg [[DBG97]]
// CHECK-NEXT:    [[TMP98:%.*]] = load i8, i8* [[TMP96]], align 1, !dbg [[DBG97]]
// CHECK-NEXT:    [[TMP99:%.*]] = cmpxchg i8* getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED]], %struct.BitFields4_packed* @bfx4_packed, i32 0, i32 0, i64 2), i8 [[TMP95]], i8 [[TMP98]] monotonic monotonic, align 1, !dbg [[DBG97]]
// CHECK-NEXT:    [[TMP100]] = extractvalue { i8, i1 } [[TMP99]], 0, !dbg [[DBG97]]
// CHECK-NEXT:    [[TMP101:%.*]] = extractvalue { i8, i1 } [[TMP99]], 1, !dbg [[DBG97]]
// CHECK-NEXT:    br i1 [[TMP101]], label [[ATOMIC_EXIT106:%.*]], label [[ATOMIC_CONT100]], !dbg [[DBG97]]
// CHECK:       atomic_exit106:
// CHECK-NEXT:    [[TMP102:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG98:![0-9]+]]
// CHECK-NEXT:    [[CONV107:%.*]] = fptosi x86_fp80 [[TMP102]] to i64, !dbg [[DBG98]]
// CHECK-NEXT:    [[ATOMIC_LOAD108:%.*]] = load atomic i64, i64* bitcast (%struct.BitFields4* @bfx4 to i64*) monotonic, align 8, !dbg [[DBG99:![0-9]+]]
// CHECK-NEXT:    br label [[ATOMIC_CONT109:%.*]], !dbg [[DBG99]]
// CHECK:       atomic_cont109:
// CHECK-NEXT:    [[TMP103:%.*]] = phi i64 [ [[ATOMIC_LOAD108]], [[ATOMIC_EXIT106]] ], [ [[TMP106:%.*]], [[ATOMIC_CONT109]] ], !dbg [[DBG99]]
// CHECK-NEXT:    store i64 [[TMP103]], i64* [[ATOMIC_TEMP110]], align 8, !dbg [[DBG99]]
// CHECK-NEXT:    [[BF_LOAD111:%.*]] = load i64, i64* [[ATOMIC_TEMP110]], align 8, !dbg [[DBG99]]
// CHECK-NEXT:    [[BF_VALUE112:%.*]] = and i64 [[CONV107]], 127, !dbg [[DBG99]]
// CHECK-NEXT:    [[BF_SHL113:%.*]] = shl i64 [[BF_VALUE112]], 17, !dbg [[DBG99]]
// CHECK-NEXT:    [[BF_CLEAR114:%.*]] = and i64 [[BF_LOAD111]], -16646145, !dbg [[DBG99]]
// CHECK-NEXT:    [[BF_SET115:%.*]] = or i64 [[BF_CLEAR114]], [[BF_SHL113]], !dbg [[DBG99]]
// CHECK-NEXT:    store i64 [[BF_SET115]], i64* [[ATOMIC_TEMP110]], align 8, !dbg [[DBG99]]
// CHECK-NEXT:    [[TMP104:%.*]] = load i64, i64* [[ATOMIC_TEMP110]], align 8, !dbg [[DBG99]]
// CHECK-NEXT:    [[TMP105:%.*]] = cmpxchg i64* bitcast (%struct.BitFields4* @bfx4 to i64*), i64 [[TMP103]], i64 [[TMP104]] monotonic monotonic, align 8, !dbg [[DBG99]]
// CHECK-NEXT:    [[TMP106]] = extractvalue { i64, i1 } [[TMP105]], 0, !dbg [[DBG99]]
// CHECK-NEXT:    [[TMP107:%.*]] = extractvalue { i64, i1 } [[TMP105]], 1, !dbg [[DBG99]]
// CHECK-NEXT:    br i1 [[TMP107]], label [[ATOMIC_EXIT116:%.*]], label [[ATOMIC_CONT109]], !dbg [[DBG99]]
// CHECK:       atomic_exit116:
// CHECK-NEXT:    [[TMP108:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG100:![0-9]+]]
// CHECK-NEXT:    [[CONV117:%.*]] = fptosi x86_fp80 [[TMP108]] to i64, !dbg [[DBG100]]
// CHECK-NEXT:    [[ATOMIC_LOAD118:%.*]] = load atomic i8, i8* getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED]], %struct.BitFields4_packed* @bfx4_packed, i32 0, i32 0, i64 2) monotonic, align 1, !dbg [[DBG101:![0-9]+]]
// CHECK-NEXT:    br label [[ATOMIC_CONT119:%.*]], !dbg [[DBG101]]
// CHECK:       atomic_cont119:
// CHECK-NEXT:    [[TMP109:%.*]] = phi i8 [ [[ATOMIC_LOAD118]], [[ATOMIC_EXIT116]] ], [ [[TMP114:%.*]], [[ATOMIC_CONT119]] ], !dbg [[DBG101]]
// CHECK-NEXT:    [[TMP110:%.*]] = bitcast i64* [[ATOMIC_TEMP120]] to i8*, !dbg [[DBG101]]
// CHECK-NEXT:    store i8 [[TMP109]], i8* [[TMP110]], align 1, !dbg [[DBG101]]
// CHECK-NEXT:    [[TMP111:%.*]] = trunc i64 [[CONV117]] to i8, !dbg [[DBG101]]
// CHECK-NEXT:    [[BF_LOAD121:%.*]] = load i8, i8* [[TMP110]], align 1, !dbg [[DBG101]]
// CHECK-NEXT:    [[BF_VALUE122:%.*]] = and i8 [[TMP111]], 127, !dbg [[DBG101]]
// CHECK-NEXT:    [[BF_SHL123:%.*]] = shl i8 [[BF_VALUE122]], 1, !dbg [[DBG101]]
// CHECK-NEXT:    [[BF_CLEAR124:%.*]] = and i8 [[BF_LOAD121]], 1, !dbg [[DBG101]]
// CHECK-NEXT:    [[BF_SET125:%.*]] = or i8 [[BF_CLEAR124]], [[BF_SHL123]], !dbg [[DBG101]]
// CHECK-NEXT:    store i8 [[BF_SET125]], i8* [[TMP110]], align 1, !dbg [[DBG101]]
// CHECK-NEXT:    [[TMP112:%.*]] = load i8, i8* [[TMP110]], align 1, !dbg [[DBG101]]
// CHECK-NEXT:    [[TMP113:%.*]] = cmpxchg i8* getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED]], %struct.BitFields4_packed* @bfx4_packed, i32 0, i32 0, i64 2), i8 [[TMP109]], i8 [[TMP112]] monotonic monotonic, align 1, !dbg [[DBG101]]
// CHECK-NEXT:    [[TMP114]] = extractvalue { i8, i1 } [[TMP113]], 0, !dbg [[DBG101]]
// CHECK-NEXT:    [[TMP115:%.*]] = extractvalue { i8, i1 } [[TMP113]], 1, !dbg [[DBG101]]
// CHECK-NEXT:    br i1 [[TMP115]], label [[ATOMIC_EXIT126:%.*]], label [[ATOMIC_CONT119]], !dbg [[DBG101]]
// CHECK:       atomic_exit126:
// CHECK-NEXT:    [[TMP116:%.*]] = load i64, i64* @ulv, align 8, !dbg [[DBG102:![0-9]+]]
// CHECK-NEXT:    [[CONV127:%.*]] = uitofp i64 [[TMP116]] to float, !dbg [[DBG102]]
// CHECK-NEXT:    [[ATOMIC_LOAD128:%.*]] = load atomic i64, i64* bitcast (<2 x float>* @float2x to i64*) monotonic, align 8, !dbg [[DBG103:![0-9]+]]
// CHECK-NEXT:    br label [[ATOMIC_CONT129:%.*]], !dbg [[DBG103]]
// CHECK:       atomic_cont129:
// CHECK-NEXT:    [[TMP117:%.*]] = phi i64 [ [[ATOMIC_LOAD128]], [[ATOMIC_EXIT126]] ], [ [[TMP123:%.*]], [[ATOMIC_CONT129]] ], !dbg [[DBG103]]
// CHECK-NEXT:    [[TMP118:%.*]] = bitcast <2 x float>* [[ATOMIC_TEMP130]] to i64*, !dbg [[DBG103]]
// CHECK-NEXT:    store i64 [[TMP117]], i64* [[TMP118]], align 8, !dbg [[DBG103]]
// CHECK-NEXT:    [[TMP119:%.*]] = load <2 x float>, <2 x float>* [[ATOMIC_TEMP130]], align 8, !dbg [[DBG103]]
// CHECK-NEXT:    [[TMP120:%.*]] = insertelement <2 x float> [[TMP119]], float [[CONV127]], i64 0, !dbg [[DBG103]]
// CHECK-NEXT:    store <2 x float> [[TMP120]], <2 x float>* [[ATOMIC_TEMP130]], align 8, !dbg [[DBG103]]
// CHECK-NEXT:    [[TMP121:%.*]] = load i64, i64* [[TMP118]], align 8, !dbg [[DBG103]]
// CHECK-NEXT:    [[TMP122:%.*]] = cmpxchg i64* bitcast (<2 x float>* @float2x to i64*), i64 [[TMP117]], i64 [[TMP121]] monotonic monotonic, align 8, !dbg [[DBG103]]
// CHECK-NEXT:    [[TMP123]] = extractvalue { i64, i1 } [[TMP122]], 0, !dbg [[DBG103]]
// CHECK-NEXT:    [[TMP124:%.*]] = extractvalue { i64, i1 } [[TMP122]], 1, !dbg [[DBG103]]
// CHECK-NEXT:    br i1 [[TMP124]], label [[ATOMIC_EXIT131:%.*]], label [[ATOMIC_CONT129]], !dbg [[DBG103]]
// CHECK:       atomic_exit131:
// CHECK-NEXT:    [[TMP125:%.*]] = call i32 @llvm.read_register.i32(metadata [[META2:![0-9]+]]), !dbg [[DBG104:![0-9]+]]
// CHECK-NEXT:    [[CONV132:%.*]] = sitofp i32 [[TMP125]] to double, !dbg [[DBG104]]
// CHECK-NEXT:    [[TMP126:%.*]] = bitcast double [[CONV132]] to i64, !dbg [[DBG105:![0-9]+]]
// CHECK-NEXT:    store atomic i64 [[TMP126]], i64* bitcast (double* @dv to i64*) seq_cst, align 8, !dbg [[DBG105]]
// CHECK-NEXT:    fence release
// CHECK-NEXT:    ret i32 0, !dbg [[DBG106:![0-9]+]]
//
int main(void) {
#pragma oss atomic write
 __imag(civ) = 1;
#pragma oss atomic write
  bx = bv;
#pragma oss atomic write release
  cx = cv;
#pragma oss atomic write
  ucx = ucv;
#pragma oss atomic write
  sx = sv;
#pragma oss atomic write
  usx = usv;
#pragma oss atomic write
  ix = iv;
#pragma oss atomic write
  uix = uiv;
#pragma oss atomic write
  lx = lv;
#pragma oss atomic write
  ulx = ulv;
#pragma oss atomic write
  llx = llv;
#pragma oss atomic write
  ullx = ullv;
#pragma oss atomic write
  fx = fv;
#pragma oss atomic write
  dx = dv;
#pragma oss atomic write
  ldx = ldv;
#pragma oss atomic write
  cix = civ;
#pragma oss atomic write
  cfx = cfv;
#pragma oss atomic seq_cst write
  cdx = cdv;
#pragma oss atomic write
  ulx = bv;
#pragma oss atomic write
  bx = cv;
#pragma oss atomic write, seq_cst
  cx = ucv;
#pragma oss atomic write
  ulx = sv;
#pragma oss atomic write
  lx = usv;
#pragma oss atomic seq_cst, write
  uix = iv;
#pragma oss atomic write
  ix = uiv;
#pragma oss atomic write
  cix = lv;
#pragma oss atomic write
  fx = ulv;
#pragma oss atomic write
  dx = llv;
#pragma oss atomic write
  ldx = ullv;
#pragma oss atomic write
  cix = fv;
#pragma oss atomic write
  sx = dv;
#pragma oss atomic write
  bx = ldv;
#pragma oss atomic write
  bx = civ;
#pragma oss atomic write
  usx = cfv;
#pragma oss atomic write
  llx = cdv;
#pragma oss atomic write
  int4x[sv] = bv;
#pragma oss atomic write
  bfx.a = ldv;
#pragma oss atomic write
  bfx_packed.a = ldv;
#pragma oss atomic write
  bfx2.a = ldv;
#pragma oss atomic write
  bfx2_packed.a = ldv;
#pragma oss atomic write
  bfx3.a = ldv;
#pragma oss atomic write
  bfx3_packed.a = ldv;
#pragma oss atomic write
  bfx4.a = ldv;
#pragma oss atomic write
  bfx4_packed.a = ldv;
#pragma oss atomic write
  bfx4.b = ldv;
#pragma oss atomic relaxed write
  bfx4_packed.b = ldv;
#pragma oss atomic write relaxed
  float2x.x = ulv;
#ifdef __x86_64__
#pragma oss atomic write seq_cst
  dv = rix;
#endif
  return 0;
}

#endif
