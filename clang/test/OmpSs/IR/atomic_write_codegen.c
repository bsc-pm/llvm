// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --function-signature --include-generated-funcs
// RUN: %clang_cc1 -x c -triple x86_64-gnu-linux -verify -fompss-2 -disable-llvm-passes -ferror-limit 100 %s -S -emit-llvm -o - | FileCheck %s --check-prefixes=LIN64
// RUN: %clang_cc1 -x c -triple ppc64 -verify -fompss-2 -disable-llvm-passes -ferror-limit 100 %s -S -emit-llvm -o - | FileCheck %s --check-prefixes=PPC64
// RUN: %clang_cc1 -x c -triple aarch64 -verify -fompss-2 -disable-llvm-passes -ferror-limit 100 %s -S -emit-llvm -o - | FileCheck %s --check-prefixes=AARCH64
// expected-no-diagnostics
#ifndef HEADER
#define HEADER

_Bool bv, bx;
char cv, cx;
unsigned char ucv, ucx;
short sv, sx;
unsigned short usv, usx;
int iv, ix;
unsigned int uiv, uix;
long lv, lx;
unsigned long ulv, ulx;
long long llv, llx;
unsigned long long ullv, ullx;
float fv, fx;
double dv, dx;
long double ldv, ldx;
_Complex int civ, cix;
_Complex float cfv, cfx;
_Complex double cdv, cdx;

typedef int int4 __attribute__((__vector_size__(16)));
int4 int4x;

struct BitFields {
  int : 32;
  int a : 31;
} bfx;

struct BitFields_packed {
  int : 32;
  int a : 31;
} __attribute__ ((__packed__)) bfx_packed;

struct BitFields2 {
  int : 31;
  int a : 1;
} bfx2;

struct BitFields2_packed {
  int : 31;
  int a : 1;
} __attribute__ ((__packed__)) bfx2_packed;

struct BitFields3 {
  int : 11;
  int a : 14;
} bfx3;

struct BitFields3_packed {
  int : 11;
  int a : 14;
} __attribute__ ((__packed__)) bfx3_packed;

struct BitFields4 {
  short : 16;
  int a: 1;
  long b : 7;
} bfx4;

struct BitFields4_packed {
  short : 16;
  int a: 1;
  long b : 7;
} __attribute__ ((__packed__)) bfx4_packed;

typedef float float2 __attribute__((ext_vector_type(2)));
float2 float2x;

#if defined(__x86_64__)
// Register "0" is currently an invalid register for global register variables.
// Use "esp" instead of "0".
// register int rix __asm__("0");
register int rix __asm__("esp");
#endif

int main(void) {
#pragma oss atomic write
 __imag(civ) = 1;
#pragma oss atomic write
  bx = bv;
#pragma oss atomic write release
  cx = cv;
#pragma oss atomic write
  ucx = ucv;
#pragma oss atomic write
  sx = sv;
#pragma oss atomic write
  usx = usv;
#pragma oss atomic write
  ix = iv;
#pragma oss atomic write
  uix = uiv;
#pragma oss atomic write
  lx = lv;
#pragma oss atomic write
  ulx = ulv;
#pragma oss atomic write
  llx = llv;
#pragma oss atomic write
  ullx = ullv;
#pragma oss atomic write
  fx = fv;
#pragma oss atomic write
  dx = dv;
#pragma oss atomic write
  ldx = ldv;
#pragma oss atomic write
  cix = civ;
#pragma oss atomic write
  cfx = cfv;
#pragma oss atomic seq_cst write
  cdx = cdv;
#pragma oss atomic write
  ulx = bv;
#pragma oss atomic write
  bx = cv;
#pragma oss atomic write, seq_cst
  cx = ucv;
#pragma oss atomic write
  ulx = sv;
#pragma oss atomic write
  lx = usv;
#pragma oss atomic seq_cst, write
  uix = iv;
#pragma oss atomic write
  ix = uiv;
#pragma oss atomic write
  cix = lv;
#pragma oss atomic write
  fx = ulv;
#pragma oss atomic write
  dx = llv;
#pragma oss atomic write
  ldx = ullv;
#pragma oss atomic write
  cix = fv;
#pragma oss atomic write
  sx = dv;
#pragma oss atomic write
  bx = ldv;
#pragma oss atomic write
  bx = civ;
#pragma oss atomic write
  usx = cfv;
#pragma oss atomic write
  llx = cdv;
#pragma oss atomic write
  int4x[sv] = bv;
#pragma oss atomic write
  bfx.a = ldv;
#pragma oss atomic write
  bfx_packed.a = ldv;
#pragma oss atomic write
  bfx2.a = ldv;
#pragma oss atomic write
  bfx2_packed.a = ldv;
#pragma oss atomic write
  bfx3.a = ldv;
#pragma oss atomic write
  bfx3_packed.a = ldv;
#pragma oss atomic write
  bfx4.a = ldv;
#pragma oss atomic write
  bfx4_packed.a = ldv;
#pragma oss atomic write
  bfx4.b = ldv;
#pragma oss atomic relaxed write
  bfx4_packed.b = ldv;
#pragma oss atomic write relaxed
  float2x.x = ulv;
#if defined(__x86_64__)
#pragma oss atomic write seq_cst
  dv = rix;
#endif
  return 0;
}

#endif
// LIN64-LABEL: define {{[^@]+}}@main
// LIN64-SAME: () #[[ATTR0:[0-9]+]] !dbg [[DBG6:![0-9]+]] {
// LIN64-NEXT:  entry:
// LIN64-NEXT:    [[RETVAL:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca x86_fp80, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP1:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP2:%.*]] = alloca { float, float }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP3:%.*]] = alloca { double, double }, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP10:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP14:%.*]] = alloca x86_fp80, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP16:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP32:%.*]] = alloca <4 x i32>, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP33:%.*]] = alloca <4 x i32>, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP36:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP39:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP41:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP51:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP60:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP70:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP78:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP80:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP91:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP101:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP110:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP120:%.*]] = alloca i64, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP130:%.*]] = alloca <2 x float>, align 8
// LIN64-NEXT:    store i32 0, ptr [[RETVAL]], align 4
// LIN64-NEXT:    store atomic i32 1, ptr getelementptr inbounds ({ i32, i32 }, ptr @civ, i32 0, i32 1) monotonic, align 4, !dbg [[DBG10:![0-9]+]]
// LIN64-NEXT:    [[TMP0:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG11:![0-9]+]]
// LIN64-NEXT:    [[TOBOOL:%.*]] = trunc i8 [[TMP0]] to i1, !dbg [[DBG11]]
// LIN64-NEXT:    [[FROMBOOL:%.*]] = zext i1 [[TOBOOL]] to i8, !dbg [[DBG12:![0-9]+]]
// LIN64-NEXT:    store atomic i8 [[FROMBOOL]], ptr @bx monotonic, align 1, !dbg [[DBG12]]
// LIN64-NEXT:    [[TMP1:%.*]] = load i8, ptr @cv, align 1, !dbg [[DBG13:![0-9]+]]
// LIN64-NEXT:    store atomic i8 [[TMP1]], ptr @cx release, align 1, !dbg [[DBG14:![0-9]+]]
// LIN64-NEXT:    fence release
// LIN64-NEXT:    [[TMP2:%.*]] = load i8, ptr @ucv, align 1, !dbg [[DBG15:![0-9]+]]
// LIN64-NEXT:    store atomic i8 [[TMP2]], ptr @ucx monotonic, align 1, !dbg [[DBG16:![0-9]+]]
// LIN64-NEXT:    [[TMP3:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG17:![0-9]+]]
// LIN64-NEXT:    store atomic i16 [[TMP3]], ptr @sx monotonic, align 2, !dbg [[DBG18:![0-9]+]]
// LIN64-NEXT:    [[TMP4:%.*]] = load i16, ptr @usv, align 2, !dbg [[DBG19:![0-9]+]]
// LIN64-NEXT:    store atomic i16 [[TMP4]], ptr @usx monotonic, align 2, !dbg [[DBG20:![0-9]+]]
// LIN64-NEXT:    [[TMP5:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG21:![0-9]+]]
// LIN64-NEXT:    store atomic i32 [[TMP5]], ptr @ix monotonic, align 4, !dbg [[DBG22:![0-9]+]]
// LIN64-NEXT:    [[TMP6:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG23:![0-9]+]]
// LIN64-NEXT:    store atomic i32 [[TMP6]], ptr @uix monotonic, align 4, !dbg [[DBG24:![0-9]+]]
// LIN64-NEXT:    [[TMP7:%.*]] = load i64, ptr @lv, align 8, !dbg [[DBG25:![0-9]+]]
// LIN64-NEXT:    store atomic i64 [[TMP7]], ptr @lx monotonic, align 8, !dbg [[DBG26:![0-9]+]]
// LIN64-NEXT:    [[TMP8:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG27:![0-9]+]]
// LIN64-NEXT:    store atomic i64 [[TMP8]], ptr @ulx monotonic, align 8, !dbg [[DBG28:![0-9]+]]
// LIN64-NEXT:    [[TMP9:%.*]] = load i64, ptr @llv, align 8, !dbg [[DBG29:![0-9]+]]
// LIN64-NEXT:    store atomic i64 [[TMP9]], ptr @llx monotonic, align 8, !dbg [[DBG30:![0-9]+]]
// LIN64-NEXT:    [[TMP10:%.*]] = load i64, ptr @ullv, align 8, !dbg [[DBG31:![0-9]+]]
// LIN64-NEXT:    store atomic i64 [[TMP10]], ptr @ullx monotonic, align 8, !dbg [[DBG32:![0-9]+]]
// LIN64-NEXT:    [[TMP11:%.*]] = load float, ptr @fv, align 4, !dbg [[DBG33:![0-9]+]]
// LIN64-NEXT:    store atomic float [[TMP11]], ptr @fx monotonic, align 4, !dbg [[DBG34:![0-9]+]]
// LIN64-NEXT:    [[TMP12:%.*]] = load double, ptr @dv, align 8, !dbg [[DBG35:![0-9]+]]
// LIN64-NEXT:    store atomic double [[TMP12]], ptr @dx monotonic, align 8, !dbg [[DBG36:![0-9]+]]
// LIN64-NEXT:    [[TMP13:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG37:![0-9]+]]
// LIN64-NEXT:    call void @llvm.memset.p0.i64(ptr align 16 [[ATOMIC_TEMP]], i8 0, i64 16, i1 false), !dbg [[DBG38:![0-9]+]]
// LIN64-NEXT:    store x86_fp80 [[TMP13]], ptr [[ATOMIC_TEMP]], align 16, !dbg [[DBG38]]
// LIN64-NEXT:    call void @__atomic_store(i64 noundef 16, ptr noundef @ldx, ptr noundef [[ATOMIC_TEMP]], i32 noundef 0), !dbg [[DBG38]]
// LIN64-NEXT:    [[CIV_REAL:%.*]] = load i32, ptr @civ, align 4, !dbg [[DBG39:![0-9]+]]
// LIN64-NEXT:    [[CIV_IMAG:%.*]] = load i32, ptr getelementptr inbounds ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG39]]
// LIN64-NEXT:    [[ATOMIC_TEMP1_REALP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP1]], i32 0, i32 0, !dbg [[DBG40:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_TEMP1_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP1]], i32 0, i32 1, !dbg [[DBG40]]
// LIN64-NEXT:    store i32 [[CIV_REAL]], ptr [[ATOMIC_TEMP1_REALP]], align 4, !dbg [[DBG40]]
// LIN64-NEXT:    store i32 [[CIV_IMAG]], ptr [[ATOMIC_TEMP1_IMAGP]], align 4, !dbg [[DBG40]]
// LIN64-NEXT:    call void @__atomic_store(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP1]], i32 noundef 0), !dbg [[DBG40]]
// LIN64-NEXT:    [[CFV_REAL:%.*]] = load float, ptr @cfv, align 4, !dbg [[DBG41:![0-9]+]]
// LIN64-NEXT:    [[CFV_IMAG:%.*]] = load float, ptr getelementptr inbounds ({ float, float }, ptr @cfv, i32 0, i32 1), align 4, !dbg [[DBG41]]
// LIN64-NEXT:    [[ATOMIC_TEMP2_REALP:%.*]] = getelementptr inbounds { float, float }, ptr [[ATOMIC_TEMP2]], i32 0, i32 0, !dbg [[DBG42:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_TEMP2_IMAGP:%.*]] = getelementptr inbounds { float, float }, ptr [[ATOMIC_TEMP2]], i32 0, i32 1, !dbg [[DBG42]]
// LIN64-NEXT:    store float [[CFV_REAL]], ptr [[ATOMIC_TEMP2_REALP]], align 4, !dbg [[DBG42]]
// LIN64-NEXT:    store float [[CFV_IMAG]], ptr [[ATOMIC_TEMP2_IMAGP]], align 4, !dbg [[DBG42]]
// LIN64-NEXT:    call void @__atomic_store(i64 noundef 8, ptr noundef @cfx, ptr noundef [[ATOMIC_TEMP2]], i32 noundef 0), !dbg [[DBG42]]
// LIN64-NEXT:    [[CDV_REAL:%.*]] = load double, ptr @cdv, align 8, !dbg [[DBG43:![0-9]+]]
// LIN64-NEXT:    [[CDV_IMAG:%.*]] = load double, ptr getelementptr inbounds ({ double, double }, ptr @cdv, i32 0, i32 1), align 8, !dbg [[DBG43]]
// LIN64-NEXT:    [[ATOMIC_TEMP3_REALP:%.*]] = getelementptr inbounds { double, double }, ptr [[ATOMIC_TEMP3]], i32 0, i32 0, !dbg [[DBG44:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_TEMP3_IMAGP:%.*]] = getelementptr inbounds { double, double }, ptr [[ATOMIC_TEMP3]], i32 0, i32 1, !dbg [[DBG44]]
// LIN64-NEXT:    store double [[CDV_REAL]], ptr [[ATOMIC_TEMP3_REALP]], align 8, !dbg [[DBG44]]
// LIN64-NEXT:    store double [[CDV_IMAG]], ptr [[ATOMIC_TEMP3_IMAGP]], align 8, !dbg [[DBG44]]
// LIN64-NEXT:    call void @__atomic_store(i64 noundef 16, ptr noundef @cdx, ptr noundef [[ATOMIC_TEMP3]], i32 noundef 5), !dbg [[DBG44]]
// LIN64-NEXT:    fence release
// LIN64-NEXT:    [[TMP14:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG45:![0-9]+]]
// LIN64-NEXT:    [[TOBOOL4:%.*]] = trunc i8 [[TMP14]] to i1, !dbg [[DBG45]]
// LIN64-NEXT:    [[CONV:%.*]] = zext i1 [[TOBOOL4]] to i64, !dbg [[DBG45]]
// LIN64-NEXT:    store atomic i64 [[CONV]], ptr @ulx monotonic, align 8, !dbg [[DBG46:![0-9]+]]
// LIN64-NEXT:    [[TMP15:%.*]] = load i8, ptr @cv, align 1, !dbg [[DBG47:![0-9]+]]
// LIN64-NEXT:    [[TOBOOL5:%.*]] = icmp ne i8 [[TMP15]], 0, !dbg [[DBG47]]
// LIN64-NEXT:    [[FROMBOOL6:%.*]] = zext i1 [[TOBOOL5]] to i8, !dbg [[DBG48:![0-9]+]]
// LIN64-NEXT:    store atomic i8 [[FROMBOOL6]], ptr @bx monotonic, align 1, !dbg [[DBG48]]
// LIN64-NEXT:    [[TMP16:%.*]] = load i8, ptr @ucv, align 1, !dbg [[DBG49:![0-9]+]]
// LIN64-NEXT:    store atomic i8 [[TMP16]], ptr @cx seq_cst, align 1, !dbg [[DBG50:![0-9]+]]
// LIN64-NEXT:    fence release
// LIN64-NEXT:    [[TMP17:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG51:![0-9]+]]
// LIN64-NEXT:    [[CONV7:%.*]] = sext i16 [[TMP17]] to i64, !dbg [[DBG51]]
// LIN64-NEXT:    store atomic i64 [[CONV7]], ptr @ulx monotonic, align 8, !dbg [[DBG52:![0-9]+]]
// LIN64-NEXT:    [[TMP18:%.*]] = load i16, ptr @usv, align 2, !dbg [[DBG53:![0-9]+]]
// LIN64-NEXT:    [[CONV8:%.*]] = zext i16 [[TMP18]] to i64, !dbg [[DBG53]]
// LIN64-NEXT:    store atomic i64 [[CONV8]], ptr @lx monotonic, align 8, !dbg [[DBG54:![0-9]+]]
// LIN64-NEXT:    [[TMP19:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG55:![0-9]+]]
// LIN64-NEXT:    store atomic i32 [[TMP19]], ptr @uix seq_cst, align 4, !dbg [[DBG56:![0-9]+]]
// LIN64-NEXT:    fence release
// LIN64-NEXT:    [[TMP20:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG57:![0-9]+]]
// LIN64-NEXT:    store atomic i32 [[TMP20]], ptr @ix monotonic, align 4, !dbg [[DBG58:![0-9]+]]
// LIN64-NEXT:    [[TMP21:%.*]] = load i64, ptr @lv, align 8, !dbg [[DBG59:![0-9]+]]
// LIN64-NEXT:    [[CONV9:%.*]] = trunc i64 [[TMP21]] to i32, !dbg [[DBG59]]
// LIN64-NEXT:    [[ATOMIC_TEMP10_REALP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP10]], i32 0, i32 0, !dbg [[DBG60:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_TEMP10_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP10]], i32 0, i32 1, !dbg [[DBG60]]
// LIN64-NEXT:    store i32 [[CONV9]], ptr [[ATOMIC_TEMP10_REALP]], align 4, !dbg [[DBG60]]
// LIN64-NEXT:    store i32 0, ptr [[ATOMIC_TEMP10_IMAGP]], align 4, !dbg [[DBG60]]
// LIN64-NEXT:    call void @__atomic_store(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP10]], i32 noundef 0), !dbg [[DBG60]]
// LIN64-NEXT:    [[TMP22:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG61:![0-9]+]]
// LIN64-NEXT:    [[CONV11:%.*]] = uitofp i64 [[TMP22]] to float, !dbg [[DBG61]]
// LIN64-NEXT:    store atomic float [[CONV11]], ptr @fx monotonic, align 4, !dbg [[DBG62:![0-9]+]]
// LIN64-NEXT:    [[TMP23:%.*]] = load i64, ptr @llv, align 8, !dbg [[DBG63:![0-9]+]]
// LIN64-NEXT:    [[CONV12:%.*]] = sitofp i64 [[TMP23]] to double, !dbg [[DBG63]]
// LIN64-NEXT:    store atomic double [[CONV12]], ptr @dx monotonic, align 8, !dbg [[DBG64:![0-9]+]]
// LIN64-NEXT:    [[TMP24:%.*]] = load i64, ptr @ullv, align 8, !dbg [[DBG65:![0-9]+]]
// LIN64-NEXT:    [[CONV13:%.*]] = uitofp i64 [[TMP24]] to x86_fp80, !dbg [[DBG65]]
// LIN64-NEXT:    call void @llvm.memset.p0.i64(ptr align 16 [[ATOMIC_TEMP14]], i8 0, i64 16, i1 false), !dbg [[DBG66:![0-9]+]]
// LIN64-NEXT:    store x86_fp80 [[CONV13]], ptr [[ATOMIC_TEMP14]], align 16, !dbg [[DBG66]]
// LIN64-NEXT:    call void @__atomic_store(i64 noundef 16, ptr noundef @ldx, ptr noundef [[ATOMIC_TEMP14]], i32 noundef 0), !dbg [[DBG66]]
// LIN64-NEXT:    [[TMP25:%.*]] = load float, ptr @fv, align 4, !dbg [[DBG67:![0-9]+]]
// LIN64-NEXT:    [[CONV15:%.*]] = fptosi float [[TMP25]] to i32, !dbg [[DBG67]]
// LIN64-NEXT:    [[ATOMIC_TEMP16_REALP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP16]], i32 0, i32 0, !dbg [[DBG68:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_TEMP16_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP16]], i32 0, i32 1, !dbg [[DBG68]]
// LIN64-NEXT:    store i32 [[CONV15]], ptr [[ATOMIC_TEMP16_REALP]], align 4, !dbg [[DBG68]]
// LIN64-NEXT:    store i32 0, ptr [[ATOMIC_TEMP16_IMAGP]], align 4, !dbg [[DBG68]]
// LIN64-NEXT:    call void @__atomic_store(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP16]], i32 noundef 0), !dbg [[DBG68]]
// LIN64-NEXT:    [[TMP26:%.*]] = load double, ptr @dv, align 8, !dbg [[DBG69:![0-9]+]]
// LIN64-NEXT:    [[CONV17:%.*]] = fptosi double [[TMP26]] to i16, !dbg [[DBG69]]
// LIN64-NEXT:    store atomic i16 [[CONV17]], ptr @sx monotonic, align 2, !dbg [[DBG70:![0-9]+]]
// LIN64-NEXT:    [[TMP27:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG71:![0-9]+]]
// LIN64-NEXT:    [[TOBOOL18:%.*]] = fcmp une x86_fp80 [[TMP27]], 0xK00000000000000000000, !dbg [[DBG71]]
// LIN64-NEXT:    [[FROMBOOL19:%.*]] = zext i1 [[TOBOOL18]] to i8, !dbg [[DBG72:![0-9]+]]
// LIN64-NEXT:    store atomic i8 [[FROMBOOL19]], ptr @bx monotonic, align 1, !dbg [[DBG72]]
// LIN64-NEXT:    [[CIV_REAL20:%.*]] = load i32, ptr @civ, align 4, !dbg [[DBG73:![0-9]+]]
// LIN64-NEXT:    [[CIV_IMAG21:%.*]] = load i32, ptr getelementptr inbounds ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG73]]
// LIN64-NEXT:    [[TOBOOL22:%.*]] = icmp ne i32 [[CIV_REAL20]], 0, !dbg [[DBG73]]
// LIN64-NEXT:    [[TOBOOL23:%.*]] = icmp ne i32 [[CIV_IMAG21]], 0, !dbg [[DBG73]]
// LIN64-NEXT:    [[TOBOOL24:%.*]] = or i1 [[TOBOOL22]], [[TOBOOL23]], !dbg [[DBG73]]
// LIN64-NEXT:    [[FROMBOOL25:%.*]] = zext i1 [[TOBOOL24]] to i8, !dbg [[DBG74:![0-9]+]]
// LIN64-NEXT:    store atomic i8 [[FROMBOOL25]], ptr @bx monotonic, align 1, !dbg [[DBG74]]
// LIN64-NEXT:    [[CFV_REAL26:%.*]] = load float, ptr @cfv, align 4, !dbg [[DBG75:![0-9]+]]
// LIN64-NEXT:    [[CONV27:%.*]] = fptoui float [[CFV_REAL26]] to i16, !dbg [[DBG75]]
// LIN64-NEXT:    store atomic i16 [[CONV27]], ptr @usx monotonic, align 2, !dbg [[DBG76:![0-9]+]]
// LIN64-NEXT:    [[CDV_REAL28:%.*]] = load double, ptr @cdv, align 8, !dbg [[DBG77:![0-9]+]]
// LIN64-NEXT:    [[CONV29:%.*]] = fptosi double [[CDV_REAL28]] to i64, !dbg [[DBG77]]
// LIN64-NEXT:    store atomic i64 [[CONV29]], ptr @llx monotonic, align 8, !dbg [[DBG78:![0-9]+]]
// LIN64-NEXT:    [[TMP28:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG79:![0-9]+]]
// LIN64-NEXT:    [[TMP29:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG80:![0-9]+]]
// LIN64-NEXT:    [[TOBOOL30:%.*]] = trunc i8 [[TMP29]] to i1, !dbg [[DBG80]]
// LIN64-NEXT:    [[CONV31:%.*]] = zext i1 [[TOBOOL30]] to i32, !dbg [[DBG80]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 16, ptr noundef @int4x, ptr noundef [[ATOMIC_TEMP32]], i32 noundef 0), !dbg [[DBG81:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT:%.*]], !dbg [[DBG81]]
// LIN64:       atomic_cont:
// LIN64-NEXT:    [[TMP30:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP32]], align 16, !dbg [[DBG81]]
// LIN64-NEXT:    store <4 x i32> [[TMP30]], ptr [[ATOMIC_TEMP33]], align 16, !dbg [[DBG81]]
// LIN64-NEXT:    [[TMP31:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP33]], align 16, !dbg [[DBG81]]
// LIN64-NEXT:    [[VECINS:%.*]] = insertelement <4 x i32> [[TMP31]], i32 [[CONV31]], i16 [[TMP28]], !dbg [[DBG81]]
// LIN64-NEXT:    store <4 x i32> [[VECINS]], ptr [[ATOMIC_TEMP33]], align 16, !dbg [[DBG81]]
// LIN64-NEXT:    [[CALL:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, ptr noundef @int4x, ptr noundef [[ATOMIC_TEMP32]], ptr noundef [[ATOMIC_TEMP33]], i32 noundef 0, i32 noundef 0), !dbg [[DBG81]]
// LIN64-NEXT:    br i1 [[CALL]], label [[ATOMIC_EXIT:%.*]], label [[ATOMIC_CONT]], !dbg [[DBG81]]
// LIN64:       atomic_exit:
// LIN64-NEXT:    [[TMP32:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG82:![0-9]+]]
// LIN64-NEXT:    [[CONV34:%.*]] = fptosi x86_fp80 [[TMP32]] to i32, !dbg [[DBG82]]
// LIN64-NEXT:    [[ATOMIC_LOAD:%.*]] = load atomic i32, ptr getelementptr (i8, ptr @bfx, i64 4) monotonic, align 4, !dbg [[DBG83:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT35:%.*]], !dbg [[DBG83]]
// LIN64:       atomic_cont35:
// LIN64-NEXT:    [[TMP33:%.*]] = phi i32 [ [[ATOMIC_LOAD]], [[ATOMIC_EXIT]] ], [ [[TMP36:%.*]], [[ATOMIC_CONT35]] ], !dbg [[DBG83]]
// LIN64-NEXT:    store i32 [[TMP33]], ptr [[ATOMIC_TEMP36]], align 4, !dbg [[DBG83]]
// LIN64-NEXT:    [[BF_LOAD:%.*]] = load i32, ptr [[ATOMIC_TEMP36]], align 4, !dbg [[DBG83]]
// LIN64-NEXT:    [[BF_VALUE:%.*]] = and i32 [[CONV34]], 2147483647, !dbg [[DBG83]]
// LIN64-NEXT:    [[BF_CLEAR:%.*]] = and i32 [[BF_LOAD]], -2147483648, !dbg [[DBG83]]
// LIN64-NEXT:    [[BF_SET:%.*]] = or i32 [[BF_CLEAR]], [[BF_VALUE]], !dbg [[DBG83]]
// LIN64-NEXT:    store i32 [[BF_SET]], ptr [[ATOMIC_TEMP36]], align 4, !dbg [[DBG83]]
// LIN64-NEXT:    [[TMP34:%.*]] = load i32, ptr [[ATOMIC_TEMP36]], align 4, !dbg [[DBG83]]
// LIN64-NEXT:    [[TMP35:%.*]] = cmpxchg ptr getelementptr (i8, ptr @bfx, i64 4), i32 [[TMP33]], i32 [[TMP34]] monotonic monotonic, align 4, !dbg [[DBG83]]
// LIN64-NEXT:    [[TMP36]] = extractvalue { i32, i1 } [[TMP35]], 0, !dbg [[DBG83]]
// LIN64-NEXT:    [[TMP37:%.*]] = extractvalue { i32, i1 } [[TMP35]], 1, !dbg [[DBG83]]
// LIN64-NEXT:    br i1 [[TMP37]], label [[ATOMIC_EXIT37:%.*]], label [[ATOMIC_CONT35]], !dbg [[DBG83]]
// LIN64:       atomic_exit37:
// LIN64-NEXT:    [[TMP38:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG84:![0-9]+]]
// LIN64-NEXT:    [[CONV38:%.*]] = fptosi x86_fp80 [[TMP38]] to i32, !dbg [[DBG84]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 4, ptr noundef getelementptr (i8, ptr @bfx_packed, i64 4), ptr noundef [[ATOMIC_TEMP39]], i32 noundef 0), !dbg [[DBG85:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT40:%.*]], !dbg [[DBG85]]
// LIN64:       atomic_cont40:
// LIN64-NEXT:    [[TMP39:%.*]] = load i32, ptr [[ATOMIC_TEMP39]], align 1, !dbg [[DBG85]]
// LIN64-NEXT:    store i32 [[TMP39]], ptr [[ATOMIC_TEMP41]], align 1, !dbg [[DBG85]]
// LIN64-NEXT:    [[BF_LOAD42:%.*]] = load i32, ptr [[ATOMIC_TEMP41]], align 1, !dbg [[DBG85]]
// LIN64-NEXT:    [[BF_VALUE43:%.*]] = and i32 [[CONV38]], 2147483647, !dbg [[DBG85]]
// LIN64-NEXT:    [[BF_CLEAR44:%.*]] = and i32 [[BF_LOAD42]], -2147483648, !dbg [[DBG85]]
// LIN64-NEXT:    [[BF_SET45:%.*]] = or i32 [[BF_CLEAR44]], [[BF_VALUE43]], !dbg [[DBG85]]
// LIN64-NEXT:    store i32 [[BF_SET45]], ptr [[ATOMIC_TEMP41]], align 1, !dbg [[DBG85]]
// LIN64-NEXT:    [[CALL46:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 4, ptr noundef getelementptr (i8, ptr @bfx_packed, i64 4), ptr noundef [[ATOMIC_TEMP39]], ptr noundef [[ATOMIC_TEMP41]], i32 noundef 0, i32 noundef 0), !dbg [[DBG85]]
// LIN64-NEXT:    br i1 [[CALL46]], label [[ATOMIC_EXIT47:%.*]], label [[ATOMIC_CONT40]], !dbg [[DBG85]]
// LIN64:       atomic_exit47:
// LIN64-NEXT:    [[TMP40:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG86:![0-9]+]]
// LIN64-NEXT:    [[CONV48:%.*]] = fptosi x86_fp80 [[TMP40]] to i32, !dbg [[DBG86]]
// LIN64-NEXT:    [[ATOMIC_LOAD49:%.*]] = load atomic i32, ptr @bfx2 monotonic, align 4, !dbg [[DBG87:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT50:%.*]], !dbg [[DBG87]]
// LIN64:       atomic_cont50:
// LIN64-NEXT:    [[TMP41:%.*]] = phi i32 [ [[ATOMIC_LOAD49]], [[ATOMIC_EXIT47]] ], [ [[TMP44:%.*]], [[ATOMIC_CONT50]] ], !dbg [[DBG87]]
// LIN64-NEXT:    store i32 [[TMP41]], ptr [[ATOMIC_TEMP51]], align 4, !dbg [[DBG87]]
// LIN64-NEXT:    [[BF_LOAD52:%.*]] = load i32, ptr [[ATOMIC_TEMP51]], align 4, !dbg [[DBG87]]
// LIN64-NEXT:    [[BF_VALUE53:%.*]] = and i32 [[CONV48]], 1, !dbg [[DBG87]]
// LIN64-NEXT:    [[BF_SHL:%.*]] = shl i32 [[BF_VALUE53]], 31, !dbg [[DBG87]]
// LIN64-NEXT:    [[BF_CLEAR54:%.*]] = and i32 [[BF_LOAD52]], 2147483647, !dbg [[DBG87]]
// LIN64-NEXT:    [[BF_SET55:%.*]] = or i32 [[BF_CLEAR54]], [[BF_SHL]], !dbg [[DBG87]]
// LIN64-NEXT:    store i32 [[BF_SET55]], ptr [[ATOMIC_TEMP51]], align 4, !dbg [[DBG87]]
// LIN64-NEXT:    [[TMP42:%.*]] = load i32, ptr [[ATOMIC_TEMP51]], align 4, !dbg [[DBG87]]
// LIN64-NEXT:    [[TMP43:%.*]] = cmpxchg ptr @bfx2, i32 [[TMP41]], i32 [[TMP42]] monotonic monotonic, align 4, !dbg [[DBG87]]
// LIN64-NEXT:    [[TMP44]] = extractvalue { i32, i1 } [[TMP43]], 0, !dbg [[DBG87]]
// LIN64-NEXT:    [[TMP45:%.*]] = extractvalue { i32, i1 } [[TMP43]], 1, !dbg [[DBG87]]
// LIN64-NEXT:    br i1 [[TMP45]], label [[ATOMIC_EXIT56:%.*]], label [[ATOMIC_CONT50]], !dbg [[DBG87]]
// LIN64:       atomic_exit56:
// LIN64-NEXT:    [[TMP46:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG88:![0-9]+]]
// LIN64-NEXT:    [[CONV57:%.*]] = fptosi x86_fp80 [[TMP46]] to i32, !dbg [[DBG88]]
// LIN64-NEXT:    [[ATOMIC_LOAD58:%.*]] = load atomic i8, ptr getelementptr (i8, ptr @bfx2_packed, i64 3) monotonic, align 1, !dbg [[DBG89:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT59:%.*]], !dbg [[DBG89]]
// LIN64:       atomic_cont59:
// LIN64-NEXT:    [[TMP47:%.*]] = phi i8 [ [[ATOMIC_LOAD58]], [[ATOMIC_EXIT56]] ], [ [[TMP51:%.*]], [[ATOMIC_CONT59]] ], !dbg [[DBG89]]
// LIN64-NEXT:    store i8 [[TMP47]], ptr [[ATOMIC_TEMP60]], align 1, !dbg [[DBG89]]
// LIN64-NEXT:    [[TMP48:%.*]] = trunc i32 [[CONV57]] to i8, !dbg [[DBG89]]
// LIN64-NEXT:    [[BF_LOAD61:%.*]] = load i8, ptr [[ATOMIC_TEMP60]], align 1, !dbg [[DBG89]]
// LIN64-NEXT:    [[BF_VALUE62:%.*]] = and i8 [[TMP48]], 1, !dbg [[DBG89]]
// LIN64-NEXT:    [[BF_SHL63:%.*]] = shl i8 [[BF_VALUE62]], 7, !dbg [[DBG89]]
// LIN64-NEXT:    [[BF_CLEAR64:%.*]] = and i8 [[BF_LOAD61]], 127, !dbg [[DBG89]]
// LIN64-NEXT:    [[BF_SET65:%.*]] = or i8 [[BF_CLEAR64]], [[BF_SHL63]], !dbg [[DBG89]]
// LIN64-NEXT:    store i8 [[BF_SET65]], ptr [[ATOMIC_TEMP60]], align 1, !dbg [[DBG89]]
// LIN64-NEXT:    [[TMP49:%.*]] = load i8, ptr [[ATOMIC_TEMP60]], align 1, !dbg [[DBG89]]
// LIN64-NEXT:    [[TMP50:%.*]] = cmpxchg ptr getelementptr (i8, ptr @bfx2_packed, i64 3), i8 [[TMP47]], i8 [[TMP49]] monotonic monotonic, align 1, !dbg [[DBG89]]
// LIN64-NEXT:    [[TMP51]] = extractvalue { i8, i1 } [[TMP50]], 0, !dbg [[DBG89]]
// LIN64-NEXT:    [[TMP52:%.*]] = extractvalue { i8, i1 } [[TMP50]], 1, !dbg [[DBG89]]
// LIN64-NEXT:    br i1 [[TMP52]], label [[ATOMIC_EXIT66:%.*]], label [[ATOMIC_CONT59]], !dbg [[DBG89]]
// LIN64:       atomic_exit66:
// LIN64-NEXT:    [[TMP53:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG90:![0-9]+]]
// LIN64-NEXT:    [[CONV67:%.*]] = fptosi x86_fp80 [[TMP53]] to i32, !dbg [[DBG90]]
// LIN64-NEXT:    [[ATOMIC_LOAD68:%.*]] = load atomic i32, ptr @bfx3 monotonic, align 4, !dbg [[DBG91:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT69:%.*]], !dbg [[DBG91]]
// LIN64:       atomic_cont69:
// LIN64-NEXT:    [[TMP54:%.*]] = phi i32 [ [[ATOMIC_LOAD68]], [[ATOMIC_EXIT66]] ], [ [[TMP57:%.*]], [[ATOMIC_CONT69]] ], !dbg [[DBG91]]
// LIN64-NEXT:    store i32 [[TMP54]], ptr [[ATOMIC_TEMP70]], align 4, !dbg [[DBG91]]
// LIN64-NEXT:    [[BF_LOAD71:%.*]] = load i32, ptr [[ATOMIC_TEMP70]], align 4, !dbg [[DBG91]]
// LIN64-NEXT:    [[BF_VALUE72:%.*]] = and i32 [[CONV67]], 16383, !dbg [[DBG91]]
// LIN64-NEXT:    [[BF_SHL73:%.*]] = shl i32 [[BF_VALUE72]], 11, !dbg [[DBG91]]
// LIN64-NEXT:    [[BF_CLEAR74:%.*]] = and i32 [[BF_LOAD71]], -33552385, !dbg [[DBG91]]
// LIN64-NEXT:    [[BF_SET75:%.*]] = or i32 [[BF_CLEAR74]], [[BF_SHL73]], !dbg [[DBG91]]
// LIN64-NEXT:    store i32 [[BF_SET75]], ptr [[ATOMIC_TEMP70]], align 4, !dbg [[DBG91]]
// LIN64-NEXT:    [[TMP55:%.*]] = load i32, ptr [[ATOMIC_TEMP70]], align 4, !dbg [[DBG91]]
// LIN64-NEXT:    [[TMP56:%.*]] = cmpxchg ptr @bfx3, i32 [[TMP54]], i32 [[TMP55]] monotonic monotonic, align 4, !dbg [[DBG91]]
// LIN64-NEXT:    [[TMP57]] = extractvalue { i32, i1 } [[TMP56]], 0, !dbg [[DBG91]]
// LIN64-NEXT:    [[TMP58:%.*]] = extractvalue { i32, i1 } [[TMP56]], 1, !dbg [[DBG91]]
// LIN64-NEXT:    br i1 [[TMP58]], label [[ATOMIC_EXIT76:%.*]], label [[ATOMIC_CONT69]], !dbg [[DBG91]]
// LIN64:       atomic_exit76:
// LIN64-NEXT:    [[TMP59:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG92:![0-9]+]]
// LIN64-NEXT:    [[CONV77:%.*]] = fptosi x86_fp80 [[TMP59]] to i32, !dbg [[DBG92]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 3, ptr noundef getelementptr (i8, ptr @bfx3_packed, i64 1), ptr noundef [[ATOMIC_TEMP78]], i32 noundef 0), !dbg [[DBG93:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT79:%.*]], !dbg [[DBG93]]
// LIN64:       atomic_cont79:
// LIN64-NEXT:    [[TMP60:%.*]] = load i24, ptr [[ATOMIC_TEMP78]], align 1, !dbg [[DBG93]]
// LIN64-NEXT:    store i24 [[TMP60]], ptr [[ATOMIC_TEMP80]], align 1, !dbg [[DBG93]]
// LIN64-NEXT:    [[TMP61:%.*]] = trunc i32 [[CONV77]] to i24, !dbg [[DBG93]]
// LIN64-NEXT:    [[BF_LOAD81:%.*]] = load i24, ptr [[ATOMIC_TEMP80]], align 1, !dbg [[DBG93]]
// LIN64-NEXT:    [[BF_VALUE82:%.*]] = and i24 [[TMP61]], 16383, !dbg [[DBG93]]
// LIN64-NEXT:    [[BF_SHL83:%.*]] = shl i24 [[BF_VALUE82]], 3, !dbg [[DBG93]]
// LIN64-NEXT:    [[BF_CLEAR84:%.*]] = and i24 [[BF_LOAD81]], -131065, !dbg [[DBG93]]
// LIN64-NEXT:    [[BF_SET85:%.*]] = or i24 [[BF_CLEAR84]], [[BF_SHL83]], !dbg [[DBG93]]
// LIN64-NEXT:    store i24 [[BF_SET85]], ptr [[ATOMIC_TEMP80]], align 1, !dbg [[DBG93]]
// LIN64-NEXT:    [[CALL86:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 3, ptr noundef getelementptr (i8, ptr @bfx3_packed, i64 1), ptr noundef [[ATOMIC_TEMP78]], ptr noundef [[ATOMIC_TEMP80]], i32 noundef 0, i32 noundef 0), !dbg [[DBG93]]
// LIN64-NEXT:    br i1 [[CALL86]], label [[ATOMIC_EXIT87:%.*]], label [[ATOMIC_CONT79]], !dbg [[DBG93]]
// LIN64:       atomic_exit87:
// LIN64-NEXT:    [[TMP62:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG94:![0-9]+]]
// LIN64-NEXT:    [[CONV88:%.*]] = fptosi x86_fp80 [[TMP62]] to i32, !dbg [[DBG94]]
// LIN64-NEXT:    [[ATOMIC_LOAD89:%.*]] = load atomic i64, ptr @bfx4 monotonic, align 8, !dbg [[DBG95:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT90:%.*]], !dbg [[DBG95]]
// LIN64:       atomic_cont90:
// LIN64-NEXT:    [[TMP63:%.*]] = phi i64 [ [[ATOMIC_LOAD89]], [[ATOMIC_EXIT87]] ], [ [[TMP67:%.*]], [[ATOMIC_CONT90]] ], !dbg [[DBG95]]
// LIN64-NEXT:    store i64 [[TMP63]], ptr [[ATOMIC_TEMP91]], align 8, !dbg [[DBG95]]
// LIN64-NEXT:    [[TMP64:%.*]] = zext i32 [[CONV88]] to i64, !dbg [[DBG95]]
// LIN64-NEXT:    [[BF_LOAD92:%.*]] = load i64, ptr [[ATOMIC_TEMP91]], align 8, !dbg [[DBG95]]
// LIN64-NEXT:    [[BF_VALUE93:%.*]] = and i64 [[TMP64]], 1, !dbg [[DBG95]]
// LIN64-NEXT:    [[BF_SHL94:%.*]] = shl i64 [[BF_VALUE93]], 16, !dbg [[DBG95]]
// LIN64-NEXT:    [[BF_CLEAR95:%.*]] = and i64 [[BF_LOAD92]], -65537, !dbg [[DBG95]]
// LIN64-NEXT:    [[BF_SET96:%.*]] = or i64 [[BF_CLEAR95]], [[BF_SHL94]], !dbg [[DBG95]]
// LIN64-NEXT:    store i64 [[BF_SET96]], ptr [[ATOMIC_TEMP91]], align 8, !dbg [[DBG95]]
// LIN64-NEXT:    [[TMP65:%.*]] = load i64, ptr [[ATOMIC_TEMP91]], align 8, !dbg [[DBG95]]
// LIN64-NEXT:    [[TMP66:%.*]] = cmpxchg ptr @bfx4, i64 [[TMP63]], i64 [[TMP65]] monotonic monotonic, align 8, !dbg [[DBG95]]
// LIN64-NEXT:    [[TMP67]] = extractvalue { i64, i1 } [[TMP66]], 0, !dbg [[DBG95]]
// LIN64-NEXT:    [[TMP68:%.*]] = extractvalue { i64, i1 } [[TMP66]], 1, !dbg [[DBG95]]
// LIN64-NEXT:    br i1 [[TMP68]], label [[ATOMIC_EXIT97:%.*]], label [[ATOMIC_CONT90]], !dbg [[DBG95]]
// LIN64:       atomic_exit97:
// LIN64-NEXT:    [[TMP69:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG96:![0-9]+]]
// LIN64-NEXT:    [[CONV98:%.*]] = fptosi x86_fp80 [[TMP69]] to i32, !dbg [[DBG96]]
// LIN64-NEXT:    [[ATOMIC_LOAD99:%.*]] = load atomic i8, ptr getelementptr (i8, ptr @bfx4_packed, i64 2) monotonic, align 1, !dbg [[DBG97:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT100:%.*]], !dbg [[DBG97]]
// LIN64:       atomic_cont100:
// LIN64-NEXT:    [[TMP70:%.*]] = phi i8 [ [[ATOMIC_LOAD99]], [[ATOMIC_EXIT97]] ], [ [[TMP74:%.*]], [[ATOMIC_CONT100]] ], !dbg [[DBG97]]
// LIN64-NEXT:    store i8 [[TMP70]], ptr [[ATOMIC_TEMP101]], align 1, !dbg [[DBG97]]
// LIN64-NEXT:    [[TMP71:%.*]] = trunc i32 [[CONV98]] to i8, !dbg [[DBG97]]
// LIN64-NEXT:    [[BF_LOAD102:%.*]] = load i8, ptr [[ATOMIC_TEMP101]], align 1, !dbg [[DBG97]]
// LIN64-NEXT:    [[BF_VALUE103:%.*]] = and i8 [[TMP71]], 1, !dbg [[DBG97]]
// LIN64-NEXT:    [[BF_CLEAR104:%.*]] = and i8 [[BF_LOAD102]], -2, !dbg [[DBG97]]
// LIN64-NEXT:    [[BF_SET105:%.*]] = or i8 [[BF_CLEAR104]], [[BF_VALUE103]], !dbg [[DBG97]]
// LIN64-NEXT:    store i8 [[BF_SET105]], ptr [[ATOMIC_TEMP101]], align 1, !dbg [[DBG97]]
// LIN64-NEXT:    [[TMP72:%.*]] = load i8, ptr [[ATOMIC_TEMP101]], align 1, !dbg [[DBG97]]
// LIN64-NEXT:    [[TMP73:%.*]] = cmpxchg ptr getelementptr (i8, ptr @bfx4_packed, i64 2), i8 [[TMP70]], i8 [[TMP72]] monotonic monotonic, align 1, !dbg [[DBG97]]
// LIN64-NEXT:    [[TMP74]] = extractvalue { i8, i1 } [[TMP73]], 0, !dbg [[DBG97]]
// LIN64-NEXT:    [[TMP75:%.*]] = extractvalue { i8, i1 } [[TMP73]], 1, !dbg [[DBG97]]
// LIN64-NEXT:    br i1 [[TMP75]], label [[ATOMIC_EXIT106:%.*]], label [[ATOMIC_CONT100]], !dbg [[DBG97]]
// LIN64:       atomic_exit106:
// LIN64-NEXT:    [[TMP76:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG98:![0-9]+]]
// LIN64-NEXT:    [[CONV107:%.*]] = fptosi x86_fp80 [[TMP76]] to i64, !dbg [[DBG98]]
// LIN64-NEXT:    [[ATOMIC_LOAD108:%.*]] = load atomic i64, ptr @bfx4 monotonic, align 8, !dbg [[DBG99:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT109:%.*]], !dbg [[DBG99]]
// LIN64:       atomic_cont109:
// LIN64-NEXT:    [[TMP77:%.*]] = phi i64 [ [[ATOMIC_LOAD108]], [[ATOMIC_EXIT106]] ], [ [[TMP80:%.*]], [[ATOMIC_CONT109]] ], !dbg [[DBG99]]
// LIN64-NEXT:    store i64 [[TMP77]], ptr [[ATOMIC_TEMP110]], align 8, !dbg [[DBG99]]
// LIN64-NEXT:    [[BF_LOAD111:%.*]] = load i64, ptr [[ATOMIC_TEMP110]], align 8, !dbg [[DBG99]]
// LIN64-NEXT:    [[BF_VALUE112:%.*]] = and i64 [[CONV107]], 127, !dbg [[DBG99]]
// LIN64-NEXT:    [[BF_SHL113:%.*]] = shl i64 [[BF_VALUE112]], 17, !dbg [[DBG99]]
// LIN64-NEXT:    [[BF_CLEAR114:%.*]] = and i64 [[BF_LOAD111]], -16646145, !dbg [[DBG99]]
// LIN64-NEXT:    [[BF_SET115:%.*]] = or i64 [[BF_CLEAR114]], [[BF_SHL113]], !dbg [[DBG99]]
// LIN64-NEXT:    store i64 [[BF_SET115]], ptr [[ATOMIC_TEMP110]], align 8, !dbg [[DBG99]]
// LIN64-NEXT:    [[TMP78:%.*]] = load i64, ptr [[ATOMIC_TEMP110]], align 8, !dbg [[DBG99]]
// LIN64-NEXT:    [[TMP79:%.*]] = cmpxchg ptr @bfx4, i64 [[TMP77]], i64 [[TMP78]] monotonic monotonic, align 8, !dbg [[DBG99]]
// LIN64-NEXT:    [[TMP80]] = extractvalue { i64, i1 } [[TMP79]], 0, !dbg [[DBG99]]
// LIN64-NEXT:    [[TMP81:%.*]] = extractvalue { i64, i1 } [[TMP79]], 1, !dbg [[DBG99]]
// LIN64-NEXT:    br i1 [[TMP81]], label [[ATOMIC_EXIT116:%.*]], label [[ATOMIC_CONT109]], !dbg [[DBG99]]
// LIN64:       atomic_exit116:
// LIN64-NEXT:    [[TMP82:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG100:![0-9]+]]
// LIN64-NEXT:    [[CONV117:%.*]] = fptosi x86_fp80 [[TMP82]] to i64, !dbg [[DBG100]]
// LIN64-NEXT:    [[ATOMIC_LOAD118:%.*]] = load atomic i8, ptr getelementptr (i8, ptr @bfx4_packed, i64 2) monotonic, align 1, !dbg [[DBG101:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT119:%.*]], !dbg [[DBG101]]
// LIN64:       atomic_cont119:
// LIN64-NEXT:    [[TMP83:%.*]] = phi i8 [ [[ATOMIC_LOAD118]], [[ATOMIC_EXIT116]] ], [ [[TMP87:%.*]], [[ATOMIC_CONT119]] ], !dbg [[DBG101]]
// LIN64-NEXT:    store i8 [[TMP83]], ptr [[ATOMIC_TEMP120]], align 1, !dbg [[DBG101]]
// LIN64-NEXT:    [[TMP84:%.*]] = trunc i64 [[CONV117]] to i8, !dbg [[DBG101]]
// LIN64-NEXT:    [[BF_LOAD121:%.*]] = load i8, ptr [[ATOMIC_TEMP120]], align 1, !dbg [[DBG101]]
// LIN64-NEXT:    [[BF_VALUE122:%.*]] = and i8 [[TMP84]], 127, !dbg [[DBG101]]
// LIN64-NEXT:    [[BF_SHL123:%.*]] = shl i8 [[BF_VALUE122]], 1, !dbg [[DBG101]]
// LIN64-NEXT:    [[BF_CLEAR124:%.*]] = and i8 [[BF_LOAD121]], 1, !dbg [[DBG101]]
// LIN64-NEXT:    [[BF_SET125:%.*]] = or i8 [[BF_CLEAR124]], [[BF_SHL123]], !dbg [[DBG101]]
// LIN64-NEXT:    store i8 [[BF_SET125]], ptr [[ATOMIC_TEMP120]], align 1, !dbg [[DBG101]]
// LIN64-NEXT:    [[TMP85:%.*]] = load i8, ptr [[ATOMIC_TEMP120]], align 1, !dbg [[DBG101]]
// LIN64-NEXT:    [[TMP86:%.*]] = cmpxchg ptr getelementptr (i8, ptr @bfx4_packed, i64 2), i8 [[TMP83]], i8 [[TMP85]] monotonic monotonic, align 1, !dbg [[DBG101]]
// LIN64-NEXT:    [[TMP87]] = extractvalue { i8, i1 } [[TMP86]], 0, !dbg [[DBG101]]
// LIN64-NEXT:    [[TMP88:%.*]] = extractvalue { i8, i1 } [[TMP86]], 1, !dbg [[DBG101]]
// LIN64-NEXT:    br i1 [[TMP88]], label [[ATOMIC_EXIT126:%.*]], label [[ATOMIC_CONT119]], !dbg [[DBG101]]
// LIN64:       atomic_exit126:
// LIN64-NEXT:    [[TMP89:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG102:![0-9]+]]
// LIN64-NEXT:    [[CONV127:%.*]] = uitofp i64 [[TMP89]] to float, !dbg [[DBG102]]
// LIN64-NEXT:    [[ATOMIC_LOAD128:%.*]] = load atomic i64, ptr @float2x monotonic, align 8, !dbg [[DBG103:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT129:%.*]], !dbg [[DBG103]]
// LIN64:       atomic_cont129:
// LIN64-NEXT:    [[TMP90:%.*]] = phi i64 [ [[ATOMIC_LOAD128]], [[ATOMIC_EXIT126]] ], [ [[TMP95:%.*]], [[ATOMIC_CONT129]] ], !dbg [[DBG103]]
// LIN64-NEXT:    store i64 [[TMP90]], ptr [[ATOMIC_TEMP130]], align 8, !dbg [[DBG103]]
// LIN64-NEXT:    [[TMP91:%.*]] = load <2 x float>, ptr [[ATOMIC_TEMP130]], align 8, !dbg [[DBG103]]
// LIN64-NEXT:    [[TMP92:%.*]] = insertelement <2 x float> [[TMP91]], float [[CONV127]], i64 0, !dbg [[DBG103]]
// LIN64-NEXT:    store <2 x float> [[TMP92]], ptr [[ATOMIC_TEMP130]], align 8, !dbg [[DBG103]]
// LIN64-NEXT:    [[TMP93:%.*]] = load i64, ptr [[ATOMIC_TEMP130]], align 8, !dbg [[DBG103]]
// LIN64-NEXT:    [[TMP94:%.*]] = cmpxchg ptr @float2x, i64 [[TMP90]], i64 [[TMP93]] monotonic monotonic, align 8, !dbg [[DBG103]]
// LIN64-NEXT:    [[TMP95]] = extractvalue { i64, i1 } [[TMP94]], 0, !dbg [[DBG103]]
// LIN64-NEXT:    [[TMP96:%.*]] = extractvalue { i64, i1 } [[TMP94]], 1, !dbg [[DBG103]]
// LIN64-NEXT:    br i1 [[TMP96]], label [[ATOMIC_EXIT131:%.*]], label [[ATOMIC_CONT129]], !dbg [[DBG103]]
// LIN64:       atomic_exit131:
// LIN64-NEXT:    [[TMP97:%.*]] = call i32 @llvm.read_register.i32(metadata [[META2:![0-9]+]]), !dbg [[DBG104:![0-9]+]]
// LIN64-NEXT:    [[CONV132:%.*]] = sitofp i32 [[TMP97]] to double, !dbg [[DBG104]]
// LIN64-NEXT:    store atomic double [[CONV132]], ptr @dv seq_cst, align 8, !dbg [[DBG105:![0-9]+]]
// LIN64-NEXT:    fence release
// LIN64-NEXT:    ret i32 0, !dbg [[DBG106:![0-9]+]]
//
//
// PPC64-LABEL: define {{[^@]+}}@main
// PPC64-SAME: () #[[ATTR0:[0-9]+]] !dbg [[DBG6:![0-9]+]] {
// PPC64-NEXT:  entry:
// PPC64-NEXT:    [[RETVAL:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca ppc_fp128, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP1:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP2:%.*]] = alloca { float, float }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP3:%.*]] = alloca { double, double }, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP10:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP14:%.*]] = alloca ppc_fp128, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP16:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP32:%.*]] = alloca <4 x i32>, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP33:%.*]] = alloca <4 x i32>, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP36:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP39:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP41:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP52:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP61:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP70:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP78:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP80:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP91:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP101:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP111:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP121:%.*]] = alloca i64, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP130:%.*]] = alloca <2 x float>, align 8
// PPC64-NEXT:    store i32 0, ptr [[RETVAL]], align 4
// PPC64-NEXT:    store atomic i32 1, ptr getelementptr inbounds ({ i32, i32 }, ptr @civ, i32 0, i32 1) monotonic, align 4, !dbg [[DBG10:![0-9]+]]
// PPC64-NEXT:    [[TMP0:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG11:![0-9]+]]
// PPC64-NEXT:    [[TOBOOL:%.*]] = trunc i8 [[TMP0]] to i1, !dbg [[DBG11]]
// PPC64-NEXT:    [[FROMBOOL:%.*]] = zext i1 [[TOBOOL]] to i8, !dbg [[DBG12:![0-9]+]]
// PPC64-NEXT:    store atomic i8 [[FROMBOOL]], ptr @bx monotonic, align 1, !dbg [[DBG12]]
// PPC64-NEXT:    [[TMP1:%.*]] = load i8, ptr @cv, align 1, !dbg [[DBG13:![0-9]+]]
// PPC64-NEXT:    store atomic i8 [[TMP1]], ptr @cx release, align 1, !dbg [[DBG14:![0-9]+]]
// PPC64-NEXT:    fence release
// PPC64-NEXT:    [[TMP2:%.*]] = load i8, ptr @ucv, align 1, !dbg [[DBG15:![0-9]+]]
// PPC64-NEXT:    store atomic i8 [[TMP2]], ptr @ucx monotonic, align 1, !dbg [[DBG16:![0-9]+]]
// PPC64-NEXT:    [[TMP3:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG17:![0-9]+]]
// PPC64-NEXT:    store atomic i16 [[TMP3]], ptr @sx monotonic, align 2, !dbg [[DBG18:![0-9]+]]
// PPC64-NEXT:    [[TMP4:%.*]] = load i16, ptr @usv, align 2, !dbg [[DBG19:![0-9]+]]
// PPC64-NEXT:    store atomic i16 [[TMP4]], ptr @usx monotonic, align 2, !dbg [[DBG20:![0-9]+]]
// PPC64-NEXT:    [[TMP5:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG21:![0-9]+]]
// PPC64-NEXT:    store atomic i32 [[TMP5]], ptr @ix monotonic, align 4, !dbg [[DBG22:![0-9]+]]
// PPC64-NEXT:    [[TMP6:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG23:![0-9]+]]
// PPC64-NEXT:    store atomic i32 [[TMP6]], ptr @uix monotonic, align 4, !dbg [[DBG24:![0-9]+]]
// PPC64-NEXT:    [[TMP7:%.*]] = load i64, ptr @lv, align 8, !dbg [[DBG25:![0-9]+]]
// PPC64-NEXT:    store atomic i64 [[TMP7]], ptr @lx monotonic, align 8, !dbg [[DBG26:![0-9]+]]
// PPC64-NEXT:    [[TMP8:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG27:![0-9]+]]
// PPC64-NEXT:    store atomic i64 [[TMP8]], ptr @ulx monotonic, align 8, !dbg [[DBG28:![0-9]+]]
// PPC64-NEXT:    [[TMP9:%.*]] = load i64, ptr @llv, align 8, !dbg [[DBG29:![0-9]+]]
// PPC64-NEXT:    store atomic i64 [[TMP9]], ptr @llx monotonic, align 8, !dbg [[DBG30:![0-9]+]]
// PPC64-NEXT:    [[TMP10:%.*]] = load i64, ptr @ullv, align 8, !dbg [[DBG31:![0-9]+]]
// PPC64-NEXT:    store atomic i64 [[TMP10]], ptr @ullx monotonic, align 8, !dbg [[DBG32:![0-9]+]]
// PPC64-NEXT:    [[TMP11:%.*]] = load float, ptr @fv, align 4, !dbg [[DBG33:![0-9]+]]
// PPC64-NEXT:    store atomic float [[TMP11]], ptr @fx monotonic, align 4, !dbg [[DBG34:![0-9]+]]
// PPC64-NEXT:    [[TMP12:%.*]] = load double, ptr @dv, align 8, !dbg [[DBG35:![0-9]+]]
// PPC64-NEXT:    store atomic double [[TMP12]], ptr @dx monotonic, align 8, !dbg [[DBG36:![0-9]+]]
// PPC64-NEXT:    [[TMP13:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG37:![0-9]+]]
// PPC64-NEXT:    store ppc_fp128 [[TMP13]], ptr [[ATOMIC_TEMP]], align 16, !dbg [[DBG38:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_store(i64 noundef 16, ptr noundef @ldx, ptr noundef [[ATOMIC_TEMP]], i32 noundef signext 0), !dbg [[DBG38]]
// PPC64-NEXT:    [[CIV_REAL:%.*]] = load i32, ptr @civ, align 4, !dbg [[DBG39:![0-9]+]]
// PPC64-NEXT:    [[CIV_IMAG:%.*]] = load i32, ptr getelementptr inbounds ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG39]]
// PPC64-NEXT:    [[ATOMIC_TEMP1_REALP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP1]], i32 0, i32 0, !dbg [[DBG40:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_TEMP1_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP1]], i32 0, i32 1, !dbg [[DBG40]]
// PPC64-NEXT:    store i32 [[CIV_REAL]], ptr [[ATOMIC_TEMP1_REALP]], align 4, !dbg [[DBG40]]
// PPC64-NEXT:    store i32 [[CIV_IMAG]], ptr [[ATOMIC_TEMP1_IMAGP]], align 4, !dbg [[DBG40]]
// PPC64-NEXT:    call void @__atomic_store(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP1]], i32 noundef signext 0), !dbg [[DBG40]]
// PPC64-NEXT:    [[CFV_REAL:%.*]] = load float, ptr @cfv, align 4, !dbg [[DBG41:![0-9]+]]
// PPC64-NEXT:    [[CFV_IMAG:%.*]] = load float, ptr getelementptr inbounds ({ float, float }, ptr @cfv, i32 0, i32 1), align 4, !dbg [[DBG41]]
// PPC64-NEXT:    [[ATOMIC_TEMP2_REALP:%.*]] = getelementptr inbounds { float, float }, ptr [[ATOMIC_TEMP2]], i32 0, i32 0, !dbg [[DBG42:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_TEMP2_IMAGP:%.*]] = getelementptr inbounds { float, float }, ptr [[ATOMIC_TEMP2]], i32 0, i32 1, !dbg [[DBG42]]
// PPC64-NEXT:    store float [[CFV_REAL]], ptr [[ATOMIC_TEMP2_REALP]], align 4, !dbg [[DBG42]]
// PPC64-NEXT:    store float [[CFV_IMAG]], ptr [[ATOMIC_TEMP2_IMAGP]], align 4, !dbg [[DBG42]]
// PPC64-NEXT:    call void @__atomic_store(i64 noundef 8, ptr noundef @cfx, ptr noundef [[ATOMIC_TEMP2]], i32 noundef signext 0), !dbg [[DBG42]]
// PPC64-NEXT:    [[CDV_REAL:%.*]] = load double, ptr @cdv, align 8, !dbg [[DBG43:![0-9]+]]
// PPC64-NEXT:    [[CDV_IMAG:%.*]] = load double, ptr getelementptr inbounds ({ double, double }, ptr @cdv, i32 0, i32 1), align 8, !dbg [[DBG43]]
// PPC64-NEXT:    [[ATOMIC_TEMP3_REALP:%.*]] = getelementptr inbounds { double, double }, ptr [[ATOMIC_TEMP3]], i32 0, i32 0, !dbg [[DBG44:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_TEMP3_IMAGP:%.*]] = getelementptr inbounds { double, double }, ptr [[ATOMIC_TEMP3]], i32 0, i32 1, !dbg [[DBG44]]
// PPC64-NEXT:    store double [[CDV_REAL]], ptr [[ATOMIC_TEMP3_REALP]], align 8, !dbg [[DBG44]]
// PPC64-NEXT:    store double [[CDV_IMAG]], ptr [[ATOMIC_TEMP3_IMAGP]], align 8, !dbg [[DBG44]]
// PPC64-NEXT:    call void @__atomic_store(i64 noundef 16, ptr noundef @cdx, ptr noundef [[ATOMIC_TEMP3]], i32 noundef signext 5), !dbg [[DBG44]]
// PPC64-NEXT:    fence release
// PPC64-NEXT:    [[TMP14:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG45:![0-9]+]]
// PPC64-NEXT:    [[TOBOOL4:%.*]] = trunc i8 [[TMP14]] to i1, !dbg [[DBG45]]
// PPC64-NEXT:    [[CONV:%.*]] = zext i1 [[TOBOOL4]] to i64, !dbg [[DBG45]]
// PPC64-NEXT:    store atomic i64 [[CONV]], ptr @ulx monotonic, align 8, !dbg [[DBG46:![0-9]+]]
// PPC64-NEXT:    [[TMP15:%.*]] = load i8, ptr @cv, align 1, !dbg [[DBG47:![0-9]+]]
// PPC64-NEXT:    [[TOBOOL5:%.*]] = icmp ne i8 [[TMP15]], 0, !dbg [[DBG47]]
// PPC64-NEXT:    [[FROMBOOL6:%.*]] = zext i1 [[TOBOOL5]] to i8, !dbg [[DBG48:![0-9]+]]
// PPC64-NEXT:    store atomic i8 [[FROMBOOL6]], ptr @bx monotonic, align 1, !dbg [[DBG48]]
// PPC64-NEXT:    [[TMP16:%.*]] = load i8, ptr @ucv, align 1, !dbg [[DBG49:![0-9]+]]
// PPC64-NEXT:    store atomic i8 [[TMP16]], ptr @cx seq_cst, align 1, !dbg [[DBG50:![0-9]+]]
// PPC64-NEXT:    fence release
// PPC64-NEXT:    [[TMP17:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG51:![0-9]+]]
// PPC64-NEXT:    [[CONV7:%.*]] = sext i16 [[TMP17]] to i64, !dbg [[DBG51]]
// PPC64-NEXT:    store atomic i64 [[CONV7]], ptr @ulx monotonic, align 8, !dbg [[DBG52:![0-9]+]]
// PPC64-NEXT:    [[TMP18:%.*]] = load i16, ptr @usv, align 2, !dbg [[DBG53:![0-9]+]]
// PPC64-NEXT:    [[CONV8:%.*]] = zext i16 [[TMP18]] to i64, !dbg [[DBG53]]
// PPC64-NEXT:    store atomic i64 [[CONV8]], ptr @lx monotonic, align 8, !dbg [[DBG54:![0-9]+]]
// PPC64-NEXT:    [[TMP19:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG55:![0-9]+]]
// PPC64-NEXT:    store atomic i32 [[TMP19]], ptr @uix seq_cst, align 4, !dbg [[DBG56:![0-9]+]]
// PPC64-NEXT:    fence release
// PPC64-NEXT:    [[TMP20:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG57:![0-9]+]]
// PPC64-NEXT:    store atomic i32 [[TMP20]], ptr @ix monotonic, align 4, !dbg [[DBG58:![0-9]+]]
// PPC64-NEXT:    [[TMP21:%.*]] = load i64, ptr @lv, align 8, !dbg [[DBG59:![0-9]+]]
// PPC64-NEXT:    [[CONV9:%.*]] = trunc i64 [[TMP21]] to i32, !dbg [[DBG59]]
// PPC64-NEXT:    [[ATOMIC_TEMP10_REALP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP10]], i32 0, i32 0, !dbg [[DBG60:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_TEMP10_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP10]], i32 0, i32 1, !dbg [[DBG60]]
// PPC64-NEXT:    store i32 [[CONV9]], ptr [[ATOMIC_TEMP10_REALP]], align 4, !dbg [[DBG60]]
// PPC64-NEXT:    store i32 0, ptr [[ATOMIC_TEMP10_IMAGP]], align 4, !dbg [[DBG60]]
// PPC64-NEXT:    call void @__atomic_store(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP10]], i32 noundef signext 0), !dbg [[DBG60]]
// PPC64-NEXT:    [[TMP22:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG61:![0-9]+]]
// PPC64-NEXT:    [[CONV11:%.*]] = uitofp i64 [[TMP22]] to float, !dbg [[DBG61]]
// PPC64-NEXT:    store atomic float [[CONV11]], ptr @fx monotonic, align 4, !dbg [[DBG62:![0-9]+]]
// PPC64-NEXT:    [[TMP23:%.*]] = load i64, ptr @llv, align 8, !dbg [[DBG63:![0-9]+]]
// PPC64-NEXT:    [[CONV12:%.*]] = sitofp i64 [[TMP23]] to double, !dbg [[DBG63]]
// PPC64-NEXT:    store atomic double [[CONV12]], ptr @dx monotonic, align 8, !dbg [[DBG64:![0-9]+]]
// PPC64-NEXT:    [[TMP24:%.*]] = load i64, ptr @ullv, align 8, !dbg [[DBG65:![0-9]+]]
// PPC64-NEXT:    [[CONV13:%.*]] = uitofp i64 [[TMP24]] to ppc_fp128, !dbg [[DBG65]]
// PPC64-NEXT:    store ppc_fp128 [[CONV13]], ptr [[ATOMIC_TEMP14]], align 16, !dbg [[DBG66:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_store(i64 noundef 16, ptr noundef @ldx, ptr noundef [[ATOMIC_TEMP14]], i32 noundef signext 0), !dbg [[DBG66]]
// PPC64-NEXT:    [[TMP25:%.*]] = load float, ptr @fv, align 4, !dbg [[DBG67:![0-9]+]]
// PPC64-NEXT:    [[CONV15:%.*]] = fptosi float [[TMP25]] to i32, !dbg [[DBG67]]
// PPC64-NEXT:    [[ATOMIC_TEMP16_REALP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP16]], i32 0, i32 0, !dbg [[DBG68:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_TEMP16_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP16]], i32 0, i32 1, !dbg [[DBG68]]
// PPC64-NEXT:    store i32 [[CONV15]], ptr [[ATOMIC_TEMP16_REALP]], align 4, !dbg [[DBG68]]
// PPC64-NEXT:    store i32 0, ptr [[ATOMIC_TEMP16_IMAGP]], align 4, !dbg [[DBG68]]
// PPC64-NEXT:    call void @__atomic_store(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP16]], i32 noundef signext 0), !dbg [[DBG68]]
// PPC64-NEXT:    [[TMP26:%.*]] = load double, ptr @dv, align 8, !dbg [[DBG69:![0-9]+]]
// PPC64-NEXT:    [[CONV17:%.*]] = fptosi double [[TMP26]] to i16, !dbg [[DBG69]]
// PPC64-NEXT:    store atomic i16 [[CONV17]], ptr @sx monotonic, align 2, !dbg [[DBG70:![0-9]+]]
// PPC64-NEXT:    [[TMP27:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG71:![0-9]+]]
// PPC64-NEXT:    [[TOBOOL18:%.*]] = fcmp une ppc_fp128 [[TMP27]], 0xM00000000000000000000000000000000, !dbg [[DBG71]]
// PPC64-NEXT:    [[FROMBOOL19:%.*]] = zext i1 [[TOBOOL18]] to i8, !dbg [[DBG72:![0-9]+]]
// PPC64-NEXT:    store atomic i8 [[FROMBOOL19]], ptr @bx monotonic, align 1, !dbg [[DBG72]]
// PPC64-NEXT:    [[CIV_REAL20:%.*]] = load i32, ptr @civ, align 4, !dbg [[DBG73:![0-9]+]]
// PPC64-NEXT:    [[CIV_IMAG21:%.*]] = load i32, ptr getelementptr inbounds ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG73]]
// PPC64-NEXT:    [[TOBOOL22:%.*]] = icmp ne i32 [[CIV_REAL20]], 0, !dbg [[DBG73]]
// PPC64-NEXT:    [[TOBOOL23:%.*]] = icmp ne i32 [[CIV_IMAG21]], 0, !dbg [[DBG73]]
// PPC64-NEXT:    [[TOBOOL24:%.*]] = or i1 [[TOBOOL22]], [[TOBOOL23]], !dbg [[DBG73]]
// PPC64-NEXT:    [[FROMBOOL25:%.*]] = zext i1 [[TOBOOL24]] to i8, !dbg [[DBG74:![0-9]+]]
// PPC64-NEXT:    store atomic i8 [[FROMBOOL25]], ptr @bx monotonic, align 1, !dbg [[DBG74]]
// PPC64-NEXT:    [[CFV_REAL26:%.*]] = load float, ptr @cfv, align 4, !dbg [[DBG75:![0-9]+]]
// PPC64-NEXT:    [[CONV27:%.*]] = fptoui float [[CFV_REAL26]] to i16, !dbg [[DBG75]]
// PPC64-NEXT:    store atomic i16 [[CONV27]], ptr @usx monotonic, align 2, !dbg [[DBG76:![0-9]+]]
// PPC64-NEXT:    [[CDV_REAL28:%.*]] = load double, ptr @cdv, align 8, !dbg [[DBG77:![0-9]+]]
// PPC64-NEXT:    [[CONV29:%.*]] = fptosi double [[CDV_REAL28]] to i64, !dbg [[DBG77]]
// PPC64-NEXT:    store atomic i64 [[CONV29]], ptr @llx monotonic, align 8, !dbg [[DBG78:![0-9]+]]
// PPC64-NEXT:    [[TMP28:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG79:![0-9]+]]
// PPC64-NEXT:    [[TMP29:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG80:![0-9]+]]
// PPC64-NEXT:    [[TOBOOL30:%.*]] = trunc i8 [[TMP29]] to i1, !dbg [[DBG80]]
// PPC64-NEXT:    [[CONV31:%.*]] = zext i1 [[TOBOOL30]] to i32, !dbg [[DBG80]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 16, ptr noundef @int4x, ptr noundef [[ATOMIC_TEMP32]], i32 noundef signext 0), !dbg [[DBG81:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT:%.*]], !dbg [[DBG81]]
// PPC64:       atomic_cont:
// PPC64-NEXT:    [[TMP30:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP32]], align 16, !dbg [[DBG81]]
// PPC64-NEXT:    store <4 x i32> [[TMP30]], ptr [[ATOMIC_TEMP33]], align 16, !dbg [[DBG81]]
// PPC64-NEXT:    [[TMP31:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP33]], align 16, !dbg [[DBG81]]
// PPC64-NEXT:    [[VECINS:%.*]] = insertelement <4 x i32> [[TMP31]], i32 [[CONV31]], i16 [[TMP28]], !dbg [[DBG81]]
// PPC64-NEXT:    store <4 x i32> [[VECINS]], ptr [[ATOMIC_TEMP33]], align 16, !dbg [[DBG81]]
// PPC64-NEXT:    [[CALL:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, ptr noundef @int4x, ptr noundef [[ATOMIC_TEMP32]], ptr noundef [[ATOMIC_TEMP33]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG81]]
// PPC64-NEXT:    br i1 [[CALL]], label [[ATOMIC_EXIT:%.*]], label [[ATOMIC_CONT]], !dbg [[DBG81]]
// PPC64:       atomic_exit:
// PPC64-NEXT:    [[TMP32:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG82:![0-9]+]]
// PPC64-NEXT:    [[CONV34:%.*]] = fptosi ppc_fp128 [[TMP32]] to i32, !dbg [[DBG82]]
// PPC64-NEXT:    [[ATOMIC_LOAD:%.*]] = load atomic i32, ptr @bfx monotonic, align 4, !dbg [[DBG83:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT35:%.*]], !dbg [[DBG83]]
// PPC64:       atomic_cont35:
// PPC64-NEXT:    [[TMP33:%.*]] = phi i32 [ [[ATOMIC_LOAD]], [[ATOMIC_EXIT]] ], [ [[TMP36:%.*]], [[ATOMIC_CONT35]] ], !dbg [[DBG83]]
// PPC64-NEXT:    store i32 [[TMP33]], ptr [[ATOMIC_TEMP36]], align 4, !dbg [[DBG83]]
// PPC64-NEXT:    [[BF_LOAD:%.*]] = load i32, ptr [[ATOMIC_TEMP36]], align 4, !dbg [[DBG83]]
// PPC64-NEXT:    [[BF_VALUE:%.*]] = and i32 [[CONV34]], 2147483647, !dbg [[DBG83]]
// PPC64-NEXT:    [[BF_SHL:%.*]] = shl i32 [[BF_VALUE]], 1, !dbg [[DBG83]]
// PPC64-NEXT:    [[BF_CLEAR:%.*]] = and i32 [[BF_LOAD]], 1, !dbg [[DBG83]]
// PPC64-NEXT:    [[BF_SET:%.*]] = or i32 [[BF_CLEAR]], [[BF_SHL]], !dbg [[DBG83]]
// PPC64-NEXT:    store i32 [[BF_SET]], ptr [[ATOMIC_TEMP36]], align 4, !dbg [[DBG83]]
// PPC64-NEXT:    [[TMP34:%.*]] = load i32, ptr [[ATOMIC_TEMP36]], align 4, !dbg [[DBG83]]
// PPC64-NEXT:    [[TMP35:%.*]] = cmpxchg ptr @bfx, i32 [[TMP33]], i32 [[TMP34]] monotonic monotonic, align 4, !dbg [[DBG83]]
// PPC64-NEXT:    [[TMP36]] = extractvalue { i32, i1 } [[TMP35]], 0, !dbg [[DBG83]]
// PPC64-NEXT:    [[TMP37:%.*]] = extractvalue { i32, i1 } [[TMP35]], 1, !dbg [[DBG83]]
// PPC64-NEXT:    br i1 [[TMP37]], label [[ATOMIC_EXIT37:%.*]], label [[ATOMIC_CONT35]], !dbg [[DBG83]]
// PPC64:       atomic_exit37:
// PPC64-NEXT:    [[TMP38:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG84:![0-9]+]]
// PPC64-NEXT:    [[CONV38:%.*]] = fptosi ppc_fp128 [[TMP38]] to i32, !dbg [[DBG84]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 4, ptr noundef @bfx_packed, ptr noundef [[ATOMIC_TEMP39]], i32 noundef signext 0), !dbg [[DBG85:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT40:%.*]], !dbg [[DBG85]]
// PPC64:       atomic_cont40:
// PPC64-NEXT:    [[TMP39:%.*]] = load i32, ptr [[ATOMIC_TEMP39]], align 1, !dbg [[DBG85]]
// PPC64-NEXT:    store i32 [[TMP39]], ptr [[ATOMIC_TEMP41]], align 1, !dbg [[DBG85]]
// PPC64-NEXT:    [[BF_LOAD42:%.*]] = load i32, ptr [[ATOMIC_TEMP41]], align 1, !dbg [[DBG85]]
// PPC64-NEXT:    [[BF_VALUE43:%.*]] = and i32 [[CONV38]], 2147483647, !dbg [[DBG85]]
// PPC64-NEXT:    [[BF_SHL44:%.*]] = shl i32 [[BF_VALUE43]], 1, !dbg [[DBG85]]
// PPC64-NEXT:    [[BF_CLEAR45:%.*]] = and i32 [[BF_LOAD42]], 1, !dbg [[DBG85]]
// PPC64-NEXT:    [[BF_SET46:%.*]] = or i32 [[BF_CLEAR45]], [[BF_SHL44]], !dbg [[DBG85]]
// PPC64-NEXT:    store i32 [[BF_SET46]], ptr [[ATOMIC_TEMP41]], align 1, !dbg [[DBG85]]
// PPC64-NEXT:    [[CALL47:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 4, ptr noundef @bfx_packed, ptr noundef [[ATOMIC_TEMP39]], ptr noundef [[ATOMIC_TEMP41]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG85]]
// PPC64-NEXT:    br i1 [[CALL47]], label [[ATOMIC_EXIT48:%.*]], label [[ATOMIC_CONT40]], !dbg [[DBG85]]
// PPC64:       atomic_exit48:
// PPC64-NEXT:    [[TMP40:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG86:![0-9]+]]
// PPC64-NEXT:    [[CONV49:%.*]] = fptosi ppc_fp128 [[TMP40]] to i32, !dbg [[DBG86]]
// PPC64-NEXT:    [[ATOMIC_LOAD50:%.*]] = load atomic i32, ptr @bfx2 monotonic, align 4, !dbg [[DBG87:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT51:%.*]], !dbg [[DBG87]]
// PPC64:       atomic_cont51:
// PPC64-NEXT:    [[TMP41:%.*]] = phi i32 [ [[ATOMIC_LOAD50]], [[ATOMIC_EXIT48]] ], [ [[TMP44:%.*]], [[ATOMIC_CONT51]] ], !dbg [[DBG87]]
// PPC64-NEXT:    store i32 [[TMP41]], ptr [[ATOMIC_TEMP52]], align 4, !dbg [[DBG87]]
// PPC64-NEXT:    [[BF_LOAD53:%.*]] = load i32, ptr [[ATOMIC_TEMP52]], align 4, !dbg [[DBG87]]
// PPC64-NEXT:    [[BF_VALUE54:%.*]] = and i32 [[CONV49]], 1, !dbg [[DBG87]]
// PPC64-NEXT:    [[BF_CLEAR55:%.*]] = and i32 [[BF_LOAD53]], -2, !dbg [[DBG87]]
// PPC64-NEXT:    [[BF_SET56:%.*]] = or i32 [[BF_CLEAR55]], [[BF_VALUE54]], !dbg [[DBG87]]
// PPC64-NEXT:    store i32 [[BF_SET56]], ptr [[ATOMIC_TEMP52]], align 4, !dbg [[DBG87]]
// PPC64-NEXT:    [[TMP42:%.*]] = load i32, ptr [[ATOMIC_TEMP52]], align 4, !dbg [[DBG87]]
// PPC64-NEXT:    [[TMP43:%.*]] = cmpxchg ptr @bfx2, i32 [[TMP41]], i32 [[TMP42]] monotonic monotonic, align 4, !dbg [[DBG87]]
// PPC64-NEXT:    [[TMP44]] = extractvalue { i32, i1 } [[TMP43]], 0, !dbg [[DBG87]]
// PPC64-NEXT:    [[TMP45:%.*]] = extractvalue { i32, i1 } [[TMP43]], 1, !dbg [[DBG87]]
// PPC64-NEXT:    br i1 [[TMP45]], label [[ATOMIC_EXIT57:%.*]], label [[ATOMIC_CONT51]], !dbg [[DBG87]]
// PPC64:       atomic_exit57:
// PPC64-NEXT:    [[TMP46:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG88:![0-9]+]]
// PPC64-NEXT:    [[CONV58:%.*]] = fptosi ppc_fp128 [[TMP46]] to i32, !dbg [[DBG88]]
// PPC64-NEXT:    [[ATOMIC_LOAD59:%.*]] = load atomic i8, ptr @bfx2_packed monotonic, align 1, !dbg [[DBG89:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT60:%.*]], !dbg [[DBG89]]
// PPC64:       atomic_cont60:
// PPC64-NEXT:    [[TMP47:%.*]] = phi i8 [ [[ATOMIC_LOAD59]], [[ATOMIC_EXIT57]] ], [ [[TMP51:%.*]], [[ATOMIC_CONT60]] ], !dbg [[DBG89]]
// PPC64-NEXT:    store i8 [[TMP47]], ptr [[ATOMIC_TEMP61]], align 1, !dbg [[DBG89]]
// PPC64-NEXT:    [[TMP48:%.*]] = trunc i32 [[CONV58]] to i8, !dbg [[DBG89]]
// PPC64-NEXT:    [[BF_LOAD62:%.*]] = load i8, ptr [[ATOMIC_TEMP61]], align 1, !dbg [[DBG89]]
// PPC64-NEXT:    [[BF_VALUE63:%.*]] = and i8 [[TMP48]], 1, !dbg [[DBG89]]
// PPC64-NEXT:    [[BF_CLEAR64:%.*]] = and i8 [[BF_LOAD62]], -2, !dbg [[DBG89]]
// PPC64-NEXT:    [[BF_SET65:%.*]] = or i8 [[BF_CLEAR64]], [[BF_VALUE63]], !dbg [[DBG89]]
// PPC64-NEXT:    store i8 [[BF_SET65]], ptr [[ATOMIC_TEMP61]], align 1, !dbg [[DBG89]]
// PPC64-NEXT:    [[TMP49:%.*]] = load i8, ptr [[ATOMIC_TEMP61]], align 1, !dbg [[DBG89]]
// PPC64-NEXT:    [[TMP50:%.*]] = cmpxchg ptr @bfx2_packed, i8 [[TMP47]], i8 [[TMP49]] monotonic monotonic, align 1, !dbg [[DBG89]]
// PPC64-NEXT:    [[TMP51]] = extractvalue { i8, i1 } [[TMP50]], 0, !dbg [[DBG89]]
// PPC64-NEXT:    [[TMP52:%.*]] = extractvalue { i8, i1 } [[TMP50]], 1, !dbg [[DBG89]]
// PPC64-NEXT:    br i1 [[TMP52]], label [[ATOMIC_EXIT66:%.*]], label [[ATOMIC_CONT60]], !dbg [[DBG89]]
// PPC64:       atomic_exit66:
// PPC64-NEXT:    [[TMP53:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG90:![0-9]+]]
// PPC64-NEXT:    [[CONV67:%.*]] = fptosi ppc_fp128 [[TMP53]] to i32, !dbg [[DBG90]]
// PPC64-NEXT:    [[ATOMIC_LOAD68:%.*]] = load atomic i32, ptr @bfx3 monotonic, align 4, !dbg [[DBG91:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT69:%.*]], !dbg [[DBG91]]
// PPC64:       atomic_cont69:
// PPC64-NEXT:    [[TMP54:%.*]] = phi i32 [ [[ATOMIC_LOAD68]], [[ATOMIC_EXIT66]] ], [ [[TMP57:%.*]], [[ATOMIC_CONT69]] ], !dbg [[DBG91]]
// PPC64-NEXT:    store i32 [[TMP54]], ptr [[ATOMIC_TEMP70]], align 4, !dbg [[DBG91]]
// PPC64-NEXT:    [[BF_LOAD71:%.*]] = load i32, ptr [[ATOMIC_TEMP70]], align 4, !dbg [[DBG91]]
// PPC64-NEXT:    [[BF_VALUE72:%.*]] = and i32 [[CONV67]], 16383, !dbg [[DBG91]]
// PPC64-NEXT:    [[BF_SHL73:%.*]] = shl i32 [[BF_VALUE72]], 7, !dbg [[DBG91]]
// PPC64-NEXT:    [[BF_CLEAR74:%.*]] = and i32 [[BF_LOAD71]], -2097025, !dbg [[DBG91]]
// PPC64-NEXT:    [[BF_SET75:%.*]] = or i32 [[BF_CLEAR74]], [[BF_SHL73]], !dbg [[DBG91]]
// PPC64-NEXT:    store i32 [[BF_SET75]], ptr [[ATOMIC_TEMP70]], align 4, !dbg [[DBG91]]
// PPC64-NEXT:    [[TMP55:%.*]] = load i32, ptr [[ATOMIC_TEMP70]], align 4, !dbg [[DBG91]]
// PPC64-NEXT:    [[TMP56:%.*]] = cmpxchg ptr @bfx3, i32 [[TMP54]], i32 [[TMP55]] monotonic monotonic, align 4, !dbg [[DBG91]]
// PPC64-NEXT:    [[TMP57]] = extractvalue { i32, i1 } [[TMP56]], 0, !dbg [[DBG91]]
// PPC64-NEXT:    [[TMP58:%.*]] = extractvalue { i32, i1 } [[TMP56]], 1, !dbg [[DBG91]]
// PPC64-NEXT:    br i1 [[TMP58]], label [[ATOMIC_EXIT76:%.*]], label [[ATOMIC_CONT69]], !dbg [[DBG91]]
// PPC64:       atomic_exit76:
// PPC64-NEXT:    [[TMP59:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG92:![0-9]+]]
// PPC64-NEXT:    [[CONV77:%.*]] = fptosi ppc_fp128 [[TMP59]] to i32, !dbg [[DBG92]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 3, ptr noundef @bfx3_packed, ptr noundef [[ATOMIC_TEMP78]], i32 noundef signext 0), !dbg [[DBG93:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT79:%.*]], !dbg [[DBG93]]
// PPC64:       atomic_cont79:
// PPC64-NEXT:    [[TMP60:%.*]] = load i24, ptr [[ATOMIC_TEMP78]], align 1, !dbg [[DBG93]]
// PPC64-NEXT:    store i24 [[TMP60]], ptr [[ATOMIC_TEMP80]], align 1, !dbg [[DBG93]]
// PPC64-NEXT:    [[TMP61:%.*]] = trunc i32 [[CONV77]] to i24, !dbg [[DBG93]]
// PPC64-NEXT:    [[BF_LOAD81:%.*]] = load i24, ptr [[ATOMIC_TEMP80]], align 1, !dbg [[DBG93]]
// PPC64-NEXT:    [[BF_VALUE82:%.*]] = and i24 [[TMP61]], 16383, !dbg [[DBG93]]
// PPC64-NEXT:    [[BF_SHL83:%.*]] = shl i24 [[BF_VALUE82]], 7, !dbg [[DBG93]]
// PPC64-NEXT:    [[BF_CLEAR84:%.*]] = and i24 [[BF_LOAD81]], -2097025, !dbg [[DBG93]]
// PPC64-NEXT:    [[BF_SET85:%.*]] = or i24 [[BF_CLEAR84]], [[BF_SHL83]], !dbg [[DBG93]]
// PPC64-NEXT:    store i24 [[BF_SET85]], ptr [[ATOMIC_TEMP80]], align 1, !dbg [[DBG93]]
// PPC64-NEXT:    [[CALL86:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 3, ptr noundef @bfx3_packed, ptr noundef [[ATOMIC_TEMP78]], ptr noundef [[ATOMIC_TEMP80]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG93]]
// PPC64-NEXT:    br i1 [[CALL86]], label [[ATOMIC_EXIT87:%.*]], label [[ATOMIC_CONT79]], !dbg [[DBG93]]
// PPC64:       atomic_exit87:
// PPC64-NEXT:    [[TMP62:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG94:![0-9]+]]
// PPC64-NEXT:    [[CONV88:%.*]] = fptosi ppc_fp128 [[TMP62]] to i32, !dbg [[DBG94]]
// PPC64-NEXT:    [[ATOMIC_LOAD89:%.*]] = load atomic i64, ptr @bfx4 monotonic, align 8, !dbg [[DBG95:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT90:%.*]], !dbg [[DBG95]]
// PPC64:       atomic_cont90:
// PPC64-NEXT:    [[TMP63:%.*]] = phi i64 [ [[ATOMIC_LOAD89]], [[ATOMIC_EXIT87]] ], [ [[TMP67:%.*]], [[ATOMIC_CONT90]] ], !dbg [[DBG95]]
// PPC64-NEXT:    store i64 [[TMP63]], ptr [[ATOMIC_TEMP91]], align 8, !dbg [[DBG95]]
// PPC64-NEXT:    [[TMP64:%.*]] = zext i32 [[CONV88]] to i64, !dbg [[DBG95]]
// PPC64-NEXT:    [[BF_LOAD92:%.*]] = load i64, ptr [[ATOMIC_TEMP91]], align 8, !dbg [[DBG95]]
// PPC64-NEXT:    [[BF_VALUE93:%.*]] = and i64 [[TMP64]], 1, !dbg [[DBG95]]
// PPC64-NEXT:    [[BF_SHL94:%.*]] = shl i64 [[BF_VALUE93]], 15, !dbg [[DBG95]]
// PPC64-NEXT:    [[BF_CLEAR95:%.*]] = and i64 [[BF_LOAD92]], -32769, !dbg [[DBG95]]
// PPC64-NEXT:    [[BF_SET96:%.*]] = or i64 [[BF_CLEAR95]], [[BF_SHL94]], !dbg [[DBG95]]
// PPC64-NEXT:    store i64 [[BF_SET96]], ptr [[ATOMIC_TEMP91]], align 8, !dbg [[DBG95]]
// PPC64-NEXT:    [[TMP65:%.*]] = load i64, ptr [[ATOMIC_TEMP91]], align 8, !dbg [[DBG95]]
// PPC64-NEXT:    [[TMP66:%.*]] = cmpxchg ptr @bfx4, i64 [[TMP63]], i64 [[TMP65]] monotonic monotonic, align 8, !dbg [[DBG95]]
// PPC64-NEXT:    [[TMP67]] = extractvalue { i64, i1 } [[TMP66]], 0, !dbg [[DBG95]]
// PPC64-NEXT:    [[TMP68:%.*]] = extractvalue { i64, i1 } [[TMP66]], 1, !dbg [[DBG95]]
// PPC64-NEXT:    br i1 [[TMP68]], label [[ATOMIC_EXIT97:%.*]], label [[ATOMIC_CONT90]], !dbg [[DBG95]]
// PPC64:       atomic_exit97:
// PPC64-NEXT:    [[TMP69:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG96:![0-9]+]]
// PPC64-NEXT:    [[CONV98:%.*]] = fptosi ppc_fp128 [[TMP69]] to i32, !dbg [[DBG96]]
// PPC64-NEXT:    [[ATOMIC_LOAD99:%.*]] = load atomic i8, ptr @bfx4_packed monotonic, align 1, !dbg [[DBG97:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT100:%.*]], !dbg [[DBG97]]
// PPC64:       atomic_cont100:
// PPC64-NEXT:    [[TMP70:%.*]] = phi i8 [ [[ATOMIC_LOAD99]], [[ATOMIC_EXIT97]] ], [ [[TMP74:%.*]], [[ATOMIC_CONT100]] ], !dbg [[DBG97]]
// PPC64-NEXT:    store i8 [[TMP70]], ptr [[ATOMIC_TEMP101]], align 1, !dbg [[DBG97]]
// PPC64-NEXT:    [[TMP71:%.*]] = trunc i32 [[CONV98]] to i8, !dbg [[DBG97]]
// PPC64-NEXT:    [[BF_LOAD102:%.*]] = load i8, ptr [[ATOMIC_TEMP101]], align 1, !dbg [[DBG97]]
// PPC64-NEXT:    [[BF_VALUE103:%.*]] = and i8 [[TMP71]], 1, !dbg [[DBG97]]
// PPC64-NEXT:    [[BF_SHL104:%.*]] = shl i8 [[BF_VALUE103]], 7, !dbg [[DBG97]]
// PPC64-NEXT:    [[BF_CLEAR105:%.*]] = and i8 [[BF_LOAD102]], 127, !dbg [[DBG97]]
// PPC64-NEXT:    [[BF_SET106:%.*]] = or i8 [[BF_CLEAR105]], [[BF_SHL104]], !dbg [[DBG97]]
// PPC64-NEXT:    store i8 [[BF_SET106]], ptr [[ATOMIC_TEMP101]], align 1, !dbg [[DBG97]]
// PPC64-NEXT:    [[TMP72:%.*]] = load i8, ptr [[ATOMIC_TEMP101]], align 1, !dbg [[DBG97]]
// PPC64-NEXT:    [[TMP73:%.*]] = cmpxchg ptr @bfx4_packed, i8 [[TMP70]], i8 [[TMP72]] monotonic monotonic, align 1, !dbg [[DBG97]]
// PPC64-NEXT:    [[TMP74]] = extractvalue { i8, i1 } [[TMP73]], 0, !dbg [[DBG97]]
// PPC64-NEXT:    [[TMP75:%.*]] = extractvalue { i8, i1 } [[TMP73]], 1, !dbg [[DBG97]]
// PPC64-NEXT:    br i1 [[TMP75]], label [[ATOMIC_EXIT107:%.*]], label [[ATOMIC_CONT100]], !dbg [[DBG97]]
// PPC64:       atomic_exit107:
// PPC64-NEXT:    [[TMP76:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG98:![0-9]+]]
// PPC64-NEXT:    [[CONV108:%.*]] = fptosi ppc_fp128 [[TMP76]] to i64, !dbg [[DBG98]]
// PPC64-NEXT:    [[ATOMIC_LOAD109:%.*]] = load atomic i64, ptr @bfx4 monotonic, align 8, !dbg [[DBG99:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT110:%.*]], !dbg [[DBG99]]
// PPC64:       atomic_cont110:
// PPC64-NEXT:    [[TMP77:%.*]] = phi i64 [ [[ATOMIC_LOAD109]], [[ATOMIC_EXIT107]] ], [ [[TMP80:%.*]], [[ATOMIC_CONT110]] ], !dbg [[DBG99]]
// PPC64-NEXT:    store i64 [[TMP77]], ptr [[ATOMIC_TEMP111]], align 8, !dbg [[DBG99]]
// PPC64-NEXT:    [[BF_LOAD112:%.*]] = load i64, ptr [[ATOMIC_TEMP111]], align 8, !dbg [[DBG99]]
// PPC64-NEXT:    [[BF_VALUE113:%.*]] = and i64 [[CONV108]], 127, !dbg [[DBG99]]
// PPC64-NEXT:    [[BF_SHL114:%.*]] = shl i64 [[BF_VALUE113]], 8, !dbg [[DBG99]]
// PPC64-NEXT:    [[BF_CLEAR115:%.*]] = and i64 [[BF_LOAD112]], -32513, !dbg [[DBG99]]
// PPC64-NEXT:    [[BF_SET116:%.*]] = or i64 [[BF_CLEAR115]], [[BF_SHL114]], !dbg [[DBG99]]
// PPC64-NEXT:    store i64 [[BF_SET116]], ptr [[ATOMIC_TEMP111]], align 8, !dbg [[DBG99]]
// PPC64-NEXT:    [[TMP78:%.*]] = load i64, ptr [[ATOMIC_TEMP111]], align 8, !dbg [[DBG99]]
// PPC64-NEXT:    [[TMP79:%.*]] = cmpxchg ptr @bfx4, i64 [[TMP77]], i64 [[TMP78]] monotonic monotonic, align 8, !dbg [[DBG99]]
// PPC64-NEXT:    [[TMP80]] = extractvalue { i64, i1 } [[TMP79]], 0, !dbg [[DBG99]]
// PPC64-NEXT:    [[TMP81:%.*]] = extractvalue { i64, i1 } [[TMP79]], 1, !dbg [[DBG99]]
// PPC64-NEXT:    br i1 [[TMP81]], label [[ATOMIC_EXIT117:%.*]], label [[ATOMIC_CONT110]], !dbg [[DBG99]]
// PPC64:       atomic_exit117:
// PPC64-NEXT:    [[TMP82:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG100:![0-9]+]]
// PPC64-NEXT:    [[CONV118:%.*]] = fptosi ppc_fp128 [[TMP82]] to i64, !dbg [[DBG100]]
// PPC64-NEXT:    [[ATOMIC_LOAD119:%.*]] = load atomic i8, ptr @bfx4_packed monotonic, align 1, !dbg [[DBG101:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT120:%.*]], !dbg [[DBG101]]
// PPC64:       atomic_cont120:
// PPC64-NEXT:    [[TMP83:%.*]] = phi i8 [ [[ATOMIC_LOAD119]], [[ATOMIC_EXIT117]] ], [ [[TMP87:%.*]], [[ATOMIC_CONT120]] ], !dbg [[DBG101]]
// PPC64-NEXT:    store i8 [[TMP83]], ptr [[ATOMIC_TEMP121]], align 1, !dbg [[DBG101]]
// PPC64-NEXT:    [[TMP84:%.*]] = trunc i64 [[CONV118]] to i8, !dbg [[DBG101]]
// PPC64-NEXT:    [[BF_LOAD122:%.*]] = load i8, ptr [[ATOMIC_TEMP121]], align 1, !dbg [[DBG101]]
// PPC64-NEXT:    [[BF_VALUE123:%.*]] = and i8 [[TMP84]], 127, !dbg [[DBG101]]
// PPC64-NEXT:    [[BF_CLEAR124:%.*]] = and i8 [[BF_LOAD122]], -128, !dbg [[DBG101]]
// PPC64-NEXT:    [[BF_SET125:%.*]] = or i8 [[BF_CLEAR124]], [[BF_VALUE123]], !dbg [[DBG101]]
// PPC64-NEXT:    store i8 [[BF_SET125]], ptr [[ATOMIC_TEMP121]], align 1, !dbg [[DBG101]]
// PPC64-NEXT:    [[TMP85:%.*]] = load i8, ptr [[ATOMIC_TEMP121]], align 1, !dbg [[DBG101]]
// PPC64-NEXT:    [[TMP86:%.*]] = cmpxchg ptr @bfx4_packed, i8 [[TMP83]], i8 [[TMP85]] monotonic monotonic, align 1, !dbg [[DBG101]]
// PPC64-NEXT:    [[TMP87]] = extractvalue { i8, i1 } [[TMP86]], 0, !dbg [[DBG101]]
// PPC64-NEXT:    [[TMP88:%.*]] = extractvalue { i8, i1 } [[TMP86]], 1, !dbg [[DBG101]]
// PPC64-NEXT:    br i1 [[TMP88]], label [[ATOMIC_EXIT126:%.*]], label [[ATOMIC_CONT120]], !dbg [[DBG101]]
// PPC64:       atomic_exit126:
// PPC64-NEXT:    [[TMP89:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG102:![0-9]+]]
// PPC64-NEXT:    [[CONV127:%.*]] = uitofp i64 [[TMP89]] to float, !dbg [[DBG102]]
// PPC64-NEXT:    [[ATOMIC_LOAD128:%.*]] = load atomic i64, ptr @float2x monotonic, align 8, !dbg [[DBG103:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT129:%.*]], !dbg [[DBG103]]
// PPC64:       atomic_cont129:
// PPC64-NEXT:    [[TMP90:%.*]] = phi i64 [ [[ATOMIC_LOAD128]], [[ATOMIC_EXIT126]] ], [ [[TMP95:%.*]], [[ATOMIC_CONT129]] ], !dbg [[DBG103]]
// PPC64-NEXT:    store i64 [[TMP90]], ptr [[ATOMIC_TEMP130]], align 8, !dbg [[DBG103]]
// PPC64-NEXT:    [[TMP91:%.*]] = load <2 x float>, ptr [[ATOMIC_TEMP130]], align 8, !dbg [[DBG103]]
// PPC64-NEXT:    [[TMP92:%.*]] = insertelement <2 x float> [[TMP91]], float [[CONV127]], i64 0, !dbg [[DBG103]]
// PPC64-NEXT:    store <2 x float> [[TMP92]], ptr [[ATOMIC_TEMP130]], align 8, !dbg [[DBG103]]
// PPC64-NEXT:    [[TMP93:%.*]] = load i64, ptr [[ATOMIC_TEMP130]], align 8, !dbg [[DBG103]]
// PPC64-NEXT:    [[TMP94:%.*]] = cmpxchg ptr @float2x, i64 [[TMP90]], i64 [[TMP93]] monotonic monotonic, align 8, !dbg [[DBG103]]
// PPC64-NEXT:    [[TMP95]] = extractvalue { i64, i1 } [[TMP94]], 0, !dbg [[DBG103]]
// PPC64-NEXT:    [[TMP96:%.*]] = extractvalue { i64, i1 } [[TMP94]], 1, !dbg [[DBG103]]
// PPC64-NEXT:    br i1 [[TMP96]], label [[ATOMIC_EXIT131:%.*]], label [[ATOMIC_CONT129]], !dbg [[DBG103]]
// PPC64:       atomic_exit131:
// PPC64-NEXT:    ret i32 0, !dbg [[DBG104:![0-9]+]]
//
//
// AARCH64-LABEL: define {{[^@]+}}@main
// AARCH64-SAME: () #[[ATTR0:[0-9]+]] !dbg [[DBG5:![0-9]+]] {
// AARCH64-NEXT:  entry:
// AARCH64-NEXT:    [[RETVAL:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP1:%.*]] = alloca { float, float }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP2:%.*]] = alloca { double, double }, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP9:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP14:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP30:%.*]] = alloca <4 x i32>, align 16
// AARCH64-NEXT:    [[ATOMIC_TEMP34:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP37:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP39:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP48:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP57:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP67:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP75:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP77:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP88:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP98:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP107:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP117:%.*]] = alloca i64, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP127:%.*]] = alloca <2 x float>, align 8
// AARCH64-NEXT:    store i32 0, ptr [[RETVAL]], align 4
// AARCH64-NEXT:    store atomic i32 1, ptr getelementptr inbounds ({ i32, i32 }, ptr @civ, i32 0, i32 1) monotonic, align 4, !dbg [[DBG9:![0-9]+]]
// AARCH64-NEXT:    [[TMP0:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG10:![0-9]+]]
// AARCH64-NEXT:    [[TOBOOL:%.*]] = trunc i8 [[TMP0]] to i1, !dbg [[DBG10]]
// AARCH64-NEXT:    [[FROMBOOL:%.*]] = zext i1 [[TOBOOL]] to i8, !dbg [[DBG11:![0-9]+]]
// AARCH64-NEXT:    store atomic i8 [[FROMBOOL]], ptr @bx monotonic, align 1, !dbg [[DBG11]]
// AARCH64-NEXT:    [[TMP1:%.*]] = load i8, ptr @cv, align 1, !dbg [[DBG12:![0-9]+]]
// AARCH64-NEXT:    store atomic i8 [[TMP1]], ptr @cx release, align 1, !dbg [[DBG13:![0-9]+]]
// AARCH64-NEXT:    fence release
// AARCH64-NEXT:    [[TMP2:%.*]] = load i8, ptr @ucv, align 1, !dbg [[DBG14:![0-9]+]]
// AARCH64-NEXT:    store atomic i8 [[TMP2]], ptr @ucx monotonic, align 1, !dbg [[DBG15:![0-9]+]]
// AARCH64-NEXT:    [[TMP3:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG16:![0-9]+]]
// AARCH64-NEXT:    store atomic i16 [[TMP3]], ptr @sx monotonic, align 2, !dbg [[DBG17:![0-9]+]]
// AARCH64-NEXT:    [[TMP4:%.*]] = load i16, ptr @usv, align 2, !dbg [[DBG18:![0-9]+]]
// AARCH64-NEXT:    store atomic i16 [[TMP4]], ptr @usx monotonic, align 2, !dbg [[DBG19:![0-9]+]]
// AARCH64-NEXT:    [[TMP5:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG20:![0-9]+]]
// AARCH64-NEXT:    store atomic i32 [[TMP5]], ptr @ix monotonic, align 4, !dbg [[DBG21:![0-9]+]]
// AARCH64-NEXT:    [[TMP6:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG22:![0-9]+]]
// AARCH64-NEXT:    store atomic i32 [[TMP6]], ptr @uix monotonic, align 4, !dbg [[DBG23:![0-9]+]]
// AARCH64-NEXT:    [[TMP7:%.*]] = load i64, ptr @lv, align 8, !dbg [[DBG24:![0-9]+]]
// AARCH64-NEXT:    store atomic i64 [[TMP7]], ptr @lx monotonic, align 8, !dbg [[DBG25:![0-9]+]]
// AARCH64-NEXT:    [[TMP8:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG26:![0-9]+]]
// AARCH64-NEXT:    store atomic i64 [[TMP8]], ptr @ulx monotonic, align 8, !dbg [[DBG27:![0-9]+]]
// AARCH64-NEXT:    [[TMP9:%.*]] = load i64, ptr @llv, align 8, !dbg [[DBG28:![0-9]+]]
// AARCH64-NEXT:    store atomic i64 [[TMP9]], ptr @llx monotonic, align 8, !dbg [[DBG29:![0-9]+]]
// AARCH64-NEXT:    [[TMP10:%.*]] = load i64, ptr @ullv, align 8, !dbg [[DBG30:![0-9]+]]
// AARCH64-NEXT:    store atomic i64 [[TMP10]], ptr @ullx monotonic, align 8, !dbg [[DBG31:![0-9]+]]
// AARCH64-NEXT:    [[TMP11:%.*]] = load float, ptr @fv, align 4, !dbg [[DBG32:![0-9]+]]
// AARCH64-NEXT:    store atomic float [[TMP11]], ptr @fx monotonic, align 4, !dbg [[DBG33:![0-9]+]]
// AARCH64-NEXT:    [[TMP12:%.*]] = load double, ptr @dv, align 8, !dbg [[DBG34:![0-9]+]]
// AARCH64-NEXT:    store atomic double [[TMP12]], ptr @dx monotonic, align 8, !dbg [[DBG35:![0-9]+]]
// AARCH64-NEXT:    [[TMP13:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG36:![0-9]+]]
// AARCH64-NEXT:    store atomic fp128 [[TMP13]], ptr @ldx monotonic, align 16, !dbg [[DBG37:![0-9]+]]
// AARCH64-NEXT:    [[CIV_REAL:%.*]] = load i32, ptr @civ, align 4, !dbg [[DBG38:![0-9]+]]
// AARCH64-NEXT:    [[CIV_IMAG:%.*]] = load i32, ptr getelementptr inbounds ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG38]]
// AARCH64-NEXT:    [[ATOMIC_TEMP_REALP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP]], i32 0, i32 0, !dbg [[DBG39:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_TEMP_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP]], i32 0, i32 1, !dbg [[DBG39]]
// AARCH64-NEXT:    store i32 [[CIV_REAL]], ptr [[ATOMIC_TEMP_REALP]], align 4, !dbg [[DBG39]]
// AARCH64-NEXT:    store i32 [[CIV_IMAG]], ptr [[ATOMIC_TEMP_IMAGP]], align 4, !dbg [[DBG39]]
// AARCH64-NEXT:    call void @__atomic_store(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP]], i32 noundef 0), !dbg [[DBG39]]
// AARCH64-NEXT:    [[CFV_REAL:%.*]] = load float, ptr @cfv, align 4, !dbg [[DBG40:![0-9]+]]
// AARCH64-NEXT:    [[CFV_IMAG:%.*]] = load float, ptr getelementptr inbounds ({ float, float }, ptr @cfv, i32 0, i32 1), align 4, !dbg [[DBG40]]
// AARCH64-NEXT:    [[ATOMIC_TEMP1_REALP:%.*]] = getelementptr inbounds { float, float }, ptr [[ATOMIC_TEMP1]], i32 0, i32 0, !dbg [[DBG41:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_TEMP1_IMAGP:%.*]] = getelementptr inbounds { float, float }, ptr [[ATOMIC_TEMP1]], i32 0, i32 1, !dbg [[DBG41]]
// AARCH64-NEXT:    store float [[CFV_REAL]], ptr [[ATOMIC_TEMP1_REALP]], align 4, !dbg [[DBG41]]
// AARCH64-NEXT:    store float [[CFV_IMAG]], ptr [[ATOMIC_TEMP1_IMAGP]], align 4, !dbg [[DBG41]]
// AARCH64-NEXT:    call void @__atomic_store(i64 noundef 8, ptr noundef @cfx, ptr noundef [[ATOMIC_TEMP1]], i32 noundef 0), !dbg [[DBG41]]
// AARCH64-NEXT:    [[CDV_REAL:%.*]] = load double, ptr @cdv, align 8, !dbg [[DBG42:![0-9]+]]
// AARCH64-NEXT:    [[CDV_IMAG:%.*]] = load double, ptr getelementptr inbounds ({ double, double }, ptr @cdv, i32 0, i32 1), align 8, !dbg [[DBG42]]
// AARCH64-NEXT:    [[ATOMIC_TEMP2_REALP:%.*]] = getelementptr inbounds { double, double }, ptr [[ATOMIC_TEMP2]], i32 0, i32 0, !dbg [[DBG43:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_TEMP2_IMAGP:%.*]] = getelementptr inbounds { double, double }, ptr [[ATOMIC_TEMP2]], i32 0, i32 1, !dbg [[DBG43]]
// AARCH64-NEXT:    store double [[CDV_REAL]], ptr [[ATOMIC_TEMP2_REALP]], align 8, !dbg [[DBG43]]
// AARCH64-NEXT:    store double [[CDV_IMAG]], ptr [[ATOMIC_TEMP2_IMAGP]], align 8, !dbg [[DBG43]]
// AARCH64-NEXT:    call void @__atomic_store(i64 noundef 16, ptr noundef @cdx, ptr noundef [[ATOMIC_TEMP2]], i32 noundef 5), !dbg [[DBG43]]
// AARCH64-NEXT:    fence release
// AARCH64-NEXT:    [[TMP14:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG44:![0-9]+]]
// AARCH64-NEXT:    [[TOBOOL3:%.*]] = trunc i8 [[TMP14]] to i1, !dbg [[DBG44]]
// AARCH64-NEXT:    [[CONV:%.*]] = zext i1 [[TOBOOL3]] to i64, !dbg [[DBG44]]
// AARCH64-NEXT:    store atomic i64 [[CONV]], ptr @ulx monotonic, align 8, !dbg [[DBG45:![0-9]+]]
// AARCH64-NEXT:    [[TMP15:%.*]] = load i8, ptr @cv, align 1, !dbg [[DBG46:![0-9]+]]
// AARCH64-NEXT:    [[TOBOOL4:%.*]] = icmp ne i8 [[TMP15]], 0, !dbg [[DBG46]]
// AARCH64-NEXT:    [[FROMBOOL5:%.*]] = zext i1 [[TOBOOL4]] to i8, !dbg [[DBG47:![0-9]+]]
// AARCH64-NEXT:    store atomic i8 [[FROMBOOL5]], ptr @bx monotonic, align 1, !dbg [[DBG47]]
// AARCH64-NEXT:    [[TMP16:%.*]] = load i8, ptr @ucv, align 1, !dbg [[DBG48:![0-9]+]]
// AARCH64-NEXT:    store atomic i8 [[TMP16]], ptr @cx seq_cst, align 1, !dbg [[DBG49:![0-9]+]]
// AARCH64-NEXT:    fence release
// AARCH64-NEXT:    [[TMP17:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG50:![0-9]+]]
// AARCH64-NEXT:    [[CONV6:%.*]] = sext i16 [[TMP17]] to i64, !dbg [[DBG50]]
// AARCH64-NEXT:    store atomic i64 [[CONV6]], ptr @ulx monotonic, align 8, !dbg [[DBG51:![0-9]+]]
// AARCH64-NEXT:    [[TMP18:%.*]] = load i16, ptr @usv, align 2, !dbg [[DBG52:![0-9]+]]
// AARCH64-NEXT:    [[CONV7:%.*]] = zext i16 [[TMP18]] to i64, !dbg [[DBG52]]
// AARCH64-NEXT:    store atomic i64 [[CONV7]], ptr @lx monotonic, align 8, !dbg [[DBG53:![0-9]+]]
// AARCH64-NEXT:    [[TMP19:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG54:![0-9]+]]
// AARCH64-NEXT:    store atomic i32 [[TMP19]], ptr @uix seq_cst, align 4, !dbg [[DBG55:![0-9]+]]
// AARCH64-NEXT:    fence release
// AARCH64-NEXT:    [[TMP20:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG56:![0-9]+]]
// AARCH64-NEXT:    store atomic i32 [[TMP20]], ptr @ix monotonic, align 4, !dbg [[DBG57:![0-9]+]]
// AARCH64-NEXT:    [[TMP21:%.*]] = load i64, ptr @lv, align 8, !dbg [[DBG58:![0-9]+]]
// AARCH64-NEXT:    [[CONV8:%.*]] = trunc i64 [[TMP21]] to i32, !dbg [[DBG58]]
// AARCH64-NEXT:    [[ATOMIC_TEMP9_REALP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP9]], i32 0, i32 0, !dbg [[DBG59:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_TEMP9_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP9]], i32 0, i32 1, !dbg [[DBG59]]
// AARCH64-NEXT:    store i32 [[CONV8]], ptr [[ATOMIC_TEMP9_REALP]], align 4, !dbg [[DBG59]]
// AARCH64-NEXT:    store i32 0, ptr [[ATOMIC_TEMP9_IMAGP]], align 4, !dbg [[DBG59]]
// AARCH64-NEXT:    call void @__atomic_store(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP9]], i32 noundef 0), !dbg [[DBG59]]
// AARCH64-NEXT:    [[TMP22:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG60:![0-9]+]]
// AARCH64-NEXT:    [[CONV10:%.*]] = uitofp i64 [[TMP22]] to float, !dbg [[DBG60]]
// AARCH64-NEXT:    store atomic float [[CONV10]], ptr @fx monotonic, align 4, !dbg [[DBG61:![0-9]+]]
// AARCH64-NEXT:    [[TMP23:%.*]] = load i64, ptr @llv, align 8, !dbg [[DBG62:![0-9]+]]
// AARCH64-NEXT:    [[CONV11:%.*]] = sitofp i64 [[TMP23]] to double, !dbg [[DBG62]]
// AARCH64-NEXT:    store atomic double [[CONV11]], ptr @dx monotonic, align 8, !dbg [[DBG63:![0-9]+]]
// AARCH64-NEXT:    [[TMP24:%.*]] = load i64, ptr @ullv, align 8, !dbg [[DBG64:![0-9]+]]
// AARCH64-NEXT:    [[CONV12:%.*]] = uitofp i64 [[TMP24]] to fp128, !dbg [[DBG64]]
// AARCH64-NEXT:    store atomic fp128 [[CONV12]], ptr @ldx monotonic, align 16, !dbg [[DBG65:![0-9]+]]
// AARCH64-NEXT:    [[TMP25:%.*]] = load float, ptr @fv, align 4, !dbg [[DBG66:![0-9]+]]
// AARCH64-NEXT:    [[CONV13:%.*]] = fptosi float [[TMP25]] to i32, !dbg [[DBG66]]
// AARCH64-NEXT:    [[ATOMIC_TEMP14_REALP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP14]], i32 0, i32 0, !dbg [[DBG67:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_TEMP14_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP14]], i32 0, i32 1, !dbg [[DBG67]]
// AARCH64-NEXT:    store i32 [[CONV13]], ptr [[ATOMIC_TEMP14_REALP]], align 4, !dbg [[DBG67]]
// AARCH64-NEXT:    store i32 0, ptr [[ATOMIC_TEMP14_IMAGP]], align 4, !dbg [[DBG67]]
// AARCH64-NEXT:    call void @__atomic_store(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP14]], i32 noundef 0), !dbg [[DBG67]]
// AARCH64-NEXT:    [[TMP26:%.*]] = load double, ptr @dv, align 8, !dbg [[DBG68:![0-9]+]]
// AARCH64-NEXT:    [[CONV15:%.*]] = fptosi double [[TMP26]] to i16, !dbg [[DBG68]]
// AARCH64-NEXT:    store atomic i16 [[CONV15]], ptr @sx monotonic, align 2, !dbg [[DBG69:![0-9]+]]
// AARCH64-NEXT:    [[TMP27:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG70:![0-9]+]]
// AARCH64-NEXT:    [[TOBOOL16:%.*]] = fcmp une fp128 [[TMP27]], 0xL00000000000000000000000000000000, !dbg [[DBG70]]
// AARCH64-NEXT:    [[FROMBOOL17:%.*]] = zext i1 [[TOBOOL16]] to i8, !dbg [[DBG71:![0-9]+]]
// AARCH64-NEXT:    store atomic i8 [[FROMBOOL17]], ptr @bx monotonic, align 1, !dbg [[DBG71]]
// AARCH64-NEXT:    [[CIV_REAL18:%.*]] = load i32, ptr @civ, align 4, !dbg [[DBG72:![0-9]+]]
// AARCH64-NEXT:    [[CIV_IMAG19:%.*]] = load i32, ptr getelementptr inbounds ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG72]]
// AARCH64-NEXT:    [[TOBOOL20:%.*]] = icmp ne i32 [[CIV_REAL18]], 0, !dbg [[DBG72]]
// AARCH64-NEXT:    [[TOBOOL21:%.*]] = icmp ne i32 [[CIV_IMAG19]], 0, !dbg [[DBG72]]
// AARCH64-NEXT:    [[TOBOOL22:%.*]] = or i1 [[TOBOOL20]], [[TOBOOL21]], !dbg [[DBG72]]
// AARCH64-NEXT:    [[FROMBOOL23:%.*]] = zext i1 [[TOBOOL22]] to i8, !dbg [[DBG73:![0-9]+]]
// AARCH64-NEXT:    store atomic i8 [[FROMBOOL23]], ptr @bx monotonic, align 1, !dbg [[DBG73]]
// AARCH64-NEXT:    [[CFV_REAL24:%.*]] = load float, ptr @cfv, align 4, !dbg [[DBG74:![0-9]+]]
// AARCH64-NEXT:    [[CONV25:%.*]] = fptoui float [[CFV_REAL24]] to i16, !dbg [[DBG74]]
// AARCH64-NEXT:    store atomic i16 [[CONV25]], ptr @usx monotonic, align 2, !dbg [[DBG75:![0-9]+]]
// AARCH64-NEXT:    [[CDV_REAL26:%.*]] = load double, ptr @cdv, align 8, !dbg [[DBG76:![0-9]+]]
// AARCH64-NEXT:    [[CONV27:%.*]] = fptosi double [[CDV_REAL26]] to i64, !dbg [[DBG76]]
// AARCH64-NEXT:    store atomic i64 [[CONV27]], ptr @llx monotonic, align 8, !dbg [[DBG77:![0-9]+]]
// AARCH64-NEXT:    [[TMP28:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG78:![0-9]+]]
// AARCH64-NEXT:    [[TMP29:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG79:![0-9]+]]
// AARCH64-NEXT:    [[TOBOOL28:%.*]] = trunc i8 [[TMP29]] to i1, !dbg [[DBG79]]
// AARCH64-NEXT:    [[CONV29:%.*]] = zext i1 [[TOBOOL28]] to i32, !dbg [[DBG79]]
// AARCH64-NEXT:    [[ATOMIC_LOAD:%.*]] = load atomic i128, ptr @int4x monotonic, align 16, !dbg [[DBG80:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT:%.*]], !dbg [[DBG80]]
// AARCH64:       atomic_cont:
// AARCH64-NEXT:    [[TMP30:%.*]] = phi i128 [ [[ATOMIC_LOAD]], [[ENTRY:%.*]] ], [ [[TMP34:%.*]], [[ATOMIC_CONT]] ], !dbg [[DBG80]]
// AARCH64-NEXT:    store i128 [[TMP30]], ptr [[ATOMIC_TEMP30]], align 16, !dbg [[DBG80]]
// AARCH64-NEXT:    [[TMP31:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP30]], align 16, !dbg [[DBG80]]
// AARCH64-NEXT:    [[VECINS:%.*]] = insertelement <4 x i32> [[TMP31]], i32 [[CONV29]], i16 [[TMP28]], !dbg [[DBG80]]
// AARCH64-NEXT:    store <4 x i32> [[VECINS]], ptr [[ATOMIC_TEMP30]], align 16, !dbg [[DBG80]]
// AARCH64-NEXT:    [[TMP32:%.*]] = load i128, ptr [[ATOMIC_TEMP30]], align 16, !dbg [[DBG80]]
// AARCH64-NEXT:    [[TMP33:%.*]] = cmpxchg ptr @int4x, i128 [[TMP30]], i128 [[TMP32]] monotonic monotonic, align 16, !dbg [[DBG80]]
// AARCH64-NEXT:    [[TMP34]] = extractvalue { i128, i1 } [[TMP33]], 0, !dbg [[DBG80]]
// AARCH64-NEXT:    [[TMP35:%.*]] = extractvalue { i128, i1 } [[TMP33]], 1, !dbg [[DBG80]]
// AARCH64-NEXT:    br i1 [[TMP35]], label [[ATOMIC_EXIT:%.*]], label [[ATOMIC_CONT]], !dbg [[DBG80]]
// AARCH64:       atomic_exit:
// AARCH64-NEXT:    [[TMP36:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG81:![0-9]+]]
// AARCH64-NEXT:    [[CONV31:%.*]] = fptosi fp128 [[TMP36]] to i32, !dbg [[DBG81]]
// AARCH64-NEXT:    [[ATOMIC_LOAD32:%.*]] = load atomic i32, ptr getelementptr (i8, ptr @bfx, i64 4) monotonic, align 4, !dbg [[DBG82:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT33:%.*]], !dbg [[DBG82]]
// AARCH64:       atomic_cont33:
// AARCH64-NEXT:    [[TMP37:%.*]] = phi i32 [ [[ATOMIC_LOAD32]], [[ATOMIC_EXIT]] ], [ [[TMP40:%.*]], [[ATOMIC_CONT33]] ], !dbg [[DBG82]]
// AARCH64-NEXT:    store i32 [[TMP37]], ptr [[ATOMIC_TEMP34]], align 4, !dbg [[DBG82]]
// AARCH64-NEXT:    [[BF_LOAD:%.*]] = load i32, ptr [[ATOMIC_TEMP34]], align 4, !dbg [[DBG82]]
// AARCH64-NEXT:    [[BF_VALUE:%.*]] = and i32 [[CONV31]], 2147483647, !dbg [[DBG82]]
// AARCH64-NEXT:    [[BF_CLEAR:%.*]] = and i32 [[BF_LOAD]], -2147483648, !dbg [[DBG82]]
// AARCH64-NEXT:    [[BF_SET:%.*]] = or i32 [[BF_CLEAR]], [[BF_VALUE]], !dbg [[DBG82]]
// AARCH64-NEXT:    store i32 [[BF_SET]], ptr [[ATOMIC_TEMP34]], align 4, !dbg [[DBG82]]
// AARCH64-NEXT:    [[TMP38:%.*]] = load i32, ptr [[ATOMIC_TEMP34]], align 4, !dbg [[DBG82]]
// AARCH64-NEXT:    [[TMP39:%.*]] = cmpxchg ptr getelementptr (i8, ptr @bfx, i64 4), i32 [[TMP37]], i32 [[TMP38]] monotonic monotonic, align 4, !dbg [[DBG82]]
// AARCH64-NEXT:    [[TMP40]] = extractvalue { i32, i1 } [[TMP39]], 0, !dbg [[DBG82]]
// AARCH64-NEXT:    [[TMP41:%.*]] = extractvalue { i32, i1 } [[TMP39]], 1, !dbg [[DBG82]]
// AARCH64-NEXT:    br i1 [[TMP41]], label [[ATOMIC_EXIT35:%.*]], label [[ATOMIC_CONT33]], !dbg [[DBG82]]
// AARCH64:       atomic_exit35:
// AARCH64-NEXT:    [[TMP42:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG83:![0-9]+]]
// AARCH64-NEXT:    [[CONV36:%.*]] = fptosi fp128 [[TMP42]] to i32, !dbg [[DBG83]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 4, ptr noundef getelementptr (i8, ptr @bfx_packed, i64 4), ptr noundef [[ATOMIC_TEMP37]], i32 noundef 0), !dbg [[DBG84:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT38:%.*]], !dbg [[DBG84]]
// AARCH64:       atomic_cont38:
// AARCH64-NEXT:    [[TMP43:%.*]] = load i32, ptr [[ATOMIC_TEMP37]], align 1, !dbg [[DBG84]]
// AARCH64-NEXT:    store i32 [[TMP43]], ptr [[ATOMIC_TEMP39]], align 1, !dbg [[DBG84]]
// AARCH64-NEXT:    [[BF_LOAD40:%.*]] = load i32, ptr [[ATOMIC_TEMP39]], align 1, !dbg [[DBG84]]
// AARCH64-NEXT:    [[BF_VALUE41:%.*]] = and i32 [[CONV36]], 2147483647, !dbg [[DBG84]]
// AARCH64-NEXT:    [[BF_CLEAR42:%.*]] = and i32 [[BF_LOAD40]], -2147483648, !dbg [[DBG84]]
// AARCH64-NEXT:    [[BF_SET43:%.*]] = or i32 [[BF_CLEAR42]], [[BF_VALUE41]], !dbg [[DBG84]]
// AARCH64-NEXT:    store i32 [[BF_SET43]], ptr [[ATOMIC_TEMP39]], align 1, !dbg [[DBG84]]
// AARCH64-NEXT:    [[CALL:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 4, ptr noundef getelementptr (i8, ptr @bfx_packed, i64 4), ptr noundef [[ATOMIC_TEMP37]], ptr noundef [[ATOMIC_TEMP39]], i32 noundef 0, i32 noundef 0), !dbg [[DBG84]]
// AARCH64-NEXT:    br i1 [[CALL]], label [[ATOMIC_EXIT44:%.*]], label [[ATOMIC_CONT38]], !dbg [[DBG84]]
// AARCH64:       atomic_exit44:
// AARCH64-NEXT:    [[TMP44:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG85:![0-9]+]]
// AARCH64-NEXT:    [[CONV45:%.*]] = fptosi fp128 [[TMP44]] to i32, !dbg [[DBG85]]
// AARCH64-NEXT:    [[ATOMIC_LOAD46:%.*]] = load atomic i32, ptr @bfx2 monotonic, align 4, !dbg [[DBG86:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT47:%.*]], !dbg [[DBG86]]
// AARCH64:       atomic_cont47:
// AARCH64-NEXT:    [[TMP45:%.*]] = phi i32 [ [[ATOMIC_LOAD46]], [[ATOMIC_EXIT44]] ], [ [[TMP48:%.*]], [[ATOMIC_CONT47]] ], !dbg [[DBG86]]
// AARCH64-NEXT:    store i32 [[TMP45]], ptr [[ATOMIC_TEMP48]], align 4, !dbg [[DBG86]]
// AARCH64-NEXT:    [[BF_LOAD49:%.*]] = load i32, ptr [[ATOMIC_TEMP48]], align 4, !dbg [[DBG86]]
// AARCH64-NEXT:    [[BF_VALUE50:%.*]] = and i32 [[CONV45]], 1, !dbg [[DBG86]]
// AARCH64-NEXT:    [[BF_SHL:%.*]] = shl i32 [[BF_VALUE50]], 31, !dbg [[DBG86]]
// AARCH64-NEXT:    [[BF_CLEAR51:%.*]] = and i32 [[BF_LOAD49]], 2147483647, !dbg [[DBG86]]
// AARCH64-NEXT:    [[BF_SET52:%.*]] = or i32 [[BF_CLEAR51]], [[BF_SHL]], !dbg [[DBG86]]
// AARCH64-NEXT:    store i32 [[BF_SET52]], ptr [[ATOMIC_TEMP48]], align 4, !dbg [[DBG86]]
// AARCH64-NEXT:    [[TMP46:%.*]] = load i32, ptr [[ATOMIC_TEMP48]], align 4, !dbg [[DBG86]]
// AARCH64-NEXT:    [[TMP47:%.*]] = cmpxchg ptr @bfx2, i32 [[TMP45]], i32 [[TMP46]] monotonic monotonic, align 4, !dbg [[DBG86]]
// AARCH64-NEXT:    [[TMP48]] = extractvalue { i32, i1 } [[TMP47]], 0, !dbg [[DBG86]]
// AARCH64-NEXT:    [[TMP49:%.*]] = extractvalue { i32, i1 } [[TMP47]], 1, !dbg [[DBG86]]
// AARCH64-NEXT:    br i1 [[TMP49]], label [[ATOMIC_EXIT53:%.*]], label [[ATOMIC_CONT47]], !dbg [[DBG86]]
// AARCH64:       atomic_exit53:
// AARCH64-NEXT:    [[TMP50:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG87:![0-9]+]]
// AARCH64-NEXT:    [[CONV54:%.*]] = fptosi fp128 [[TMP50]] to i32, !dbg [[DBG87]]
// AARCH64-NEXT:    [[ATOMIC_LOAD55:%.*]] = load atomic i8, ptr getelementptr (i8, ptr @bfx2_packed, i64 3) monotonic, align 1, !dbg [[DBG88:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT56:%.*]], !dbg [[DBG88]]
// AARCH64:       atomic_cont56:
// AARCH64-NEXT:    [[TMP51:%.*]] = phi i8 [ [[ATOMIC_LOAD55]], [[ATOMIC_EXIT53]] ], [ [[TMP55:%.*]], [[ATOMIC_CONT56]] ], !dbg [[DBG88]]
// AARCH64-NEXT:    store i8 [[TMP51]], ptr [[ATOMIC_TEMP57]], align 1, !dbg [[DBG88]]
// AARCH64-NEXT:    [[TMP52:%.*]] = trunc i32 [[CONV54]] to i8, !dbg [[DBG88]]
// AARCH64-NEXT:    [[BF_LOAD58:%.*]] = load i8, ptr [[ATOMIC_TEMP57]], align 1, !dbg [[DBG88]]
// AARCH64-NEXT:    [[BF_VALUE59:%.*]] = and i8 [[TMP52]], 1, !dbg [[DBG88]]
// AARCH64-NEXT:    [[BF_SHL60:%.*]] = shl i8 [[BF_VALUE59]], 7, !dbg [[DBG88]]
// AARCH64-NEXT:    [[BF_CLEAR61:%.*]] = and i8 [[BF_LOAD58]], 127, !dbg [[DBG88]]
// AARCH64-NEXT:    [[BF_SET62:%.*]] = or i8 [[BF_CLEAR61]], [[BF_SHL60]], !dbg [[DBG88]]
// AARCH64-NEXT:    store i8 [[BF_SET62]], ptr [[ATOMIC_TEMP57]], align 1, !dbg [[DBG88]]
// AARCH64-NEXT:    [[TMP53:%.*]] = load i8, ptr [[ATOMIC_TEMP57]], align 1, !dbg [[DBG88]]
// AARCH64-NEXT:    [[TMP54:%.*]] = cmpxchg ptr getelementptr (i8, ptr @bfx2_packed, i64 3), i8 [[TMP51]], i8 [[TMP53]] monotonic monotonic, align 1, !dbg [[DBG88]]
// AARCH64-NEXT:    [[TMP55]] = extractvalue { i8, i1 } [[TMP54]], 0, !dbg [[DBG88]]
// AARCH64-NEXT:    [[TMP56:%.*]] = extractvalue { i8, i1 } [[TMP54]], 1, !dbg [[DBG88]]
// AARCH64-NEXT:    br i1 [[TMP56]], label [[ATOMIC_EXIT63:%.*]], label [[ATOMIC_CONT56]], !dbg [[DBG88]]
// AARCH64:       atomic_exit63:
// AARCH64-NEXT:    [[TMP57:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG89:![0-9]+]]
// AARCH64-NEXT:    [[CONV64:%.*]] = fptosi fp128 [[TMP57]] to i32, !dbg [[DBG89]]
// AARCH64-NEXT:    [[ATOMIC_LOAD65:%.*]] = load atomic i32, ptr @bfx3 monotonic, align 4, !dbg [[DBG90:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT66:%.*]], !dbg [[DBG90]]
// AARCH64:       atomic_cont66:
// AARCH64-NEXT:    [[TMP58:%.*]] = phi i32 [ [[ATOMIC_LOAD65]], [[ATOMIC_EXIT63]] ], [ [[TMP61:%.*]], [[ATOMIC_CONT66]] ], !dbg [[DBG90]]
// AARCH64-NEXT:    store i32 [[TMP58]], ptr [[ATOMIC_TEMP67]], align 4, !dbg [[DBG90]]
// AARCH64-NEXT:    [[BF_LOAD68:%.*]] = load i32, ptr [[ATOMIC_TEMP67]], align 4, !dbg [[DBG90]]
// AARCH64-NEXT:    [[BF_VALUE69:%.*]] = and i32 [[CONV64]], 16383, !dbg [[DBG90]]
// AARCH64-NEXT:    [[BF_SHL70:%.*]] = shl i32 [[BF_VALUE69]], 11, !dbg [[DBG90]]
// AARCH64-NEXT:    [[BF_CLEAR71:%.*]] = and i32 [[BF_LOAD68]], -33552385, !dbg [[DBG90]]
// AARCH64-NEXT:    [[BF_SET72:%.*]] = or i32 [[BF_CLEAR71]], [[BF_SHL70]], !dbg [[DBG90]]
// AARCH64-NEXT:    store i32 [[BF_SET72]], ptr [[ATOMIC_TEMP67]], align 4, !dbg [[DBG90]]
// AARCH64-NEXT:    [[TMP59:%.*]] = load i32, ptr [[ATOMIC_TEMP67]], align 4, !dbg [[DBG90]]
// AARCH64-NEXT:    [[TMP60:%.*]] = cmpxchg ptr @bfx3, i32 [[TMP58]], i32 [[TMP59]] monotonic monotonic, align 4, !dbg [[DBG90]]
// AARCH64-NEXT:    [[TMP61]] = extractvalue { i32, i1 } [[TMP60]], 0, !dbg [[DBG90]]
// AARCH64-NEXT:    [[TMP62:%.*]] = extractvalue { i32, i1 } [[TMP60]], 1, !dbg [[DBG90]]
// AARCH64-NEXT:    br i1 [[TMP62]], label [[ATOMIC_EXIT73:%.*]], label [[ATOMIC_CONT66]], !dbg [[DBG90]]
// AARCH64:       atomic_exit73:
// AARCH64-NEXT:    [[TMP63:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG91:![0-9]+]]
// AARCH64-NEXT:    [[CONV74:%.*]] = fptosi fp128 [[TMP63]] to i32, !dbg [[DBG91]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 3, ptr noundef getelementptr (i8, ptr @bfx3_packed, i64 1), ptr noundef [[ATOMIC_TEMP75]], i32 noundef 0), !dbg [[DBG92:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT76:%.*]], !dbg [[DBG92]]
// AARCH64:       atomic_cont76:
// AARCH64-NEXT:    [[TMP64:%.*]] = load i24, ptr [[ATOMIC_TEMP75]], align 1, !dbg [[DBG92]]
// AARCH64-NEXT:    store i24 [[TMP64]], ptr [[ATOMIC_TEMP77]], align 1, !dbg [[DBG92]]
// AARCH64-NEXT:    [[TMP65:%.*]] = trunc i32 [[CONV74]] to i24, !dbg [[DBG92]]
// AARCH64-NEXT:    [[BF_LOAD78:%.*]] = load i24, ptr [[ATOMIC_TEMP77]], align 1, !dbg [[DBG92]]
// AARCH64-NEXT:    [[BF_VALUE79:%.*]] = and i24 [[TMP65]], 16383, !dbg [[DBG92]]
// AARCH64-NEXT:    [[BF_SHL80:%.*]] = shl i24 [[BF_VALUE79]], 3, !dbg [[DBG92]]
// AARCH64-NEXT:    [[BF_CLEAR81:%.*]] = and i24 [[BF_LOAD78]], -131065, !dbg [[DBG92]]
// AARCH64-NEXT:    [[BF_SET82:%.*]] = or i24 [[BF_CLEAR81]], [[BF_SHL80]], !dbg [[DBG92]]
// AARCH64-NEXT:    store i24 [[BF_SET82]], ptr [[ATOMIC_TEMP77]], align 1, !dbg [[DBG92]]
// AARCH64-NEXT:    [[CALL83:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 3, ptr noundef getelementptr (i8, ptr @bfx3_packed, i64 1), ptr noundef [[ATOMIC_TEMP75]], ptr noundef [[ATOMIC_TEMP77]], i32 noundef 0, i32 noundef 0), !dbg [[DBG92]]
// AARCH64-NEXT:    br i1 [[CALL83]], label [[ATOMIC_EXIT84:%.*]], label [[ATOMIC_CONT76]], !dbg [[DBG92]]
// AARCH64:       atomic_exit84:
// AARCH64-NEXT:    [[TMP66:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG93:![0-9]+]]
// AARCH64-NEXT:    [[CONV85:%.*]] = fptosi fp128 [[TMP66]] to i32, !dbg [[DBG93]]
// AARCH64-NEXT:    [[ATOMIC_LOAD86:%.*]] = load atomic i64, ptr @bfx4 monotonic, align 8, !dbg [[DBG94:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT87:%.*]], !dbg [[DBG94]]
// AARCH64:       atomic_cont87:
// AARCH64-NEXT:    [[TMP67:%.*]] = phi i64 [ [[ATOMIC_LOAD86]], [[ATOMIC_EXIT84]] ], [ [[TMP71:%.*]], [[ATOMIC_CONT87]] ], !dbg [[DBG94]]
// AARCH64-NEXT:    store i64 [[TMP67]], ptr [[ATOMIC_TEMP88]], align 8, !dbg [[DBG94]]
// AARCH64-NEXT:    [[TMP68:%.*]] = zext i32 [[CONV85]] to i64, !dbg [[DBG94]]
// AARCH64-NEXT:    [[BF_LOAD89:%.*]] = load i64, ptr [[ATOMIC_TEMP88]], align 8, !dbg [[DBG94]]
// AARCH64-NEXT:    [[BF_VALUE90:%.*]] = and i64 [[TMP68]], 1, !dbg [[DBG94]]
// AARCH64-NEXT:    [[BF_SHL91:%.*]] = shl i64 [[BF_VALUE90]], 16, !dbg [[DBG94]]
// AARCH64-NEXT:    [[BF_CLEAR92:%.*]] = and i64 [[BF_LOAD89]], -65537, !dbg [[DBG94]]
// AARCH64-NEXT:    [[BF_SET93:%.*]] = or i64 [[BF_CLEAR92]], [[BF_SHL91]], !dbg [[DBG94]]
// AARCH64-NEXT:    store i64 [[BF_SET93]], ptr [[ATOMIC_TEMP88]], align 8, !dbg [[DBG94]]
// AARCH64-NEXT:    [[TMP69:%.*]] = load i64, ptr [[ATOMIC_TEMP88]], align 8, !dbg [[DBG94]]
// AARCH64-NEXT:    [[TMP70:%.*]] = cmpxchg ptr @bfx4, i64 [[TMP67]], i64 [[TMP69]] monotonic monotonic, align 8, !dbg [[DBG94]]
// AARCH64-NEXT:    [[TMP71]] = extractvalue { i64, i1 } [[TMP70]], 0, !dbg [[DBG94]]
// AARCH64-NEXT:    [[TMP72:%.*]] = extractvalue { i64, i1 } [[TMP70]], 1, !dbg [[DBG94]]
// AARCH64-NEXT:    br i1 [[TMP72]], label [[ATOMIC_EXIT94:%.*]], label [[ATOMIC_CONT87]], !dbg [[DBG94]]
// AARCH64:       atomic_exit94:
// AARCH64-NEXT:    [[TMP73:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG95:![0-9]+]]
// AARCH64-NEXT:    [[CONV95:%.*]] = fptosi fp128 [[TMP73]] to i32, !dbg [[DBG95]]
// AARCH64-NEXT:    [[ATOMIC_LOAD96:%.*]] = load atomic i8, ptr getelementptr (i8, ptr @bfx4_packed, i64 2) monotonic, align 1, !dbg [[DBG96:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT97:%.*]], !dbg [[DBG96]]
// AARCH64:       atomic_cont97:
// AARCH64-NEXT:    [[TMP74:%.*]] = phi i8 [ [[ATOMIC_LOAD96]], [[ATOMIC_EXIT94]] ], [ [[TMP78:%.*]], [[ATOMIC_CONT97]] ], !dbg [[DBG96]]
// AARCH64-NEXT:    store i8 [[TMP74]], ptr [[ATOMIC_TEMP98]], align 1, !dbg [[DBG96]]
// AARCH64-NEXT:    [[TMP75:%.*]] = trunc i32 [[CONV95]] to i8, !dbg [[DBG96]]
// AARCH64-NEXT:    [[BF_LOAD99:%.*]] = load i8, ptr [[ATOMIC_TEMP98]], align 1, !dbg [[DBG96]]
// AARCH64-NEXT:    [[BF_VALUE100:%.*]] = and i8 [[TMP75]], 1, !dbg [[DBG96]]
// AARCH64-NEXT:    [[BF_CLEAR101:%.*]] = and i8 [[BF_LOAD99]], -2, !dbg [[DBG96]]
// AARCH64-NEXT:    [[BF_SET102:%.*]] = or i8 [[BF_CLEAR101]], [[BF_VALUE100]], !dbg [[DBG96]]
// AARCH64-NEXT:    store i8 [[BF_SET102]], ptr [[ATOMIC_TEMP98]], align 1, !dbg [[DBG96]]
// AARCH64-NEXT:    [[TMP76:%.*]] = load i8, ptr [[ATOMIC_TEMP98]], align 1, !dbg [[DBG96]]
// AARCH64-NEXT:    [[TMP77:%.*]] = cmpxchg ptr getelementptr (i8, ptr @bfx4_packed, i64 2), i8 [[TMP74]], i8 [[TMP76]] monotonic monotonic, align 1, !dbg [[DBG96]]
// AARCH64-NEXT:    [[TMP78]] = extractvalue { i8, i1 } [[TMP77]], 0, !dbg [[DBG96]]
// AARCH64-NEXT:    [[TMP79:%.*]] = extractvalue { i8, i1 } [[TMP77]], 1, !dbg [[DBG96]]
// AARCH64-NEXT:    br i1 [[TMP79]], label [[ATOMIC_EXIT103:%.*]], label [[ATOMIC_CONT97]], !dbg [[DBG96]]
// AARCH64:       atomic_exit103:
// AARCH64-NEXT:    [[TMP80:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG97:![0-9]+]]
// AARCH64-NEXT:    [[CONV104:%.*]] = fptosi fp128 [[TMP80]] to i64, !dbg [[DBG97]]
// AARCH64-NEXT:    [[ATOMIC_LOAD105:%.*]] = load atomic i64, ptr @bfx4 monotonic, align 8, !dbg [[DBG98:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT106:%.*]], !dbg [[DBG98]]
// AARCH64:       atomic_cont106:
// AARCH64-NEXT:    [[TMP81:%.*]] = phi i64 [ [[ATOMIC_LOAD105]], [[ATOMIC_EXIT103]] ], [ [[TMP84:%.*]], [[ATOMIC_CONT106]] ], !dbg [[DBG98]]
// AARCH64-NEXT:    store i64 [[TMP81]], ptr [[ATOMIC_TEMP107]], align 8, !dbg [[DBG98]]
// AARCH64-NEXT:    [[BF_LOAD108:%.*]] = load i64, ptr [[ATOMIC_TEMP107]], align 8, !dbg [[DBG98]]
// AARCH64-NEXT:    [[BF_VALUE109:%.*]] = and i64 [[CONV104]], 127, !dbg [[DBG98]]
// AARCH64-NEXT:    [[BF_SHL110:%.*]] = shl i64 [[BF_VALUE109]], 17, !dbg [[DBG98]]
// AARCH64-NEXT:    [[BF_CLEAR111:%.*]] = and i64 [[BF_LOAD108]], -16646145, !dbg [[DBG98]]
// AARCH64-NEXT:    [[BF_SET112:%.*]] = or i64 [[BF_CLEAR111]], [[BF_SHL110]], !dbg [[DBG98]]
// AARCH64-NEXT:    store i64 [[BF_SET112]], ptr [[ATOMIC_TEMP107]], align 8, !dbg [[DBG98]]
// AARCH64-NEXT:    [[TMP82:%.*]] = load i64, ptr [[ATOMIC_TEMP107]], align 8, !dbg [[DBG98]]
// AARCH64-NEXT:    [[TMP83:%.*]] = cmpxchg ptr @bfx4, i64 [[TMP81]], i64 [[TMP82]] monotonic monotonic, align 8, !dbg [[DBG98]]
// AARCH64-NEXT:    [[TMP84]] = extractvalue { i64, i1 } [[TMP83]], 0, !dbg [[DBG98]]
// AARCH64-NEXT:    [[TMP85:%.*]] = extractvalue { i64, i1 } [[TMP83]], 1, !dbg [[DBG98]]
// AARCH64-NEXT:    br i1 [[TMP85]], label [[ATOMIC_EXIT113:%.*]], label [[ATOMIC_CONT106]], !dbg [[DBG98]]
// AARCH64:       atomic_exit113:
// AARCH64-NEXT:    [[TMP86:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG99:![0-9]+]]
// AARCH64-NEXT:    [[CONV114:%.*]] = fptosi fp128 [[TMP86]] to i64, !dbg [[DBG99]]
// AARCH64-NEXT:    [[ATOMIC_LOAD115:%.*]] = load atomic i8, ptr getelementptr (i8, ptr @bfx4_packed, i64 2) monotonic, align 1, !dbg [[DBG100:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT116:%.*]], !dbg [[DBG100]]
// AARCH64:       atomic_cont116:
// AARCH64-NEXT:    [[TMP87:%.*]] = phi i8 [ [[ATOMIC_LOAD115]], [[ATOMIC_EXIT113]] ], [ [[TMP91:%.*]], [[ATOMIC_CONT116]] ], !dbg [[DBG100]]
// AARCH64-NEXT:    store i8 [[TMP87]], ptr [[ATOMIC_TEMP117]], align 1, !dbg [[DBG100]]
// AARCH64-NEXT:    [[TMP88:%.*]] = trunc i64 [[CONV114]] to i8, !dbg [[DBG100]]
// AARCH64-NEXT:    [[BF_LOAD118:%.*]] = load i8, ptr [[ATOMIC_TEMP117]], align 1, !dbg [[DBG100]]
// AARCH64-NEXT:    [[BF_VALUE119:%.*]] = and i8 [[TMP88]], 127, !dbg [[DBG100]]
// AARCH64-NEXT:    [[BF_SHL120:%.*]] = shl i8 [[BF_VALUE119]], 1, !dbg [[DBG100]]
// AARCH64-NEXT:    [[BF_CLEAR121:%.*]] = and i8 [[BF_LOAD118]], 1, !dbg [[DBG100]]
// AARCH64-NEXT:    [[BF_SET122:%.*]] = or i8 [[BF_CLEAR121]], [[BF_SHL120]], !dbg [[DBG100]]
// AARCH64-NEXT:    store i8 [[BF_SET122]], ptr [[ATOMIC_TEMP117]], align 1, !dbg [[DBG100]]
// AARCH64-NEXT:    [[TMP89:%.*]] = load i8, ptr [[ATOMIC_TEMP117]], align 1, !dbg [[DBG100]]
// AARCH64-NEXT:    [[TMP90:%.*]] = cmpxchg ptr getelementptr (i8, ptr @bfx4_packed, i64 2), i8 [[TMP87]], i8 [[TMP89]] monotonic monotonic, align 1, !dbg [[DBG100]]
// AARCH64-NEXT:    [[TMP91]] = extractvalue { i8, i1 } [[TMP90]], 0, !dbg [[DBG100]]
// AARCH64-NEXT:    [[TMP92:%.*]] = extractvalue { i8, i1 } [[TMP90]], 1, !dbg [[DBG100]]
// AARCH64-NEXT:    br i1 [[TMP92]], label [[ATOMIC_EXIT123:%.*]], label [[ATOMIC_CONT116]], !dbg [[DBG100]]
// AARCH64:       atomic_exit123:
// AARCH64-NEXT:    [[TMP93:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG101:![0-9]+]]
// AARCH64-NEXT:    [[CONV124:%.*]] = uitofp i64 [[TMP93]] to float, !dbg [[DBG101]]
// AARCH64-NEXT:    [[ATOMIC_LOAD125:%.*]] = load atomic i64, ptr @float2x monotonic, align 8, !dbg [[DBG102:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT126:%.*]], !dbg [[DBG102]]
// AARCH64:       atomic_cont126:
// AARCH64-NEXT:    [[TMP94:%.*]] = phi i64 [ [[ATOMIC_LOAD125]], [[ATOMIC_EXIT123]] ], [ [[TMP99:%.*]], [[ATOMIC_CONT126]] ], !dbg [[DBG102]]
// AARCH64-NEXT:    store i64 [[TMP94]], ptr [[ATOMIC_TEMP127]], align 8, !dbg [[DBG102]]
// AARCH64-NEXT:    [[TMP95:%.*]] = load <2 x float>, ptr [[ATOMIC_TEMP127]], align 8, !dbg [[DBG102]]
// AARCH64-NEXT:    [[TMP96:%.*]] = insertelement <2 x float> [[TMP95]], float [[CONV124]], i64 0, !dbg [[DBG102]]
// AARCH64-NEXT:    store <2 x float> [[TMP96]], ptr [[ATOMIC_TEMP127]], align 8, !dbg [[DBG102]]
// AARCH64-NEXT:    [[TMP97:%.*]] = load i64, ptr [[ATOMIC_TEMP127]], align 8, !dbg [[DBG102]]
// AARCH64-NEXT:    [[TMP98:%.*]] = cmpxchg ptr @float2x, i64 [[TMP94]], i64 [[TMP97]] monotonic monotonic, align 8, !dbg [[DBG102]]
// AARCH64-NEXT:    [[TMP99]] = extractvalue { i64, i1 } [[TMP98]], 0, !dbg [[DBG102]]
// AARCH64-NEXT:    [[TMP100:%.*]] = extractvalue { i64, i1 } [[TMP98]], 1, !dbg [[DBG102]]
// AARCH64-NEXT:    br i1 [[TMP100]], label [[ATOMIC_EXIT128:%.*]], label [[ATOMIC_CONT126]], !dbg [[DBG102]]
// AARCH64:       atomic_exit128:
// AARCH64-NEXT:    ret i32 0, !dbg [[DBG103:![0-9]+]]
//
