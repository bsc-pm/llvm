// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --function-signature --include-generated-funcs
// RUN: %clang_cc1 -x c -triple x86_64-gnu-linux -verify -fompss-2 -disable-llvm-passes -ferror-limit 100 %s -emit-llvm -o - | FileCheck %s --check-prefixes=LIN64
// RUN: %clang_cc1 -x c -triple ppc64 -verify -fompss-2 -disable-llvm-passes -ferror-limit 100 %s -emit-llvm -o - | FileCheck %s --check-prefixes=PPC64
// RUN: %clang_cc1 -x c -triple aarch64 -verify -fompss-2 -disable-llvm-passes -ferror-limit 100 %s -emit-llvm -o - | FileCheck %s --check-prefixes=AARCH64
// expected-no-diagnostics
#ifndef HEADER
#define HEADER

_Bool bv, bx;
char cv, cx;
unsigned char ucv, ucx;
short sv, sx;
unsigned short usv, usx;
int iv, ix;
unsigned int uiv, uix;
long lv, lx;
unsigned long ulv, ulx;
long long llv, llx;
unsigned long long ullv, ullx;
float fv, fx;
double dv, dx;
long double ldv, ldx;
_Complex int civ, cix;
_Complex float cfv, cfx;
_Complex double cdv, cdx;

typedef int int4 __attribute__((__vector_size__(16)));
int4 int4x;

struct BitFields {
  int : 32;
  int a : 31;
} bfx;

struct BitFields_packed {
  int : 32;
  int a : 31;
} __attribute__ ((__packed__)) bfx_packed;

struct BitFields2 {
  int : 31;
  int a : 1;
} bfx2;

struct BitFields2_packed {
  int : 31;
  int a : 1;
} __attribute__ ((__packed__)) bfx2_packed;

struct BitFields3 {
  int : 11;
  int a : 14;
} bfx3;

struct BitFields3_packed {
  int : 11;
  int a : 14;
} __attribute__ ((__packed__)) bfx3_packed;

struct BitFields4 {
  short : 16;
  int a: 1;
  long b : 7;
} bfx4;

struct BitFields4_packed {
  short : 16;
  int a: 1;
  long b : 7;
} __attribute__ ((__packed__)) bfx4_packed;

typedef float float2 __attribute__((ext_vector_type(2)));
float2 float2x;

#if defined(__x86_64__)
// Register "0" is currently an invalid register for global register variables.
// Use "esp" instead of "0".
// register int rix __asm__("0");
register int rix __asm__("esp");
#endif

int main(void) {
#pragma oss atomic write
 __imag(civ) = 1;
#pragma oss atomic write
  bx = bv;
#pragma oss atomic write release
  cx = cv;
#pragma oss atomic write
  ucx = ucv;
#pragma oss atomic write
  sx = sv;
#pragma oss atomic write
  usx = usv;
#pragma oss atomic write
  ix = iv;
#pragma oss atomic write
  uix = uiv;
#pragma oss atomic write
  lx = lv;
#pragma oss atomic write
  ulx = ulv;
#pragma oss atomic write
  llx = llv;
#pragma oss atomic write
  ullx = ullv;
#pragma oss atomic write
  fx = fv;
#pragma oss atomic write
  dx = dv;
#pragma oss atomic write
  ldx = ldv;
#pragma oss atomic write
  cix = civ;
#pragma oss atomic write
  cfx = cfv;
#pragma oss atomic seq_cst write
  cdx = cdv;
#pragma oss atomic write
  ulx = bv;
#pragma oss atomic write
  bx = cv;
#pragma oss atomic write, seq_cst
  cx = ucv;
#pragma oss atomic write
  ulx = sv;
#pragma oss atomic write
  lx = usv;
#pragma oss atomic seq_cst, write
  uix = iv;
#pragma oss atomic write
  ix = uiv;
#pragma oss atomic write
  cix = lv;
#pragma oss atomic write
  fx = ulv;
#pragma oss atomic write
  dx = llv;
#pragma oss atomic write
  ldx = ullv;
#pragma oss atomic write
  cix = fv;
#pragma oss atomic write
  sx = dv;
#pragma oss atomic write
  bx = ldv;
#pragma oss atomic write
  bx = civ;
#pragma oss atomic write
  usx = cfv;
#pragma oss atomic write
  llx = cdv;
#pragma oss atomic write
  int4x[sv] = bv;
#pragma oss atomic write
  bfx.a = ldv;
#pragma oss atomic write
  bfx_packed.a = ldv;
#pragma oss atomic write
  bfx2.a = ldv;
#pragma oss atomic write
  bfx2_packed.a = ldv;
#pragma oss atomic write
  bfx3.a = ldv;
#pragma oss atomic write
  bfx3_packed.a = ldv;
#pragma oss atomic write
  bfx4.a = ldv;
#pragma oss atomic write
  bfx4_packed.a = ldv;
#pragma oss atomic write
  bfx4.b = ldv;
#pragma oss atomic relaxed write
  bfx4_packed.b = ldv;
#pragma oss atomic write relaxed
  float2x.x = ulv;
#if defined(__x86_64__)
#pragma oss atomic write seq_cst
  dv = rix;
#endif
  return 0;
}

#endif
// LIN64-LABEL: define {{[^@]+}}@main
// LIN64-SAME: () #[[ATTR0:[0-9]+]] !dbg [[DBG6:![0-9]+]] {
// LIN64-NEXT:  entry:
// LIN64-NEXT:    [[RETVAL:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca x86_fp80, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP1:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP2:%.*]] = alloca { float, float }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP3:%.*]] = alloca { double, double }, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP9:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP13:%.*]] = alloca x86_fp80, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP15:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP31:%.*]] = alloca <4 x i32>, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP32:%.*]] = alloca <4 x i32>, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP35:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP38:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP40:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP50:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP59:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP69:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP77:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP79:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP90:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP100:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP109:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP119:%.*]] = alloca i64, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP129:%.*]] = alloca <2 x float>, align 8
// LIN64-NEXT:    store i32 0, ptr [[RETVAL]], align 4
// LIN64-NEXT:    store atomic i32 1, ptr getelementptr inbounds nuw ({ i32, i32 }, ptr @civ, i32 0, i32 1) monotonic, align 4, !dbg [[DBG10:![0-9]+]]
// LIN64-NEXT:    [[TMP0:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG11:![0-9]+]]
// LIN64-NEXT:    [[LOADEDV:%.*]] = trunc i8 [[TMP0]] to i1, !dbg [[DBG11]]
// LIN64-NEXT:    [[STOREDV:%.*]] = zext i1 [[LOADEDV]] to i8, !dbg [[DBG12:![0-9]+]]
// LIN64-NEXT:    store atomic i8 [[STOREDV]], ptr @bx monotonic, align 1, !dbg [[DBG12]]
// LIN64-NEXT:    [[TMP1:%.*]] = load i8, ptr @cv, align 1, !dbg [[DBG13:![0-9]+]]
// LIN64-NEXT:    store atomic i8 [[TMP1]], ptr @cx release, align 1, !dbg [[DBG14:![0-9]+]]
// LIN64-NEXT:    fence release
// LIN64-NEXT:    [[TMP2:%.*]] = load i8, ptr @ucv, align 1, !dbg [[DBG15:![0-9]+]]
// LIN64-NEXT:    store atomic i8 [[TMP2]], ptr @ucx monotonic, align 1, !dbg [[DBG16:![0-9]+]]
// LIN64-NEXT:    [[TMP3:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG17:![0-9]+]]
// LIN64-NEXT:    store atomic i16 [[TMP3]], ptr @sx monotonic, align 2, !dbg [[DBG18:![0-9]+]]
// LIN64-NEXT:    [[TMP4:%.*]] = load i16, ptr @usv, align 2, !dbg [[DBG19:![0-9]+]]
// LIN64-NEXT:    store atomic i16 [[TMP4]], ptr @usx monotonic, align 2, !dbg [[DBG20:![0-9]+]]
// LIN64-NEXT:    [[TMP5:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG21:![0-9]+]]
// LIN64-NEXT:    store atomic i32 [[TMP5]], ptr @ix monotonic, align 4, !dbg [[DBG22:![0-9]+]]
// LIN64-NEXT:    [[TMP6:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG23:![0-9]+]]
// LIN64-NEXT:    store atomic i32 [[TMP6]], ptr @uix monotonic, align 4, !dbg [[DBG24:![0-9]+]]
// LIN64-NEXT:    [[TMP7:%.*]] = load i64, ptr @lv, align 8, !dbg [[DBG25:![0-9]+]]
// LIN64-NEXT:    store atomic i64 [[TMP7]], ptr @lx monotonic, align 8, !dbg [[DBG26:![0-9]+]]
// LIN64-NEXT:    [[TMP8:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG27:![0-9]+]]
// LIN64-NEXT:    store atomic i64 [[TMP8]], ptr @ulx monotonic, align 8, !dbg [[DBG28:![0-9]+]]
// LIN64-NEXT:    [[TMP9:%.*]] = load i64, ptr @llv, align 8, !dbg [[DBG29:![0-9]+]]
// LIN64-NEXT:    store atomic i64 [[TMP9]], ptr @llx monotonic, align 8, !dbg [[DBG30:![0-9]+]]
// LIN64-NEXT:    [[TMP10:%.*]] = load i64, ptr @ullv, align 8, !dbg [[DBG31:![0-9]+]]
// LIN64-NEXT:    store atomic i64 [[TMP10]], ptr @ullx monotonic, align 8, !dbg [[DBG32:![0-9]+]]
// LIN64-NEXT:    [[TMP11:%.*]] = load float, ptr @fv, align 4, !dbg [[DBG33:![0-9]+]]
// LIN64-NEXT:    store atomic float [[TMP11]], ptr @fx monotonic, align 4, !dbg [[DBG34:![0-9]+]]
// LIN64-NEXT:    [[TMP12:%.*]] = load double, ptr @dv, align 8, !dbg [[DBG35:![0-9]+]]
// LIN64-NEXT:    store atomic double [[TMP12]], ptr @dx monotonic, align 8, !dbg [[DBG36:![0-9]+]]
// LIN64-NEXT:    [[TMP13:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG37:![0-9]+]]
// LIN64-NEXT:    call void @llvm.memset.p0.i64(ptr align 16 [[ATOMIC_TEMP]], i8 0, i64 16, i1 false), !dbg [[DBG38:![0-9]+]]
// LIN64-NEXT:    store x86_fp80 [[TMP13]], ptr [[ATOMIC_TEMP]], align 16, !dbg [[DBG38]]
// LIN64-NEXT:    call void @__atomic_store(i64 noundef 16, ptr noundef @ldx, ptr noundef [[ATOMIC_TEMP]], i32 noundef 0), !dbg [[DBG38]]
// LIN64-NEXT:    [[CIV_REAL:%.*]] = load i32, ptr @civ, align 4, !dbg [[DBG39:![0-9]+]]
// LIN64-NEXT:    [[CIV_IMAG:%.*]] = load i32, ptr getelementptr inbounds nuw ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG39]]
// LIN64-NEXT:    [[ATOMIC_TEMP1_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP1]], i32 0, i32 0, !dbg [[DBG40:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_TEMP1_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP1]], i32 0, i32 1, !dbg [[DBG40]]
// LIN64-NEXT:    store i32 [[CIV_REAL]], ptr [[ATOMIC_TEMP1_REALP]], align 4, !dbg [[DBG40]]
// LIN64-NEXT:    store i32 [[CIV_IMAG]], ptr [[ATOMIC_TEMP1_IMAGP]], align 4, !dbg [[DBG40]]
// LIN64-NEXT:    call void @__atomic_store(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP1]], i32 noundef 0), !dbg [[DBG40]]
// LIN64-NEXT:    [[CFV_REAL:%.*]] = load float, ptr @cfv, align 4, !dbg [[DBG41:![0-9]+]]
// LIN64-NEXT:    [[CFV_IMAG:%.*]] = load float, ptr getelementptr inbounds nuw ({ float, float }, ptr @cfv, i32 0, i32 1), align 4, !dbg [[DBG41]]
// LIN64-NEXT:    [[ATOMIC_TEMP2_REALP:%.*]] = getelementptr inbounds nuw { float, float }, ptr [[ATOMIC_TEMP2]], i32 0, i32 0, !dbg [[DBG42:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_TEMP2_IMAGP:%.*]] = getelementptr inbounds nuw { float, float }, ptr [[ATOMIC_TEMP2]], i32 0, i32 1, !dbg [[DBG42]]
// LIN64-NEXT:    store float [[CFV_REAL]], ptr [[ATOMIC_TEMP2_REALP]], align 4, !dbg [[DBG42]]
// LIN64-NEXT:    store float [[CFV_IMAG]], ptr [[ATOMIC_TEMP2_IMAGP]], align 4, !dbg [[DBG42]]
// LIN64-NEXT:    call void @__atomic_store(i64 noundef 8, ptr noundef @cfx, ptr noundef [[ATOMIC_TEMP2]], i32 noundef 0), !dbg [[DBG42]]
// LIN64-NEXT:    [[CDV_REAL:%.*]] = load double, ptr @cdv, align 8, !dbg [[DBG43:![0-9]+]]
// LIN64-NEXT:    [[CDV_IMAG:%.*]] = load double, ptr getelementptr inbounds nuw ({ double, double }, ptr @cdv, i32 0, i32 1), align 8, !dbg [[DBG43]]
// LIN64-NEXT:    [[ATOMIC_TEMP3_REALP:%.*]] = getelementptr inbounds nuw { double, double }, ptr [[ATOMIC_TEMP3]], i32 0, i32 0, !dbg [[DBG44:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_TEMP3_IMAGP:%.*]] = getelementptr inbounds nuw { double, double }, ptr [[ATOMIC_TEMP3]], i32 0, i32 1, !dbg [[DBG44]]
// LIN64-NEXT:    store double [[CDV_REAL]], ptr [[ATOMIC_TEMP3_REALP]], align 8, !dbg [[DBG44]]
// LIN64-NEXT:    store double [[CDV_IMAG]], ptr [[ATOMIC_TEMP3_IMAGP]], align 8, !dbg [[DBG44]]
// LIN64-NEXT:    call void @__atomic_store(i64 noundef 16, ptr noundef @cdx, ptr noundef [[ATOMIC_TEMP3]], i32 noundef 5), !dbg [[DBG44]]
// LIN64-NEXT:    fence release
// LIN64-NEXT:    [[TMP14:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG45:![0-9]+]]
// LIN64-NEXT:    [[LOADEDV4:%.*]] = trunc i8 [[TMP14]] to i1, !dbg [[DBG45]]
// LIN64-NEXT:    [[CONV:%.*]] = zext i1 [[LOADEDV4]] to i64, !dbg [[DBG45]]
// LIN64-NEXT:    store atomic i64 [[CONV]], ptr @ulx monotonic, align 8, !dbg [[DBG46:![0-9]+]]
// LIN64-NEXT:    [[TMP15:%.*]] = load i8, ptr @cv, align 1, !dbg [[DBG47:![0-9]+]]
// LIN64-NEXT:    [[TOBOOL:%.*]] = icmp ne i8 [[TMP15]], 0, !dbg [[DBG47]]
// LIN64-NEXT:    [[STOREDV5:%.*]] = zext i1 [[TOBOOL]] to i8, !dbg [[DBG48:![0-9]+]]
// LIN64-NEXT:    store atomic i8 [[STOREDV5]], ptr @bx monotonic, align 1, !dbg [[DBG48]]
// LIN64-NEXT:    [[TMP16:%.*]] = load i8, ptr @ucv, align 1, !dbg [[DBG49:![0-9]+]]
// LIN64-NEXT:    store atomic i8 [[TMP16]], ptr @cx seq_cst, align 1, !dbg [[DBG50:![0-9]+]]
// LIN64-NEXT:    fence release
// LIN64-NEXT:    [[TMP17:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG51:![0-9]+]]
// LIN64-NEXT:    [[CONV6:%.*]] = sext i16 [[TMP17]] to i64, !dbg [[DBG51]]
// LIN64-NEXT:    store atomic i64 [[CONV6]], ptr @ulx monotonic, align 8, !dbg [[DBG52:![0-9]+]]
// LIN64-NEXT:    [[TMP18:%.*]] = load i16, ptr @usv, align 2, !dbg [[DBG53:![0-9]+]]
// LIN64-NEXT:    [[CONV7:%.*]] = zext i16 [[TMP18]] to i64, !dbg [[DBG53]]
// LIN64-NEXT:    store atomic i64 [[CONV7]], ptr @lx monotonic, align 8, !dbg [[DBG54:![0-9]+]]
// LIN64-NEXT:    [[TMP19:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG55:![0-9]+]]
// LIN64-NEXT:    store atomic i32 [[TMP19]], ptr @uix seq_cst, align 4, !dbg [[DBG56:![0-9]+]]
// LIN64-NEXT:    fence release
// LIN64-NEXT:    [[TMP20:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG57:![0-9]+]]
// LIN64-NEXT:    store atomic i32 [[TMP20]], ptr @ix monotonic, align 4, !dbg [[DBG58:![0-9]+]]
// LIN64-NEXT:    [[TMP21:%.*]] = load i64, ptr @lv, align 8, !dbg [[DBG59:![0-9]+]]
// LIN64-NEXT:    [[CONV8:%.*]] = trunc i64 [[TMP21]] to i32, !dbg [[DBG59]]
// LIN64-NEXT:    [[ATOMIC_TEMP9_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP9]], i32 0, i32 0, !dbg [[DBG60:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_TEMP9_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP9]], i32 0, i32 1, !dbg [[DBG60]]
// LIN64-NEXT:    store i32 [[CONV8]], ptr [[ATOMIC_TEMP9_REALP]], align 4, !dbg [[DBG60]]
// LIN64-NEXT:    store i32 0, ptr [[ATOMIC_TEMP9_IMAGP]], align 4, !dbg [[DBG60]]
// LIN64-NEXT:    call void @__atomic_store(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP9]], i32 noundef 0), !dbg [[DBG60]]
// LIN64-NEXT:    [[TMP22:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG61:![0-9]+]]
// LIN64-NEXT:    [[CONV10:%.*]] = uitofp i64 [[TMP22]] to float, !dbg [[DBG61]]
// LIN64-NEXT:    store atomic float [[CONV10]], ptr @fx monotonic, align 4, !dbg [[DBG62:![0-9]+]]
// LIN64-NEXT:    [[TMP23:%.*]] = load i64, ptr @llv, align 8, !dbg [[DBG63:![0-9]+]]
// LIN64-NEXT:    [[CONV11:%.*]] = sitofp i64 [[TMP23]] to double, !dbg [[DBG63]]
// LIN64-NEXT:    store atomic double [[CONV11]], ptr @dx monotonic, align 8, !dbg [[DBG64:![0-9]+]]
// LIN64-NEXT:    [[TMP24:%.*]] = load i64, ptr @ullv, align 8, !dbg [[DBG65:![0-9]+]]
// LIN64-NEXT:    [[CONV12:%.*]] = uitofp i64 [[TMP24]] to x86_fp80, !dbg [[DBG65]]
// LIN64-NEXT:    call void @llvm.memset.p0.i64(ptr align 16 [[ATOMIC_TEMP13]], i8 0, i64 16, i1 false), !dbg [[DBG66:![0-9]+]]
// LIN64-NEXT:    store x86_fp80 [[CONV12]], ptr [[ATOMIC_TEMP13]], align 16, !dbg [[DBG66]]
// LIN64-NEXT:    call void @__atomic_store(i64 noundef 16, ptr noundef @ldx, ptr noundef [[ATOMIC_TEMP13]], i32 noundef 0), !dbg [[DBG66]]
// LIN64-NEXT:    [[TMP25:%.*]] = load float, ptr @fv, align 4, !dbg [[DBG67:![0-9]+]]
// LIN64-NEXT:    [[CONV14:%.*]] = fptosi float [[TMP25]] to i32, !dbg [[DBG67]]
// LIN64-NEXT:    [[ATOMIC_TEMP15_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP15]], i32 0, i32 0, !dbg [[DBG68:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_TEMP15_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP15]], i32 0, i32 1, !dbg [[DBG68]]
// LIN64-NEXT:    store i32 [[CONV14]], ptr [[ATOMIC_TEMP15_REALP]], align 4, !dbg [[DBG68]]
// LIN64-NEXT:    store i32 0, ptr [[ATOMIC_TEMP15_IMAGP]], align 4, !dbg [[DBG68]]
// LIN64-NEXT:    call void @__atomic_store(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP15]], i32 noundef 0), !dbg [[DBG68]]
// LIN64-NEXT:    [[TMP26:%.*]] = load double, ptr @dv, align 8, !dbg [[DBG69:![0-9]+]]
// LIN64-NEXT:    [[CONV16:%.*]] = fptosi double [[TMP26]] to i16, !dbg [[DBG69]]
// LIN64-NEXT:    store atomic i16 [[CONV16]], ptr @sx monotonic, align 2, !dbg [[DBG70:![0-9]+]]
// LIN64-NEXT:    [[TMP27:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG71:![0-9]+]]
// LIN64-NEXT:    [[TOBOOL17:%.*]] = fcmp une x86_fp80 [[TMP27]], 0xK00000000000000000000, !dbg [[DBG71]]
// LIN64-NEXT:    [[STOREDV18:%.*]] = zext i1 [[TOBOOL17]] to i8, !dbg [[DBG72:![0-9]+]]
// LIN64-NEXT:    store atomic i8 [[STOREDV18]], ptr @bx monotonic, align 1, !dbg [[DBG72]]
// LIN64-NEXT:    [[CIV_REAL19:%.*]] = load i32, ptr @civ, align 4, !dbg [[DBG73:![0-9]+]]
// LIN64-NEXT:    [[CIV_IMAG20:%.*]] = load i32, ptr getelementptr inbounds nuw ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG73]]
// LIN64-NEXT:    [[TOBOOL21:%.*]] = icmp ne i32 [[CIV_REAL19]], 0, !dbg [[DBG73]]
// LIN64-NEXT:    [[TOBOOL22:%.*]] = icmp ne i32 [[CIV_IMAG20]], 0, !dbg [[DBG73]]
// LIN64-NEXT:    [[TOBOOL23:%.*]] = or i1 [[TOBOOL21]], [[TOBOOL22]], !dbg [[DBG73]]
// LIN64-NEXT:    [[STOREDV24:%.*]] = zext i1 [[TOBOOL23]] to i8, !dbg [[DBG74:![0-9]+]]
// LIN64-NEXT:    store atomic i8 [[STOREDV24]], ptr @bx monotonic, align 1, !dbg [[DBG74]]
// LIN64-NEXT:    [[CFV_REAL25:%.*]] = load float, ptr @cfv, align 4, !dbg [[DBG75:![0-9]+]]
// LIN64-NEXT:    [[CONV26:%.*]] = fptoui float [[CFV_REAL25]] to i16, !dbg [[DBG75]]
// LIN64-NEXT:    store atomic i16 [[CONV26]], ptr @usx monotonic, align 2, !dbg [[DBG76:![0-9]+]]
// LIN64-NEXT:    [[CDV_REAL27:%.*]] = load double, ptr @cdv, align 8, !dbg [[DBG77:![0-9]+]]
// LIN64-NEXT:    [[CONV28:%.*]] = fptosi double [[CDV_REAL27]] to i64, !dbg [[DBG77]]
// LIN64-NEXT:    store atomic i64 [[CONV28]], ptr @llx monotonic, align 8, !dbg [[DBG78:![0-9]+]]
// LIN64-NEXT:    [[TMP28:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG79:![0-9]+]]
// LIN64-NEXT:    [[TMP29:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG80:![0-9]+]]
// LIN64-NEXT:    [[LOADEDV29:%.*]] = trunc i8 [[TMP29]] to i1, !dbg [[DBG80]]
// LIN64-NEXT:    [[CONV30:%.*]] = zext i1 [[LOADEDV29]] to i32, !dbg [[DBG80]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 16, ptr noundef @int4x, ptr noundef [[ATOMIC_TEMP31]], i32 noundef 0), !dbg [[DBG81:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT:%.*]], !dbg [[DBG81]]
// LIN64:       atomic_cont:
// LIN64-NEXT:    [[TMP30:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP31]], align 16, !dbg [[DBG81]]
// LIN64-NEXT:    store <4 x i32> [[TMP30]], ptr [[ATOMIC_TEMP32]], align 16, !dbg [[DBG81]]
// LIN64-NEXT:    [[TMP31:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP32]], align 16, !dbg [[DBG81]]
// LIN64-NEXT:    [[VECINS:%.*]] = insertelement <4 x i32> [[TMP31]], i32 [[CONV30]], i16 [[TMP28]], !dbg [[DBG81]]
// LIN64-NEXT:    store <4 x i32> [[VECINS]], ptr [[ATOMIC_TEMP32]], align 16, !dbg [[DBG81]]
// LIN64-NEXT:    [[CALL:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, ptr noundef @int4x, ptr noundef [[ATOMIC_TEMP31]], ptr noundef [[ATOMIC_TEMP32]], i32 noundef 0, i32 noundef 0), !dbg [[DBG81]]
// LIN64-NEXT:    br i1 [[CALL]], label [[ATOMIC_EXIT:%.*]], label [[ATOMIC_CONT]], !dbg [[DBG81]]
// LIN64:       atomic_exit:
// LIN64-NEXT:    [[TMP32:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG82:![0-9]+]]
// LIN64-NEXT:    [[CONV33:%.*]] = fptosi x86_fp80 [[TMP32]] to i32, !dbg [[DBG82]]
// LIN64-NEXT:    [[ATOMIC_LOAD:%.*]] = load atomic i32, ptr getelementptr (i8, ptr @bfx, i64 4) monotonic, align 4, !dbg [[DBG83:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT34:%.*]], !dbg [[DBG83]]
// LIN64:       atomic_cont34:
// LIN64-NEXT:    [[TMP33:%.*]] = phi i32 [ [[ATOMIC_LOAD]], [[ATOMIC_EXIT]] ], [ [[TMP36:%.*]], [[ATOMIC_CONT34]] ], !dbg [[DBG83]]
// LIN64-NEXT:    store i32 [[TMP33]], ptr [[ATOMIC_TEMP35]], align 4, !dbg [[DBG83]]
// LIN64-NEXT:    [[BF_LOAD:%.*]] = load i32, ptr [[ATOMIC_TEMP35]], align 4, !dbg [[DBG83]]
// LIN64-NEXT:    [[BF_VALUE:%.*]] = and i32 [[CONV33]], 2147483647, !dbg [[DBG83]]
// LIN64-NEXT:    [[BF_CLEAR:%.*]] = and i32 [[BF_LOAD]], -2147483648, !dbg [[DBG83]]
// LIN64-NEXT:    [[BF_SET:%.*]] = or i32 [[BF_CLEAR]], [[BF_VALUE]], !dbg [[DBG83]]
// LIN64-NEXT:    store i32 [[BF_SET]], ptr [[ATOMIC_TEMP35]], align 4, !dbg [[DBG83]]
// LIN64-NEXT:    [[TMP34:%.*]] = load i32, ptr [[ATOMIC_TEMP35]], align 4, !dbg [[DBG83]]
// LIN64-NEXT:    [[TMP35:%.*]] = cmpxchg ptr getelementptr (i8, ptr @bfx, i64 4), i32 [[TMP33]], i32 [[TMP34]] monotonic monotonic, align 4, !dbg [[DBG83]]
// LIN64-NEXT:    [[TMP36]] = extractvalue { i32, i1 } [[TMP35]], 0, !dbg [[DBG83]]
// LIN64-NEXT:    [[TMP37:%.*]] = extractvalue { i32, i1 } [[TMP35]], 1, !dbg [[DBG83]]
// LIN64-NEXT:    br i1 [[TMP37]], label [[ATOMIC_EXIT36:%.*]], label [[ATOMIC_CONT34]], !dbg [[DBG83]]
// LIN64:       atomic_exit36:
// LIN64-NEXT:    [[TMP38:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG84:![0-9]+]]
// LIN64-NEXT:    [[CONV37:%.*]] = fptosi x86_fp80 [[TMP38]] to i32, !dbg [[DBG84]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 4, ptr noundef getelementptr (i8, ptr @bfx_packed, i64 4), ptr noundef [[ATOMIC_TEMP38]], i32 noundef 0), !dbg [[DBG85:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT39:%.*]], !dbg [[DBG85]]
// LIN64:       atomic_cont39:
// LIN64-NEXT:    [[TMP39:%.*]] = load i32, ptr [[ATOMIC_TEMP38]], align 1, !dbg [[DBG85]]
// LIN64-NEXT:    store i32 [[TMP39]], ptr [[ATOMIC_TEMP40]], align 1, !dbg [[DBG85]]
// LIN64-NEXT:    [[BF_LOAD41:%.*]] = load i32, ptr [[ATOMIC_TEMP40]], align 1, !dbg [[DBG85]]
// LIN64-NEXT:    [[BF_VALUE42:%.*]] = and i32 [[CONV37]], 2147483647, !dbg [[DBG85]]
// LIN64-NEXT:    [[BF_CLEAR43:%.*]] = and i32 [[BF_LOAD41]], -2147483648, !dbg [[DBG85]]
// LIN64-NEXT:    [[BF_SET44:%.*]] = or i32 [[BF_CLEAR43]], [[BF_VALUE42]], !dbg [[DBG85]]
// LIN64-NEXT:    store i32 [[BF_SET44]], ptr [[ATOMIC_TEMP40]], align 1, !dbg [[DBG85]]
// LIN64-NEXT:    [[CALL45:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 4, ptr noundef getelementptr (i8, ptr @bfx_packed, i64 4), ptr noundef [[ATOMIC_TEMP38]], ptr noundef [[ATOMIC_TEMP40]], i32 noundef 0, i32 noundef 0), !dbg [[DBG85]]
// LIN64-NEXT:    br i1 [[CALL45]], label [[ATOMIC_EXIT46:%.*]], label [[ATOMIC_CONT39]], !dbg [[DBG85]]
// LIN64:       atomic_exit46:
// LIN64-NEXT:    [[TMP40:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG86:![0-9]+]]
// LIN64-NEXT:    [[CONV47:%.*]] = fptosi x86_fp80 [[TMP40]] to i32, !dbg [[DBG86]]
// LIN64-NEXT:    [[ATOMIC_LOAD48:%.*]] = load atomic i32, ptr @bfx2 monotonic, align 4, !dbg [[DBG87:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT49:%.*]], !dbg [[DBG87]]
// LIN64:       atomic_cont49:
// LIN64-NEXT:    [[TMP41:%.*]] = phi i32 [ [[ATOMIC_LOAD48]], [[ATOMIC_EXIT46]] ], [ [[TMP44:%.*]], [[ATOMIC_CONT49]] ], !dbg [[DBG87]]
// LIN64-NEXT:    store i32 [[TMP41]], ptr [[ATOMIC_TEMP50]], align 4, !dbg [[DBG87]]
// LIN64-NEXT:    [[BF_LOAD51:%.*]] = load i32, ptr [[ATOMIC_TEMP50]], align 4, !dbg [[DBG87]]
// LIN64-NEXT:    [[BF_VALUE52:%.*]] = and i32 [[CONV47]], 1, !dbg [[DBG87]]
// LIN64-NEXT:    [[BF_SHL:%.*]] = shl i32 [[BF_VALUE52]], 31, !dbg [[DBG87]]
// LIN64-NEXT:    [[BF_CLEAR53:%.*]] = and i32 [[BF_LOAD51]], 2147483647, !dbg [[DBG87]]
// LIN64-NEXT:    [[BF_SET54:%.*]] = or i32 [[BF_CLEAR53]], [[BF_SHL]], !dbg [[DBG87]]
// LIN64-NEXT:    store i32 [[BF_SET54]], ptr [[ATOMIC_TEMP50]], align 4, !dbg [[DBG87]]
// LIN64-NEXT:    [[TMP42:%.*]] = load i32, ptr [[ATOMIC_TEMP50]], align 4, !dbg [[DBG87]]
// LIN64-NEXT:    [[TMP43:%.*]] = cmpxchg ptr @bfx2, i32 [[TMP41]], i32 [[TMP42]] monotonic monotonic, align 4, !dbg [[DBG87]]
// LIN64-NEXT:    [[TMP44]] = extractvalue { i32, i1 } [[TMP43]], 0, !dbg [[DBG87]]
// LIN64-NEXT:    [[TMP45:%.*]] = extractvalue { i32, i1 } [[TMP43]], 1, !dbg [[DBG87]]
// LIN64-NEXT:    br i1 [[TMP45]], label [[ATOMIC_EXIT55:%.*]], label [[ATOMIC_CONT49]], !dbg [[DBG87]]
// LIN64:       atomic_exit55:
// LIN64-NEXT:    [[TMP46:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG88:![0-9]+]]
// LIN64-NEXT:    [[CONV56:%.*]] = fptosi x86_fp80 [[TMP46]] to i32, !dbg [[DBG88]]
// LIN64-NEXT:    [[ATOMIC_LOAD57:%.*]] = load atomic i8, ptr getelementptr (i8, ptr @bfx2_packed, i64 3) monotonic, align 1, !dbg [[DBG89:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT58:%.*]], !dbg [[DBG89]]
// LIN64:       atomic_cont58:
// LIN64-NEXT:    [[TMP47:%.*]] = phi i8 [ [[ATOMIC_LOAD57]], [[ATOMIC_EXIT55]] ], [ [[TMP51:%.*]], [[ATOMIC_CONT58]] ], !dbg [[DBG89]]
// LIN64-NEXT:    store i8 [[TMP47]], ptr [[ATOMIC_TEMP59]], align 1, !dbg [[DBG89]]
// LIN64-NEXT:    [[TMP48:%.*]] = trunc i32 [[CONV56]] to i8, !dbg [[DBG89]]
// LIN64-NEXT:    [[BF_LOAD60:%.*]] = load i8, ptr [[ATOMIC_TEMP59]], align 1, !dbg [[DBG89]]
// LIN64-NEXT:    [[BF_VALUE61:%.*]] = and i8 [[TMP48]], 1, !dbg [[DBG89]]
// LIN64-NEXT:    [[BF_SHL62:%.*]] = shl i8 [[BF_VALUE61]], 7, !dbg [[DBG89]]
// LIN64-NEXT:    [[BF_CLEAR63:%.*]] = and i8 [[BF_LOAD60]], 127, !dbg [[DBG89]]
// LIN64-NEXT:    [[BF_SET64:%.*]] = or i8 [[BF_CLEAR63]], [[BF_SHL62]], !dbg [[DBG89]]
// LIN64-NEXT:    store i8 [[BF_SET64]], ptr [[ATOMIC_TEMP59]], align 1, !dbg [[DBG89]]
// LIN64-NEXT:    [[TMP49:%.*]] = load i8, ptr [[ATOMIC_TEMP59]], align 1, !dbg [[DBG89]]
// LIN64-NEXT:    [[TMP50:%.*]] = cmpxchg ptr getelementptr (i8, ptr @bfx2_packed, i64 3), i8 [[TMP47]], i8 [[TMP49]] monotonic monotonic, align 1, !dbg [[DBG89]]
// LIN64-NEXT:    [[TMP51]] = extractvalue { i8, i1 } [[TMP50]], 0, !dbg [[DBG89]]
// LIN64-NEXT:    [[TMP52:%.*]] = extractvalue { i8, i1 } [[TMP50]], 1, !dbg [[DBG89]]
// LIN64-NEXT:    br i1 [[TMP52]], label [[ATOMIC_EXIT65:%.*]], label [[ATOMIC_CONT58]], !dbg [[DBG89]]
// LIN64:       atomic_exit65:
// LIN64-NEXT:    [[TMP53:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG90:![0-9]+]]
// LIN64-NEXT:    [[CONV66:%.*]] = fptosi x86_fp80 [[TMP53]] to i32, !dbg [[DBG90]]
// LIN64-NEXT:    [[ATOMIC_LOAD67:%.*]] = load atomic i32, ptr @bfx3 monotonic, align 4, !dbg [[DBG91:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT68:%.*]], !dbg [[DBG91]]
// LIN64:       atomic_cont68:
// LIN64-NEXT:    [[TMP54:%.*]] = phi i32 [ [[ATOMIC_LOAD67]], [[ATOMIC_EXIT65]] ], [ [[TMP57:%.*]], [[ATOMIC_CONT68]] ], !dbg [[DBG91]]
// LIN64-NEXT:    store i32 [[TMP54]], ptr [[ATOMIC_TEMP69]], align 4, !dbg [[DBG91]]
// LIN64-NEXT:    [[BF_LOAD70:%.*]] = load i32, ptr [[ATOMIC_TEMP69]], align 4, !dbg [[DBG91]]
// LIN64-NEXT:    [[BF_VALUE71:%.*]] = and i32 [[CONV66]], 16383, !dbg [[DBG91]]
// LIN64-NEXT:    [[BF_SHL72:%.*]] = shl i32 [[BF_VALUE71]], 11, !dbg [[DBG91]]
// LIN64-NEXT:    [[BF_CLEAR73:%.*]] = and i32 [[BF_LOAD70]], -33552385, !dbg [[DBG91]]
// LIN64-NEXT:    [[BF_SET74:%.*]] = or i32 [[BF_CLEAR73]], [[BF_SHL72]], !dbg [[DBG91]]
// LIN64-NEXT:    store i32 [[BF_SET74]], ptr [[ATOMIC_TEMP69]], align 4, !dbg [[DBG91]]
// LIN64-NEXT:    [[TMP55:%.*]] = load i32, ptr [[ATOMIC_TEMP69]], align 4, !dbg [[DBG91]]
// LIN64-NEXT:    [[TMP56:%.*]] = cmpxchg ptr @bfx3, i32 [[TMP54]], i32 [[TMP55]] monotonic monotonic, align 4, !dbg [[DBG91]]
// LIN64-NEXT:    [[TMP57]] = extractvalue { i32, i1 } [[TMP56]], 0, !dbg [[DBG91]]
// LIN64-NEXT:    [[TMP58:%.*]] = extractvalue { i32, i1 } [[TMP56]], 1, !dbg [[DBG91]]
// LIN64-NEXT:    br i1 [[TMP58]], label [[ATOMIC_EXIT75:%.*]], label [[ATOMIC_CONT68]], !dbg [[DBG91]]
// LIN64:       atomic_exit75:
// LIN64-NEXT:    [[TMP59:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG92:![0-9]+]]
// LIN64-NEXT:    [[CONV76:%.*]] = fptosi x86_fp80 [[TMP59]] to i32, !dbg [[DBG92]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 3, ptr noundef getelementptr (i8, ptr @bfx3_packed, i64 1), ptr noundef [[ATOMIC_TEMP77]], i32 noundef 0), !dbg [[DBG93:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT78:%.*]], !dbg [[DBG93]]
// LIN64:       atomic_cont78:
// LIN64-NEXT:    [[TMP60:%.*]] = load i24, ptr [[ATOMIC_TEMP77]], align 1, !dbg [[DBG93]]
// LIN64-NEXT:    store i24 [[TMP60]], ptr [[ATOMIC_TEMP79]], align 1, !dbg [[DBG93]]
// LIN64-NEXT:    [[TMP61:%.*]] = trunc i32 [[CONV76]] to i24, !dbg [[DBG93]]
// LIN64-NEXT:    [[BF_LOAD80:%.*]] = load i24, ptr [[ATOMIC_TEMP79]], align 1, !dbg [[DBG93]]
// LIN64-NEXT:    [[BF_VALUE81:%.*]] = and i24 [[TMP61]], 16383, !dbg [[DBG93]]
// LIN64-NEXT:    [[BF_SHL82:%.*]] = shl i24 [[BF_VALUE81]], 3, !dbg [[DBG93]]
// LIN64-NEXT:    [[BF_CLEAR83:%.*]] = and i24 [[BF_LOAD80]], -131065, !dbg [[DBG93]]
// LIN64-NEXT:    [[BF_SET84:%.*]] = or i24 [[BF_CLEAR83]], [[BF_SHL82]], !dbg [[DBG93]]
// LIN64-NEXT:    store i24 [[BF_SET84]], ptr [[ATOMIC_TEMP79]], align 1, !dbg [[DBG93]]
// LIN64-NEXT:    [[CALL85:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 3, ptr noundef getelementptr (i8, ptr @bfx3_packed, i64 1), ptr noundef [[ATOMIC_TEMP77]], ptr noundef [[ATOMIC_TEMP79]], i32 noundef 0, i32 noundef 0), !dbg [[DBG93]]
// LIN64-NEXT:    br i1 [[CALL85]], label [[ATOMIC_EXIT86:%.*]], label [[ATOMIC_CONT78]], !dbg [[DBG93]]
// LIN64:       atomic_exit86:
// LIN64-NEXT:    [[TMP62:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG94:![0-9]+]]
// LIN64-NEXT:    [[CONV87:%.*]] = fptosi x86_fp80 [[TMP62]] to i32, !dbg [[DBG94]]
// LIN64-NEXT:    [[ATOMIC_LOAD88:%.*]] = load atomic i64, ptr @bfx4 monotonic, align 8, !dbg [[DBG95:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT89:%.*]], !dbg [[DBG95]]
// LIN64:       atomic_cont89:
// LIN64-NEXT:    [[TMP63:%.*]] = phi i64 [ [[ATOMIC_LOAD88]], [[ATOMIC_EXIT86]] ], [ [[TMP67:%.*]], [[ATOMIC_CONT89]] ], !dbg [[DBG95]]
// LIN64-NEXT:    store i64 [[TMP63]], ptr [[ATOMIC_TEMP90]], align 8, !dbg [[DBG95]]
// LIN64-NEXT:    [[TMP64:%.*]] = zext i32 [[CONV87]] to i64, !dbg [[DBG95]]
// LIN64-NEXT:    [[BF_LOAD91:%.*]] = load i64, ptr [[ATOMIC_TEMP90]], align 8, !dbg [[DBG95]]
// LIN64-NEXT:    [[BF_VALUE92:%.*]] = and i64 [[TMP64]], 1, !dbg [[DBG95]]
// LIN64-NEXT:    [[BF_SHL93:%.*]] = shl i64 [[BF_VALUE92]], 16, !dbg [[DBG95]]
// LIN64-NEXT:    [[BF_CLEAR94:%.*]] = and i64 [[BF_LOAD91]], -65537, !dbg [[DBG95]]
// LIN64-NEXT:    [[BF_SET95:%.*]] = or i64 [[BF_CLEAR94]], [[BF_SHL93]], !dbg [[DBG95]]
// LIN64-NEXT:    store i64 [[BF_SET95]], ptr [[ATOMIC_TEMP90]], align 8, !dbg [[DBG95]]
// LIN64-NEXT:    [[TMP65:%.*]] = load i64, ptr [[ATOMIC_TEMP90]], align 8, !dbg [[DBG95]]
// LIN64-NEXT:    [[TMP66:%.*]] = cmpxchg ptr @bfx4, i64 [[TMP63]], i64 [[TMP65]] monotonic monotonic, align 8, !dbg [[DBG95]]
// LIN64-NEXT:    [[TMP67]] = extractvalue { i64, i1 } [[TMP66]], 0, !dbg [[DBG95]]
// LIN64-NEXT:    [[TMP68:%.*]] = extractvalue { i64, i1 } [[TMP66]], 1, !dbg [[DBG95]]
// LIN64-NEXT:    br i1 [[TMP68]], label [[ATOMIC_EXIT96:%.*]], label [[ATOMIC_CONT89]], !dbg [[DBG95]]
// LIN64:       atomic_exit96:
// LIN64-NEXT:    [[TMP69:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG96:![0-9]+]]
// LIN64-NEXT:    [[CONV97:%.*]] = fptosi x86_fp80 [[TMP69]] to i32, !dbg [[DBG96]]
// LIN64-NEXT:    [[ATOMIC_LOAD98:%.*]] = load atomic i8, ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED:%.*]], ptr @bfx4_packed, i32 0, i32 1) monotonic, align 1, !dbg [[DBG97:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT99:%.*]], !dbg [[DBG97]]
// LIN64:       atomic_cont99:
// LIN64-NEXT:    [[TMP70:%.*]] = phi i8 [ [[ATOMIC_LOAD98]], [[ATOMIC_EXIT96]] ], [ [[TMP74:%.*]], [[ATOMIC_CONT99]] ], !dbg [[DBG97]]
// LIN64-NEXT:    store i8 [[TMP70]], ptr [[ATOMIC_TEMP100]], align 1, !dbg [[DBG97]]
// LIN64-NEXT:    [[TMP71:%.*]] = trunc i32 [[CONV97]] to i8, !dbg [[DBG97]]
// LIN64-NEXT:    [[BF_LOAD101:%.*]] = load i8, ptr [[ATOMIC_TEMP100]], align 1, !dbg [[DBG97]]
// LIN64-NEXT:    [[BF_VALUE102:%.*]] = and i8 [[TMP71]], 1, !dbg [[DBG97]]
// LIN64-NEXT:    [[BF_CLEAR103:%.*]] = and i8 [[BF_LOAD101]], -2, !dbg [[DBG97]]
// LIN64-NEXT:    [[BF_SET104:%.*]] = or i8 [[BF_CLEAR103]], [[BF_VALUE102]], !dbg [[DBG97]]
// LIN64-NEXT:    store i8 [[BF_SET104]], ptr [[ATOMIC_TEMP100]], align 1, !dbg [[DBG97]]
// LIN64-NEXT:    [[TMP72:%.*]] = load i8, ptr [[ATOMIC_TEMP100]], align 1, !dbg [[DBG97]]
// LIN64-NEXT:    [[TMP73:%.*]] = cmpxchg ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1), i8 [[TMP70]], i8 [[TMP72]] monotonic monotonic, align 1, !dbg [[DBG97]]
// LIN64-NEXT:    [[TMP74]] = extractvalue { i8, i1 } [[TMP73]], 0, !dbg [[DBG97]]
// LIN64-NEXT:    [[TMP75:%.*]] = extractvalue { i8, i1 } [[TMP73]], 1, !dbg [[DBG97]]
// LIN64-NEXT:    br i1 [[TMP75]], label [[ATOMIC_EXIT105:%.*]], label [[ATOMIC_CONT99]], !dbg [[DBG97]]
// LIN64:       atomic_exit105:
// LIN64-NEXT:    [[TMP76:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG98:![0-9]+]]
// LIN64-NEXT:    [[CONV106:%.*]] = fptosi x86_fp80 [[TMP76]] to i64, !dbg [[DBG98]]
// LIN64-NEXT:    [[ATOMIC_LOAD107:%.*]] = load atomic i64, ptr @bfx4 monotonic, align 8, !dbg [[DBG99:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT108:%.*]], !dbg [[DBG99]]
// LIN64:       atomic_cont108:
// LIN64-NEXT:    [[TMP77:%.*]] = phi i64 [ [[ATOMIC_LOAD107]], [[ATOMIC_EXIT105]] ], [ [[TMP80:%.*]], [[ATOMIC_CONT108]] ], !dbg [[DBG99]]
// LIN64-NEXT:    store i64 [[TMP77]], ptr [[ATOMIC_TEMP109]], align 8, !dbg [[DBG99]]
// LIN64-NEXT:    [[BF_LOAD110:%.*]] = load i64, ptr [[ATOMIC_TEMP109]], align 8, !dbg [[DBG99]]
// LIN64-NEXT:    [[BF_VALUE111:%.*]] = and i64 [[CONV106]], 127, !dbg [[DBG99]]
// LIN64-NEXT:    [[BF_SHL112:%.*]] = shl i64 [[BF_VALUE111]], 17, !dbg [[DBG99]]
// LIN64-NEXT:    [[BF_CLEAR113:%.*]] = and i64 [[BF_LOAD110]], -16646145, !dbg [[DBG99]]
// LIN64-NEXT:    [[BF_SET114:%.*]] = or i64 [[BF_CLEAR113]], [[BF_SHL112]], !dbg [[DBG99]]
// LIN64-NEXT:    store i64 [[BF_SET114]], ptr [[ATOMIC_TEMP109]], align 8, !dbg [[DBG99]]
// LIN64-NEXT:    [[TMP78:%.*]] = load i64, ptr [[ATOMIC_TEMP109]], align 8, !dbg [[DBG99]]
// LIN64-NEXT:    [[TMP79:%.*]] = cmpxchg ptr @bfx4, i64 [[TMP77]], i64 [[TMP78]] monotonic monotonic, align 8, !dbg [[DBG99]]
// LIN64-NEXT:    [[TMP80]] = extractvalue { i64, i1 } [[TMP79]], 0, !dbg [[DBG99]]
// LIN64-NEXT:    [[TMP81:%.*]] = extractvalue { i64, i1 } [[TMP79]], 1, !dbg [[DBG99]]
// LIN64-NEXT:    br i1 [[TMP81]], label [[ATOMIC_EXIT115:%.*]], label [[ATOMIC_CONT108]], !dbg [[DBG99]]
// LIN64:       atomic_exit115:
// LIN64-NEXT:    [[TMP82:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG100:![0-9]+]]
// LIN64-NEXT:    [[CONV116:%.*]] = fptosi x86_fp80 [[TMP82]] to i64, !dbg [[DBG100]]
// LIN64-NEXT:    [[ATOMIC_LOAD117:%.*]] = load atomic i8, ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1) monotonic, align 1, !dbg [[DBG101:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT118:%.*]], !dbg [[DBG101]]
// LIN64:       atomic_cont118:
// LIN64-NEXT:    [[TMP83:%.*]] = phi i8 [ [[ATOMIC_LOAD117]], [[ATOMIC_EXIT115]] ], [ [[TMP87:%.*]], [[ATOMIC_CONT118]] ], !dbg [[DBG101]]
// LIN64-NEXT:    store i8 [[TMP83]], ptr [[ATOMIC_TEMP119]], align 1, !dbg [[DBG101]]
// LIN64-NEXT:    [[TMP84:%.*]] = trunc i64 [[CONV116]] to i8, !dbg [[DBG101]]
// LIN64-NEXT:    [[BF_LOAD120:%.*]] = load i8, ptr [[ATOMIC_TEMP119]], align 1, !dbg [[DBG101]]
// LIN64-NEXT:    [[BF_VALUE121:%.*]] = and i8 [[TMP84]], 127, !dbg [[DBG101]]
// LIN64-NEXT:    [[BF_SHL122:%.*]] = shl i8 [[BF_VALUE121]], 1, !dbg [[DBG101]]
// LIN64-NEXT:    [[BF_CLEAR123:%.*]] = and i8 [[BF_LOAD120]], 1, !dbg [[DBG101]]
// LIN64-NEXT:    [[BF_SET124:%.*]] = or i8 [[BF_CLEAR123]], [[BF_SHL122]], !dbg [[DBG101]]
// LIN64-NEXT:    store i8 [[BF_SET124]], ptr [[ATOMIC_TEMP119]], align 1, !dbg [[DBG101]]
// LIN64-NEXT:    [[TMP85:%.*]] = load i8, ptr [[ATOMIC_TEMP119]], align 1, !dbg [[DBG101]]
// LIN64-NEXT:    [[TMP86:%.*]] = cmpxchg ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1), i8 [[TMP83]], i8 [[TMP85]] monotonic monotonic, align 1, !dbg [[DBG101]]
// LIN64-NEXT:    [[TMP87]] = extractvalue { i8, i1 } [[TMP86]], 0, !dbg [[DBG101]]
// LIN64-NEXT:    [[TMP88:%.*]] = extractvalue { i8, i1 } [[TMP86]], 1, !dbg [[DBG101]]
// LIN64-NEXT:    br i1 [[TMP88]], label [[ATOMIC_EXIT125:%.*]], label [[ATOMIC_CONT118]], !dbg [[DBG101]]
// LIN64:       atomic_exit125:
// LIN64-NEXT:    [[TMP89:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG102:![0-9]+]]
// LIN64-NEXT:    [[CONV126:%.*]] = uitofp i64 [[TMP89]] to float, !dbg [[DBG102]]
// LIN64-NEXT:    [[ATOMIC_LOAD127:%.*]] = load atomic i64, ptr @float2x monotonic, align 8, !dbg [[DBG103:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT128:%.*]], !dbg [[DBG103]]
// LIN64:       atomic_cont128:
// LIN64-NEXT:    [[TMP90:%.*]] = phi i64 [ [[ATOMIC_LOAD127]], [[ATOMIC_EXIT125]] ], [ [[TMP95:%.*]], [[ATOMIC_CONT128]] ], !dbg [[DBG103]]
// LIN64-NEXT:    store i64 [[TMP90]], ptr [[ATOMIC_TEMP129]], align 8, !dbg [[DBG103]]
// LIN64-NEXT:    [[TMP91:%.*]] = load <2 x float>, ptr [[ATOMIC_TEMP129]], align 8, !dbg [[DBG103]]
// LIN64-NEXT:    [[TMP92:%.*]] = insertelement <2 x float> [[TMP91]], float [[CONV126]], i64 0, !dbg [[DBG103]]
// LIN64-NEXT:    store <2 x float> [[TMP92]], ptr [[ATOMIC_TEMP129]], align 8, !dbg [[DBG103]]
// LIN64-NEXT:    [[TMP93:%.*]] = load i64, ptr [[ATOMIC_TEMP129]], align 8, !dbg [[DBG103]]
// LIN64-NEXT:    [[TMP94:%.*]] = cmpxchg ptr @float2x, i64 [[TMP90]], i64 [[TMP93]] monotonic monotonic, align 8, !dbg [[DBG103]]
// LIN64-NEXT:    [[TMP95]] = extractvalue { i64, i1 } [[TMP94]], 0, !dbg [[DBG103]]
// LIN64-NEXT:    [[TMP96:%.*]] = extractvalue { i64, i1 } [[TMP94]], 1, !dbg [[DBG103]]
// LIN64-NEXT:    br i1 [[TMP96]], label [[ATOMIC_EXIT130:%.*]], label [[ATOMIC_CONT128]], !dbg [[DBG103]]
// LIN64:       atomic_exit130:
// LIN64-NEXT:    [[TMP97:%.*]] = call i32 @llvm.read_register.i32(metadata [[META2:![0-9]+]]), !dbg [[DBG104:![0-9]+]]
// LIN64-NEXT:    [[CONV131:%.*]] = sitofp i32 [[TMP97]] to double, !dbg [[DBG104]]
// LIN64-NEXT:    store atomic double [[CONV131]], ptr @dv seq_cst, align 8, !dbg [[DBG105:![0-9]+]]
// LIN64-NEXT:    fence release
// LIN64-NEXT:    ret i32 0, !dbg [[DBG106:![0-9]+]]
//
//
// PPC64-LABEL: define {{[^@]+}}@main
// PPC64-SAME: () #[[ATTR0:[0-9]+]] !dbg [[DBG6:![0-9]+]] {
// PPC64-NEXT:  entry:
// PPC64-NEXT:    [[RETVAL:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca ppc_fp128, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP1:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP2:%.*]] = alloca { float, float }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP3:%.*]] = alloca { double, double }, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP9:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP13:%.*]] = alloca ppc_fp128, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP15:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP31:%.*]] = alloca <4 x i32>, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP32:%.*]] = alloca <4 x i32>, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP35:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP38:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP40:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP51:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP60:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP69:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP77:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP79:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP90:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP100:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP110:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP120:%.*]] = alloca i64, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP129:%.*]] = alloca <2 x float>, align 8
// PPC64-NEXT:    store i32 0, ptr [[RETVAL]], align 4
// PPC64-NEXT:    store atomic i32 1, ptr getelementptr inbounds nuw ({ i32, i32 }, ptr @civ, i32 0, i32 1) monotonic, align 4, !dbg [[DBG10:![0-9]+]]
// PPC64-NEXT:    [[TMP0:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG11:![0-9]+]]
// PPC64-NEXT:    [[LOADEDV:%.*]] = trunc i8 [[TMP0]] to i1, !dbg [[DBG11]]
// PPC64-NEXT:    [[STOREDV:%.*]] = zext i1 [[LOADEDV]] to i8, !dbg [[DBG12:![0-9]+]]
// PPC64-NEXT:    store atomic i8 [[STOREDV]], ptr @bx monotonic, align 1, !dbg [[DBG12]]
// PPC64-NEXT:    [[TMP1:%.*]] = load i8, ptr @cv, align 1, !dbg [[DBG13:![0-9]+]]
// PPC64-NEXT:    store atomic i8 [[TMP1]], ptr @cx release, align 1, !dbg [[DBG14:![0-9]+]]
// PPC64-NEXT:    fence release
// PPC64-NEXT:    [[TMP2:%.*]] = load i8, ptr @ucv, align 1, !dbg [[DBG15:![0-9]+]]
// PPC64-NEXT:    store atomic i8 [[TMP2]], ptr @ucx monotonic, align 1, !dbg [[DBG16:![0-9]+]]
// PPC64-NEXT:    [[TMP3:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG17:![0-9]+]]
// PPC64-NEXT:    store atomic i16 [[TMP3]], ptr @sx monotonic, align 2, !dbg [[DBG18:![0-9]+]]
// PPC64-NEXT:    [[TMP4:%.*]] = load i16, ptr @usv, align 2, !dbg [[DBG19:![0-9]+]]
// PPC64-NEXT:    store atomic i16 [[TMP4]], ptr @usx monotonic, align 2, !dbg [[DBG20:![0-9]+]]
// PPC64-NEXT:    [[TMP5:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG21:![0-9]+]]
// PPC64-NEXT:    store atomic i32 [[TMP5]], ptr @ix monotonic, align 4, !dbg [[DBG22:![0-9]+]]
// PPC64-NEXT:    [[TMP6:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG23:![0-9]+]]
// PPC64-NEXT:    store atomic i32 [[TMP6]], ptr @uix monotonic, align 4, !dbg [[DBG24:![0-9]+]]
// PPC64-NEXT:    [[TMP7:%.*]] = load i64, ptr @lv, align 8, !dbg [[DBG25:![0-9]+]]
// PPC64-NEXT:    store atomic i64 [[TMP7]], ptr @lx monotonic, align 8, !dbg [[DBG26:![0-9]+]]
// PPC64-NEXT:    [[TMP8:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG27:![0-9]+]]
// PPC64-NEXT:    store atomic i64 [[TMP8]], ptr @ulx monotonic, align 8, !dbg [[DBG28:![0-9]+]]
// PPC64-NEXT:    [[TMP9:%.*]] = load i64, ptr @llv, align 8, !dbg [[DBG29:![0-9]+]]
// PPC64-NEXT:    store atomic i64 [[TMP9]], ptr @llx monotonic, align 8, !dbg [[DBG30:![0-9]+]]
// PPC64-NEXT:    [[TMP10:%.*]] = load i64, ptr @ullv, align 8, !dbg [[DBG31:![0-9]+]]
// PPC64-NEXT:    store atomic i64 [[TMP10]], ptr @ullx monotonic, align 8, !dbg [[DBG32:![0-9]+]]
// PPC64-NEXT:    [[TMP11:%.*]] = load float, ptr @fv, align 4, !dbg [[DBG33:![0-9]+]]
// PPC64-NEXT:    store atomic float [[TMP11]], ptr @fx monotonic, align 4, !dbg [[DBG34:![0-9]+]]
// PPC64-NEXT:    [[TMP12:%.*]] = load double, ptr @dv, align 8, !dbg [[DBG35:![0-9]+]]
// PPC64-NEXT:    store atomic double [[TMP12]], ptr @dx monotonic, align 8, !dbg [[DBG36:![0-9]+]]
// PPC64-NEXT:    [[TMP13:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG37:![0-9]+]]
// PPC64-NEXT:    store ppc_fp128 [[TMP13]], ptr [[ATOMIC_TEMP]], align 16, !dbg [[DBG38:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_store(i64 noundef 16, ptr noundef @ldx, ptr noundef [[ATOMIC_TEMP]], i32 noundef signext 0), !dbg [[DBG38]]
// PPC64-NEXT:    [[CIV_REAL:%.*]] = load i32, ptr @civ, align 4, !dbg [[DBG39:![0-9]+]]
// PPC64-NEXT:    [[CIV_IMAG:%.*]] = load i32, ptr getelementptr inbounds nuw ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG39]]
// PPC64-NEXT:    [[ATOMIC_TEMP1_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP1]], i32 0, i32 0, !dbg [[DBG40:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_TEMP1_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP1]], i32 0, i32 1, !dbg [[DBG40]]
// PPC64-NEXT:    store i32 [[CIV_REAL]], ptr [[ATOMIC_TEMP1_REALP]], align 4, !dbg [[DBG40]]
// PPC64-NEXT:    store i32 [[CIV_IMAG]], ptr [[ATOMIC_TEMP1_IMAGP]], align 4, !dbg [[DBG40]]
// PPC64-NEXT:    call void @__atomic_store(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP1]], i32 noundef signext 0), !dbg [[DBG40]]
// PPC64-NEXT:    [[CFV_REAL:%.*]] = load float, ptr @cfv, align 4, !dbg [[DBG41:![0-9]+]]
// PPC64-NEXT:    [[CFV_IMAG:%.*]] = load float, ptr getelementptr inbounds nuw ({ float, float }, ptr @cfv, i32 0, i32 1), align 4, !dbg [[DBG41]]
// PPC64-NEXT:    [[ATOMIC_TEMP2_REALP:%.*]] = getelementptr inbounds nuw { float, float }, ptr [[ATOMIC_TEMP2]], i32 0, i32 0, !dbg [[DBG42:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_TEMP2_IMAGP:%.*]] = getelementptr inbounds nuw { float, float }, ptr [[ATOMIC_TEMP2]], i32 0, i32 1, !dbg [[DBG42]]
// PPC64-NEXT:    store float [[CFV_REAL]], ptr [[ATOMIC_TEMP2_REALP]], align 4, !dbg [[DBG42]]
// PPC64-NEXT:    store float [[CFV_IMAG]], ptr [[ATOMIC_TEMP2_IMAGP]], align 4, !dbg [[DBG42]]
// PPC64-NEXT:    call void @__atomic_store(i64 noundef 8, ptr noundef @cfx, ptr noundef [[ATOMIC_TEMP2]], i32 noundef signext 0), !dbg [[DBG42]]
// PPC64-NEXT:    [[CDV_REAL:%.*]] = load double, ptr @cdv, align 8, !dbg [[DBG43:![0-9]+]]
// PPC64-NEXT:    [[CDV_IMAG:%.*]] = load double, ptr getelementptr inbounds nuw ({ double, double }, ptr @cdv, i32 0, i32 1), align 8, !dbg [[DBG43]]
// PPC64-NEXT:    [[ATOMIC_TEMP3_REALP:%.*]] = getelementptr inbounds nuw { double, double }, ptr [[ATOMIC_TEMP3]], i32 0, i32 0, !dbg [[DBG44:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_TEMP3_IMAGP:%.*]] = getelementptr inbounds nuw { double, double }, ptr [[ATOMIC_TEMP3]], i32 0, i32 1, !dbg [[DBG44]]
// PPC64-NEXT:    store double [[CDV_REAL]], ptr [[ATOMIC_TEMP3_REALP]], align 8, !dbg [[DBG44]]
// PPC64-NEXT:    store double [[CDV_IMAG]], ptr [[ATOMIC_TEMP3_IMAGP]], align 8, !dbg [[DBG44]]
// PPC64-NEXT:    call void @__atomic_store(i64 noundef 16, ptr noundef @cdx, ptr noundef [[ATOMIC_TEMP3]], i32 noundef signext 5), !dbg [[DBG44]]
// PPC64-NEXT:    fence release
// PPC64-NEXT:    [[TMP14:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG45:![0-9]+]]
// PPC64-NEXT:    [[LOADEDV4:%.*]] = trunc i8 [[TMP14]] to i1, !dbg [[DBG45]]
// PPC64-NEXT:    [[CONV:%.*]] = zext i1 [[LOADEDV4]] to i64, !dbg [[DBG45]]
// PPC64-NEXT:    store atomic i64 [[CONV]], ptr @ulx monotonic, align 8, !dbg [[DBG46:![0-9]+]]
// PPC64-NEXT:    [[TMP15:%.*]] = load i8, ptr @cv, align 1, !dbg [[DBG47:![0-9]+]]
// PPC64-NEXT:    [[TOBOOL:%.*]] = icmp ne i8 [[TMP15]], 0, !dbg [[DBG47]]
// PPC64-NEXT:    [[STOREDV5:%.*]] = zext i1 [[TOBOOL]] to i8, !dbg [[DBG48:![0-9]+]]
// PPC64-NEXT:    store atomic i8 [[STOREDV5]], ptr @bx monotonic, align 1, !dbg [[DBG48]]
// PPC64-NEXT:    [[TMP16:%.*]] = load i8, ptr @ucv, align 1, !dbg [[DBG49:![0-9]+]]
// PPC64-NEXT:    store atomic i8 [[TMP16]], ptr @cx seq_cst, align 1, !dbg [[DBG50:![0-9]+]]
// PPC64-NEXT:    fence release
// PPC64-NEXT:    [[TMP17:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG51:![0-9]+]]
// PPC64-NEXT:    [[CONV6:%.*]] = sext i16 [[TMP17]] to i64, !dbg [[DBG51]]
// PPC64-NEXT:    store atomic i64 [[CONV6]], ptr @ulx monotonic, align 8, !dbg [[DBG52:![0-9]+]]
// PPC64-NEXT:    [[TMP18:%.*]] = load i16, ptr @usv, align 2, !dbg [[DBG53:![0-9]+]]
// PPC64-NEXT:    [[CONV7:%.*]] = zext i16 [[TMP18]] to i64, !dbg [[DBG53]]
// PPC64-NEXT:    store atomic i64 [[CONV7]], ptr @lx monotonic, align 8, !dbg [[DBG54:![0-9]+]]
// PPC64-NEXT:    [[TMP19:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG55:![0-9]+]]
// PPC64-NEXT:    store atomic i32 [[TMP19]], ptr @uix seq_cst, align 4, !dbg [[DBG56:![0-9]+]]
// PPC64-NEXT:    fence release
// PPC64-NEXT:    [[TMP20:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG57:![0-9]+]]
// PPC64-NEXT:    store atomic i32 [[TMP20]], ptr @ix monotonic, align 4, !dbg [[DBG58:![0-9]+]]
// PPC64-NEXT:    [[TMP21:%.*]] = load i64, ptr @lv, align 8, !dbg [[DBG59:![0-9]+]]
// PPC64-NEXT:    [[CONV8:%.*]] = trunc i64 [[TMP21]] to i32, !dbg [[DBG59]]
// PPC64-NEXT:    [[ATOMIC_TEMP9_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP9]], i32 0, i32 0, !dbg [[DBG60:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_TEMP9_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP9]], i32 0, i32 1, !dbg [[DBG60]]
// PPC64-NEXT:    store i32 [[CONV8]], ptr [[ATOMIC_TEMP9_REALP]], align 4, !dbg [[DBG60]]
// PPC64-NEXT:    store i32 0, ptr [[ATOMIC_TEMP9_IMAGP]], align 4, !dbg [[DBG60]]
// PPC64-NEXT:    call void @__atomic_store(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP9]], i32 noundef signext 0), !dbg [[DBG60]]
// PPC64-NEXT:    [[TMP22:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG61:![0-9]+]]
// PPC64-NEXT:    [[CONV10:%.*]] = uitofp i64 [[TMP22]] to float, !dbg [[DBG61]]
// PPC64-NEXT:    store atomic float [[CONV10]], ptr @fx monotonic, align 4, !dbg [[DBG62:![0-9]+]]
// PPC64-NEXT:    [[TMP23:%.*]] = load i64, ptr @llv, align 8, !dbg [[DBG63:![0-9]+]]
// PPC64-NEXT:    [[CONV11:%.*]] = sitofp i64 [[TMP23]] to double, !dbg [[DBG63]]
// PPC64-NEXT:    store atomic double [[CONV11]], ptr @dx monotonic, align 8, !dbg [[DBG64:![0-9]+]]
// PPC64-NEXT:    [[TMP24:%.*]] = load i64, ptr @ullv, align 8, !dbg [[DBG65:![0-9]+]]
// PPC64-NEXT:    [[CONV12:%.*]] = uitofp i64 [[TMP24]] to ppc_fp128, !dbg [[DBG65]]
// PPC64-NEXT:    store ppc_fp128 [[CONV12]], ptr [[ATOMIC_TEMP13]], align 16, !dbg [[DBG66:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_store(i64 noundef 16, ptr noundef @ldx, ptr noundef [[ATOMIC_TEMP13]], i32 noundef signext 0), !dbg [[DBG66]]
// PPC64-NEXT:    [[TMP25:%.*]] = load float, ptr @fv, align 4, !dbg [[DBG67:![0-9]+]]
// PPC64-NEXT:    [[CONV14:%.*]] = fptosi float [[TMP25]] to i32, !dbg [[DBG67]]
// PPC64-NEXT:    [[ATOMIC_TEMP15_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP15]], i32 0, i32 0, !dbg [[DBG68:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_TEMP15_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP15]], i32 0, i32 1, !dbg [[DBG68]]
// PPC64-NEXT:    store i32 [[CONV14]], ptr [[ATOMIC_TEMP15_REALP]], align 4, !dbg [[DBG68]]
// PPC64-NEXT:    store i32 0, ptr [[ATOMIC_TEMP15_IMAGP]], align 4, !dbg [[DBG68]]
// PPC64-NEXT:    call void @__atomic_store(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP15]], i32 noundef signext 0), !dbg [[DBG68]]
// PPC64-NEXT:    [[TMP26:%.*]] = load double, ptr @dv, align 8, !dbg [[DBG69:![0-9]+]]
// PPC64-NEXT:    [[CONV16:%.*]] = fptosi double [[TMP26]] to i16, !dbg [[DBG69]]
// PPC64-NEXT:    store atomic i16 [[CONV16]], ptr @sx monotonic, align 2, !dbg [[DBG70:![0-9]+]]
// PPC64-NEXT:    [[TMP27:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG71:![0-9]+]]
// PPC64-NEXT:    [[TOBOOL17:%.*]] = fcmp une ppc_fp128 [[TMP27]], 0xM00000000000000000000000000000000, !dbg [[DBG71]]
// PPC64-NEXT:    [[STOREDV18:%.*]] = zext i1 [[TOBOOL17]] to i8, !dbg [[DBG72:![0-9]+]]
// PPC64-NEXT:    store atomic i8 [[STOREDV18]], ptr @bx monotonic, align 1, !dbg [[DBG72]]
// PPC64-NEXT:    [[CIV_REAL19:%.*]] = load i32, ptr @civ, align 4, !dbg [[DBG73:![0-9]+]]
// PPC64-NEXT:    [[CIV_IMAG20:%.*]] = load i32, ptr getelementptr inbounds nuw ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG73]]
// PPC64-NEXT:    [[TOBOOL21:%.*]] = icmp ne i32 [[CIV_REAL19]], 0, !dbg [[DBG73]]
// PPC64-NEXT:    [[TOBOOL22:%.*]] = icmp ne i32 [[CIV_IMAG20]], 0, !dbg [[DBG73]]
// PPC64-NEXT:    [[TOBOOL23:%.*]] = or i1 [[TOBOOL21]], [[TOBOOL22]], !dbg [[DBG73]]
// PPC64-NEXT:    [[STOREDV24:%.*]] = zext i1 [[TOBOOL23]] to i8, !dbg [[DBG74:![0-9]+]]
// PPC64-NEXT:    store atomic i8 [[STOREDV24]], ptr @bx monotonic, align 1, !dbg [[DBG74]]
// PPC64-NEXT:    [[CFV_REAL25:%.*]] = load float, ptr @cfv, align 4, !dbg [[DBG75:![0-9]+]]
// PPC64-NEXT:    [[CONV26:%.*]] = fptoui float [[CFV_REAL25]] to i16, !dbg [[DBG75]]
// PPC64-NEXT:    store atomic i16 [[CONV26]], ptr @usx monotonic, align 2, !dbg [[DBG76:![0-9]+]]
// PPC64-NEXT:    [[CDV_REAL27:%.*]] = load double, ptr @cdv, align 8, !dbg [[DBG77:![0-9]+]]
// PPC64-NEXT:    [[CONV28:%.*]] = fptosi double [[CDV_REAL27]] to i64, !dbg [[DBG77]]
// PPC64-NEXT:    store atomic i64 [[CONV28]], ptr @llx monotonic, align 8, !dbg [[DBG78:![0-9]+]]
// PPC64-NEXT:    [[TMP28:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG79:![0-9]+]]
// PPC64-NEXT:    [[TMP29:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG80:![0-9]+]]
// PPC64-NEXT:    [[LOADEDV29:%.*]] = trunc i8 [[TMP29]] to i1, !dbg [[DBG80]]
// PPC64-NEXT:    [[CONV30:%.*]] = zext i1 [[LOADEDV29]] to i32, !dbg [[DBG80]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 16, ptr noundef @int4x, ptr noundef [[ATOMIC_TEMP31]], i32 noundef signext 0), !dbg [[DBG81:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT:%.*]], !dbg [[DBG81]]
// PPC64:       atomic_cont:
// PPC64-NEXT:    [[TMP30:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP31]], align 16, !dbg [[DBG81]]
// PPC64-NEXT:    store <4 x i32> [[TMP30]], ptr [[ATOMIC_TEMP32]], align 16, !dbg [[DBG81]]
// PPC64-NEXT:    [[TMP31:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP32]], align 16, !dbg [[DBG81]]
// PPC64-NEXT:    [[VECINS:%.*]] = insertelement <4 x i32> [[TMP31]], i32 [[CONV30]], i16 [[TMP28]], !dbg [[DBG81]]
// PPC64-NEXT:    store <4 x i32> [[VECINS]], ptr [[ATOMIC_TEMP32]], align 16, !dbg [[DBG81]]
// PPC64-NEXT:    [[CALL:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, ptr noundef @int4x, ptr noundef [[ATOMIC_TEMP31]], ptr noundef [[ATOMIC_TEMP32]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG81]]
// PPC64-NEXT:    br i1 [[CALL]], label [[ATOMIC_EXIT:%.*]], label [[ATOMIC_CONT]], !dbg [[DBG81]]
// PPC64:       atomic_exit:
// PPC64-NEXT:    [[TMP32:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG82:![0-9]+]]
// PPC64-NEXT:    [[CONV33:%.*]] = fptosi ppc_fp128 [[TMP32]] to i32, !dbg [[DBG82]]
// PPC64-NEXT:    [[ATOMIC_LOAD:%.*]] = load atomic i32, ptr @bfx monotonic, align 4, !dbg [[DBG83:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT34:%.*]], !dbg [[DBG83]]
// PPC64:       atomic_cont34:
// PPC64-NEXT:    [[TMP33:%.*]] = phi i32 [ [[ATOMIC_LOAD]], [[ATOMIC_EXIT]] ], [ [[TMP36:%.*]], [[ATOMIC_CONT34]] ], !dbg [[DBG83]]
// PPC64-NEXT:    store i32 [[TMP33]], ptr [[ATOMIC_TEMP35]], align 4, !dbg [[DBG83]]
// PPC64-NEXT:    [[BF_LOAD:%.*]] = load i32, ptr [[ATOMIC_TEMP35]], align 4, !dbg [[DBG83]]
// PPC64-NEXT:    [[BF_VALUE:%.*]] = and i32 [[CONV33]], 2147483647, !dbg [[DBG83]]
// PPC64-NEXT:    [[BF_SHL:%.*]] = shl i32 [[BF_VALUE]], 1, !dbg [[DBG83]]
// PPC64-NEXT:    [[BF_CLEAR:%.*]] = and i32 [[BF_LOAD]], 1, !dbg [[DBG83]]
// PPC64-NEXT:    [[BF_SET:%.*]] = or i32 [[BF_CLEAR]], [[BF_SHL]], !dbg [[DBG83]]
// PPC64-NEXT:    store i32 [[BF_SET]], ptr [[ATOMIC_TEMP35]], align 4, !dbg [[DBG83]]
// PPC64-NEXT:    [[TMP34:%.*]] = load i32, ptr [[ATOMIC_TEMP35]], align 4, !dbg [[DBG83]]
// PPC64-NEXT:    [[TMP35:%.*]] = cmpxchg ptr @bfx, i32 [[TMP33]], i32 [[TMP34]] monotonic monotonic, align 4, !dbg [[DBG83]]
// PPC64-NEXT:    [[TMP36]] = extractvalue { i32, i1 } [[TMP35]], 0, !dbg [[DBG83]]
// PPC64-NEXT:    [[TMP37:%.*]] = extractvalue { i32, i1 } [[TMP35]], 1, !dbg [[DBG83]]
// PPC64-NEXT:    br i1 [[TMP37]], label [[ATOMIC_EXIT36:%.*]], label [[ATOMIC_CONT34]], !dbg [[DBG83]]
// PPC64:       atomic_exit36:
// PPC64-NEXT:    [[TMP38:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG84:![0-9]+]]
// PPC64-NEXT:    [[CONV37:%.*]] = fptosi ppc_fp128 [[TMP38]] to i32, !dbg [[DBG84]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 4, ptr noundef @bfx_packed, ptr noundef [[ATOMIC_TEMP38]], i32 noundef signext 0), !dbg [[DBG85:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT39:%.*]], !dbg [[DBG85]]
// PPC64:       atomic_cont39:
// PPC64-NEXT:    [[TMP39:%.*]] = load i32, ptr [[ATOMIC_TEMP38]], align 1, !dbg [[DBG85]]
// PPC64-NEXT:    store i32 [[TMP39]], ptr [[ATOMIC_TEMP40]], align 1, !dbg [[DBG85]]
// PPC64-NEXT:    [[BF_LOAD41:%.*]] = load i32, ptr [[ATOMIC_TEMP40]], align 1, !dbg [[DBG85]]
// PPC64-NEXT:    [[BF_VALUE42:%.*]] = and i32 [[CONV37]], 2147483647, !dbg [[DBG85]]
// PPC64-NEXT:    [[BF_SHL43:%.*]] = shl i32 [[BF_VALUE42]], 1, !dbg [[DBG85]]
// PPC64-NEXT:    [[BF_CLEAR44:%.*]] = and i32 [[BF_LOAD41]], 1, !dbg [[DBG85]]
// PPC64-NEXT:    [[BF_SET45:%.*]] = or i32 [[BF_CLEAR44]], [[BF_SHL43]], !dbg [[DBG85]]
// PPC64-NEXT:    store i32 [[BF_SET45]], ptr [[ATOMIC_TEMP40]], align 1, !dbg [[DBG85]]
// PPC64-NEXT:    [[CALL46:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 4, ptr noundef @bfx_packed, ptr noundef [[ATOMIC_TEMP38]], ptr noundef [[ATOMIC_TEMP40]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG85]]
// PPC64-NEXT:    br i1 [[CALL46]], label [[ATOMIC_EXIT47:%.*]], label [[ATOMIC_CONT39]], !dbg [[DBG85]]
// PPC64:       atomic_exit47:
// PPC64-NEXT:    [[TMP40:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG86:![0-9]+]]
// PPC64-NEXT:    [[CONV48:%.*]] = fptosi ppc_fp128 [[TMP40]] to i32, !dbg [[DBG86]]
// PPC64-NEXT:    [[ATOMIC_LOAD49:%.*]] = load atomic i32, ptr @bfx2 monotonic, align 4, !dbg [[DBG87:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT50:%.*]], !dbg [[DBG87]]
// PPC64:       atomic_cont50:
// PPC64-NEXT:    [[TMP41:%.*]] = phi i32 [ [[ATOMIC_LOAD49]], [[ATOMIC_EXIT47]] ], [ [[TMP44:%.*]], [[ATOMIC_CONT50]] ], !dbg [[DBG87]]
// PPC64-NEXT:    store i32 [[TMP41]], ptr [[ATOMIC_TEMP51]], align 4, !dbg [[DBG87]]
// PPC64-NEXT:    [[BF_LOAD52:%.*]] = load i32, ptr [[ATOMIC_TEMP51]], align 4, !dbg [[DBG87]]
// PPC64-NEXT:    [[BF_VALUE53:%.*]] = and i32 [[CONV48]], 1, !dbg [[DBG87]]
// PPC64-NEXT:    [[BF_CLEAR54:%.*]] = and i32 [[BF_LOAD52]], -2, !dbg [[DBG87]]
// PPC64-NEXT:    [[BF_SET55:%.*]] = or i32 [[BF_CLEAR54]], [[BF_VALUE53]], !dbg [[DBG87]]
// PPC64-NEXT:    store i32 [[BF_SET55]], ptr [[ATOMIC_TEMP51]], align 4, !dbg [[DBG87]]
// PPC64-NEXT:    [[TMP42:%.*]] = load i32, ptr [[ATOMIC_TEMP51]], align 4, !dbg [[DBG87]]
// PPC64-NEXT:    [[TMP43:%.*]] = cmpxchg ptr @bfx2, i32 [[TMP41]], i32 [[TMP42]] monotonic monotonic, align 4, !dbg [[DBG87]]
// PPC64-NEXT:    [[TMP44]] = extractvalue { i32, i1 } [[TMP43]], 0, !dbg [[DBG87]]
// PPC64-NEXT:    [[TMP45:%.*]] = extractvalue { i32, i1 } [[TMP43]], 1, !dbg [[DBG87]]
// PPC64-NEXT:    br i1 [[TMP45]], label [[ATOMIC_EXIT56:%.*]], label [[ATOMIC_CONT50]], !dbg [[DBG87]]
// PPC64:       atomic_exit56:
// PPC64-NEXT:    [[TMP46:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG88:![0-9]+]]
// PPC64-NEXT:    [[CONV57:%.*]] = fptosi ppc_fp128 [[TMP46]] to i32, !dbg [[DBG88]]
// PPC64-NEXT:    [[ATOMIC_LOAD58:%.*]] = load atomic i8, ptr @bfx2_packed monotonic, align 1, !dbg [[DBG89:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT59:%.*]], !dbg [[DBG89]]
// PPC64:       atomic_cont59:
// PPC64-NEXT:    [[TMP47:%.*]] = phi i8 [ [[ATOMIC_LOAD58]], [[ATOMIC_EXIT56]] ], [ [[TMP51:%.*]], [[ATOMIC_CONT59]] ], !dbg [[DBG89]]
// PPC64-NEXT:    store i8 [[TMP47]], ptr [[ATOMIC_TEMP60]], align 1, !dbg [[DBG89]]
// PPC64-NEXT:    [[TMP48:%.*]] = trunc i32 [[CONV57]] to i8, !dbg [[DBG89]]
// PPC64-NEXT:    [[BF_LOAD61:%.*]] = load i8, ptr [[ATOMIC_TEMP60]], align 1, !dbg [[DBG89]]
// PPC64-NEXT:    [[BF_VALUE62:%.*]] = and i8 [[TMP48]], 1, !dbg [[DBG89]]
// PPC64-NEXT:    [[BF_CLEAR63:%.*]] = and i8 [[BF_LOAD61]], -2, !dbg [[DBG89]]
// PPC64-NEXT:    [[BF_SET64:%.*]] = or i8 [[BF_CLEAR63]], [[BF_VALUE62]], !dbg [[DBG89]]
// PPC64-NEXT:    store i8 [[BF_SET64]], ptr [[ATOMIC_TEMP60]], align 1, !dbg [[DBG89]]
// PPC64-NEXT:    [[TMP49:%.*]] = load i8, ptr [[ATOMIC_TEMP60]], align 1, !dbg [[DBG89]]
// PPC64-NEXT:    [[TMP50:%.*]] = cmpxchg ptr @bfx2_packed, i8 [[TMP47]], i8 [[TMP49]] monotonic monotonic, align 1, !dbg [[DBG89]]
// PPC64-NEXT:    [[TMP51]] = extractvalue { i8, i1 } [[TMP50]], 0, !dbg [[DBG89]]
// PPC64-NEXT:    [[TMP52:%.*]] = extractvalue { i8, i1 } [[TMP50]], 1, !dbg [[DBG89]]
// PPC64-NEXT:    br i1 [[TMP52]], label [[ATOMIC_EXIT65:%.*]], label [[ATOMIC_CONT59]], !dbg [[DBG89]]
// PPC64:       atomic_exit65:
// PPC64-NEXT:    [[TMP53:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG90:![0-9]+]]
// PPC64-NEXT:    [[CONV66:%.*]] = fptosi ppc_fp128 [[TMP53]] to i32, !dbg [[DBG90]]
// PPC64-NEXT:    [[ATOMIC_LOAD67:%.*]] = load atomic i32, ptr @bfx3 monotonic, align 4, !dbg [[DBG91:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT68:%.*]], !dbg [[DBG91]]
// PPC64:       atomic_cont68:
// PPC64-NEXT:    [[TMP54:%.*]] = phi i32 [ [[ATOMIC_LOAD67]], [[ATOMIC_EXIT65]] ], [ [[TMP57:%.*]], [[ATOMIC_CONT68]] ], !dbg [[DBG91]]
// PPC64-NEXT:    store i32 [[TMP54]], ptr [[ATOMIC_TEMP69]], align 4, !dbg [[DBG91]]
// PPC64-NEXT:    [[BF_LOAD70:%.*]] = load i32, ptr [[ATOMIC_TEMP69]], align 4, !dbg [[DBG91]]
// PPC64-NEXT:    [[BF_VALUE71:%.*]] = and i32 [[CONV66]], 16383, !dbg [[DBG91]]
// PPC64-NEXT:    [[BF_SHL72:%.*]] = shl i32 [[BF_VALUE71]], 7, !dbg [[DBG91]]
// PPC64-NEXT:    [[BF_CLEAR73:%.*]] = and i32 [[BF_LOAD70]], -2097025, !dbg [[DBG91]]
// PPC64-NEXT:    [[BF_SET74:%.*]] = or i32 [[BF_CLEAR73]], [[BF_SHL72]], !dbg [[DBG91]]
// PPC64-NEXT:    store i32 [[BF_SET74]], ptr [[ATOMIC_TEMP69]], align 4, !dbg [[DBG91]]
// PPC64-NEXT:    [[TMP55:%.*]] = load i32, ptr [[ATOMIC_TEMP69]], align 4, !dbg [[DBG91]]
// PPC64-NEXT:    [[TMP56:%.*]] = cmpxchg ptr @bfx3, i32 [[TMP54]], i32 [[TMP55]] monotonic monotonic, align 4, !dbg [[DBG91]]
// PPC64-NEXT:    [[TMP57]] = extractvalue { i32, i1 } [[TMP56]], 0, !dbg [[DBG91]]
// PPC64-NEXT:    [[TMP58:%.*]] = extractvalue { i32, i1 } [[TMP56]], 1, !dbg [[DBG91]]
// PPC64-NEXT:    br i1 [[TMP58]], label [[ATOMIC_EXIT75:%.*]], label [[ATOMIC_CONT68]], !dbg [[DBG91]]
// PPC64:       atomic_exit75:
// PPC64-NEXT:    [[TMP59:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG92:![0-9]+]]
// PPC64-NEXT:    [[CONV76:%.*]] = fptosi ppc_fp128 [[TMP59]] to i32, !dbg [[DBG92]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 3, ptr noundef @bfx3_packed, ptr noundef [[ATOMIC_TEMP77]], i32 noundef signext 0), !dbg [[DBG93:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT78:%.*]], !dbg [[DBG93]]
// PPC64:       atomic_cont78:
// PPC64-NEXT:    [[TMP60:%.*]] = load i24, ptr [[ATOMIC_TEMP77]], align 1, !dbg [[DBG93]]
// PPC64-NEXT:    store i24 [[TMP60]], ptr [[ATOMIC_TEMP79]], align 1, !dbg [[DBG93]]
// PPC64-NEXT:    [[TMP61:%.*]] = trunc i32 [[CONV76]] to i24, !dbg [[DBG93]]
// PPC64-NEXT:    [[BF_LOAD80:%.*]] = load i24, ptr [[ATOMIC_TEMP79]], align 1, !dbg [[DBG93]]
// PPC64-NEXT:    [[BF_VALUE81:%.*]] = and i24 [[TMP61]], 16383, !dbg [[DBG93]]
// PPC64-NEXT:    [[BF_SHL82:%.*]] = shl i24 [[BF_VALUE81]], 7, !dbg [[DBG93]]
// PPC64-NEXT:    [[BF_CLEAR83:%.*]] = and i24 [[BF_LOAD80]], -2097025, !dbg [[DBG93]]
// PPC64-NEXT:    [[BF_SET84:%.*]] = or i24 [[BF_CLEAR83]], [[BF_SHL82]], !dbg [[DBG93]]
// PPC64-NEXT:    store i24 [[BF_SET84]], ptr [[ATOMIC_TEMP79]], align 1, !dbg [[DBG93]]
// PPC64-NEXT:    [[CALL85:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 3, ptr noundef @bfx3_packed, ptr noundef [[ATOMIC_TEMP77]], ptr noundef [[ATOMIC_TEMP79]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG93]]
// PPC64-NEXT:    br i1 [[CALL85]], label [[ATOMIC_EXIT86:%.*]], label [[ATOMIC_CONT78]], !dbg [[DBG93]]
// PPC64:       atomic_exit86:
// PPC64-NEXT:    [[TMP62:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG94:![0-9]+]]
// PPC64-NEXT:    [[CONV87:%.*]] = fptosi ppc_fp128 [[TMP62]] to i32, !dbg [[DBG94]]
// PPC64-NEXT:    [[ATOMIC_LOAD88:%.*]] = load atomic i64, ptr @bfx4 monotonic, align 8, !dbg [[DBG95:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT89:%.*]], !dbg [[DBG95]]
// PPC64:       atomic_cont89:
// PPC64-NEXT:    [[TMP63:%.*]] = phi i64 [ [[ATOMIC_LOAD88]], [[ATOMIC_EXIT86]] ], [ [[TMP67:%.*]], [[ATOMIC_CONT89]] ], !dbg [[DBG95]]
// PPC64-NEXT:    store i64 [[TMP63]], ptr [[ATOMIC_TEMP90]], align 8, !dbg [[DBG95]]
// PPC64-NEXT:    [[TMP64:%.*]] = zext i32 [[CONV87]] to i64, !dbg [[DBG95]]
// PPC64-NEXT:    [[BF_LOAD91:%.*]] = load i64, ptr [[ATOMIC_TEMP90]], align 8, !dbg [[DBG95]]
// PPC64-NEXT:    [[BF_VALUE92:%.*]] = and i64 [[TMP64]], 1, !dbg [[DBG95]]
// PPC64-NEXT:    [[BF_SHL93:%.*]] = shl i64 [[BF_VALUE92]], 15, !dbg [[DBG95]]
// PPC64-NEXT:    [[BF_CLEAR94:%.*]] = and i64 [[BF_LOAD91]], -32769, !dbg [[DBG95]]
// PPC64-NEXT:    [[BF_SET95:%.*]] = or i64 [[BF_CLEAR94]], [[BF_SHL93]], !dbg [[DBG95]]
// PPC64-NEXT:    store i64 [[BF_SET95]], ptr [[ATOMIC_TEMP90]], align 8, !dbg [[DBG95]]
// PPC64-NEXT:    [[TMP65:%.*]] = load i64, ptr [[ATOMIC_TEMP90]], align 8, !dbg [[DBG95]]
// PPC64-NEXT:    [[TMP66:%.*]] = cmpxchg ptr @bfx4, i64 [[TMP63]], i64 [[TMP65]] monotonic monotonic, align 8, !dbg [[DBG95]]
// PPC64-NEXT:    [[TMP67]] = extractvalue { i64, i1 } [[TMP66]], 0, !dbg [[DBG95]]
// PPC64-NEXT:    [[TMP68:%.*]] = extractvalue { i64, i1 } [[TMP66]], 1, !dbg [[DBG95]]
// PPC64-NEXT:    br i1 [[TMP68]], label [[ATOMIC_EXIT96:%.*]], label [[ATOMIC_CONT89]], !dbg [[DBG95]]
// PPC64:       atomic_exit96:
// PPC64-NEXT:    [[TMP69:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG96:![0-9]+]]
// PPC64-NEXT:    [[CONV97:%.*]] = fptosi ppc_fp128 [[TMP69]] to i32, !dbg [[DBG96]]
// PPC64-NEXT:    [[ATOMIC_LOAD98:%.*]] = load atomic i8, ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED:%.*]], ptr @bfx4_packed, i32 0, i32 1) monotonic, align 1, !dbg [[DBG97:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT99:%.*]], !dbg [[DBG97]]
// PPC64:       atomic_cont99:
// PPC64-NEXT:    [[TMP70:%.*]] = phi i8 [ [[ATOMIC_LOAD98]], [[ATOMIC_EXIT96]] ], [ [[TMP74:%.*]], [[ATOMIC_CONT99]] ], !dbg [[DBG97]]
// PPC64-NEXT:    store i8 [[TMP70]], ptr [[ATOMIC_TEMP100]], align 1, !dbg [[DBG97]]
// PPC64-NEXT:    [[TMP71:%.*]] = trunc i32 [[CONV97]] to i8, !dbg [[DBG97]]
// PPC64-NEXT:    [[BF_LOAD101:%.*]] = load i8, ptr [[ATOMIC_TEMP100]], align 1, !dbg [[DBG97]]
// PPC64-NEXT:    [[BF_VALUE102:%.*]] = and i8 [[TMP71]], 1, !dbg [[DBG97]]
// PPC64-NEXT:    [[BF_SHL103:%.*]] = shl i8 [[BF_VALUE102]], 7, !dbg [[DBG97]]
// PPC64-NEXT:    [[BF_CLEAR104:%.*]] = and i8 [[BF_LOAD101]], 127, !dbg [[DBG97]]
// PPC64-NEXT:    [[BF_SET105:%.*]] = or i8 [[BF_CLEAR104]], [[BF_SHL103]], !dbg [[DBG97]]
// PPC64-NEXT:    store i8 [[BF_SET105]], ptr [[ATOMIC_TEMP100]], align 1, !dbg [[DBG97]]
// PPC64-NEXT:    [[TMP72:%.*]] = load i8, ptr [[ATOMIC_TEMP100]], align 1, !dbg [[DBG97]]
// PPC64-NEXT:    [[TMP73:%.*]] = cmpxchg ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1), i8 [[TMP70]], i8 [[TMP72]] monotonic monotonic, align 1, !dbg [[DBG97]]
// PPC64-NEXT:    [[TMP74]] = extractvalue { i8, i1 } [[TMP73]], 0, !dbg [[DBG97]]
// PPC64-NEXT:    [[TMP75:%.*]] = extractvalue { i8, i1 } [[TMP73]], 1, !dbg [[DBG97]]
// PPC64-NEXT:    br i1 [[TMP75]], label [[ATOMIC_EXIT106:%.*]], label [[ATOMIC_CONT99]], !dbg [[DBG97]]
// PPC64:       atomic_exit106:
// PPC64-NEXT:    [[TMP76:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG98:![0-9]+]]
// PPC64-NEXT:    [[CONV107:%.*]] = fptosi ppc_fp128 [[TMP76]] to i64, !dbg [[DBG98]]
// PPC64-NEXT:    [[ATOMIC_LOAD108:%.*]] = load atomic i64, ptr @bfx4 monotonic, align 8, !dbg [[DBG99:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT109:%.*]], !dbg [[DBG99]]
// PPC64:       atomic_cont109:
// PPC64-NEXT:    [[TMP77:%.*]] = phi i64 [ [[ATOMIC_LOAD108]], [[ATOMIC_EXIT106]] ], [ [[TMP80:%.*]], [[ATOMIC_CONT109]] ], !dbg [[DBG99]]
// PPC64-NEXT:    store i64 [[TMP77]], ptr [[ATOMIC_TEMP110]], align 8, !dbg [[DBG99]]
// PPC64-NEXT:    [[BF_LOAD111:%.*]] = load i64, ptr [[ATOMIC_TEMP110]], align 8, !dbg [[DBG99]]
// PPC64-NEXT:    [[BF_VALUE112:%.*]] = and i64 [[CONV107]], 127, !dbg [[DBG99]]
// PPC64-NEXT:    [[BF_SHL113:%.*]] = shl i64 [[BF_VALUE112]], 8, !dbg [[DBG99]]
// PPC64-NEXT:    [[BF_CLEAR114:%.*]] = and i64 [[BF_LOAD111]], -32513, !dbg [[DBG99]]
// PPC64-NEXT:    [[BF_SET115:%.*]] = or i64 [[BF_CLEAR114]], [[BF_SHL113]], !dbg [[DBG99]]
// PPC64-NEXT:    store i64 [[BF_SET115]], ptr [[ATOMIC_TEMP110]], align 8, !dbg [[DBG99]]
// PPC64-NEXT:    [[TMP78:%.*]] = load i64, ptr [[ATOMIC_TEMP110]], align 8, !dbg [[DBG99]]
// PPC64-NEXT:    [[TMP79:%.*]] = cmpxchg ptr @bfx4, i64 [[TMP77]], i64 [[TMP78]] monotonic monotonic, align 8, !dbg [[DBG99]]
// PPC64-NEXT:    [[TMP80]] = extractvalue { i64, i1 } [[TMP79]], 0, !dbg [[DBG99]]
// PPC64-NEXT:    [[TMP81:%.*]] = extractvalue { i64, i1 } [[TMP79]], 1, !dbg [[DBG99]]
// PPC64-NEXT:    br i1 [[TMP81]], label [[ATOMIC_EXIT116:%.*]], label [[ATOMIC_CONT109]], !dbg [[DBG99]]
// PPC64:       atomic_exit116:
// PPC64-NEXT:    [[TMP82:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG100:![0-9]+]]
// PPC64-NEXT:    [[CONV117:%.*]] = fptosi ppc_fp128 [[TMP82]] to i64, !dbg [[DBG100]]
// PPC64-NEXT:    [[ATOMIC_LOAD118:%.*]] = load atomic i8, ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1) monotonic, align 1, !dbg [[DBG101:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT119:%.*]], !dbg [[DBG101]]
// PPC64:       atomic_cont119:
// PPC64-NEXT:    [[TMP83:%.*]] = phi i8 [ [[ATOMIC_LOAD118]], [[ATOMIC_EXIT116]] ], [ [[TMP87:%.*]], [[ATOMIC_CONT119]] ], !dbg [[DBG101]]
// PPC64-NEXT:    store i8 [[TMP83]], ptr [[ATOMIC_TEMP120]], align 1, !dbg [[DBG101]]
// PPC64-NEXT:    [[TMP84:%.*]] = trunc i64 [[CONV117]] to i8, !dbg [[DBG101]]
// PPC64-NEXT:    [[BF_LOAD121:%.*]] = load i8, ptr [[ATOMIC_TEMP120]], align 1, !dbg [[DBG101]]
// PPC64-NEXT:    [[BF_VALUE122:%.*]] = and i8 [[TMP84]], 127, !dbg [[DBG101]]
// PPC64-NEXT:    [[BF_CLEAR123:%.*]] = and i8 [[BF_LOAD121]], -128, !dbg [[DBG101]]
// PPC64-NEXT:    [[BF_SET124:%.*]] = or i8 [[BF_CLEAR123]], [[BF_VALUE122]], !dbg [[DBG101]]
// PPC64-NEXT:    store i8 [[BF_SET124]], ptr [[ATOMIC_TEMP120]], align 1, !dbg [[DBG101]]
// PPC64-NEXT:    [[TMP85:%.*]] = load i8, ptr [[ATOMIC_TEMP120]], align 1, !dbg [[DBG101]]
// PPC64-NEXT:    [[TMP86:%.*]] = cmpxchg ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1), i8 [[TMP83]], i8 [[TMP85]] monotonic monotonic, align 1, !dbg [[DBG101]]
// PPC64-NEXT:    [[TMP87]] = extractvalue { i8, i1 } [[TMP86]], 0, !dbg [[DBG101]]
// PPC64-NEXT:    [[TMP88:%.*]] = extractvalue { i8, i1 } [[TMP86]], 1, !dbg [[DBG101]]
// PPC64-NEXT:    br i1 [[TMP88]], label [[ATOMIC_EXIT125:%.*]], label [[ATOMIC_CONT119]], !dbg [[DBG101]]
// PPC64:       atomic_exit125:
// PPC64-NEXT:    [[TMP89:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG102:![0-9]+]]
// PPC64-NEXT:    [[CONV126:%.*]] = uitofp i64 [[TMP89]] to float, !dbg [[DBG102]]
// PPC64-NEXT:    [[ATOMIC_LOAD127:%.*]] = load atomic i64, ptr @float2x monotonic, align 8, !dbg [[DBG103:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT128:%.*]], !dbg [[DBG103]]
// PPC64:       atomic_cont128:
// PPC64-NEXT:    [[TMP90:%.*]] = phi i64 [ [[ATOMIC_LOAD127]], [[ATOMIC_EXIT125]] ], [ [[TMP95:%.*]], [[ATOMIC_CONT128]] ], !dbg [[DBG103]]
// PPC64-NEXT:    store i64 [[TMP90]], ptr [[ATOMIC_TEMP129]], align 8, !dbg [[DBG103]]
// PPC64-NEXT:    [[TMP91:%.*]] = load <2 x float>, ptr [[ATOMIC_TEMP129]], align 8, !dbg [[DBG103]]
// PPC64-NEXT:    [[TMP92:%.*]] = insertelement <2 x float> [[TMP91]], float [[CONV126]], i64 0, !dbg [[DBG103]]
// PPC64-NEXT:    store <2 x float> [[TMP92]], ptr [[ATOMIC_TEMP129]], align 8, !dbg [[DBG103]]
// PPC64-NEXT:    [[TMP93:%.*]] = load i64, ptr [[ATOMIC_TEMP129]], align 8, !dbg [[DBG103]]
// PPC64-NEXT:    [[TMP94:%.*]] = cmpxchg ptr @float2x, i64 [[TMP90]], i64 [[TMP93]] monotonic monotonic, align 8, !dbg [[DBG103]]
// PPC64-NEXT:    [[TMP95]] = extractvalue { i64, i1 } [[TMP94]], 0, !dbg [[DBG103]]
// PPC64-NEXT:    [[TMP96:%.*]] = extractvalue { i64, i1 } [[TMP94]], 1, !dbg [[DBG103]]
// PPC64-NEXT:    br i1 [[TMP96]], label [[ATOMIC_EXIT130:%.*]], label [[ATOMIC_CONT128]], !dbg [[DBG103]]
// PPC64:       atomic_exit130:
// PPC64-NEXT:    ret i32 0, !dbg [[DBG104:![0-9]+]]
//
//
// AARCH64-LABEL: define {{[^@]+}}@main
// AARCH64-SAME: () #[[ATTR0:[0-9]+]] !dbg [[DBG5:![0-9]+]] {
// AARCH64-NEXT:  entry:
// AARCH64-NEXT:    [[RETVAL:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP1:%.*]] = alloca { float, float }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP2:%.*]] = alloca { double, double }, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP8:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP13:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP29:%.*]] = alloca <4 x i32>, align 16
// AARCH64-NEXT:    [[ATOMIC_TEMP33:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP36:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP38:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP47:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP56:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP66:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP74:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP76:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP87:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP97:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP106:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP116:%.*]] = alloca i64, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP126:%.*]] = alloca <2 x float>, align 8
// AARCH64-NEXT:    store i32 0, ptr [[RETVAL]], align 4
// AARCH64-NEXT:    store atomic i32 1, ptr getelementptr inbounds nuw ({ i32, i32 }, ptr @civ, i32 0, i32 1) monotonic, align 4, !dbg [[DBG9:![0-9]+]]
// AARCH64-NEXT:    [[TMP0:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG10:![0-9]+]]
// AARCH64-NEXT:    [[LOADEDV:%.*]] = trunc i8 [[TMP0]] to i1, !dbg [[DBG10]]
// AARCH64-NEXT:    [[STOREDV:%.*]] = zext i1 [[LOADEDV]] to i8, !dbg [[DBG11:![0-9]+]]
// AARCH64-NEXT:    store atomic i8 [[STOREDV]], ptr @bx monotonic, align 1, !dbg [[DBG11]]
// AARCH64-NEXT:    [[TMP1:%.*]] = load i8, ptr @cv, align 1, !dbg [[DBG12:![0-9]+]]
// AARCH64-NEXT:    store atomic i8 [[TMP1]], ptr @cx release, align 1, !dbg [[DBG13:![0-9]+]]
// AARCH64-NEXT:    fence release
// AARCH64-NEXT:    [[TMP2:%.*]] = load i8, ptr @ucv, align 1, !dbg [[DBG14:![0-9]+]]
// AARCH64-NEXT:    store atomic i8 [[TMP2]], ptr @ucx monotonic, align 1, !dbg [[DBG15:![0-9]+]]
// AARCH64-NEXT:    [[TMP3:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG16:![0-9]+]]
// AARCH64-NEXT:    store atomic i16 [[TMP3]], ptr @sx monotonic, align 2, !dbg [[DBG17:![0-9]+]]
// AARCH64-NEXT:    [[TMP4:%.*]] = load i16, ptr @usv, align 2, !dbg [[DBG18:![0-9]+]]
// AARCH64-NEXT:    store atomic i16 [[TMP4]], ptr @usx monotonic, align 2, !dbg [[DBG19:![0-9]+]]
// AARCH64-NEXT:    [[TMP5:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG20:![0-9]+]]
// AARCH64-NEXT:    store atomic i32 [[TMP5]], ptr @ix monotonic, align 4, !dbg [[DBG21:![0-9]+]]
// AARCH64-NEXT:    [[TMP6:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG22:![0-9]+]]
// AARCH64-NEXT:    store atomic i32 [[TMP6]], ptr @uix monotonic, align 4, !dbg [[DBG23:![0-9]+]]
// AARCH64-NEXT:    [[TMP7:%.*]] = load i64, ptr @lv, align 8, !dbg [[DBG24:![0-9]+]]
// AARCH64-NEXT:    store atomic i64 [[TMP7]], ptr @lx monotonic, align 8, !dbg [[DBG25:![0-9]+]]
// AARCH64-NEXT:    [[TMP8:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG26:![0-9]+]]
// AARCH64-NEXT:    store atomic i64 [[TMP8]], ptr @ulx monotonic, align 8, !dbg [[DBG27:![0-9]+]]
// AARCH64-NEXT:    [[TMP9:%.*]] = load i64, ptr @llv, align 8, !dbg [[DBG28:![0-9]+]]
// AARCH64-NEXT:    store atomic i64 [[TMP9]], ptr @llx monotonic, align 8, !dbg [[DBG29:![0-9]+]]
// AARCH64-NEXT:    [[TMP10:%.*]] = load i64, ptr @ullv, align 8, !dbg [[DBG30:![0-9]+]]
// AARCH64-NEXT:    store atomic i64 [[TMP10]], ptr @ullx monotonic, align 8, !dbg [[DBG31:![0-9]+]]
// AARCH64-NEXT:    [[TMP11:%.*]] = load float, ptr @fv, align 4, !dbg [[DBG32:![0-9]+]]
// AARCH64-NEXT:    store atomic float [[TMP11]], ptr @fx monotonic, align 4, !dbg [[DBG33:![0-9]+]]
// AARCH64-NEXT:    [[TMP12:%.*]] = load double, ptr @dv, align 8, !dbg [[DBG34:![0-9]+]]
// AARCH64-NEXT:    store atomic double [[TMP12]], ptr @dx monotonic, align 8, !dbg [[DBG35:![0-9]+]]
// AARCH64-NEXT:    [[TMP13:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG36:![0-9]+]]
// AARCH64-NEXT:    store atomic fp128 [[TMP13]], ptr @ldx monotonic, align 16, !dbg [[DBG37:![0-9]+]]
// AARCH64-NEXT:    [[CIV_REAL:%.*]] = load i32, ptr @civ, align 4, !dbg [[DBG38:![0-9]+]]
// AARCH64-NEXT:    [[CIV_IMAG:%.*]] = load i32, ptr getelementptr inbounds nuw ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG38]]
// AARCH64-NEXT:    [[ATOMIC_TEMP_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP]], i32 0, i32 0, !dbg [[DBG39:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_TEMP_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP]], i32 0, i32 1, !dbg [[DBG39]]
// AARCH64-NEXT:    store i32 [[CIV_REAL]], ptr [[ATOMIC_TEMP_REALP]], align 4, !dbg [[DBG39]]
// AARCH64-NEXT:    store i32 [[CIV_IMAG]], ptr [[ATOMIC_TEMP_IMAGP]], align 4, !dbg [[DBG39]]
// AARCH64-NEXT:    call void @__atomic_store(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP]], i32 noundef 0), !dbg [[DBG39]]
// AARCH64-NEXT:    [[CFV_REAL:%.*]] = load float, ptr @cfv, align 4, !dbg [[DBG40:![0-9]+]]
// AARCH64-NEXT:    [[CFV_IMAG:%.*]] = load float, ptr getelementptr inbounds nuw ({ float, float }, ptr @cfv, i32 0, i32 1), align 4, !dbg [[DBG40]]
// AARCH64-NEXT:    [[ATOMIC_TEMP1_REALP:%.*]] = getelementptr inbounds nuw { float, float }, ptr [[ATOMIC_TEMP1]], i32 0, i32 0, !dbg [[DBG41:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_TEMP1_IMAGP:%.*]] = getelementptr inbounds nuw { float, float }, ptr [[ATOMIC_TEMP1]], i32 0, i32 1, !dbg [[DBG41]]
// AARCH64-NEXT:    store float [[CFV_REAL]], ptr [[ATOMIC_TEMP1_REALP]], align 4, !dbg [[DBG41]]
// AARCH64-NEXT:    store float [[CFV_IMAG]], ptr [[ATOMIC_TEMP1_IMAGP]], align 4, !dbg [[DBG41]]
// AARCH64-NEXT:    call void @__atomic_store(i64 noundef 8, ptr noundef @cfx, ptr noundef [[ATOMIC_TEMP1]], i32 noundef 0), !dbg [[DBG41]]
// AARCH64-NEXT:    [[CDV_REAL:%.*]] = load double, ptr @cdv, align 8, !dbg [[DBG42:![0-9]+]]
// AARCH64-NEXT:    [[CDV_IMAG:%.*]] = load double, ptr getelementptr inbounds nuw ({ double, double }, ptr @cdv, i32 0, i32 1), align 8, !dbg [[DBG42]]
// AARCH64-NEXT:    [[ATOMIC_TEMP2_REALP:%.*]] = getelementptr inbounds nuw { double, double }, ptr [[ATOMIC_TEMP2]], i32 0, i32 0, !dbg [[DBG43:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_TEMP2_IMAGP:%.*]] = getelementptr inbounds nuw { double, double }, ptr [[ATOMIC_TEMP2]], i32 0, i32 1, !dbg [[DBG43]]
// AARCH64-NEXT:    store double [[CDV_REAL]], ptr [[ATOMIC_TEMP2_REALP]], align 8, !dbg [[DBG43]]
// AARCH64-NEXT:    store double [[CDV_IMAG]], ptr [[ATOMIC_TEMP2_IMAGP]], align 8, !dbg [[DBG43]]
// AARCH64-NEXT:    call void @__atomic_store(i64 noundef 16, ptr noundef @cdx, ptr noundef [[ATOMIC_TEMP2]], i32 noundef 5), !dbg [[DBG43]]
// AARCH64-NEXT:    fence release
// AARCH64-NEXT:    [[TMP14:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG44:![0-9]+]]
// AARCH64-NEXT:    [[LOADEDV3:%.*]] = trunc i8 [[TMP14]] to i1, !dbg [[DBG44]]
// AARCH64-NEXT:    [[CONV:%.*]] = zext i1 [[LOADEDV3]] to i64, !dbg [[DBG44]]
// AARCH64-NEXT:    store atomic i64 [[CONV]], ptr @ulx monotonic, align 8, !dbg [[DBG45:![0-9]+]]
// AARCH64-NEXT:    [[TMP15:%.*]] = load i8, ptr @cv, align 1, !dbg [[DBG46:![0-9]+]]
// AARCH64-NEXT:    [[TOBOOL:%.*]] = icmp ne i8 [[TMP15]], 0, !dbg [[DBG46]]
// AARCH64-NEXT:    [[STOREDV4:%.*]] = zext i1 [[TOBOOL]] to i8, !dbg [[DBG47:![0-9]+]]
// AARCH64-NEXT:    store atomic i8 [[STOREDV4]], ptr @bx monotonic, align 1, !dbg [[DBG47]]
// AARCH64-NEXT:    [[TMP16:%.*]] = load i8, ptr @ucv, align 1, !dbg [[DBG48:![0-9]+]]
// AARCH64-NEXT:    store atomic i8 [[TMP16]], ptr @cx seq_cst, align 1, !dbg [[DBG49:![0-9]+]]
// AARCH64-NEXT:    fence release
// AARCH64-NEXT:    [[TMP17:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG50:![0-9]+]]
// AARCH64-NEXT:    [[CONV5:%.*]] = sext i16 [[TMP17]] to i64, !dbg [[DBG50]]
// AARCH64-NEXT:    store atomic i64 [[CONV5]], ptr @ulx monotonic, align 8, !dbg [[DBG51:![0-9]+]]
// AARCH64-NEXT:    [[TMP18:%.*]] = load i16, ptr @usv, align 2, !dbg [[DBG52:![0-9]+]]
// AARCH64-NEXT:    [[CONV6:%.*]] = zext i16 [[TMP18]] to i64, !dbg [[DBG52]]
// AARCH64-NEXT:    store atomic i64 [[CONV6]], ptr @lx monotonic, align 8, !dbg [[DBG53:![0-9]+]]
// AARCH64-NEXT:    [[TMP19:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG54:![0-9]+]]
// AARCH64-NEXT:    store atomic i32 [[TMP19]], ptr @uix seq_cst, align 4, !dbg [[DBG55:![0-9]+]]
// AARCH64-NEXT:    fence release
// AARCH64-NEXT:    [[TMP20:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG56:![0-9]+]]
// AARCH64-NEXT:    store atomic i32 [[TMP20]], ptr @ix monotonic, align 4, !dbg [[DBG57:![0-9]+]]
// AARCH64-NEXT:    [[TMP21:%.*]] = load i64, ptr @lv, align 8, !dbg [[DBG58:![0-9]+]]
// AARCH64-NEXT:    [[CONV7:%.*]] = trunc i64 [[TMP21]] to i32, !dbg [[DBG58]]
// AARCH64-NEXT:    [[ATOMIC_TEMP8_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP8]], i32 0, i32 0, !dbg [[DBG59:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_TEMP8_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP8]], i32 0, i32 1, !dbg [[DBG59]]
// AARCH64-NEXT:    store i32 [[CONV7]], ptr [[ATOMIC_TEMP8_REALP]], align 4, !dbg [[DBG59]]
// AARCH64-NEXT:    store i32 0, ptr [[ATOMIC_TEMP8_IMAGP]], align 4, !dbg [[DBG59]]
// AARCH64-NEXT:    call void @__atomic_store(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP8]], i32 noundef 0), !dbg [[DBG59]]
// AARCH64-NEXT:    [[TMP22:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG60:![0-9]+]]
// AARCH64-NEXT:    [[CONV9:%.*]] = uitofp i64 [[TMP22]] to float, !dbg [[DBG60]]
// AARCH64-NEXT:    store atomic float [[CONV9]], ptr @fx monotonic, align 4, !dbg [[DBG61:![0-9]+]]
// AARCH64-NEXT:    [[TMP23:%.*]] = load i64, ptr @llv, align 8, !dbg [[DBG62:![0-9]+]]
// AARCH64-NEXT:    [[CONV10:%.*]] = sitofp i64 [[TMP23]] to double, !dbg [[DBG62]]
// AARCH64-NEXT:    store atomic double [[CONV10]], ptr @dx monotonic, align 8, !dbg [[DBG63:![0-9]+]]
// AARCH64-NEXT:    [[TMP24:%.*]] = load i64, ptr @ullv, align 8, !dbg [[DBG64:![0-9]+]]
// AARCH64-NEXT:    [[CONV11:%.*]] = uitofp i64 [[TMP24]] to fp128, !dbg [[DBG64]]
// AARCH64-NEXT:    store atomic fp128 [[CONV11]], ptr @ldx monotonic, align 16, !dbg [[DBG65:![0-9]+]]
// AARCH64-NEXT:    [[TMP25:%.*]] = load float, ptr @fv, align 4, !dbg [[DBG66:![0-9]+]]
// AARCH64-NEXT:    [[CONV12:%.*]] = fptosi float [[TMP25]] to i32, !dbg [[DBG66]]
// AARCH64-NEXT:    [[ATOMIC_TEMP13_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP13]], i32 0, i32 0, !dbg [[DBG67:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_TEMP13_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP13]], i32 0, i32 1, !dbg [[DBG67]]
// AARCH64-NEXT:    store i32 [[CONV12]], ptr [[ATOMIC_TEMP13_REALP]], align 4, !dbg [[DBG67]]
// AARCH64-NEXT:    store i32 0, ptr [[ATOMIC_TEMP13_IMAGP]], align 4, !dbg [[DBG67]]
// AARCH64-NEXT:    call void @__atomic_store(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP13]], i32 noundef 0), !dbg [[DBG67]]
// AARCH64-NEXT:    [[TMP26:%.*]] = load double, ptr @dv, align 8, !dbg [[DBG68:![0-9]+]]
// AARCH64-NEXT:    [[CONV14:%.*]] = fptosi double [[TMP26]] to i16, !dbg [[DBG68]]
// AARCH64-NEXT:    store atomic i16 [[CONV14]], ptr @sx monotonic, align 2, !dbg [[DBG69:![0-9]+]]
// AARCH64-NEXT:    [[TMP27:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG70:![0-9]+]]
// AARCH64-NEXT:    [[TOBOOL15:%.*]] = fcmp une fp128 [[TMP27]], 0xL00000000000000000000000000000000, !dbg [[DBG70]]
// AARCH64-NEXT:    [[STOREDV16:%.*]] = zext i1 [[TOBOOL15]] to i8, !dbg [[DBG71:![0-9]+]]
// AARCH64-NEXT:    store atomic i8 [[STOREDV16]], ptr @bx monotonic, align 1, !dbg [[DBG71]]
// AARCH64-NEXT:    [[CIV_REAL17:%.*]] = load i32, ptr @civ, align 4, !dbg [[DBG72:![0-9]+]]
// AARCH64-NEXT:    [[CIV_IMAG18:%.*]] = load i32, ptr getelementptr inbounds nuw ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG72]]
// AARCH64-NEXT:    [[TOBOOL19:%.*]] = icmp ne i32 [[CIV_REAL17]], 0, !dbg [[DBG72]]
// AARCH64-NEXT:    [[TOBOOL20:%.*]] = icmp ne i32 [[CIV_IMAG18]], 0, !dbg [[DBG72]]
// AARCH64-NEXT:    [[TOBOOL21:%.*]] = or i1 [[TOBOOL19]], [[TOBOOL20]], !dbg [[DBG72]]
// AARCH64-NEXT:    [[STOREDV22:%.*]] = zext i1 [[TOBOOL21]] to i8, !dbg [[DBG73:![0-9]+]]
// AARCH64-NEXT:    store atomic i8 [[STOREDV22]], ptr @bx monotonic, align 1, !dbg [[DBG73]]
// AARCH64-NEXT:    [[CFV_REAL23:%.*]] = load float, ptr @cfv, align 4, !dbg [[DBG74:![0-9]+]]
// AARCH64-NEXT:    [[CONV24:%.*]] = fptoui float [[CFV_REAL23]] to i16, !dbg [[DBG74]]
// AARCH64-NEXT:    store atomic i16 [[CONV24]], ptr @usx monotonic, align 2, !dbg [[DBG75:![0-9]+]]
// AARCH64-NEXT:    [[CDV_REAL25:%.*]] = load double, ptr @cdv, align 8, !dbg [[DBG76:![0-9]+]]
// AARCH64-NEXT:    [[CONV26:%.*]] = fptosi double [[CDV_REAL25]] to i64, !dbg [[DBG76]]
// AARCH64-NEXT:    store atomic i64 [[CONV26]], ptr @llx monotonic, align 8, !dbg [[DBG77:![0-9]+]]
// AARCH64-NEXT:    [[TMP28:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG78:![0-9]+]]
// AARCH64-NEXT:    [[TMP29:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG79:![0-9]+]]
// AARCH64-NEXT:    [[LOADEDV27:%.*]] = trunc i8 [[TMP29]] to i1, !dbg [[DBG79]]
// AARCH64-NEXT:    [[CONV28:%.*]] = zext i1 [[LOADEDV27]] to i32, !dbg [[DBG79]]
// AARCH64-NEXT:    [[ATOMIC_LOAD:%.*]] = load atomic i128, ptr @int4x monotonic, align 16, !dbg [[DBG80:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT:%.*]], !dbg [[DBG80]]
// AARCH64:       atomic_cont:
// AARCH64-NEXT:    [[TMP30:%.*]] = phi i128 [ [[ATOMIC_LOAD]], [[ENTRY:%.*]] ], [ [[TMP34:%.*]], [[ATOMIC_CONT]] ], !dbg [[DBG80]]
// AARCH64-NEXT:    store i128 [[TMP30]], ptr [[ATOMIC_TEMP29]], align 16, !dbg [[DBG80]]
// AARCH64-NEXT:    [[TMP31:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP29]], align 16, !dbg [[DBG80]]
// AARCH64-NEXT:    [[VECINS:%.*]] = insertelement <4 x i32> [[TMP31]], i32 [[CONV28]], i16 [[TMP28]], !dbg [[DBG80]]
// AARCH64-NEXT:    store <4 x i32> [[VECINS]], ptr [[ATOMIC_TEMP29]], align 16, !dbg [[DBG80]]
// AARCH64-NEXT:    [[TMP32:%.*]] = load i128, ptr [[ATOMIC_TEMP29]], align 16, !dbg [[DBG80]]
// AARCH64-NEXT:    [[TMP33:%.*]] = cmpxchg ptr @int4x, i128 [[TMP30]], i128 [[TMP32]] monotonic monotonic, align 16, !dbg [[DBG80]]
// AARCH64-NEXT:    [[TMP34]] = extractvalue { i128, i1 } [[TMP33]], 0, !dbg [[DBG80]]
// AARCH64-NEXT:    [[TMP35:%.*]] = extractvalue { i128, i1 } [[TMP33]], 1, !dbg [[DBG80]]
// AARCH64-NEXT:    br i1 [[TMP35]], label [[ATOMIC_EXIT:%.*]], label [[ATOMIC_CONT]], !dbg [[DBG80]]
// AARCH64:       atomic_exit:
// AARCH64-NEXT:    [[TMP36:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG81:![0-9]+]]
// AARCH64-NEXT:    [[CONV30:%.*]] = fptosi fp128 [[TMP36]] to i32, !dbg [[DBG81]]
// AARCH64-NEXT:    [[ATOMIC_LOAD31:%.*]] = load atomic i32, ptr getelementptr (i8, ptr @bfx, i64 4) monotonic, align 4, !dbg [[DBG82:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT32:%.*]], !dbg [[DBG82]]
// AARCH64:       atomic_cont32:
// AARCH64-NEXT:    [[TMP37:%.*]] = phi i32 [ [[ATOMIC_LOAD31]], [[ATOMIC_EXIT]] ], [ [[TMP40:%.*]], [[ATOMIC_CONT32]] ], !dbg [[DBG82]]
// AARCH64-NEXT:    store i32 [[TMP37]], ptr [[ATOMIC_TEMP33]], align 4, !dbg [[DBG82]]
// AARCH64-NEXT:    [[BF_LOAD:%.*]] = load i32, ptr [[ATOMIC_TEMP33]], align 4, !dbg [[DBG82]]
// AARCH64-NEXT:    [[BF_VALUE:%.*]] = and i32 [[CONV30]], 2147483647, !dbg [[DBG82]]
// AARCH64-NEXT:    [[BF_CLEAR:%.*]] = and i32 [[BF_LOAD]], -2147483648, !dbg [[DBG82]]
// AARCH64-NEXT:    [[BF_SET:%.*]] = or i32 [[BF_CLEAR]], [[BF_VALUE]], !dbg [[DBG82]]
// AARCH64-NEXT:    store i32 [[BF_SET]], ptr [[ATOMIC_TEMP33]], align 4, !dbg [[DBG82]]
// AARCH64-NEXT:    [[TMP38:%.*]] = load i32, ptr [[ATOMIC_TEMP33]], align 4, !dbg [[DBG82]]
// AARCH64-NEXT:    [[TMP39:%.*]] = cmpxchg ptr getelementptr (i8, ptr @bfx, i64 4), i32 [[TMP37]], i32 [[TMP38]] monotonic monotonic, align 4, !dbg [[DBG82]]
// AARCH64-NEXT:    [[TMP40]] = extractvalue { i32, i1 } [[TMP39]], 0, !dbg [[DBG82]]
// AARCH64-NEXT:    [[TMP41:%.*]] = extractvalue { i32, i1 } [[TMP39]], 1, !dbg [[DBG82]]
// AARCH64-NEXT:    br i1 [[TMP41]], label [[ATOMIC_EXIT34:%.*]], label [[ATOMIC_CONT32]], !dbg [[DBG82]]
// AARCH64:       atomic_exit34:
// AARCH64-NEXT:    [[TMP42:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG83:![0-9]+]]
// AARCH64-NEXT:    [[CONV35:%.*]] = fptosi fp128 [[TMP42]] to i32, !dbg [[DBG83]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 4, ptr noundef getelementptr (i8, ptr @bfx_packed, i64 4), ptr noundef [[ATOMIC_TEMP36]], i32 noundef 0), !dbg [[DBG84:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT37:%.*]], !dbg [[DBG84]]
// AARCH64:       atomic_cont37:
// AARCH64-NEXT:    [[TMP43:%.*]] = load i32, ptr [[ATOMIC_TEMP36]], align 1, !dbg [[DBG84]]
// AARCH64-NEXT:    store i32 [[TMP43]], ptr [[ATOMIC_TEMP38]], align 1, !dbg [[DBG84]]
// AARCH64-NEXT:    [[BF_LOAD39:%.*]] = load i32, ptr [[ATOMIC_TEMP38]], align 1, !dbg [[DBG84]]
// AARCH64-NEXT:    [[BF_VALUE40:%.*]] = and i32 [[CONV35]], 2147483647, !dbg [[DBG84]]
// AARCH64-NEXT:    [[BF_CLEAR41:%.*]] = and i32 [[BF_LOAD39]], -2147483648, !dbg [[DBG84]]
// AARCH64-NEXT:    [[BF_SET42:%.*]] = or i32 [[BF_CLEAR41]], [[BF_VALUE40]], !dbg [[DBG84]]
// AARCH64-NEXT:    store i32 [[BF_SET42]], ptr [[ATOMIC_TEMP38]], align 1, !dbg [[DBG84]]
// AARCH64-NEXT:    [[CALL:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 4, ptr noundef getelementptr (i8, ptr @bfx_packed, i64 4), ptr noundef [[ATOMIC_TEMP36]], ptr noundef [[ATOMIC_TEMP38]], i32 noundef 0, i32 noundef 0), !dbg [[DBG84]]
// AARCH64-NEXT:    br i1 [[CALL]], label [[ATOMIC_EXIT43:%.*]], label [[ATOMIC_CONT37]], !dbg [[DBG84]]
// AARCH64:       atomic_exit43:
// AARCH64-NEXT:    [[TMP44:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG85:![0-9]+]]
// AARCH64-NEXT:    [[CONV44:%.*]] = fptosi fp128 [[TMP44]] to i32, !dbg [[DBG85]]
// AARCH64-NEXT:    [[ATOMIC_LOAD45:%.*]] = load atomic i32, ptr @bfx2 monotonic, align 4, !dbg [[DBG86:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT46:%.*]], !dbg [[DBG86]]
// AARCH64:       atomic_cont46:
// AARCH64-NEXT:    [[TMP45:%.*]] = phi i32 [ [[ATOMIC_LOAD45]], [[ATOMIC_EXIT43]] ], [ [[TMP48:%.*]], [[ATOMIC_CONT46]] ], !dbg [[DBG86]]
// AARCH64-NEXT:    store i32 [[TMP45]], ptr [[ATOMIC_TEMP47]], align 4, !dbg [[DBG86]]
// AARCH64-NEXT:    [[BF_LOAD48:%.*]] = load i32, ptr [[ATOMIC_TEMP47]], align 4, !dbg [[DBG86]]
// AARCH64-NEXT:    [[BF_VALUE49:%.*]] = and i32 [[CONV44]], 1, !dbg [[DBG86]]
// AARCH64-NEXT:    [[BF_SHL:%.*]] = shl i32 [[BF_VALUE49]], 31, !dbg [[DBG86]]
// AARCH64-NEXT:    [[BF_CLEAR50:%.*]] = and i32 [[BF_LOAD48]], 2147483647, !dbg [[DBG86]]
// AARCH64-NEXT:    [[BF_SET51:%.*]] = or i32 [[BF_CLEAR50]], [[BF_SHL]], !dbg [[DBG86]]
// AARCH64-NEXT:    store i32 [[BF_SET51]], ptr [[ATOMIC_TEMP47]], align 4, !dbg [[DBG86]]
// AARCH64-NEXT:    [[TMP46:%.*]] = load i32, ptr [[ATOMIC_TEMP47]], align 4, !dbg [[DBG86]]
// AARCH64-NEXT:    [[TMP47:%.*]] = cmpxchg ptr @bfx2, i32 [[TMP45]], i32 [[TMP46]] monotonic monotonic, align 4, !dbg [[DBG86]]
// AARCH64-NEXT:    [[TMP48]] = extractvalue { i32, i1 } [[TMP47]], 0, !dbg [[DBG86]]
// AARCH64-NEXT:    [[TMP49:%.*]] = extractvalue { i32, i1 } [[TMP47]], 1, !dbg [[DBG86]]
// AARCH64-NEXT:    br i1 [[TMP49]], label [[ATOMIC_EXIT52:%.*]], label [[ATOMIC_CONT46]], !dbg [[DBG86]]
// AARCH64:       atomic_exit52:
// AARCH64-NEXT:    [[TMP50:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG87:![0-9]+]]
// AARCH64-NEXT:    [[CONV53:%.*]] = fptosi fp128 [[TMP50]] to i32, !dbg [[DBG87]]
// AARCH64-NEXT:    [[ATOMIC_LOAD54:%.*]] = load atomic i8, ptr getelementptr (i8, ptr @bfx2_packed, i64 3) monotonic, align 1, !dbg [[DBG88:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT55:%.*]], !dbg [[DBG88]]
// AARCH64:       atomic_cont55:
// AARCH64-NEXT:    [[TMP51:%.*]] = phi i8 [ [[ATOMIC_LOAD54]], [[ATOMIC_EXIT52]] ], [ [[TMP55:%.*]], [[ATOMIC_CONT55]] ], !dbg [[DBG88]]
// AARCH64-NEXT:    store i8 [[TMP51]], ptr [[ATOMIC_TEMP56]], align 1, !dbg [[DBG88]]
// AARCH64-NEXT:    [[TMP52:%.*]] = trunc i32 [[CONV53]] to i8, !dbg [[DBG88]]
// AARCH64-NEXT:    [[BF_LOAD57:%.*]] = load i8, ptr [[ATOMIC_TEMP56]], align 1, !dbg [[DBG88]]
// AARCH64-NEXT:    [[BF_VALUE58:%.*]] = and i8 [[TMP52]], 1, !dbg [[DBG88]]
// AARCH64-NEXT:    [[BF_SHL59:%.*]] = shl i8 [[BF_VALUE58]], 7, !dbg [[DBG88]]
// AARCH64-NEXT:    [[BF_CLEAR60:%.*]] = and i8 [[BF_LOAD57]], 127, !dbg [[DBG88]]
// AARCH64-NEXT:    [[BF_SET61:%.*]] = or i8 [[BF_CLEAR60]], [[BF_SHL59]], !dbg [[DBG88]]
// AARCH64-NEXT:    store i8 [[BF_SET61]], ptr [[ATOMIC_TEMP56]], align 1, !dbg [[DBG88]]
// AARCH64-NEXT:    [[TMP53:%.*]] = load i8, ptr [[ATOMIC_TEMP56]], align 1, !dbg [[DBG88]]
// AARCH64-NEXT:    [[TMP54:%.*]] = cmpxchg ptr getelementptr (i8, ptr @bfx2_packed, i64 3), i8 [[TMP51]], i8 [[TMP53]] monotonic monotonic, align 1, !dbg [[DBG88]]
// AARCH64-NEXT:    [[TMP55]] = extractvalue { i8, i1 } [[TMP54]], 0, !dbg [[DBG88]]
// AARCH64-NEXT:    [[TMP56:%.*]] = extractvalue { i8, i1 } [[TMP54]], 1, !dbg [[DBG88]]
// AARCH64-NEXT:    br i1 [[TMP56]], label [[ATOMIC_EXIT62:%.*]], label [[ATOMIC_CONT55]], !dbg [[DBG88]]
// AARCH64:       atomic_exit62:
// AARCH64-NEXT:    [[TMP57:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG89:![0-9]+]]
// AARCH64-NEXT:    [[CONV63:%.*]] = fptosi fp128 [[TMP57]] to i32, !dbg [[DBG89]]
// AARCH64-NEXT:    [[ATOMIC_LOAD64:%.*]] = load atomic i32, ptr @bfx3 monotonic, align 4, !dbg [[DBG90:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT65:%.*]], !dbg [[DBG90]]
// AARCH64:       atomic_cont65:
// AARCH64-NEXT:    [[TMP58:%.*]] = phi i32 [ [[ATOMIC_LOAD64]], [[ATOMIC_EXIT62]] ], [ [[TMP61:%.*]], [[ATOMIC_CONT65]] ], !dbg [[DBG90]]
// AARCH64-NEXT:    store i32 [[TMP58]], ptr [[ATOMIC_TEMP66]], align 4, !dbg [[DBG90]]
// AARCH64-NEXT:    [[BF_LOAD67:%.*]] = load i32, ptr [[ATOMIC_TEMP66]], align 4, !dbg [[DBG90]]
// AARCH64-NEXT:    [[BF_VALUE68:%.*]] = and i32 [[CONV63]], 16383, !dbg [[DBG90]]
// AARCH64-NEXT:    [[BF_SHL69:%.*]] = shl i32 [[BF_VALUE68]], 11, !dbg [[DBG90]]
// AARCH64-NEXT:    [[BF_CLEAR70:%.*]] = and i32 [[BF_LOAD67]], -33552385, !dbg [[DBG90]]
// AARCH64-NEXT:    [[BF_SET71:%.*]] = or i32 [[BF_CLEAR70]], [[BF_SHL69]], !dbg [[DBG90]]
// AARCH64-NEXT:    store i32 [[BF_SET71]], ptr [[ATOMIC_TEMP66]], align 4, !dbg [[DBG90]]
// AARCH64-NEXT:    [[TMP59:%.*]] = load i32, ptr [[ATOMIC_TEMP66]], align 4, !dbg [[DBG90]]
// AARCH64-NEXT:    [[TMP60:%.*]] = cmpxchg ptr @bfx3, i32 [[TMP58]], i32 [[TMP59]] monotonic monotonic, align 4, !dbg [[DBG90]]
// AARCH64-NEXT:    [[TMP61]] = extractvalue { i32, i1 } [[TMP60]], 0, !dbg [[DBG90]]
// AARCH64-NEXT:    [[TMP62:%.*]] = extractvalue { i32, i1 } [[TMP60]], 1, !dbg [[DBG90]]
// AARCH64-NEXT:    br i1 [[TMP62]], label [[ATOMIC_EXIT72:%.*]], label [[ATOMIC_CONT65]], !dbg [[DBG90]]
// AARCH64:       atomic_exit72:
// AARCH64-NEXT:    [[TMP63:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG91:![0-9]+]]
// AARCH64-NEXT:    [[CONV73:%.*]] = fptosi fp128 [[TMP63]] to i32, !dbg [[DBG91]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 3, ptr noundef getelementptr (i8, ptr @bfx3_packed, i64 1), ptr noundef [[ATOMIC_TEMP74]], i32 noundef 0), !dbg [[DBG92:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT75:%.*]], !dbg [[DBG92]]
// AARCH64:       atomic_cont75:
// AARCH64-NEXT:    [[TMP64:%.*]] = load i24, ptr [[ATOMIC_TEMP74]], align 1, !dbg [[DBG92]]
// AARCH64-NEXT:    store i24 [[TMP64]], ptr [[ATOMIC_TEMP76]], align 1, !dbg [[DBG92]]
// AARCH64-NEXT:    [[TMP65:%.*]] = trunc i32 [[CONV73]] to i24, !dbg [[DBG92]]
// AARCH64-NEXT:    [[BF_LOAD77:%.*]] = load i24, ptr [[ATOMIC_TEMP76]], align 1, !dbg [[DBG92]]
// AARCH64-NEXT:    [[BF_VALUE78:%.*]] = and i24 [[TMP65]], 16383, !dbg [[DBG92]]
// AARCH64-NEXT:    [[BF_SHL79:%.*]] = shl i24 [[BF_VALUE78]], 3, !dbg [[DBG92]]
// AARCH64-NEXT:    [[BF_CLEAR80:%.*]] = and i24 [[BF_LOAD77]], -131065, !dbg [[DBG92]]
// AARCH64-NEXT:    [[BF_SET81:%.*]] = or i24 [[BF_CLEAR80]], [[BF_SHL79]], !dbg [[DBG92]]
// AARCH64-NEXT:    store i24 [[BF_SET81]], ptr [[ATOMIC_TEMP76]], align 1, !dbg [[DBG92]]
// AARCH64-NEXT:    [[CALL82:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 3, ptr noundef getelementptr (i8, ptr @bfx3_packed, i64 1), ptr noundef [[ATOMIC_TEMP74]], ptr noundef [[ATOMIC_TEMP76]], i32 noundef 0, i32 noundef 0), !dbg [[DBG92]]
// AARCH64-NEXT:    br i1 [[CALL82]], label [[ATOMIC_EXIT83:%.*]], label [[ATOMIC_CONT75]], !dbg [[DBG92]]
// AARCH64:       atomic_exit83:
// AARCH64-NEXT:    [[TMP66:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG93:![0-9]+]]
// AARCH64-NEXT:    [[CONV84:%.*]] = fptosi fp128 [[TMP66]] to i32, !dbg [[DBG93]]
// AARCH64-NEXT:    [[ATOMIC_LOAD85:%.*]] = load atomic i64, ptr @bfx4 monotonic, align 8, !dbg [[DBG94:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT86:%.*]], !dbg [[DBG94]]
// AARCH64:       atomic_cont86:
// AARCH64-NEXT:    [[TMP67:%.*]] = phi i64 [ [[ATOMIC_LOAD85]], [[ATOMIC_EXIT83]] ], [ [[TMP71:%.*]], [[ATOMIC_CONT86]] ], !dbg [[DBG94]]
// AARCH64-NEXT:    store i64 [[TMP67]], ptr [[ATOMIC_TEMP87]], align 8, !dbg [[DBG94]]
// AARCH64-NEXT:    [[TMP68:%.*]] = zext i32 [[CONV84]] to i64, !dbg [[DBG94]]
// AARCH64-NEXT:    [[BF_LOAD88:%.*]] = load i64, ptr [[ATOMIC_TEMP87]], align 8, !dbg [[DBG94]]
// AARCH64-NEXT:    [[BF_VALUE89:%.*]] = and i64 [[TMP68]], 1, !dbg [[DBG94]]
// AARCH64-NEXT:    [[BF_SHL90:%.*]] = shl i64 [[BF_VALUE89]], 16, !dbg [[DBG94]]
// AARCH64-NEXT:    [[BF_CLEAR91:%.*]] = and i64 [[BF_LOAD88]], -65537, !dbg [[DBG94]]
// AARCH64-NEXT:    [[BF_SET92:%.*]] = or i64 [[BF_CLEAR91]], [[BF_SHL90]], !dbg [[DBG94]]
// AARCH64-NEXT:    store i64 [[BF_SET92]], ptr [[ATOMIC_TEMP87]], align 8, !dbg [[DBG94]]
// AARCH64-NEXT:    [[TMP69:%.*]] = load i64, ptr [[ATOMIC_TEMP87]], align 8, !dbg [[DBG94]]
// AARCH64-NEXT:    [[TMP70:%.*]] = cmpxchg ptr @bfx4, i64 [[TMP67]], i64 [[TMP69]] monotonic monotonic, align 8, !dbg [[DBG94]]
// AARCH64-NEXT:    [[TMP71]] = extractvalue { i64, i1 } [[TMP70]], 0, !dbg [[DBG94]]
// AARCH64-NEXT:    [[TMP72:%.*]] = extractvalue { i64, i1 } [[TMP70]], 1, !dbg [[DBG94]]
// AARCH64-NEXT:    br i1 [[TMP72]], label [[ATOMIC_EXIT93:%.*]], label [[ATOMIC_CONT86]], !dbg [[DBG94]]
// AARCH64:       atomic_exit93:
// AARCH64-NEXT:    [[TMP73:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG95:![0-9]+]]
// AARCH64-NEXT:    [[CONV94:%.*]] = fptosi fp128 [[TMP73]] to i32, !dbg [[DBG95]]
// AARCH64-NEXT:    [[ATOMIC_LOAD95:%.*]] = load atomic i8, ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED:%.*]], ptr @bfx4_packed, i32 0, i32 1) monotonic, align 1, !dbg [[DBG96:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT96:%.*]], !dbg [[DBG96]]
// AARCH64:       atomic_cont96:
// AARCH64-NEXT:    [[TMP74:%.*]] = phi i8 [ [[ATOMIC_LOAD95]], [[ATOMIC_EXIT93]] ], [ [[TMP78:%.*]], [[ATOMIC_CONT96]] ], !dbg [[DBG96]]
// AARCH64-NEXT:    store i8 [[TMP74]], ptr [[ATOMIC_TEMP97]], align 1, !dbg [[DBG96]]
// AARCH64-NEXT:    [[TMP75:%.*]] = trunc i32 [[CONV94]] to i8, !dbg [[DBG96]]
// AARCH64-NEXT:    [[BF_LOAD98:%.*]] = load i8, ptr [[ATOMIC_TEMP97]], align 1, !dbg [[DBG96]]
// AARCH64-NEXT:    [[BF_VALUE99:%.*]] = and i8 [[TMP75]], 1, !dbg [[DBG96]]
// AARCH64-NEXT:    [[BF_CLEAR100:%.*]] = and i8 [[BF_LOAD98]], -2, !dbg [[DBG96]]
// AARCH64-NEXT:    [[BF_SET101:%.*]] = or i8 [[BF_CLEAR100]], [[BF_VALUE99]], !dbg [[DBG96]]
// AARCH64-NEXT:    store i8 [[BF_SET101]], ptr [[ATOMIC_TEMP97]], align 1, !dbg [[DBG96]]
// AARCH64-NEXT:    [[TMP76:%.*]] = load i8, ptr [[ATOMIC_TEMP97]], align 1, !dbg [[DBG96]]
// AARCH64-NEXT:    [[TMP77:%.*]] = cmpxchg ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1), i8 [[TMP74]], i8 [[TMP76]] monotonic monotonic, align 1, !dbg [[DBG96]]
// AARCH64-NEXT:    [[TMP78]] = extractvalue { i8, i1 } [[TMP77]], 0, !dbg [[DBG96]]
// AARCH64-NEXT:    [[TMP79:%.*]] = extractvalue { i8, i1 } [[TMP77]], 1, !dbg [[DBG96]]
// AARCH64-NEXT:    br i1 [[TMP79]], label [[ATOMIC_EXIT102:%.*]], label [[ATOMIC_CONT96]], !dbg [[DBG96]]
// AARCH64:       atomic_exit102:
// AARCH64-NEXT:    [[TMP80:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG97:![0-9]+]]
// AARCH64-NEXT:    [[CONV103:%.*]] = fptosi fp128 [[TMP80]] to i64, !dbg [[DBG97]]
// AARCH64-NEXT:    [[ATOMIC_LOAD104:%.*]] = load atomic i64, ptr @bfx4 monotonic, align 8, !dbg [[DBG98:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT105:%.*]], !dbg [[DBG98]]
// AARCH64:       atomic_cont105:
// AARCH64-NEXT:    [[TMP81:%.*]] = phi i64 [ [[ATOMIC_LOAD104]], [[ATOMIC_EXIT102]] ], [ [[TMP84:%.*]], [[ATOMIC_CONT105]] ], !dbg [[DBG98]]
// AARCH64-NEXT:    store i64 [[TMP81]], ptr [[ATOMIC_TEMP106]], align 8, !dbg [[DBG98]]
// AARCH64-NEXT:    [[BF_LOAD107:%.*]] = load i64, ptr [[ATOMIC_TEMP106]], align 8, !dbg [[DBG98]]
// AARCH64-NEXT:    [[BF_VALUE108:%.*]] = and i64 [[CONV103]], 127, !dbg [[DBG98]]
// AARCH64-NEXT:    [[BF_SHL109:%.*]] = shl i64 [[BF_VALUE108]], 17, !dbg [[DBG98]]
// AARCH64-NEXT:    [[BF_CLEAR110:%.*]] = and i64 [[BF_LOAD107]], -16646145, !dbg [[DBG98]]
// AARCH64-NEXT:    [[BF_SET111:%.*]] = or i64 [[BF_CLEAR110]], [[BF_SHL109]], !dbg [[DBG98]]
// AARCH64-NEXT:    store i64 [[BF_SET111]], ptr [[ATOMIC_TEMP106]], align 8, !dbg [[DBG98]]
// AARCH64-NEXT:    [[TMP82:%.*]] = load i64, ptr [[ATOMIC_TEMP106]], align 8, !dbg [[DBG98]]
// AARCH64-NEXT:    [[TMP83:%.*]] = cmpxchg ptr @bfx4, i64 [[TMP81]], i64 [[TMP82]] monotonic monotonic, align 8, !dbg [[DBG98]]
// AARCH64-NEXT:    [[TMP84]] = extractvalue { i64, i1 } [[TMP83]], 0, !dbg [[DBG98]]
// AARCH64-NEXT:    [[TMP85:%.*]] = extractvalue { i64, i1 } [[TMP83]], 1, !dbg [[DBG98]]
// AARCH64-NEXT:    br i1 [[TMP85]], label [[ATOMIC_EXIT112:%.*]], label [[ATOMIC_CONT105]], !dbg [[DBG98]]
// AARCH64:       atomic_exit112:
// AARCH64-NEXT:    [[TMP86:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG99:![0-9]+]]
// AARCH64-NEXT:    [[CONV113:%.*]] = fptosi fp128 [[TMP86]] to i64, !dbg [[DBG99]]
// AARCH64-NEXT:    [[ATOMIC_LOAD114:%.*]] = load atomic i8, ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1) monotonic, align 1, !dbg [[DBG100:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT115:%.*]], !dbg [[DBG100]]
// AARCH64:       atomic_cont115:
// AARCH64-NEXT:    [[TMP87:%.*]] = phi i8 [ [[ATOMIC_LOAD114]], [[ATOMIC_EXIT112]] ], [ [[TMP91:%.*]], [[ATOMIC_CONT115]] ], !dbg [[DBG100]]
// AARCH64-NEXT:    store i8 [[TMP87]], ptr [[ATOMIC_TEMP116]], align 1, !dbg [[DBG100]]
// AARCH64-NEXT:    [[TMP88:%.*]] = trunc i64 [[CONV113]] to i8, !dbg [[DBG100]]
// AARCH64-NEXT:    [[BF_LOAD117:%.*]] = load i8, ptr [[ATOMIC_TEMP116]], align 1, !dbg [[DBG100]]
// AARCH64-NEXT:    [[BF_VALUE118:%.*]] = and i8 [[TMP88]], 127, !dbg [[DBG100]]
// AARCH64-NEXT:    [[BF_SHL119:%.*]] = shl i8 [[BF_VALUE118]], 1, !dbg [[DBG100]]
// AARCH64-NEXT:    [[BF_CLEAR120:%.*]] = and i8 [[BF_LOAD117]], 1, !dbg [[DBG100]]
// AARCH64-NEXT:    [[BF_SET121:%.*]] = or i8 [[BF_CLEAR120]], [[BF_SHL119]], !dbg [[DBG100]]
// AARCH64-NEXT:    store i8 [[BF_SET121]], ptr [[ATOMIC_TEMP116]], align 1, !dbg [[DBG100]]
// AARCH64-NEXT:    [[TMP89:%.*]] = load i8, ptr [[ATOMIC_TEMP116]], align 1, !dbg [[DBG100]]
// AARCH64-NEXT:    [[TMP90:%.*]] = cmpxchg ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1), i8 [[TMP87]], i8 [[TMP89]] monotonic monotonic, align 1, !dbg [[DBG100]]
// AARCH64-NEXT:    [[TMP91]] = extractvalue { i8, i1 } [[TMP90]], 0, !dbg [[DBG100]]
// AARCH64-NEXT:    [[TMP92:%.*]] = extractvalue { i8, i1 } [[TMP90]], 1, !dbg [[DBG100]]
// AARCH64-NEXT:    br i1 [[TMP92]], label [[ATOMIC_EXIT122:%.*]], label [[ATOMIC_CONT115]], !dbg [[DBG100]]
// AARCH64:       atomic_exit122:
// AARCH64-NEXT:    [[TMP93:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG101:![0-9]+]]
// AARCH64-NEXT:    [[CONV123:%.*]] = uitofp i64 [[TMP93]] to float, !dbg [[DBG101]]
// AARCH64-NEXT:    [[ATOMIC_LOAD124:%.*]] = load atomic i64, ptr @float2x monotonic, align 8, !dbg [[DBG102:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT125:%.*]], !dbg [[DBG102]]
// AARCH64:       atomic_cont125:
// AARCH64-NEXT:    [[TMP94:%.*]] = phi i64 [ [[ATOMIC_LOAD124]], [[ATOMIC_EXIT122]] ], [ [[TMP99:%.*]], [[ATOMIC_CONT125]] ], !dbg [[DBG102]]
// AARCH64-NEXT:    store i64 [[TMP94]], ptr [[ATOMIC_TEMP126]], align 8, !dbg [[DBG102]]
// AARCH64-NEXT:    [[TMP95:%.*]] = load <2 x float>, ptr [[ATOMIC_TEMP126]], align 8, !dbg [[DBG102]]
// AARCH64-NEXT:    [[TMP96:%.*]] = insertelement <2 x float> [[TMP95]], float [[CONV123]], i64 0, !dbg [[DBG102]]
// AARCH64-NEXT:    store <2 x float> [[TMP96]], ptr [[ATOMIC_TEMP126]], align 8, !dbg [[DBG102]]
// AARCH64-NEXT:    [[TMP97:%.*]] = load i64, ptr [[ATOMIC_TEMP126]], align 8, !dbg [[DBG102]]
// AARCH64-NEXT:    [[TMP98:%.*]] = cmpxchg ptr @float2x, i64 [[TMP94]], i64 [[TMP97]] monotonic monotonic, align 8, !dbg [[DBG102]]
// AARCH64-NEXT:    [[TMP99]] = extractvalue { i64, i1 } [[TMP98]], 0, !dbg [[DBG102]]
// AARCH64-NEXT:    [[TMP100:%.*]] = extractvalue { i64, i1 } [[TMP98]], 1, !dbg [[DBG102]]
// AARCH64-NEXT:    br i1 [[TMP100]], label [[ATOMIC_EXIT127:%.*]], label [[ATOMIC_CONT125]], !dbg [[DBG102]]
// AARCH64:       atomic_exit127:
// AARCH64-NEXT:    ret i32 0, !dbg [[DBG103:![0-9]+]]
//
