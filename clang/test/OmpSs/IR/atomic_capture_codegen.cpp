// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --function-signature --include-generated-funcs
// RUN: %clang_cc1 -x c -triple x86_64-gnu-linux -verify -fompss-2 -disable-llvm-passes -ferror-limit 100 %s -emit-llvm -o - | FileCheck %s --check-prefixes=LIN64
// RUN: %clang_cc1 -x c -triple ppc64 -verify -fompss-2 -disable-llvm-passes -ferror-limit 100 %s -emit-llvm -o - | FileCheck %s --check-prefixes=PPC64
// RUN: %clang_cc1 -x c -triple aarch64 -verify -fompss-2 -disable-llvm-passes -ferror-limit 100 %s -emit-llvm -o - | FileCheck %s --check-prefixes=AARCH64
// expected-no-diagnostics
#ifndef HEADER
#define HEADER

_Bool bv, bx;
char cv, cx;
unsigned char ucv, ucx;
short sv, sx;
unsigned short usv, usx;
int iv, ix;
unsigned int uiv, uix;
long lv, lx;
unsigned long ulv, ulx;
long long llv, llx;
unsigned long long ullv, ullx;
float fv, fx;
double dv, dx;
long double ldv, ldx;
_Complex int civ, cix;
_Complex float cfv, cfx;
_Complex double cdv, cdx;

typedef int int4 __attribute__((__vector_size__(16)));
int4 int4x;

struct BitFields {
  int : 32;
  int a : 31;
} bfx;

struct BitFields_packed {
  int : 32;
  int a : 31;
} __attribute__ ((__packed__)) bfx_packed;

struct BitFields2 {
  int : 31;
  int a : 1;
} bfx2;

struct BitFields2_packed {
  int : 31;
  int a : 1;
} __attribute__ ((__packed__)) bfx2_packed;

struct BitFields3 {
  int : 11;
  int a : 14;
} bfx3;

struct BitFields3_packed {
  int : 11;
  int a : 14;
} __attribute__ ((__packed__)) bfx3_packed;

struct BitFields4 {
  short : 16;
  int a: 1;
  long b : 7;
} bfx4;

struct BitFields4_packed {
  short : 16;
  int a: 1;
  long b : 7;
} __attribute__ ((__packed__)) bfx4_packed;

typedef float float2 __attribute__((ext_vector_type(2)));
float2 float2x;

#if defined(__x86_64__)
// Register "0" is currently an invalid register for global register variables.
// Use "esp" instead of "0".
// register int rix __asm__("0");
register int rix __asm__("esp");
#endif

int main(void) {
#pragma oss atomic capture
  bv = bx++;
#pragma oss atomic capture
  cv = ++cx;
#pragma oss atomic capture
  ucv = ucx--;
#pragma oss atomic capture
  sv = --sx;
#pragma oss atomic capture
  sv = usx += usv;
#pragma oss atomic capture
  uiv = ix *= iv;
#pragma oss atomic capture
  {iv = uix; uix -= uiv;}
#pragma oss atomic capture
  {ix <<= iv; uiv = ix;}
#pragma oss atomic capture
  iv = uix >>= uiv;
#pragma oss atomic capture
  {ulv = lx; lx /= lv;}
#pragma oss atomic capture
  {ulx &= ulv; lv = ulx;}
#pragma oss atomic capture
  ullv = llx ^= llv;
#pragma oss atomic capture
  llv = ullx |= ullv;
#pragma oss atomic capture
  dv = fx = fx + fv;
#pragma oss atomic capture
  {fv = dx; dx = dv - dx;}
#pragma oss atomic capture
  {ldx = ldx * ldv; dv = ldx;}
// <Skip checks for complex calculations>
#pragma oss atomic capture
  cfv = cix = civ / cix;
// <Skip checks for complex calculations>
#pragma oss atomic capture
  {civ = cfx; cfx = cfv + cfx;}
// <Skip checks for complex calculations>
#pragma oss atomic capture seq_cst
  {cdx = cdx - cdv; cfv = cdx;}
#pragma oss atomic capture
  ulv = ulx = ulx & bv;
#pragma oss atomic capture
  {bv = bx; bx = cv & bx;}
#pragma oss atomic capture, seq_cst
  {cx = cx >> ucv; cv = cx;}
#pragma oss atomic capture
  ulv = ulx = sv << ulx;
#pragma oss atomic capture
  {lv = lx; lx = lx % usv;}
#pragma oss atomic seq_cst, capture
  {uix = iv | uix; uiv = uix;}
#pragma oss atomic capture
  iv = ix = ix & uiv;
// <Skip checks for complex calculations>
#pragma oss atomic capture
  {civ = cix; cix = lv + cix;}
#pragma oss atomic capture
  {fx = fx * ulv; fv = fx;}
#pragma oss atomic capture
  dv = dx /= llv;
#pragma oss atomic capture
  {ldv = ldx; ldx -= ullv;}
// <Skip checks for complex calculations>
#pragma oss atomic capture
  {cix = fv / cix; civ = cix;}
#pragma oss atomic capture
  sv = sx = sx + dv;
#pragma oss atomic capture
  {bv = bx; bx = ldv * bx;}
#pragma oss atomic capture
  {bx = civ - bx; bv = bx;}
#pragma oss atomic capture
  {int4x[sv] |= bv; iv = int4x[sv];}
#pragma oss atomic capture
  iv = bfx.a = bfx.a - ldv;
#pragma oss atomic capture
  {iv = bfx_packed.a; bfx_packed.a *= ldv;}
#pragma oss atomic capture
  {bfx2.a -= ldv; iv = bfx2.a;}
#pragma oss atomic capture
  iv = bfx2_packed.a = ldv / bfx2_packed.a;
#pragma oss atomic capture
  {iv = bfx3.a; bfx3.a /= ldv;}
#pragma oss atomic capture
  {bfx3_packed.a += ldv; iv = bfx3_packed.a;}
#pragma oss atomic relaxed capture
  iv = bfx4.a = bfx4.a * ldv;
#pragma oss atomic capture relaxed
  {iv = bfx4_packed.a; bfx4_packed.a -= ldv;}
#pragma oss atomic capture release
  {bfx4.b /= ldv; iv = bfx4.b;}
#pragma oss atomic capture acquire
  iv = bfx4_packed.b += ldv;
#pragma oss atomic capture acq_rel
  {fv = float2x.x; float2x.x = ulv - float2x.x;}
#if defined(__x86_64__)
#pragma oss atomic capture seq_cst
  {rix = dv / rix; iv = rix;}
#pragma oss atomic capture
  {rix = ix; ix = 5;}
#endif
  return 0;
}
#endif
// LIN64-LABEL: define {{[^@]+}}@main
// LIN64-SAME: () #[[ATTR0:[0-9]+]] !dbg [[DBG6:![0-9]+]] {
// LIN64-NEXT:  entry:
// LIN64-NEXT:    [[RETVAL:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca i16, align 2
// LIN64-NEXT:    [[ATOMIC_TEMP10:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP14:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP18:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP22:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP28:%.*]] = alloca double, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP32:%.*]] = alloca x86_fp80, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP34:%.*]] = alloca x86_fp80, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP38:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP40:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP45:%.*]] = alloca { float, float }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP47:%.*]] = alloca { float, float }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP52:%.*]] = alloca { double, double }, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP54:%.*]] = alloca { double, double }, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP64:%.*]] = alloca i8, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP74:%.*]] = alloca i8, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP82:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP89:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP93:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP95:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP107:%.*]] = alloca float, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP113:%.*]] = alloca double, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP117:%.*]] = alloca x86_fp80, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP119:%.*]] = alloca x86_fp80, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP123:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP125:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[COERCE:%.*]] = alloca { float, float }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP135:%.*]] = alloca i16, align 2
// LIN64-NEXT:    [[ATOMIC_TEMP143:%.*]] = alloca i8, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP156:%.*]] = alloca i8, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP169:%.*]] = alloca <4 x i32>, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP171:%.*]] = alloca <4 x i32>, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP172:%.*]] = alloca <4 x i32>, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP178:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP179:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP185:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP187:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP188:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP203:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP204:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP218:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP219:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP233:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP234:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP247:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP249:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP250:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP267:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP268:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP284:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP285:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP300:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP301:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP317:%.*]] = alloca i64, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP318:%.*]] = alloca i64, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP335:%.*]] = alloca <2 x float>, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP336:%.*]] = alloca <2 x float>, align 8
// LIN64-NEXT:    store i32 0, ptr [[RETVAL]], align 4
// LIN64-NEXT:    [[TMP0:%.*]] = atomicrmw add ptr @bx, i8 1 monotonic, align 1, !dbg [[DBG10:![0-9]+]]
// LIN64-NEXT:    store i8 [[TMP0]], ptr @bv, align 1, !dbg [[DBG10]]
// LIN64-NEXT:    [[TMP1:%.*]] = atomicrmw add ptr @cx, i8 1 monotonic, align 1, !dbg [[DBG11:![0-9]+]]
// LIN64-NEXT:    [[CONV:%.*]] = sext i8 [[TMP1]] to i32, !dbg [[DBG12:![0-9]+]]
// LIN64-NEXT:    [[ADD:%.*]] = add nsw i32 [[CONV]], 1, !dbg [[DBG13:![0-9]+]]
// LIN64-NEXT:    [[CONV1:%.*]] = trunc i32 [[ADD]] to i8, !dbg [[DBG12]]
// LIN64-NEXT:    store i8 [[CONV1]], ptr @cv, align 1, !dbg [[DBG11]]
// LIN64-NEXT:    [[TMP2:%.*]] = atomicrmw sub ptr @ucx, i8 1 monotonic, align 1, !dbg [[DBG14:![0-9]+]]
// LIN64-NEXT:    store i8 [[TMP2]], ptr @ucv, align 1, !dbg [[DBG14]]
// LIN64-NEXT:    [[TMP3:%.*]] = atomicrmw sub ptr @sx, i16 1 monotonic, align 2, !dbg [[DBG15:![0-9]+]]
// LIN64-NEXT:    [[CONV2:%.*]] = sext i16 [[TMP3]] to i32, !dbg [[DBG16:![0-9]+]]
// LIN64-NEXT:    [[SUB:%.*]] = sub nsw i32 [[CONV2]], 1, !dbg [[DBG17:![0-9]+]]
// LIN64-NEXT:    [[CONV3:%.*]] = trunc i32 [[SUB]] to i16, !dbg [[DBG16]]
// LIN64-NEXT:    store i16 [[CONV3]], ptr @sv, align 2, !dbg [[DBG15]]
// LIN64-NEXT:    [[TMP4:%.*]] = load i16, ptr @usv, align 2, !dbg [[DBG18:![0-9]+]]
// LIN64-NEXT:    [[CONV4:%.*]] = zext i16 [[TMP4]] to i32, !dbg [[DBG18]]
// LIN64-NEXT:    [[ATOMIC_LOAD:%.*]] = load atomic i16, ptr @usx monotonic, align 2, !dbg [[DBG19:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT:%.*]], !dbg [[DBG19]]
// LIN64:       atomic_cont:
// LIN64-NEXT:    [[TMP5:%.*]] = phi i16 [ [[ATOMIC_LOAD]], [[ENTRY:%.*]] ], [ [[TMP8:%.*]], [[ATOMIC_CONT]] ], !dbg [[DBG19]]
// LIN64-NEXT:    [[CONV5:%.*]] = zext i16 [[TMP5]] to i32, !dbg [[DBG20:![0-9]+]]
// LIN64-NEXT:    [[ADD6:%.*]] = add nsw i32 [[CONV5]], [[CONV4]], !dbg [[DBG21:![0-9]+]]
// LIN64-NEXT:    [[CONV7:%.*]] = trunc i32 [[ADD6]] to i16, !dbg [[DBG20]]
// LIN64-NEXT:    store i16 [[CONV7]], ptr [[ATOMIC_TEMP]], align 2, !dbg [[DBG19]]
// LIN64-NEXT:    [[TMP6:%.*]] = load i16, ptr [[ATOMIC_TEMP]], align 2, !dbg [[DBG19]]
// LIN64-NEXT:    [[TMP7:%.*]] = cmpxchg ptr @usx, i16 [[TMP5]], i16 [[TMP6]] monotonic monotonic, align 2, !dbg [[DBG19]]
// LIN64-NEXT:    [[TMP8]] = extractvalue { i16, i1 } [[TMP7]], 0, !dbg [[DBG19]]
// LIN64-NEXT:    [[TMP9:%.*]] = extractvalue { i16, i1 } [[TMP7]], 1, !dbg [[DBG19]]
// LIN64-NEXT:    br i1 [[TMP9]], label [[ATOMIC_EXIT:%.*]], label [[ATOMIC_CONT]], !dbg [[DBG19]]
// LIN64:       atomic_exit:
// LIN64-NEXT:    store i16 [[CONV7]], ptr @sv, align 2, !dbg [[DBG19]]
// LIN64-NEXT:    [[TMP10:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG22:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD8:%.*]] = load atomic i32, ptr @ix monotonic, align 4, !dbg [[DBG23:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT9:%.*]], !dbg [[DBG23]]
// LIN64:       atomic_cont9:
// LIN64-NEXT:    [[TMP11:%.*]] = phi i32 [ [[ATOMIC_LOAD8]], [[ATOMIC_EXIT]] ], [ [[TMP14:%.*]], [[ATOMIC_CONT9]] ], !dbg [[DBG23]]
// LIN64-NEXT:    [[MUL:%.*]] = mul nsw i32 [[TMP11]], [[TMP10]], !dbg [[DBG24:![0-9]+]]
// LIN64-NEXT:    store i32 [[MUL]], ptr [[ATOMIC_TEMP10]], align 4, !dbg [[DBG23]]
// LIN64-NEXT:    [[TMP12:%.*]] = load i32, ptr [[ATOMIC_TEMP10]], align 4, !dbg [[DBG23]]
// LIN64-NEXT:    [[TMP13:%.*]] = cmpxchg ptr @ix, i32 [[TMP11]], i32 [[TMP12]] monotonic monotonic, align 4, !dbg [[DBG23]]
// LIN64-NEXT:    [[TMP14]] = extractvalue { i32, i1 } [[TMP13]], 0, !dbg [[DBG23]]
// LIN64-NEXT:    [[TMP15:%.*]] = extractvalue { i32, i1 } [[TMP13]], 1, !dbg [[DBG23]]
// LIN64-NEXT:    br i1 [[TMP15]], label [[ATOMIC_EXIT11:%.*]], label [[ATOMIC_CONT9]], !dbg [[DBG23]]
// LIN64:       atomic_exit11:
// LIN64-NEXT:    store i32 [[MUL]], ptr @uiv, align 4, !dbg [[DBG23]]
// LIN64-NEXT:    [[TMP16:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG25:![0-9]+]]
// LIN64-NEXT:    [[TMP17:%.*]] = atomicrmw sub ptr @uix, i32 [[TMP16]] monotonic, align 4, !dbg [[DBG26:![0-9]+]]
// LIN64-NEXT:    store i32 [[TMP17]], ptr @iv, align 4, !dbg [[DBG26]]
// LIN64-NEXT:    [[TMP18:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG27:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD12:%.*]] = load atomic i32, ptr @ix monotonic, align 4, !dbg [[DBG28:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT13:%.*]], !dbg [[DBG28]]
// LIN64:       atomic_cont13:
// LIN64-NEXT:    [[TMP19:%.*]] = phi i32 [ [[ATOMIC_LOAD12]], [[ATOMIC_EXIT11]] ], [ [[TMP22:%.*]], [[ATOMIC_CONT13]] ], !dbg [[DBG28]]
// LIN64-NEXT:    [[SHL:%.*]] = shl i32 [[TMP19]], [[TMP18]], !dbg [[DBG29:![0-9]+]]
// LIN64-NEXT:    store i32 [[SHL]], ptr [[ATOMIC_TEMP14]], align 4, !dbg [[DBG28]]
// LIN64-NEXT:    [[TMP20:%.*]] = load i32, ptr [[ATOMIC_TEMP14]], align 4, !dbg [[DBG28]]
// LIN64-NEXT:    [[TMP21:%.*]] = cmpxchg ptr @ix, i32 [[TMP19]], i32 [[TMP20]] monotonic monotonic, align 4, !dbg [[DBG28]]
// LIN64-NEXT:    [[TMP22]] = extractvalue { i32, i1 } [[TMP21]], 0, !dbg [[DBG28]]
// LIN64-NEXT:    [[TMP23:%.*]] = extractvalue { i32, i1 } [[TMP21]], 1, !dbg [[DBG28]]
// LIN64-NEXT:    br i1 [[TMP23]], label [[ATOMIC_EXIT15:%.*]], label [[ATOMIC_CONT13]], !dbg [[DBG28]]
// LIN64:       atomic_exit15:
// LIN64-NEXT:    store i32 [[SHL]], ptr @uiv, align 4, !dbg [[DBG28]]
// LIN64-NEXT:    [[TMP24:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG30:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD16:%.*]] = load atomic i32, ptr @uix monotonic, align 4, !dbg [[DBG31:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT17:%.*]], !dbg [[DBG31]]
// LIN64:       atomic_cont17:
// LIN64-NEXT:    [[TMP25:%.*]] = phi i32 [ [[ATOMIC_LOAD16]], [[ATOMIC_EXIT15]] ], [ [[TMP28:%.*]], [[ATOMIC_CONT17]] ], !dbg [[DBG31]]
// LIN64-NEXT:    [[SHR:%.*]] = lshr i32 [[TMP25]], [[TMP24]], !dbg [[DBG32:![0-9]+]]
// LIN64-NEXT:    store i32 [[SHR]], ptr [[ATOMIC_TEMP18]], align 4, !dbg [[DBG31]]
// LIN64-NEXT:    [[TMP26:%.*]] = load i32, ptr [[ATOMIC_TEMP18]], align 4, !dbg [[DBG31]]
// LIN64-NEXT:    [[TMP27:%.*]] = cmpxchg ptr @uix, i32 [[TMP25]], i32 [[TMP26]] monotonic monotonic, align 4, !dbg [[DBG31]]
// LIN64-NEXT:    [[TMP28]] = extractvalue { i32, i1 } [[TMP27]], 0, !dbg [[DBG31]]
// LIN64-NEXT:    [[TMP29:%.*]] = extractvalue { i32, i1 } [[TMP27]], 1, !dbg [[DBG31]]
// LIN64-NEXT:    br i1 [[TMP29]], label [[ATOMIC_EXIT19:%.*]], label [[ATOMIC_CONT17]], !dbg [[DBG31]]
// LIN64:       atomic_exit19:
// LIN64-NEXT:    store i32 [[SHR]], ptr @iv, align 4, !dbg [[DBG31]]
// LIN64-NEXT:    [[TMP30:%.*]] = load i64, ptr @lv, align 8, !dbg [[DBG33:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD20:%.*]] = load atomic i64, ptr @lx monotonic, align 8, !dbg [[DBG34:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT21:%.*]], !dbg [[DBG34]]
// LIN64:       atomic_cont21:
// LIN64-NEXT:    [[TMP31:%.*]] = phi i64 [ [[ATOMIC_LOAD20]], [[ATOMIC_EXIT19]] ], [ [[TMP34:%.*]], [[ATOMIC_CONT21]] ], !dbg [[DBG34]]
// LIN64-NEXT:    [[DIV:%.*]] = sdiv i64 [[TMP31]], [[TMP30]], !dbg [[DBG35:![0-9]+]]
// LIN64-NEXT:    store i64 [[DIV]], ptr [[ATOMIC_TEMP22]], align 8, !dbg [[DBG34]]
// LIN64-NEXT:    [[TMP32:%.*]] = load i64, ptr [[ATOMIC_TEMP22]], align 8, !dbg [[DBG34]]
// LIN64-NEXT:    [[TMP33:%.*]] = cmpxchg ptr @lx, i64 [[TMP31]], i64 [[TMP32]] monotonic monotonic, align 8, !dbg [[DBG34]]
// LIN64-NEXT:    [[TMP34]] = extractvalue { i64, i1 } [[TMP33]], 0, !dbg [[DBG34]]
// LIN64-NEXT:    [[TMP35:%.*]] = extractvalue { i64, i1 } [[TMP33]], 1, !dbg [[DBG34]]
// LIN64-NEXT:    br i1 [[TMP35]], label [[ATOMIC_EXIT23:%.*]], label [[ATOMIC_CONT21]], !dbg [[DBG34]]
// LIN64:       atomic_exit23:
// LIN64-NEXT:    store i64 [[TMP31]], ptr @ulv, align 8, !dbg [[DBG34]]
// LIN64-NEXT:    [[TMP36:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG36:![0-9]+]]
// LIN64-NEXT:    [[TMP37:%.*]] = atomicrmw and ptr @ulx, i64 [[TMP36]] monotonic, align 8, !dbg [[DBG37:![0-9]+]]
// LIN64-NEXT:    [[AND:%.*]] = and i64 [[TMP37]], [[TMP36]], !dbg [[DBG38:![0-9]+]]
// LIN64-NEXT:    store i64 [[AND]], ptr @lv, align 8, !dbg [[DBG37]]
// LIN64-NEXT:    [[TMP38:%.*]] = load i64, ptr @llv, align 8, !dbg [[DBG39:![0-9]+]]
// LIN64-NEXT:    [[TMP39:%.*]] = atomicrmw xor ptr @llx, i64 [[TMP38]] monotonic, align 8, !dbg [[DBG40:![0-9]+]]
// LIN64-NEXT:    [[XOR:%.*]] = xor i64 [[TMP39]], [[TMP38]], !dbg [[DBG41:![0-9]+]]
// LIN64-NEXT:    store i64 [[XOR]], ptr @ullv, align 8, !dbg [[DBG40]]
// LIN64-NEXT:    [[TMP40:%.*]] = load i64, ptr @ullv, align 8, !dbg [[DBG42:![0-9]+]]
// LIN64-NEXT:    [[TMP41:%.*]] = atomicrmw or ptr @ullx, i64 [[TMP40]] monotonic, align 8, !dbg [[DBG43:![0-9]+]]
// LIN64-NEXT:    [[OR:%.*]] = or i64 [[TMP41]], [[TMP40]], !dbg [[DBG44:![0-9]+]]
// LIN64-NEXT:    store i64 [[OR]], ptr @llv, align 8, !dbg [[DBG43]]
// LIN64-NEXT:    [[TMP42:%.*]] = load float, ptr @fv, align 4, !dbg [[DBG45:![0-9]+]]
// LIN64-NEXT:    [[TMP43:%.*]] = atomicrmw fadd ptr @fx, float [[TMP42]] monotonic, align 4, !dbg [[DBG46:![0-9]+]]
// LIN64-NEXT:    [[ADD24:%.*]] = fadd float [[TMP43]], [[TMP42]], !dbg [[DBG47:![0-9]+]]
// LIN64-NEXT:    [[CONV25:%.*]] = fpext float [[ADD24]] to double, !dbg [[DBG46]]
// LIN64-NEXT:    store double [[CONV25]], ptr @dv, align 8, !dbg [[DBG46]]
// LIN64-NEXT:    [[TMP44:%.*]] = load double, ptr @dv, align 8, !dbg [[DBG48:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD26:%.*]] = load atomic i64, ptr @dx monotonic, align 8, !dbg [[DBG49:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT27:%.*]], !dbg [[DBG49]]
// LIN64:       atomic_cont27:
// LIN64-NEXT:    [[TMP45:%.*]] = phi i64 [ [[ATOMIC_LOAD26]], [[ATOMIC_EXIT23]] ], [ [[TMP49:%.*]], [[ATOMIC_CONT27]] ], !dbg [[DBG49]]
// LIN64-NEXT:    [[TMP46:%.*]] = bitcast i64 [[TMP45]] to double, !dbg [[DBG49]]
// LIN64-NEXT:    [[SUB29:%.*]] = fsub double [[TMP44]], [[TMP46]], !dbg [[DBG50:![0-9]+]]
// LIN64-NEXT:    store double [[SUB29]], ptr [[ATOMIC_TEMP28]], align 8, !dbg [[DBG49]]
// LIN64-NEXT:    [[TMP47:%.*]] = load i64, ptr [[ATOMIC_TEMP28]], align 8, !dbg [[DBG49]]
// LIN64-NEXT:    [[TMP48:%.*]] = cmpxchg ptr @dx, i64 [[TMP45]], i64 [[TMP47]] monotonic monotonic, align 8, !dbg [[DBG49]]
// LIN64-NEXT:    [[TMP49]] = extractvalue { i64, i1 } [[TMP48]], 0, !dbg [[DBG49]]
// LIN64-NEXT:    [[TMP50:%.*]] = extractvalue { i64, i1 } [[TMP48]], 1, !dbg [[DBG49]]
// LIN64-NEXT:    br i1 [[TMP50]], label [[ATOMIC_EXIT30:%.*]], label [[ATOMIC_CONT27]], !dbg [[DBG49]]
// LIN64:       atomic_exit30:
// LIN64-NEXT:    [[CONV31:%.*]] = fptrunc double [[TMP46]] to float, !dbg [[DBG49]]
// LIN64-NEXT:    store float [[CONV31]], ptr @fv, align 4, !dbg [[DBG49]]
// LIN64-NEXT:    [[TMP51:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG51:![0-9]+]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 16, ptr noundef @ldx, ptr noundef [[ATOMIC_TEMP32]], i32 noundef 0), !dbg [[DBG52:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT33:%.*]], !dbg [[DBG52]]
// LIN64:       atomic_cont33:
// LIN64-NEXT:    [[TMP52:%.*]] = load x86_fp80, ptr [[ATOMIC_TEMP32]], align 16, !dbg [[DBG52]]
// LIN64-NEXT:    store x86_fp80 [[TMP52]], ptr [[ATOMIC_TEMP34]], align 16, !dbg [[DBG52]]
// LIN64-NEXT:    [[TMP53:%.*]] = load x86_fp80, ptr [[ATOMIC_TEMP32]], align 16, !dbg [[DBG52]]
// LIN64-NEXT:    [[MUL35:%.*]] = fmul x86_fp80 [[TMP53]], [[TMP51]], !dbg [[DBG53:![0-9]+]]
// LIN64-NEXT:    store x86_fp80 [[MUL35]], ptr [[ATOMIC_TEMP34]], align 16, !dbg [[DBG52]]
// LIN64-NEXT:    [[CALL:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, ptr noundef @ldx, ptr noundef [[ATOMIC_TEMP32]], ptr noundef [[ATOMIC_TEMP34]], i32 noundef 0, i32 noundef 0), !dbg [[DBG52]]
// LIN64-NEXT:    br i1 [[CALL]], label [[ATOMIC_EXIT36:%.*]], label [[ATOMIC_CONT33]], !dbg [[DBG52]]
// LIN64:       atomic_exit36:
// LIN64-NEXT:    [[CONV37:%.*]] = fptrunc x86_fp80 [[MUL35]] to double, !dbg [[DBG52]]
// LIN64-NEXT:    store double [[CONV37]], ptr @dv, align 8, !dbg [[DBG52]]
// LIN64-NEXT:    [[CIV_REAL:%.*]] = load i32, ptr @civ, align 4, !dbg [[DBG54:![0-9]+]]
// LIN64-NEXT:    [[CIV_IMAG:%.*]] = load i32, ptr getelementptr inbounds ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG54]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP38]], i32 noundef 0), !dbg [[DBG55:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT39:%.*]], !dbg [[DBG55]]
// LIN64:       atomic_cont39:
// LIN64-NEXT:    [[ATOMIC_TEMP38_REALP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP38]], i32 0, i32 0, !dbg [[DBG55]]
// LIN64-NEXT:    [[ATOMIC_TEMP38_REAL:%.*]] = load i32, ptr [[ATOMIC_TEMP38_REALP]], align 4, !dbg [[DBG55]]
// LIN64-NEXT:    [[ATOMIC_TEMP38_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP38]], i32 0, i32 1, !dbg [[DBG55]]
// LIN64-NEXT:    [[ATOMIC_TEMP38_IMAG:%.*]] = load i32, ptr [[ATOMIC_TEMP38_IMAGP]], align 4, !dbg [[DBG55]]
// LIN64-NEXT:    [[TMP54:%.*]] = mul i32 [[CIV_REAL]], [[ATOMIC_TEMP38_REAL]], !dbg [[DBG56:![0-9]+]]
// LIN64-NEXT:    [[TMP55:%.*]] = mul i32 [[CIV_IMAG]], [[ATOMIC_TEMP38_IMAG]], !dbg [[DBG56]]
// LIN64-NEXT:    [[TMP56:%.*]] = add i32 [[TMP54]], [[TMP55]], !dbg [[DBG56]]
// LIN64-NEXT:    [[TMP57:%.*]] = mul i32 [[ATOMIC_TEMP38_REAL]], [[ATOMIC_TEMP38_REAL]], !dbg [[DBG56]]
// LIN64-NEXT:    [[TMP58:%.*]] = mul i32 [[ATOMIC_TEMP38_IMAG]], [[ATOMIC_TEMP38_IMAG]], !dbg [[DBG56]]
// LIN64-NEXT:    [[TMP59:%.*]] = add i32 [[TMP57]], [[TMP58]], !dbg [[DBG56]]
// LIN64-NEXT:    [[TMP60:%.*]] = mul i32 [[CIV_IMAG]], [[ATOMIC_TEMP38_REAL]], !dbg [[DBG56]]
// LIN64-NEXT:    [[TMP61:%.*]] = mul i32 [[CIV_REAL]], [[ATOMIC_TEMP38_IMAG]], !dbg [[DBG56]]
// LIN64-NEXT:    [[TMP62:%.*]] = sub i32 [[TMP60]], [[TMP61]], !dbg [[DBG56]]
// LIN64-NEXT:    [[TMP63:%.*]] = sdiv i32 [[TMP56]], [[TMP59]], !dbg [[DBG56]]
// LIN64-NEXT:    [[TMP64:%.*]] = sdiv i32 [[TMP62]], [[TMP59]], !dbg [[DBG56]]
// LIN64-NEXT:    [[ATOMIC_TEMP40_REALP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP40]], i32 0, i32 0, !dbg [[DBG55]]
// LIN64-NEXT:    [[ATOMIC_TEMP40_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP40]], i32 0, i32 1, !dbg [[DBG55]]
// LIN64-NEXT:    store i32 [[TMP63]], ptr [[ATOMIC_TEMP40_REALP]], align 4, !dbg [[DBG55]]
// LIN64-NEXT:    store i32 [[TMP64]], ptr [[ATOMIC_TEMP40_IMAGP]], align 4, !dbg [[DBG55]]
// LIN64-NEXT:    [[CALL41:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP38]], ptr noundef [[ATOMIC_TEMP40]], i32 noundef 0, i32 noundef 0), !dbg [[DBG55]]
// LIN64-NEXT:    br i1 [[CALL41]], label [[ATOMIC_EXIT42:%.*]], label [[ATOMIC_CONT39]], !dbg [[DBG55]]
// LIN64:       atomic_exit42:
// LIN64-NEXT:    [[CONV43:%.*]] = sitofp i32 [[TMP63]] to float, !dbg [[DBG55]]
// LIN64-NEXT:    [[CONV44:%.*]] = sitofp i32 [[TMP64]] to float, !dbg [[DBG55]]
// LIN64-NEXT:    store float [[CONV43]], ptr @cfv, align 4, !dbg [[DBG55]]
// LIN64-NEXT:    store float [[CONV44]], ptr getelementptr inbounds ({ float, float }, ptr @cfv, i32 0, i32 1), align 4, !dbg [[DBG55]]
// LIN64-NEXT:    [[CFV_REAL:%.*]] = load float, ptr @cfv, align 4, !dbg [[DBG57:![0-9]+]]
// LIN64-NEXT:    [[CFV_IMAG:%.*]] = load float, ptr getelementptr inbounds ({ float, float }, ptr @cfv, i32 0, i32 1), align 4, !dbg [[DBG57]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cfx, ptr noundef [[ATOMIC_TEMP45]], i32 noundef 0), !dbg [[DBG58:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT46:%.*]], !dbg [[DBG58]]
// LIN64:       atomic_cont46:
// LIN64-NEXT:    [[ATOMIC_TEMP45_REALP:%.*]] = getelementptr inbounds { float, float }, ptr [[ATOMIC_TEMP45]], i32 0, i32 0, !dbg [[DBG58]]
// LIN64-NEXT:    [[ATOMIC_TEMP45_REAL:%.*]] = load float, ptr [[ATOMIC_TEMP45_REALP]], align 4, !dbg [[DBG58]]
// LIN64-NEXT:    [[ATOMIC_TEMP45_IMAGP:%.*]] = getelementptr inbounds { float, float }, ptr [[ATOMIC_TEMP45]], i32 0, i32 1, !dbg [[DBG58]]
// LIN64-NEXT:    [[ATOMIC_TEMP45_IMAG:%.*]] = load float, ptr [[ATOMIC_TEMP45_IMAGP]], align 4, !dbg [[DBG58]]
// LIN64-NEXT:    [[ADD_R:%.*]] = fadd float [[CFV_REAL]], [[ATOMIC_TEMP45_REAL]], !dbg [[DBG59:![0-9]+]]
// LIN64-NEXT:    [[ADD_I:%.*]] = fadd float [[CFV_IMAG]], [[ATOMIC_TEMP45_IMAG]], !dbg [[DBG59]]
// LIN64-NEXT:    [[ATOMIC_TEMP47_REALP:%.*]] = getelementptr inbounds { float, float }, ptr [[ATOMIC_TEMP47]], i32 0, i32 0, !dbg [[DBG58]]
// LIN64-NEXT:    [[ATOMIC_TEMP47_IMAGP:%.*]] = getelementptr inbounds { float, float }, ptr [[ATOMIC_TEMP47]], i32 0, i32 1, !dbg [[DBG58]]
// LIN64-NEXT:    store float [[ADD_R]], ptr [[ATOMIC_TEMP47_REALP]], align 4, !dbg [[DBG58]]
// LIN64-NEXT:    store float [[ADD_I]], ptr [[ATOMIC_TEMP47_IMAGP]], align 4, !dbg [[DBG58]]
// LIN64-NEXT:    [[CALL48:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cfx, ptr noundef [[ATOMIC_TEMP45]], ptr noundef [[ATOMIC_TEMP47]], i32 noundef 0, i32 noundef 0), !dbg [[DBG58]]
// LIN64-NEXT:    br i1 [[CALL48]], label [[ATOMIC_EXIT49:%.*]], label [[ATOMIC_CONT46]], !dbg [[DBG58]]
// LIN64:       atomic_exit49:
// LIN64-NEXT:    [[CONV50:%.*]] = fptosi float [[ATOMIC_TEMP45_REAL]] to i32, !dbg [[DBG58]]
// LIN64-NEXT:    [[CONV51:%.*]] = fptosi float [[ATOMIC_TEMP45_IMAG]] to i32, !dbg [[DBG58]]
// LIN64-NEXT:    store i32 [[CONV50]], ptr @civ, align 4, !dbg [[DBG58]]
// LIN64-NEXT:    store i32 [[CONV51]], ptr getelementptr inbounds ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG58]]
// LIN64-NEXT:    [[CDV_REAL:%.*]] = load double, ptr @cdv, align 8, !dbg [[DBG60:![0-9]+]]
// LIN64-NEXT:    [[CDV_IMAG:%.*]] = load double, ptr getelementptr inbounds ({ double, double }, ptr @cdv, i32 0, i32 1), align 8, !dbg [[DBG60]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 16, ptr noundef @cdx, ptr noundef [[ATOMIC_TEMP52]], i32 noundef 5), !dbg [[DBG61:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT53:%.*]], !dbg [[DBG61]]
// LIN64:       atomic_cont53:
// LIN64-NEXT:    [[ATOMIC_TEMP52_REALP:%.*]] = getelementptr inbounds { double, double }, ptr [[ATOMIC_TEMP52]], i32 0, i32 0, !dbg [[DBG61]]
// LIN64-NEXT:    [[ATOMIC_TEMP52_REAL:%.*]] = load double, ptr [[ATOMIC_TEMP52_REALP]], align 8, !dbg [[DBG61]]
// LIN64-NEXT:    [[ATOMIC_TEMP52_IMAGP:%.*]] = getelementptr inbounds { double, double }, ptr [[ATOMIC_TEMP52]], i32 0, i32 1, !dbg [[DBG61]]
// LIN64-NEXT:    [[ATOMIC_TEMP52_IMAG:%.*]] = load double, ptr [[ATOMIC_TEMP52_IMAGP]], align 8, !dbg [[DBG61]]
// LIN64-NEXT:    [[SUB_R:%.*]] = fsub double [[ATOMIC_TEMP52_REAL]], [[CDV_REAL]], !dbg [[DBG62:![0-9]+]]
// LIN64-NEXT:    [[SUB_I:%.*]] = fsub double [[ATOMIC_TEMP52_IMAG]], [[CDV_IMAG]], !dbg [[DBG62]]
// LIN64-NEXT:    [[ATOMIC_TEMP54_REALP:%.*]] = getelementptr inbounds { double, double }, ptr [[ATOMIC_TEMP54]], i32 0, i32 0, !dbg [[DBG61]]
// LIN64-NEXT:    [[ATOMIC_TEMP54_IMAGP:%.*]] = getelementptr inbounds { double, double }, ptr [[ATOMIC_TEMP54]], i32 0, i32 1, !dbg [[DBG61]]
// LIN64-NEXT:    store double [[SUB_R]], ptr [[ATOMIC_TEMP54_REALP]], align 8, !dbg [[DBG61]]
// LIN64-NEXT:    store double [[SUB_I]], ptr [[ATOMIC_TEMP54_IMAGP]], align 8, !dbg [[DBG61]]
// LIN64-NEXT:    [[CALL55:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, ptr noundef @cdx, ptr noundef [[ATOMIC_TEMP52]], ptr noundef [[ATOMIC_TEMP54]], i32 noundef 5, i32 noundef 5), !dbg [[DBG61]]
// LIN64-NEXT:    br i1 [[CALL55]], label [[ATOMIC_EXIT56:%.*]], label [[ATOMIC_CONT53]], !dbg [[DBG61]]
// LIN64:       atomic_exit56:
// LIN64-NEXT:    [[CONV57:%.*]] = fptrunc double [[SUB_R]] to float, !dbg [[DBG61]]
// LIN64-NEXT:    [[CONV58:%.*]] = fptrunc double [[SUB_I]] to float, !dbg [[DBG61]]
// LIN64-NEXT:    store float [[CONV57]], ptr @cfv, align 4, !dbg [[DBG61]]
// LIN64-NEXT:    store float [[CONV58]], ptr getelementptr inbounds ({ float, float }, ptr @cfv, i32 0, i32 1), align 4, !dbg [[DBG61]]
// LIN64-NEXT:    [[TMP65:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG63:![0-9]+]]
// LIN64-NEXT:    [[TOBOOL:%.*]] = trunc i8 [[TMP65]] to i1, !dbg [[DBG63]]
// LIN64-NEXT:    [[CONV59:%.*]] = zext i1 [[TOBOOL]] to i64, !dbg [[DBG63]]
// LIN64-NEXT:    [[TMP66:%.*]] = atomicrmw and ptr @ulx, i64 [[CONV59]] monotonic, align 8, !dbg [[DBG64:![0-9]+]]
// LIN64-NEXT:    [[AND60:%.*]] = and i64 [[TMP66]], [[CONV59]], !dbg [[DBG65:![0-9]+]]
// LIN64-NEXT:    store i64 [[AND60]], ptr @ulv, align 8, !dbg [[DBG64]]
// LIN64-NEXT:    [[TMP67:%.*]] = load i8, ptr @cv, align 1, !dbg [[DBG66:![0-9]+]]
// LIN64-NEXT:    [[CONV61:%.*]] = sext i8 [[TMP67]] to i32, !dbg [[DBG66]]
// LIN64-NEXT:    [[ATOMIC_LOAD62:%.*]] = load atomic i8, ptr @bx monotonic, align 1, !dbg [[DBG67:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT63:%.*]], !dbg [[DBG67]]
// LIN64:       atomic_cont63:
// LIN64-NEXT:    [[TMP68:%.*]] = phi i8 [ [[ATOMIC_LOAD62]], [[ATOMIC_EXIT56]] ], [ [[TMP71:%.*]], [[ATOMIC_CONT63]] ], !dbg [[DBG67]]
// LIN64-NEXT:    [[TOBOOL65:%.*]] = trunc i8 [[TMP68]] to i1, !dbg [[DBG67]]
// LIN64-NEXT:    [[CONV66:%.*]] = zext i1 [[TOBOOL65]] to i32, !dbg [[DBG68:![0-9]+]]
// LIN64-NEXT:    [[AND67:%.*]] = and i32 [[CONV61]], [[CONV66]], !dbg [[DBG69:![0-9]+]]
// LIN64-NEXT:    [[TOBOOL68:%.*]] = icmp ne i32 [[AND67]], 0, !dbg [[DBG66]]
// LIN64-NEXT:    [[FROMBOOL:%.*]] = zext i1 [[TOBOOL68]] to i8, !dbg [[DBG67]]
// LIN64-NEXT:    store i8 [[FROMBOOL]], ptr [[ATOMIC_TEMP64]], align 1, !dbg [[DBG67]]
// LIN64-NEXT:    [[TMP69:%.*]] = load i8, ptr [[ATOMIC_TEMP64]], align 1, !dbg [[DBG67]]
// LIN64-NEXT:    [[TMP70:%.*]] = cmpxchg ptr @bx, i8 [[TMP68]], i8 [[TMP69]] monotonic monotonic, align 1, !dbg [[DBG67]]
// LIN64-NEXT:    [[TMP71]] = extractvalue { i8, i1 } [[TMP70]], 0, !dbg [[DBG67]]
// LIN64-NEXT:    [[TMP72:%.*]] = extractvalue { i8, i1 } [[TMP70]], 1, !dbg [[DBG67]]
// LIN64-NEXT:    br i1 [[TMP72]], label [[ATOMIC_EXIT69:%.*]], label [[ATOMIC_CONT63]], !dbg [[DBG67]]
// LIN64:       atomic_exit69:
// LIN64-NEXT:    [[FROMBOOL70:%.*]] = zext i1 [[TOBOOL65]] to i8, !dbg [[DBG67]]
// LIN64-NEXT:    store i8 [[FROMBOOL70]], ptr @bv, align 1, !dbg [[DBG67]]
// LIN64-NEXT:    [[TMP73:%.*]] = load i8, ptr @ucv, align 1, !dbg [[DBG70:![0-9]+]]
// LIN64-NEXT:    [[CONV71:%.*]] = zext i8 [[TMP73]] to i32, !dbg [[DBG70]]
// LIN64-NEXT:    [[ATOMIC_LOAD72:%.*]] = load atomic i8, ptr @cx seq_cst, align 1, !dbg [[DBG71:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT73:%.*]], !dbg [[DBG71]]
// LIN64:       atomic_cont73:
// LIN64-NEXT:    [[TMP74:%.*]] = phi i8 [ [[ATOMIC_LOAD72]], [[ATOMIC_EXIT69]] ], [ [[TMP77:%.*]], [[ATOMIC_CONT73]] ], !dbg [[DBG71]]
// LIN64-NEXT:    [[CONV75:%.*]] = sext i8 [[TMP74]] to i32, !dbg [[DBG72:![0-9]+]]
// LIN64-NEXT:    [[SHR76:%.*]] = ashr i32 [[CONV75]], [[CONV71]], !dbg [[DBG73:![0-9]+]]
// LIN64-NEXT:    [[CONV77:%.*]] = trunc i32 [[SHR76]] to i8, !dbg [[DBG72]]
// LIN64-NEXT:    store i8 [[CONV77]], ptr [[ATOMIC_TEMP74]], align 1, !dbg [[DBG71]]
// LIN64-NEXT:    [[TMP75:%.*]] = load i8, ptr [[ATOMIC_TEMP74]], align 1, !dbg [[DBG71]]
// LIN64-NEXT:    [[TMP76:%.*]] = cmpxchg ptr @cx, i8 [[TMP74]], i8 [[TMP75]] seq_cst seq_cst, align 1, !dbg [[DBG71]]
// LIN64-NEXT:    [[TMP77]] = extractvalue { i8, i1 } [[TMP76]], 0, !dbg [[DBG71]]
// LIN64-NEXT:    [[TMP78:%.*]] = extractvalue { i8, i1 } [[TMP76]], 1, !dbg [[DBG71]]
// LIN64-NEXT:    br i1 [[TMP78]], label [[ATOMIC_EXIT78:%.*]], label [[ATOMIC_CONT73]], !dbg [[DBG71]]
// LIN64:       atomic_exit78:
// LIN64-NEXT:    store i8 [[CONV77]], ptr @cv, align 1, !dbg [[DBG71]]
// LIN64-NEXT:    [[TMP79:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG74:![0-9]+]]
// LIN64-NEXT:    [[CONV79:%.*]] = sext i16 [[TMP79]] to i32, !dbg [[DBG74]]
// LIN64-NEXT:    [[ATOMIC_LOAD80:%.*]] = load atomic i64, ptr @ulx monotonic, align 8, !dbg [[DBG75:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT81:%.*]], !dbg [[DBG75]]
// LIN64:       atomic_cont81:
// LIN64-NEXT:    [[TMP80:%.*]] = phi i64 [ [[ATOMIC_LOAD80]], [[ATOMIC_EXIT78]] ], [ [[TMP83:%.*]], [[ATOMIC_CONT81]] ], !dbg [[DBG75]]
// LIN64-NEXT:    [[SH_PROM:%.*]] = trunc i64 [[TMP80]] to i32, !dbg [[DBG76:![0-9]+]]
// LIN64-NEXT:    [[SHL83:%.*]] = shl i32 [[CONV79]], [[SH_PROM]], !dbg [[DBG76]]
// LIN64-NEXT:    [[CONV84:%.*]] = sext i32 [[SHL83]] to i64, !dbg [[DBG74]]
// LIN64-NEXT:    store i64 [[CONV84]], ptr [[ATOMIC_TEMP82]], align 8, !dbg [[DBG75]]
// LIN64-NEXT:    [[TMP81:%.*]] = load i64, ptr [[ATOMIC_TEMP82]], align 8, !dbg [[DBG75]]
// LIN64-NEXT:    [[TMP82:%.*]] = cmpxchg ptr @ulx, i64 [[TMP80]], i64 [[TMP81]] monotonic monotonic, align 8, !dbg [[DBG75]]
// LIN64-NEXT:    [[TMP83]] = extractvalue { i64, i1 } [[TMP82]], 0, !dbg [[DBG75]]
// LIN64-NEXT:    [[TMP84:%.*]] = extractvalue { i64, i1 } [[TMP82]], 1, !dbg [[DBG75]]
// LIN64-NEXT:    br i1 [[TMP84]], label [[ATOMIC_EXIT85:%.*]], label [[ATOMIC_CONT81]], !dbg [[DBG75]]
// LIN64:       atomic_exit85:
// LIN64-NEXT:    store i64 [[CONV84]], ptr @ulv, align 8, !dbg [[DBG75]]
// LIN64-NEXT:    [[TMP85:%.*]] = load i16, ptr @usv, align 2, !dbg [[DBG77:![0-9]+]]
// LIN64-NEXT:    [[CONV86:%.*]] = zext i16 [[TMP85]] to i64, !dbg [[DBG77]]
// LIN64-NEXT:    [[ATOMIC_LOAD87:%.*]] = load atomic i64, ptr @lx monotonic, align 8, !dbg [[DBG78:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT88:%.*]], !dbg [[DBG78]]
// LIN64:       atomic_cont88:
// LIN64-NEXT:    [[TMP86:%.*]] = phi i64 [ [[ATOMIC_LOAD87]], [[ATOMIC_EXIT85]] ], [ [[TMP89:%.*]], [[ATOMIC_CONT88]] ], !dbg [[DBG78]]
// LIN64-NEXT:    [[REM:%.*]] = srem i64 [[TMP86]], [[CONV86]], !dbg [[DBG79:![0-9]+]]
// LIN64-NEXT:    store i64 [[REM]], ptr [[ATOMIC_TEMP89]], align 8, !dbg [[DBG78]]
// LIN64-NEXT:    [[TMP87:%.*]] = load i64, ptr [[ATOMIC_TEMP89]], align 8, !dbg [[DBG78]]
// LIN64-NEXT:    [[TMP88:%.*]] = cmpxchg ptr @lx, i64 [[TMP86]], i64 [[TMP87]] monotonic monotonic, align 8, !dbg [[DBG78]]
// LIN64-NEXT:    [[TMP89]] = extractvalue { i64, i1 } [[TMP88]], 0, !dbg [[DBG78]]
// LIN64-NEXT:    [[TMP90:%.*]] = extractvalue { i64, i1 } [[TMP88]], 1, !dbg [[DBG78]]
// LIN64-NEXT:    br i1 [[TMP90]], label [[ATOMIC_EXIT90:%.*]], label [[ATOMIC_CONT88]], !dbg [[DBG78]]
// LIN64:       atomic_exit90:
// LIN64-NEXT:    store i64 [[TMP86]], ptr @lv, align 8, !dbg [[DBG78]]
// LIN64-NEXT:    [[TMP91:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG80:![0-9]+]]
// LIN64-NEXT:    [[TMP92:%.*]] = atomicrmw or ptr @uix, i32 [[TMP91]] seq_cst, align 4, !dbg [[DBG81:![0-9]+]]
// LIN64-NEXT:    [[OR91:%.*]] = or i32 [[TMP91]], [[TMP92]], !dbg [[DBG82:![0-9]+]]
// LIN64-NEXT:    store i32 [[OR91]], ptr @uiv, align 4, !dbg [[DBG81]]
// LIN64-NEXT:    [[TMP93:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG83:![0-9]+]]
// LIN64-NEXT:    [[TMP94:%.*]] = atomicrmw and ptr @ix, i32 [[TMP93]] monotonic, align 4, !dbg [[DBG84:![0-9]+]]
// LIN64-NEXT:    [[AND92:%.*]] = and i32 [[TMP94]], [[TMP93]], !dbg [[DBG85:![0-9]+]]
// LIN64-NEXT:    store i32 [[AND92]], ptr @iv, align 4, !dbg [[DBG84]]
// LIN64-NEXT:    [[TMP95:%.*]] = load i64, ptr @lv, align 8, !dbg [[DBG86:![0-9]+]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP93]], i32 noundef 0), !dbg [[DBG87:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT94:%.*]], !dbg [[DBG87]]
// LIN64:       atomic_cont94:
// LIN64-NEXT:    [[ATOMIC_TEMP93_REALP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP93]], i32 0, i32 0, !dbg [[DBG87]]
// LIN64-NEXT:    [[ATOMIC_TEMP93_REAL:%.*]] = load i32, ptr [[ATOMIC_TEMP93_REALP]], align 4, !dbg [[DBG87]]
// LIN64-NEXT:    [[ATOMIC_TEMP93_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP93]], i32 0, i32 1, !dbg [[DBG87]]
// LIN64-NEXT:    [[ATOMIC_TEMP93_IMAG:%.*]] = load i32, ptr [[ATOMIC_TEMP93_IMAGP]], align 4, !dbg [[DBG87]]
// LIN64-NEXT:    [[CONV96:%.*]] = sext i32 [[ATOMIC_TEMP93_REAL]] to i64, !dbg [[DBG88:![0-9]+]]
// LIN64-NEXT:    [[CONV97:%.*]] = sext i32 [[ATOMIC_TEMP93_IMAG]] to i64, !dbg [[DBG88]]
// LIN64-NEXT:    [[ADD_R98:%.*]] = add i64 [[TMP95]], [[CONV96]], !dbg [[DBG89:![0-9]+]]
// LIN64-NEXT:    [[ADD_I99:%.*]] = add i64 0, [[CONV97]], !dbg [[DBG89]]
// LIN64-NEXT:    [[CONV100:%.*]] = trunc i64 [[ADD_R98]] to i32, !dbg [[DBG86]]
// LIN64-NEXT:    [[CONV101:%.*]] = trunc i64 [[ADD_I99]] to i32, !dbg [[DBG86]]
// LIN64-NEXT:    [[ATOMIC_TEMP95_REALP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP95]], i32 0, i32 0, !dbg [[DBG87]]
// LIN64-NEXT:    [[ATOMIC_TEMP95_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP95]], i32 0, i32 1, !dbg [[DBG87]]
// LIN64-NEXT:    store i32 [[CONV100]], ptr [[ATOMIC_TEMP95_REALP]], align 4, !dbg [[DBG87]]
// LIN64-NEXT:    store i32 [[CONV101]], ptr [[ATOMIC_TEMP95_IMAGP]], align 4, !dbg [[DBG87]]
// LIN64-NEXT:    [[CALL102:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP93]], ptr noundef [[ATOMIC_TEMP95]], i32 noundef 0, i32 noundef 0), !dbg [[DBG87]]
// LIN64-NEXT:    br i1 [[CALL102]], label [[ATOMIC_EXIT103:%.*]], label [[ATOMIC_CONT94]], !dbg [[DBG87]]
// LIN64:       atomic_exit103:
// LIN64-NEXT:    store i32 [[ATOMIC_TEMP93_REAL]], ptr @civ, align 4, !dbg [[DBG87]]
// LIN64-NEXT:    store i32 [[ATOMIC_TEMP93_IMAG]], ptr getelementptr inbounds ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG87]]
// LIN64-NEXT:    [[TMP96:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG90:![0-9]+]]
// LIN64-NEXT:    [[CONV104:%.*]] = uitofp i64 [[TMP96]] to float, !dbg [[DBG90]]
// LIN64-NEXT:    [[ATOMIC_LOAD105:%.*]] = load atomic i32, ptr @fx monotonic, align 4, !dbg [[DBG91:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT106:%.*]], !dbg [[DBG91]]
// LIN64:       atomic_cont106:
// LIN64-NEXT:    [[TMP97:%.*]] = phi i32 [ [[ATOMIC_LOAD105]], [[ATOMIC_EXIT103]] ], [ [[TMP101:%.*]], [[ATOMIC_CONT106]] ], !dbg [[DBG91]]
// LIN64-NEXT:    [[TMP98:%.*]] = bitcast i32 [[TMP97]] to float, !dbg [[DBG91]]
// LIN64-NEXT:    [[MUL108:%.*]] = fmul float [[TMP98]], [[CONV104]], !dbg [[DBG92:![0-9]+]]
// LIN64-NEXT:    store float [[MUL108]], ptr [[ATOMIC_TEMP107]], align 4, !dbg [[DBG91]]
// LIN64-NEXT:    [[TMP99:%.*]] = load i32, ptr [[ATOMIC_TEMP107]], align 4, !dbg [[DBG91]]
// LIN64-NEXT:    [[TMP100:%.*]] = cmpxchg ptr @fx, i32 [[TMP97]], i32 [[TMP99]] monotonic monotonic, align 4, !dbg [[DBG91]]
// LIN64-NEXT:    [[TMP101]] = extractvalue { i32, i1 } [[TMP100]], 0, !dbg [[DBG91]]
// LIN64-NEXT:    [[TMP102:%.*]] = extractvalue { i32, i1 } [[TMP100]], 1, !dbg [[DBG91]]
// LIN64-NEXT:    br i1 [[TMP102]], label [[ATOMIC_EXIT109:%.*]], label [[ATOMIC_CONT106]], !dbg [[DBG91]]
// LIN64:       atomic_exit109:
// LIN64-NEXT:    store float [[MUL108]], ptr @fv, align 4, !dbg [[DBG91]]
// LIN64-NEXT:    [[TMP103:%.*]] = load i64, ptr @llv, align 8, !dbg [[DBG93:![0-9]+]]
// LIN64-NEXT:    [[CONV110:%.*]] = sitofp i64 [[TMP103]] to double, !dbg [[DBG93]]
// LIN64-NEXT:    [[ATOMIC_LOAD111:%.*]] = load atomic i64, ptr @dx monotonic, align 8, !dbg [[DBG94:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT112:%.*]], !dbg [[DBG94]]
// LIN64:       atomic_cont112:
// LIN64-NEXT:    [[TMP104:%.*]] = phi i64 [ [[ATOMIC_LOAD111]], [[ATOMIC_EXIT109]] ], [ [[TMP108:%.*]], [[ATOMIC_CONT112]] ], !dbg [[DBG94]]
// LIN64-NEXT:    [[TMP105:%.*]] = bitcast i64 [[TMP104]] to double, !dbg [[DBG94]]
// LIN64-NEXT:    [[DIV114:%.*]] = fdiv double [[TMP105]], [[CONV110]], !dbg [[DBG95:![0-9]+]]
// LIN64-NEXT:    store double [[DIV114]], ptr [[ATOMIC_TEMP113]], align 8, !dbg [[DBG94]]
// LIN64-NEXT:    [[TMP106:%.*]] = load i64, ptr [[ATOMIC_TEMP113]], align 8, !dbg [[DBG94]]
// LIN64-NEXT:    [[TMP107:%.*]] = cmpxchg ptr @dx, i64 [[TMP104]], i64 [[TMP106]] monotonic monotonic, align 8, !dbg [[DBG94]]
// LIN64-NEXT:    [[TMP108]] = extractvalue { i64, i1 } [[TMP107]], 0, !dbg [[DBG94]]
// LIN64-NEXT:    [[TMP109:%.*]] = extractvalue { i64, i1 } [[TMP107]], 1, !dbg [[DBG94]]
// LIN64-NEXT:    br i1 [[TMP109]], label [[ATOMIC_EXIT115:%.*]], label [[ATOMIC_CONT112]], !dbg [[DBG94]]
// LIN64:       atomic_exit115:
// LIN64-NEXT:    store double [[DIV114]], ptr @dv, align 8, !dbg [[DBG94]]
// LIN64-NEXT:    [[TMP110:%.*]] = load i64, ptr @ullv, align 8, !dbg [[DBG96:![0-9]+]]
// LIN64-NEXT:    [[CONV116:%.*]] = uitofp i64 [[TMP110]] to x86_fp80, !dbg [[DBG96]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 16, ptr noundef @ldx, ptr noundef [[ATOMIC_TEMP117]], i32 noundef 0), !dbg [[DBG97:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT118:%.*]], !dbg [[DBG97]]
// LIN64:       atomic_cont118:
// LIN64-NEXT:    [[TMP111:%.*]] = load x86_fp80, ptr [[ATOMIC_TEMP117]], align 16, !dbg [[DBG97]]
// LIN64-NEXT:    store x86_fp80 [[TMP111]], ptr [[ATOMIC_TEMP119]], align 16, !dbg [[DBG97]]
// LIN64-NEXT:    [[TMP112:%.*]] = load x86_fp80, ptr [[ATOMIC_TEMP117]], align 16, !dbg [[DBG97]]
// LIN64-NEXT:    [[SUB120:%.*]] = fsub x86_fp80 [[TMP112]], [[CONV116]], !dbg [[DBG98:![0-9]+]]
// LIN64-NEXT:    store x86_fp80 [[SUB120]], ptr [[ATOMIC_TEMP119]], align 16, !dbg [[DBG97]]
// LIN64-NEXT:    [[CALL121:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, ptr noundef @ldx, ptr noundef [[ATOMIC_TEMP117]], ptr noundef [[ATOMIC_TEMP119]], i32 noundef 0, i32 noundef 0), !dbg [[DBG97]]
// LIN64-NEXT:    br i1 [[CALL121]], label [[ATOMIC_EXIT122:%.*]], label [[ATOMIC_CONT118]], !dbg [[DBG97]]
// LIN64:       atomic_exit122:
// LIN64-NEXT:    store x86_fp80 [[TMP112]], ptr @ldv, align 16, !dbg [[DBG97]]
// LIN64-NEXT:    [[TMP113:%.*]] = load float, ptr @fv, align 4, !dbg [[DBG99:![0-9]+]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP123]], i32 noundef 0), !dbg [[DBG100:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT124:%.*]], !dbg [[DBG100]]
// LIN64:       atomic_cont124:
// LIN64-NEXT:    [[ATOMIC_TEMP123_REALP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP123]], i32 0, i32 0, !dbg [[DBG100]]
// LIN64-NEXT:    [[ATOMIC_TEMP123_REAL:%.*]] = load i32, ptr [[ATOMIC_TEMP123_REALP]], align 4, !dbg [[DBG100]]
// LIN64-NEXT:    [[ATOMIC_TEMP123_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP123]], i32 0, i32 1, !dbg [[DBG100]]
// LIN64-NEXT:    [[ATOMIC_TEMP123_IMAG:%.*]] = load i32, ptr [[ATOMIC_TEMP123_IMAGP]], align 4, !dbg [[DBG100]]
// LIN64-NEXT:    [[CONV126:%.*]] = sitofp i32 [[ATOMIC_TEMP123_REAL]] to float, !dbg [[DBG101:![0-9]+]]
// LIN64-NEXT:    [[CONV127:%.*]] = sitofp i32 [[ATOMIC_TEMP123_IMAG]] to float, !dbg [[DBG101]]
// LIN64-NEXT:    [[CALL128:%.*]] = call <2 x float> @__divsc3(float noundef [[TMP113]], float noundef 0.000000e+00, float noundef [[CONV126]], float noundef [[CONV127]]) #[[ATTR4:[0-9]+]], !dbg [[DBG102:![0-9]+]]
// LIN64-NEXT:    store <2 x float> [[CALL128]], ptr [[COERCE]], align 4, !dbg [[DBG102]]
// LIN64-NEXT:    [[COERCE_REALP:%.*]] = getelementptr inbounds { float, float }, ptr [[COERCE]], i32 0, i32 0, !dbg [[DBG102]]
// LIN64-NEXT:    [[COERCE_REAL:%.*]] = load float, ptr [[COERCE_REALP]], align 4, !dbg [[DBG102]]
// LIN64-NEXT:    [[COERCE_IMAGP:%.*]] = getelementptr inbounds { float, float }, ptr [[COERCE]], i32 0, i32 1, !dbg [[DBG102]]
// LIN64-NEXT:    [[COERCE_IMAG:%.*]] = load float, ptr [[COERCE_IMAGP]], align 4, !dbg [[DBG102]]
// LIN64-NEXT:    [[CONV129:%.*]] = fptosi float [[COERCE_REAL]] to i32, !dbg [[DBG99]]
// LIN64-NEXT:    [[CONV130:%.*]] = fptosi float [[COERCE_IMAG]] to i32, !dbg [[DBG99]]
// LIN64-NEXT:    [[ATOMIC_TEMP125_REALP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP125]], i32 0, i32 0, !dbg [[DBG100]]
// LIN64-NEXT:    [[ATOMIC_TEMP125_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP125]], i32 0, i32 1, !dbg [[DBG100]]
// LIN64-NEXT:    store i32 [[CONV129]], ptr [[ATOMIC_TEMP125_REALP]], align 4, !dbg [[DBG100]]
// LIN64-NEXT:    store i32 [[CONV130]], ptr [[ATOMIC_TEMP125_IMAGP]], align 4, !dbg [[DBG100]]
// LIN64-NEXT:    [[CALL131:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP123]], ptr noundef [[ATOMIC_TEMP125]], i32 noundef 0, i32 noundef 0), !dbg [[DBG100]]
// LIN64-NEXT:    br i1 [[CALL131]], label [[ATOMIC_EXIT132:%.*]], label [[ATOMIC_CONT124]], !dbg [[DBG100]]
// LIN64:       atomic_exit132:
// LIN64-NEXT:    store i32 [[CONV129]], ptr @civ, align 4, !dbg [[DBG100]]
// LIN64-NEXT:    store i32 [[CONV130]], ptr getelementptr inbounds ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG100]]
// LIN64-NEXT:    [[TMP114:%.*]] = load double, ptr @dv, align 8, !dbg [[DBG103:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD133:%.*]] = load atomic i16, ptr @sx monotonic, align 2, !dbg [[DBG104:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT134:%.*]], !dbg [[DBG104]]
// LIN64:       atomic_cont134:
// LIN64-NEXT:    [[TMP115:%.*]] = phi i16 [ [[ATOMIC_LOAD133]], [[ATOMIC_EXIT132]] ], [ [[TMP118:%.*]], [[ATOMIC_CONT134]] ], !dbg [[DBG104]]
// LIN64-NEXT:    [[CONV136:%.*]] = sext i16 [[TMP115]] to i32, !dbg [[DBG105:![0-9]+]]
// LIN64-NEXT:    [[CONV137:%.*]] = sitofp i32 [[CONV136]] to double, !dbg [[DBG105]]
// LIN64-NEXT:    [[ADD138:%.*]] = fadd double [[CONV137]], [[TMP114]], !dbg [[DBG106:![0-9]+]]
// LIN64-NEXT:    [[CONV139:%.*]] = fptosi double [[ADD138]] to i16, !dbg [[DBG105]]
// LIN64-NEXT:    store i16 [[CONV139]], ptr [[ATOMIC_TEMP135]], align 2, !dbg [[DBG104]]
// LIN64-NEXT:    [[TMP116:%.*]] = load i16, ptr [[ATOMIC_TEMP135]], align 2, !dbg [[DBG104]]
// LIN64-NEXT:    [[TMP117:%.*]] = cmpxchg ptr @sx, i16 [[TMP115]], i16 [[TMP116]] monotonic monotonic, align 2, !dbg [[DBG104]]
// LIN64-NEXT:    [[TMP118]] = extractvalue { i16, i1 } [[TMP117]], 0, !dbg [[DBG104]]
// LIN64-NEXT:    [[TMP119:%.*]] = extractvalue { i16, i1 } [[TMP117]], 1, !dbg [[DBG104]]
// LIN64-NEXT:    br i1 [[TMP119]], label [[ATOMIC_EXIT140:%.*]], label [[ATOMIC_CONT134]], !dbg [[DBG104]]
// LIN64:       atomic_exit140:
// LIN64-NEXT:    store i16 [[CONV139]], ptr @sv, align 2, !dbg [[DBG104]]
// LIN64-NEXT:    [[TMP120:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG107:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD141:%.*]] = load atomic i8, ptr @bx monotonic, align 1, !dbg [[DBG108:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT142:%.*]], !dbg [[DBG108]]
// LIN64:       atomic_cont142:
// LIN64-NEXT:    [[TMP121:%.*]] = phi i8 [ [[ATOMIC_LOAD141]], [[ATOMIC_EXIT140]] ], [ [[TMP124:%.*]], [[ATOMIC_CONT142]] ], !dbg [[DBG108]]
// LIN64-NEXT:    [[TOBOOL144:%.*]] = trunc i8 [[TMP121]] to i1, !dbg [[DBG108]]
// LIN64-NEXT:    [[CONV145:%.*]] = zext i1 [[TOBOOL144]] to i32, !dbg [[DBG109:![0-9]+]]
// LIN64-NEXT:    [[CONV146:%.*]] = sitofp i32 [[CONV145]] to x86_fp80, !dbg [[DBG109]]
// LIN64-NEXT:    [[MUL147:%.*]] = fmul x86_fp80 [[TMP120]], [[CONV146]], !dbg [[DBG110:![0-9]+]]
// LIN64-NEXT:    [[TOBOOL148:%.*]] = fcmp une x86_fp80 [[MUL147]], 0xK00000000000000000000, !dbg [[DBG107]]
// LIN64-NEXT:    [[FROMBOOL149:%.*]] = zext i1 [[TOBOOL148]] to i8, !dbg [[DBG108]]
// LIN64-NEXT:    store i8 [[FROMBOOL149]], ptr [[ATOMIC_TEMP143]], align 1, !dbg [[DBG108]]
// LIN64-NEXT:    [[TMP122:%.*]] = load i8, ptr [[ATOMIC_TEMP143]], align 1, !dbg [[DBG108]]
// LIN64-NEXT:    [[TMP123:%.*]] = cmpxchg ptr @bx, i8 [[TMP121]], i8 [[TMP122]] monotonic monotonic, align 1, !dbg [[DBG108]]
// LIN64-NEXT:    [[TMP124]] = extractvalue { i8, i1 } [[TMP123]], 0, !dbg [[DBG108]]
// LIN64-NEXT:    [[TMP125:%.*]] = extractvalue { i8, i1 } [[TMP123]], 1, !dbg [[DBG108]]
// LIN64-NEXT:    br i1 [[TMP125]], label [[ATOMIC_EXIT150:%.*]], label [[ATOMIC_CONT142]], !dbg [[DBG108]]
// LIN64:       atomic_exit150:
// LIN64-NEXT:    [[FROMBOOL151:%.*]] = zext i1 [[TOBOOL144]] to i8, !dbg [[DBG108]]
// LIN64-NEXT:    store i8 [[FROMBOOL151]], ptr @bv, align 1, !dbg [[DBG108]]
// LIN64-NEXT:    [[CIV_REAL152:%.*]] = load i32, ptr @civ, align 4, !dbg [[DBG111:![0-9]+]]
// LIN64-NEXT:    [[CIV_IMAG153:%.*]] = load i32, ptr getelementptr inbounds ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG111]]
// LIN64-NEXT:    [[ATOMIC_LOAD154:%.*]] = load atomic i8, ptr @bx monotonic, align 1, !dbg [[DBG112:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT155:%.*]], !dbg [[DBG112]]
// LIN64:       atomic_cont155:
// LIN64-NEXT:    [[TMP126:%.*]] = phi i8 [ [[ATOMIC_LOAD154]], [[ATOMIC_EXIT150]] ], [ [[TMP129:%.*]], [[ATOMIC_CONT155]] ], !dbg [[DBG112]]
// LIN64-NEXT:    [[TOBOOL157:%.*]] = trunc i8 [[TMP126]] to i1, !dbg [[DBG112]]
// LIN64-NEXT:    [[CONV158:%.*]] = zext i1 [[TOBOOL157]] to i32, !dbg [[DBG113:![0-9]+]]
// LIN64-NEXT:    [[SUB_R159:%.*]] = sub i32 [[CIV_REAL152]], [[CONV158]], !dbg [[DBG114:![0-9]+]]
// LIN64-NEXT:    [[SUB_I160:%.*]] = sub i32 [[CIV_IMAG153]], 0, !dbg [[DBG114]]
// LIN64-NEXT:    [[TOBOOL161:%.*]] = icmp ne i32 [[SUB_R159]], 0, !dbg [[DBG111]]
// LIN64-NEXT:    [[TOBOOL162:%.*]] = icmp ne i32 [[SUB_I160]], 0, !dbg [[DBG111]]
// LIN64-NEXT:    [[TOBOOL163:%.*]] = or i1 [[TOBOOL161]], [[TOBOOL162]], !dbg [[DBG111]]
// LIN64-NEXT:    [[FROMBOOL164:%.*]] = zext i1 [[TOBOOL163]] to i8, !dbg [[DBG112]]
// LIN64-NEXT:    store i8 [[FROMBOOL164]], ptr [[ATOMIC_TEMP156]], align 1, !dbg [[DBG112]]
// LIN64-NEXT:    [[TMP127:%.*]] = load i8, ptr [[ATOMIC_TEMP156]], align 1, !dbg [[DBG112]]
// LIN64-NEXT:    [[TMP128:%.*]] = cmpxchg ptr @bx, i8 [[TMP126]], i8 [[TMP127]] monotonic monotonic, align 1, !dbg [[DBG112]]
// LIN64-NEXT:    [[TMP129]] = extractvalue { i8, i1 } [[TMP128]], 0, !dbg [[DBG112]]
// LIN64-NEXT:    [[TMP130:%.*]] = extractvalue { i8, i1 } [[TMP128]], 1, !dbg [[DBG112]]
// LIN64-NEXT:    br i1 [[TMP130]], label [[ATOMIC_EXIT165:%.*]], label [[ATOMIC_CONT155]], !dbg [[DBG112]]
// LIN64:       atomic_exit165:
// LIN64-NEXT:    [[FROMBOOL166:%.*]] = zext i1 [[TOBOOL163]] to i8, !dbg [[DBG112]]
// LIN64-NEXT:    store i8 [[FROMBOOL166]], ptr @bv, align 1, !dbg [[DBG112]]
// LIN64-NEXT:    [[TMP131:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG115:![0-9]+]]
// LIN64-NEXT:    [[TMP132:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG116:![0-9]+]]
// LIN64-NEXT:    [[TOBOOL167:%.*]] = trunc i8 [[TMP132]] to i1, !dbg [[DBG116]]
// LIN64-NEXT:    [[CONV168:%.*]] = zext i1 [[TOBOOL167]] to i32, !dbg [[DBG116]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 16, ptr noundef @int4x, ptr noundef [[ATOMIC_TEMP169]], i32 noundef 0), !dbg [[DBG117:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT170:%.*]], !dbg [[DBG117]]
// LIN64:       atomic_cont170:
// LIN64-NEXT:    [[TMP133:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP169]], align 16, !dbg [[DBG117]]
// LIN64-NEXT:    store <4 x i32> [[TMP133]], ptr [[ATOMIC_TEMP171]], align 16, !dbg [[DBG117]]
// LIN64-NEXT:    [[TMP134:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP169]], align 16, !dbg [[DBG117]]
// LIN64-NEXT:    store <4 x i32> [[TMP134]], ptr [[ATOMIC_TEMP172]], align 16, !dbg [[DBG117]]
// LIN64-NEXT:    [[TMP135:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP172]], align 16, !dbg [[DBG117]]
// LIN64-NEXT:    [[VECEXT:%.*]] = extractelement <4 x i32> [[TMP135]], i16 [[TMP131]], !dbg [[DBG117]]
// LIN64-NEXT:    [[OR173:%.*]] = or i32 [[VECEXT]], [[CONV168]], !dbg [[DBG118:![0-9]+]]
// LIN64-NEXT:    [[TMP136:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP171]], align 16, !dbg [[DBG117]]
// LIN64-NEXT:    [[VECINS:%.*]] = insertelement <4 x i32> [[TMP136]], i32 [[OR173]], i16 [[TMP131]], !dbg [[DBG117]]
// LIN64-NEXT:    store <4 x i32> [[VECINS]], ptr [[ATOMIC_TEMP171]], align 16, !dbg [[DBG117]]
// LIN64-NEXT:    [[CALL174:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, ptr noundef @int4x, ptr noundef [[ATOMIC_TEMP169]], ptr noundef [[ATOMIC_TEMP171]], i32 noundef 0, i32 noundef 0), !dbg [[DBG117]]
// LIN64-NEXT:    br i1 [[CALL174]], label [[ATOMIC_EXIT175:%.*]], label [[ATOMIC_CONT170]], !dbg [[DBG117]]
// LIN64:       atomic_exit175:
// LIN64-NEXT:    store i32 [[OR173]], ptr @iv, align 4, !dbg [[DBG117]]
// LIN64-NEXT:    [[TMP137:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG119:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD176:%.*]] = load atomic i32, ptr getelementptr (i8, ptr @bfx, i64 4) monotonic, align 4, !dbg [[DBG120:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT177:%.*]], !dbg [[DBG120]]
// LIN64:       atomic_cont177:
// LIN64-NEXT:    [[TMP138:%.*]] = phi i32 [ [[ATOMIC_LOAD176]], [[ATOMIC_EXIT175]] ], [ [[TMP141:%.*]], [[ATOMIC_CONT177]] ], !dbg [[DBG120]]
// LIN64-NEXT:    store i32 [[TMP138]], ptr [[ATOMIC_TEMP178]], align 4, !dbg [[DBG120]]
// LIN64-NEXT:    store i32 [[TMP138]], ptr [[ATOMIC_TEMP179]], align 4, !dbg [[DBG120]]
// LIN64-NEXT:    [[BF_LOAD:%.*]] = load i32, ptr [[ATOMIC_TEMP179]], align 4, !dbg [[DBG120]]
// LIN64-NEXT:    [[BF_SHL:%.*]] = shl i32 [[BF_LOAD]], 1, !dbg [[DBG120]]
// LIN64-NEXT:    [[BF_ASHR:%.*]] = ashr i32 [[BF_SHL]], 1, !dbg [[DBG120]]
// LIN64-NEXT:    [[CONV180:%.*]] = sitofp i32 [[BF_ASHR]] to x86_fp80, !dbg [[DBG121:![0-9]+]]
// LIN64-NEXT:    [[SUB181:%.*]] = fsub x86_fp80 [[CONV180]], [[TMP137]], !dbg [[DBG122:![0-9]+]]
// LIN64-NEXT:    [[CONV182:%.*]] = fptosi x86_fp80 [[SUB181]] to i32, !dbg [[DBG121]]
// LIN64-NEXT:    [[BF_LOAD183:%.*]] = load i32, ptr [[ATOMIC_TEMP178]], align 4, !dbg [[DBG120]]
// LIN64-NEXT:    [[BF_VALUE:%.*]] = and i32 [[CONV182]], 2147483647, !dbg [[DBG120]]
// LIN64-NEXT:    [[BF_CLEAR:%.*]] = and i32 [[BF_LOAD183]], -2147483648, !dbg [[DBG120]]
// LIN64-NEXT:    [[BF_SET:%.*]] = or i32 [[BF_CLEAR]], [[BF_VALUE]], !dbg [[DBG120]]
// LIN64-NEXT:    store i32 [[BF_SET]], ptr [[ATOMIC_TEMP178]], align 4, !dbg [[DBG120]]
// LIN64-NEXT:    [[TMP139:%.*]] = load i32, ptr [[ATOMIC_TEMP178]], align 4, !dbg [[DBG120]]
// LIN64-NEXT:    [[TMP140:%.*]] = cmpxchg ptr getelementptr (i8, ptr @bfx, i64 4), i32 [[TMP138]], i32 [[TMP139]] monotonic monotonic, align 4, !dbg [[DBG120]]
// LIN64-NEXT:    [[TMP141]] = extractvalue { i32, i1 } [[TMP140]], 0, !dbg [[DBG120]]
// LIN64-NEXT:    [[TMP142:%.*]] = extractvalue { i32, i1 } [[TMP140]], 1, !dbg [[DBG120]]
// LIN64-NEXT:    br i1 [[TMP142]], label [[ATOMIC_EXIT184:%.*]], label [[ATOMIC_CONT177]], !dbg [[DBG120]]
// LIN64:       atomic_exit184:
// LIN64-NEXT:    store i32 [[CONV182]], ptr @iv, align 4, !dbg [[DBG120]]
// LIN64-NEXT:    [[TMP143:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG123:![0-9]+]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 4, ptr noundef getelementptr (i8, ptr @bfx_packed, i64 4), ptr noundef [[ATOMIC_TEMP185]], i32 noundef 0), !dbg [[DBG124:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT186:%.*]], !dbg [[DBG124]]
// LIN64:       atomic_cont186:
// LIN64-NEXT:    [[TMP144:%.*]] = load i32, ptr [[ATOMIC_TEMP185]], align 1, !dbg [[DBG124]]
// LIN64-NEXT:    store i32 [[TMP144]], ptr [[ATOMIC_TEMP187]], align 1, !dbg [[DBG124]]
// LIN64-NEXT:    [[TMP145:%.*]] = load i32, ptr [[ATOMIC_TEMP185]], align 1, !dbg [[DBG124]]
// LIN64-NEXT:    store i32 [[TMP145]], ptr [[ATOMIC_TEMP188]], align 4, !dbg [[DBG124]]
// LIN64-NEXT:    [[BF_LOAD189:%.*]] = load i32, ptr [[ATOMIC_TEMP188]], align 1, !dbg [[DBG124]]
// LIN64-NEXT:    [[BF_SHL190:%.*]] = shl i32 [[BF_LOAD189]], 1, !dbg [[DBG124]]
// LIN64-NEXT:    [[BF_ASHR191:%.*]] = ashr i32 [[BF_SHL190]], 1, !dbg [[DBG124]]
// LIN64-NEXT:    [[CONV192:%.*]] = sitofp i32 [[BF_ASHR191]] to x86_fp80, !dbg [[DBG125:![0-9]+]]
// LIN64-NEXT:    [[MUL193:%.*]] = fmul x86_fp80 [[CONV192]], [[TMP143]], !dbg [[DBG126:![0-9]+]]
// LIN64-NEXT:    [[CONV194:%.*]] = fptosi x86_fp80 [[MUL193]] to i32, !dbg [[DBG125]]
// LIN64-NEXT:    [[BF_LOAD195:%.*]] = load i32, ptr [[ATOMIC_TEMP187]], align 1, !dbg [[DBG124]]
// LIN64-NEXT:    [[BF_VALUE196:%.*]] = and i32 [[CONV194]], 2147483647, !dbg [[DBG124]]
// LIN64-NEXT:    [[BF_CLEAR197:%.*]] = and i32 [[BF_LOAD195]], -2147483648, !dbg [[DBG124]]
// LIN64-NEXT:    [[BF_SET198:%.*]] = or i32 [[BF_CLEAR197]], [[BF_VALUE196]], !dbg [[DBG124]]
// LIN64-NEXT:    store i32 [[BF_SET198]], ptr [[ATOMIC_TEMP187]], align 1, !dbg [[DBG124]]
// LIN64-NEXT:    [[CALL199:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 4, ptr noundef getelementptr (i8, ptr @bfx_packed, i64 4), ptr noundef [[ATOMIC_TEMP185]], ptr noundef [[ATOMIC_TEMP187]], i32 noundef 0, i32 noundef 0), !dbg [[DBG124]]
// LIN64-NEXT:    br i1 [[CALL199]], label [[ATOMIC_EXIT200:%.*]], label [[ATOMIC_CONT186]], !dbg [[DBG124]]
// LIN64:       atomic_exit200:
// LIN64-NEXT:    store i32 [[BF_ASHR191]], ptr @iv, align 4, !dbg [[DBG124]]
// LIN64-NEXT:    [[TMP146:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG127:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD201:%.*]] = load atomic i32, ptr @bfx2 monotonic, align 4, !dbg [[DBG128:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT202:%.*]], !dbg [[DBG128]]
// LIN64:       atomic_cont202:
// LIN64-NEXT:    [[TMP147:%.*]] = phi i32 [ [[ATOMIC_LOAD201]], [[ATOMIC_EXIT200]] ], [ [[TMP150:%.*]], [[ATOMIC_CONT202]] ], !dbg [[DBG128]]
// LIN64-NEXT:    store i32 [[TMP147]], ptr [[ATOMIC_TEMP203]], align 4, !dbg [[DBG128]]
// LIN64-NEXT:    store i32 [[TMP147]], ptr [[ATOMIC_TEMP204]], align 4, !dbg [[DBG128]]
// LIN64-NEXT:    [[BF_LOAD205:%.*]] = load i32, ptr [[ATOMIC_TEMP204]], align 4, !dbg [[DBG128]]
// LIN64-NEXT:    [[BF_ASHR206:%.*]] = ashr i32 [[BF_LOAD205]], 31, !dbg [[DBG128]]
// LIN64-NEXT:    [[CONV207:%.*]] = sitofp i32 [[BF_ASHR206]] to x86_fp80, !dbg [[DBG129:![0-9]+]]
// LIN64-NEXT:    [[SUB208:%.*]] = fsub x86_fp80 [[CONV207]], [[TMP146]], !dbg [[DBG130:![0-9]+]]
// LIN64-NEXT:    [[CONV209:%.*]] = fptosi x86_fp80 [[SUB208]] to i32, !dbg [[DBG129]]
// LIN64-NEXT:    [[BF_LOAD210:%.*]] = load i32, ptr [[ATOMIC_TEMP203]], align 4, !dbg [[DBG128]]
// LIN64-NEXT:    [[BF_VALUE211:%.*]] = and i32 [[CONV209]], 1, !dbg [[DBG128]]
// LIN64-NEXT:    [[BF_SHL212:%.*]] = shl i32 [[BF_VALUE211]], 31, !dbg [[DBG128]]
// LIN64-NEXT:    [[BF_CLEAR213:%.*]] = and i32 [[BF_LOAD210]], 2147483647, !dbg [[DBG128]]
// LIN64-NEXT:    [[BF_SET214:%.*]] = or i32 [[BF_CLEAR213]], [[BF_SHL212]], !dbg [[DBG128]]
// LIN64-NEXT:    store i32 [[BF_SET214]], ptr [[ATOMIC_TEMP203]], align 4, !dbg [[DBG128]]
// LIN64-NEXT:    [[TMP148:%.*]] = load i32, ptr [[ATOMIC_TEMP203]], align 4, !dbg [[DBG128]]
// LIN64-NEXT:    [[TMP149:%.*]] = cmpxchg ptr @bfx2, i32 [[TMP147]], i32 [[TMP148]] monotonic monotonic, align 4, !dbg [[DBG128]]
// LIN64-NEXT:    [[TMP150]] = extractvalue { i32, i1 } [[TMP149]], 0, !dbg [[DBG128]]
// LIN64-NEXT:    [[TMP151:%.*]] = extractvalue { i32, i1 } [[TMP149]], 1, !dbg [[DBG128]]
// LIN64-NEXT:    br i1 [[TMP151]], label [[ATOMIC_EXIT215:%.*]], label [[ATOMIC_CONT202]], !dbg [[DBG128]]
// LIN64:       atomic_exit215:
// LIN64-NEXT:    store i32 [[CONV209]], ptr @iv, align 4, !dbg [[DBG128]]
// LIN64-NEXT:    [[TMP152:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG131:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD216:%.*]] = load atomic i8, ptr getelementptr (i8, ptr @bfx2_packed, i64 3) monotonic, align 1, !dbg [[DBG132:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT217:%.*]], !dbg [[DBG132]]
// LIN64:       atomic_cont217:
// LIN64-NEXT:    [[TMP153:%.*]] = phi i8 [ [[ATOMIC_LOAD216]], [[ATOMIC_EXIT215]] ], [ [[TMP157:%.*]], [[ATOMIC_CONT217]] ], !dbg [[DBG132]]
// LIN64-NEXT:    store i8 [[TMP153]], ptr [[ATOMIC_TEMP218]], align 1, !dbg [[DBG132]]
// LIN64-NEXT:    store i8 [[TMP153]], ptr [[ATOMIC_TEMP219]], align 1, !dbg [[DBG132]]
// LIN64-NEXT:    [[BF_LOAD220:%.*]] = load i8, ptr [[ATOMIC_TEMP219]], align 1, !dbg [[DBG132]]
// LIN64-NEXT:    [[BF_ASHR221:%.*]] = ashr i8 [[BF_LOAD220]], 7, !dbg [[DBG132]]
// LIN64-NEXT:    [[BF_CAST:%.*]] = sext i8 [[BF_ASHR221]] to i32, !dbg [[DBG132]]
// LIN64-NEXT:    [[CONV222:%.*]] = sitofp i32 [[BF_CAST]] to x86_fp80, !dbg [[DBG133:![0-9]+]]
// LIN64-NEXT:    [[DIV223:%.*]] = fdiv x86_fp80 [[TMP152]], [[CONV222]], !dbg [[DBG134:![0-9]+]]
// LIN64-NEXT:    [[CONV224:%.*]] = fptosi x86_fp80 [[DIV223]] to i32, !dbg [[DBG131]]
// LIN64-NEXT:    [[TMP154:%.*]] = trunc i32 [[CONV224]] to i8, !dbg [[DBG132]]
// LIN64-NEXT:    [[BF_LOAD225:%.*]] = load i8, ptr [[ATOMIC_TEMP218]], align 1, !dbg [[DBG132]]
// LIN64-NEXT:    [[BF_VALUE226:%.*]] = and i8 [[TMP154]], 1, !dbg [[DBG132]]
// LIN64-NEXT:    [[BF_SHL227:%.*]] = shl i8 [[BF_VALUE226]], 7, !dbg [[DBG132]]
// LIN64-NEXT:    [[BF_CLEAR228:%.*]] = and i8 [[BF_LOAD225]], 127, !dbg [[DBG132]]
// LIN64-NEXT:    [[BF_SET229:%.*]] = or i8 [[BF_CLEAR228]], [[BF_SHL227]], !dbg [[DBG132]]
// LIN64-NEXT:    store i8 [[BF_SET229]], ptr [[ATOMIC_TEMP218]], align 1, !dbg [[DBG132]]
// LIN64-NEXT:    [[TMP155:%.*]] = load i8, ptr [[ATOMIC_TEMP218]], align 1, !dbg [[DBG132]]
// LIN64-NEXT:    [[TMP156:%.*]] = cmpxchg ptr getelementptr (i8, ptr @bfx2_packed, i64 3), i8 [[TMP153]], i8 [[TMP155]] monotonic monotonic, align 1, !dbg [[DBG132]]
// LIN64-NEXT:    [[TMP157]] = extractvalue { i8, i1 } [[TMP156]], 0, !dbg [[DBG132]]
// LIN64-NEXT:    [[TMP158:%.*]] = extractvalue { i8, i1 } [[TMP156]], 1, !dbg [[DBG132]]
// LIN64-NEXT:    br i1 [[TMP158]], label [[ATOMIC_EXIT230:%.*]], label [[ATOMIC_CONT217]], !dbg [[DBG132]]
// LIN64:       atomic_exit230:
// LIN64-NEXT:    store i32 [[CONV224]], ptr @iv, align 4, !dbg [[DBG132]]
// LIN64-NEXT:    [[TMP159:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG135:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD231:%.*]] = load atomic i32, ptr @bfx3 monotonic, align 4, !dbg [[DBG136:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT232:%.*]], !dbg [[DBG136]]
// LIN64:       atomic_cont232:
// LIN64-NEXT:    [[TMP160:%.*]] = phi i32 [ [[ATOMIC_LOAD231]], [[ATOMIC_EXIT230]] ], [ [[TMP163:%.*]], [[ATOMIC_CONT232]] ], !dbg [[DBG136]]
// LIN64-NEXT:    store i32 [[TMP160]], ptr [[ATOMIC_TEMP233]], align 4, !dbg [[DBG136]]
// LIN64-NEXT:    store i32 [[TMP160]], ptr [[ATOMIC_TEMP234]], align 4, !dbg [[DBG136]]
// LIN64-NEXT:    [[BF_LOAD235:%.*]] = load i32, ptr [[ATOMIC_TEMP234]], align 4, !dbg [[DBG136]]
// LIN64-NEXT:    [[BF_SHL236:%.*]] = shl i32 [[BF_LOAD235]], 7, !dbg [[DBG136]]
// LIN64-NEXT:    [[BF_ASHR237:%.*]] = ashr i32 [[BF_SHL236]], 18, !dbg [[DBG136]]
// LIN64-NEXT:    [[CONV238:%.*]] = sitofp i32 [[BF_ASHR237]] to x86_fp80, !dbg [[DBG137:![0-9]+]]
// LIN64-NEXT:    [[DIV239:%.*]] = fdiv x86_fp80 [[CONV238]], [[TMP159]], !dbg [[DBG138:![0-9]+]]
// LIN64-NEXT:    [[CONV240:%.*]] = fptosi x86_fp80 [[DIV239]] to i32, !dbg [[DBG137]]
// LIN64-NEXT:    [[BF_LOAD241:%.*]] = load i32, ptr [[ATOMIC_TEMP233]], align 4, !dbg [[DBG136]]
// LIN64-NEXT:    [[BF_VALUE242:%.*]] = and i32 [[CONV240]], 16383, !dbg [[DBG136]]
// LIN64-NEXT:    [[BF_SHL243:%.*]] = shl i32 [[BF_VALUE242]], 11, !dbg [[DBG136]]
// LIN64-NEXT:    [[BF_CLEAR244:%.*]] = and i32 [[BF_LOAD241]], -33552385, !dbg [[DBG136]]
// LIN64-NEXT:    [[BF_SET245:%.*]] = or i32 [[BF_CLEAR244]], [[BF_SHL243]], !dbg [[DBG136]]
// LIN64-NEXT:    store i32 [[BF_SET245]], ptr [[ATOMIC_TEMP233]], align 4, !dbg [[DBG136]]
// LIN64-NEXT:    [[TMP161:%.*]] = load i32, ptr [[ATOMIC_TEMP233]], align 4, !dbg [[DBG136]]
// LIN64-NEXT:    [[TMP162:%.*]] = cmpxchg ptr @bfx3, i32 [[TMP160]], i32 [[TMP161]] monotonic monotonic, align 4, !dbg [[DBG136]]
// LIN64-NEXT:    [[TMP163]] = extractvalue { i32, i1 } [[TMP162]], 0, !dbg [[DBG136]]
// LIN64-NEXT:    [[TMP164:%.*]] = extractvalue { i32, i1 } [[TMP162]], 1, !dbg [[DBG136]]
// LIN64-NEXT:    br i1 [[TMP164]], label [[ATOMIC_EXIT246:%.*]], label [[ATOMIC_CONT232]], !dbg [[DBG136]]
// LIN64:       atomic_exit246:
// LIN64-NEXT:    store i32 [[BF_ASHR237]], ptr @iv, align 4, !dbg [[DBG136]]
// LIN64-NEXT:    [[TMP165:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG139:![0-9]+]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 3, ptr noundef getelementptr (i8, ptr @bfx3_packed, i64 1), ptr noundef [[ATOMIC_TEMP247]], i32 noundef 0), !dbg [[DBG140:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT248:%.*]], !dbg [[DBG140]]
// LIN64:       atomic_cont248:
// LIN64-NEXT:    [[TMP166:%.*]] = load i24, ptr [[ATOMIC_TEMP247]], align 1, !dbg [[DBG140]]
// LIN64-NEXT:    store i24 [[TMP166]], ptr [[ATOMIC_TEMP249]], align 1, !dbg [[DBG140]]
// LIN64-NEXT:    [[TMP167:%.*]] = load i24, ptr [[ATOMIC_TEMP247]], align 1, !dbg [[DBG140]]
// LIN64-NEXT:    store i24 [[TMP167]], ptr [[ATOMIC_TEMP250]], align 1, !dbg [[DBG140]]
// LIN64-NEXT:    [[BF_LOAD251:%.*]] = load i24, ptr [[ATOMIC_TEMP250]], align 1, !dbg [[DBG140]]
// LIN64-NEXT:    [[BF_SHL252:%.*]] = shl i24 [[BF_LOAD251]], 7, !dbg [[DBG140]]
// LIN64-NEXT:    [[BF_ASHR253:%.*]] = ashr i24 [[BF_SHL252]], 10, !dbg [[DBG140]]
// LIN64-NEXT:    [[BF_CAST254:%.*]] = sext i24 [[BF_ASHR253]] to i32, !dbg [[DBG140]]
// LIN64-NEXT:    [[CONV255:%.*]] = sitofp i32 [[BF_CAST254]] to x86_fp80, !dbg [[DBG141:![0-9]+]]
// LIN64-NEXT:    [[ADD256:%.*]] = fadd x86_fp80 [[CONV255]], [[TMP165]], !dbg [[DBG142:![0-9]+]]
// LIN64-NEXT:    [[CONV257:%.*]] = fptosi x86_fp80 [[ADD256]] to i32, !dbg [[DBG141]]
// LIN64-NEXT:    [[TMP168:%.*]] = trunc i32 [[CONV257]] to i24, !dbg [[DBG140]]
// LIN64-NEXT:    [[BF_LOAD258:%.*]] = load i24, ptr [[ATOMIC_TEMP249]], align 1, !dbg [[DBG140]]
// LIN64-NEXT:    [[BF_VALUE259:%.*]] = and i24 [[TMP168]], 16383, !dbg [[DBG140]]
// LIN64-NEXT:    [[BF_SHL260:%.*]] = shl i24 [[BF_VALUE259]], 3, !dbg [[DBG140]]
// LIN64-NEXT:    [[BF_CLEAR261:%.*]] = and i24 [[BF_LOAD258]], -131065, !dbg [[DBG140]]
// LIN64-NEXT:    [[BF_SET262:%.*]] = or i24 [[BF_CLEAR261]], [[BF_SHL260]], !dbg [[DBG140]]
// LIN64-NEXT:    store i24 [[BF_SET262]], ptr [[ATOMIC_TEMP249]], align 1, !dbg [[DBG140]]
// LIN64-NEXT:    [[CALL263:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 3, ptr noundef getelementptr (i8, ptr @bfx3_packed, i64 1), ptr noundef [[ATOMIC_TEMP247]], ptr noundef [[ATOMIC_TEMP249]], i32 noundef 0, i32 noundef 0), !dbg [[DBG140]]
// LIN64-NEXT:    br i1 [[CALL263]], label [[ATOMIC_EXIT264:%.*]], label [[ATOMIC_CONT248]], !dbg [[DBG140]]
// LIN64:       atomic_exit264:
// LIN64-NEXT:    store i32 [[CONV257]], ptr @iv, align 4, !dbg [[DBG140]]
// LIN64-NEXT:    [[TMP169:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG143:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD265:%.*]] = load atomic i64, ptr @bfx4 monotonic, align 8, !dbg [[DBG144:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT266:%.*]], !dbg [[DBG144]]
// LIN64:       atomic_cont266:
// LIN64-NEXT:    [[TMP170:%.*]] = phi i64 [ [[ATOMIC_LOAD265]], [[ATOMIC_EXIT264]] ], [ [[TMP174:%.*]], [[ATOMIC_CONT266]] ], !dbg [[DBG144]]
// LIN64-NEXT:    store i64 [[TMP170]], ptr [[ATOMIC_TEMP267]], align 8, !dbg [[DBG144]]
// LIN64-NEXT:    store i64 [[TMP170]], ptr [[ATOMIC_TEMP268]], align 8, !dbg [[DBG144]]
// LIN64-NEXT:    [[BF_LOAD269:%.*]] = load i64, ptr [[ATOMIC_TEMP268]], align 8, !dbg [[DBG144]]
// LIN64-NEXT:    [[BF_SHL270:%.*]] = shl i64 [[BF_LOAD269]], 47, !dbg [[DBG144]]
// LIN64-NEXT:    [[BF_ASHR271:%.*]] = ashr i64 [[BF_SHL270]], 63, !dbg [[DBG144]]
// LIN64-NEXT:    [[BF_CAST272:%.*]] = trunc i64 [[BF_ASHR271]] to i32, !dbg [[DBG144]]
// LIN64-NEXT:    [[CONV273:%.*]] = sitofp i32 [[BF_CAST272]] to x86_fp80, !dbg [[DBG145:![0-9]+]]
// LIN64-NEXT:    [[MUL274:%.*]] = fmul x86_fp80 [[CONV273]], [[TMP169]], !dbg [[DBG146:![0-9]+]]
// LIN64-NEXT:    [[CONV275:%.*]] = fptosi x86_fp80 [[MUL274]] to i32, !dbg [[DBG145]]
// LIN64-NEXT:    [[TMP171:%.*]] = zext i32 [[CONV275]] to i64, !dbg [[DBG144]]
// LIN64-NEXT:    [[BF_LOAD276:%.*]] = load i64, ptr [[ATOMIC_TEMP267]], align 8, !dbg [[DBG144]]
// LIN64-NEXT:    [[BF_VALUE277:%.*]] = and i64 [[TMP171]], 1, !dbg [[DBG144]]
// LIN64-NEXT:    [[BF_SHL278:%.*]] = shl i64 [[BF_VALUE277]], 16, !dbg [[DBG144]]
// LIN64-NEXT:    [[BF_CLEAR279:%.*]] = and i64 [[BF_LOAD276]], -65537, !dbg [[DBG144]]
// LIN64-NEXT:    [[BF_SET280:%.*]] = or i64 [[BF_CLEAR279]], [[BF_SHL278]], !dbg [[DBG144]]
// LIN64-NEXT:    store i64 [[BF_SET280]], ptr [[ATOMIC_TEMP267]], align 8, !dbg [[DBG144]]
// LIN64-NEXT:    [[TMP172:%.*]] = load i64, ptr [[ATOMIC_TEMP267]], align 8, !dbg [[DBG144]]
// LIN64-NEXT:    [[TMP173:%.*]] = cmpxchg ptr @bfx4, i64 [[TMP170]], i64 [[TMP172]] monotonic monotonic, align 8, !dbg [[DBG144]]
// LIN64-NEXT:    [[TMP174]] = extractvalue { i64, i1 } [[TMP173]], 0, !dbg [[DBG144]]
// LIN64-NEXT:    [[TMP175:%.*]] = extractvalue { i64, i1 } [[TMP173]], 1, !dbg [[DBG144]]
// LIN64-NEXT:    br i1 [[TMP175]], label [[ATOMIC_EXIT281:%.*]], label [[ATOMIC_CONT266]], !dbg [[DBG144]]
// LIN64:       atomic_exit281:
// LIN64-NEXT:    store i32 [[CONV275]], ptr @iv, align 4, !dbg [[DBG144]]
// LIN64-NEXT:    [[TMP176:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG147:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD282:%.*]] = load atomic i8, ptr getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED:%.*]], ptr @bfx4_packed, i32 0, i32 1) monotonic, align 1, !dbg [[DBG148:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT283:%.*]], !dbg [[DBG148]]
// LIN64:       atomic_cont283:
// LIN64-NEXT:    [[TMP177:%.*]] = phi i8 [ [[ATOMIC_LOAD282]], [[ATOMIC_EXIT281]] ], [ [[TMP181:%.*]], [[ATOMIC_CONT283]] ], !dbg [[DBG148]]
// LIN64-NEXT:    store i8 [[TMP177]], ptr [[ATOMIC_TEMP284]], align 1, !dbg [[DBG148]]
// LIN64-NEXT:    store i8 [[TMP177]], ptr [[ATOMIC_TEMP285]], align 1, !dbg [[DBG148]]
// LIN64-NEXT:    [[BF_LOAD286:%.*]] = load i8, ptr [[ATOMIC_TEMP285]], align 1, !dbg [[DBG148]]
// LIN64-NEXT:    [[BF_SHL287:%.*]] = shl i8 [[BF_LOAD286]], 7, !dbg [[DBG148]]
// LIN64-NEXT:    [[BF_ASHR288:%.*]] = ashr i8 [[BF_SHL287]], 7, !dbg [[DBG148]]
// LIN64-NEXT:    [[BF_CAST289:%.*]] = sext i8 [[BF_ASHR288]] to i32, !dbg [[DBG148]]
// LIN64-NEXT:    [[CONV290:%.*]] = sitofp i32 [[BF_CAST289]] to x86_fp80, !dbg [[DBG149:![0-9]+]]
// LIN64-NEXT:    [[SUB291:%.*]] = fsub x86_fp80 [[CONV290]], [[TMP176]], !dbg [[DBG150:![0-9]+]]
// LIN64-NEXT:    [[CONV292:%.*]] = fptosi x86_fp80 [[SUB291]] to i32, !dbg [[DBG149]]
// LIN64-NEXT:    [[TMP178:%.*]] = trunc i32 [[CONV292]] to i8, !dbg [[DBG148]]
// LIN64-NEXT:    [[BF_LOAD293:%.*]] = load i8, ptr [[ATOMIC_TEMP284]], align 1, !dbg [[DBG148]]
// LIN64-NEXT:    [[BF_VALUE294:%.*]] = and i8 [[TMP178]], 1, !dbg [[DBG148]]
// LIN64-NEXT:    [[BF_CLEAR295:%.*]] = and i8 [[BF_LOAD293]], -2, !dbg [[DBG148]]
// LIN64-NEXT:    [[BF_SET296:%.*]] = or i8 [[BF_CLEAR295]], [[BF_VALUE294]], !dbg [[DBG148]]
// LIN64-NEXT:    store i8 [[BF_SET296]], ptr [[ATOMIC_TEMP284]], align 1, !dbg [[DBG148]]
// LIN64-NEXT:    [[TMP179:%.*]] = load i8, ptr [[ATOMIC_TEMP284]], align 1, !dbg [[DBG148]]
// LIN64-NEXT:    [[TMP180:%.*]] = cmpxchg ptr getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1), i8 [[TMP177]], i8 [[TMP179]] monotonic monotonic, align 1, !dbg [[DBG148]]
// LIN64-NEXT:    [[TMP181]] = extractvalue { i8, i1 } [[TMP180]], 0, !dbg [[DBG148]]
// LIN64-NEXT:    [[TMP182:%.*]] = extractvalue { i8, i1 } [[TMP180]], 1, !dbg [[DBG148]]
// LIN64-NEXT:    br i1 [[TMP182]], label [[ATOMIC_EXIT297:%.*]], label [[ATOMIC_CONT283]], !dbg [[DBG148]]
// LIN64:       atomic_exit297:
// LIN64-NEXT:    store i32 [[BF_CAST289]], ptr @iv, align 4, !dbg [[DBG148]]
// LIN64-NEXT:    [[TMP183:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG151:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD298:%.*]] = load atomic i64, ptr @bfx4 monotonic, align 8, !dbg [[DBG152:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT299:%.*]], !dbg [[DBG152]]
// LIN64:       atomic_cont299:
// LIN64-NEXT:    [[TMP184:%.*]] = phi i64 [ [[ATOMIC_LOAD298]], [[ATOMIC_EXIT297]] ], [ [[TMP187:%.*]], [[ATOMIC_CONT299]] ], !dbg [[DBG152]]
// LIN64-NEXT:    store i64 [[TMP184]], ptr [[ATOMIC_TEMP300]], align 8, !dbg [[DBG152]]
// LIN64-NEXT:    store i64 [[TMP184]], ptr [[ATOMIC_TEMP301]], align 8, !dbg [[DBG152]]
// LIN64-NEXT:    [[BF_LOAD302:%.*]] = load i64, ptr [[ATOMIC_TEMP301]], align 8, !dbg [[DBG152]]
// LIN64-NEXT:    [[BF_SHL303:%.*]] = shl i64 [[BF_LOAD302]], 40, !dbg [[DBG152]]
// LIN64-NEXT:    [[BF_ASHR304:%.*]] = ashr i64 [[BF_SHL303]], 57, !dbg [[DBG152]]
// LIN64-NEXT:    [[CONV305:%.*]] = sitofp i64 [[BF_ASHR304]] to x86_fp80, !dbg [[DBG153:![0-9]+]]
// LIN64-NEXT:    [[DIV306:%.*]] = fdiv x86_fp80 [[CONV305]], [[TMP183]], !dbg [[DBG154:![0-9]+]]
// LIN64-NEXT:    [[CONV307:%.*]] = fptosi x86_fp80 [[DIV306]] to i64, !dbg [[DBG153]]
// LIN64-NEXT:    [[BF_LOAD308:%.*]] = load i64, ptr [[ATOMIC_TEMP300]], align 8, !dbg [[DBG152]]
// LIN64-NEXT:    [[BF_VALUE309:%.*]] = and i64 [[CONV307]], 127, !dbg [[DBG152]]
// LIN64-NEXT:    [[BF_SHL310:%.*]] = shl i64 [[BF_VALUE309]], 17, !dbg [[DBG152]]
// LIN64-NEXT:    [[BF_CLEAR311:%.*]] = and i64 [[BF_LOAD308]], -16646145, !dbg [[DBG152]]
// LIN64-NEXT:    [[BF_SET312:%.*]] = or i64 [[BF_CLEAR311]], [[BF_SHL310]], !dbg [[DBG152]]
// LIN64-NEXT:    store i64 [[BF_SET312]], ptr [[ATOMIC_TEMP300]], align 8, !dbg [[DBG152]]
// LIN64-NEXT:    [[TMP185:%.*]] = load i64, ptr [[ATOMIC_TEMP300]], align 8, !dbg [[DBG152]]
// LIN64-NEXT:    [[TMP186:%.*]] = cmpxchg ptr @bfx4, i64 [[TMP184]], i64 [[TMP185]] release monotonic, align 8, !dbg [[DBG152]]
// LIN64-NEXT:    [[TMP187]] = extractvalue { i64, i1 } [[TMP186]], 0, !dbg [[DBG152]]
// LIN64-NEXT:    [[TMP188:%.*]] = extractvalue { i64, i1 } [[TMP186]], 1, !dbg [[DBG152]]
// LIN64-NEXT:    br i1 [[TMP188]], label [[ATOMIC_EXIT313:%.*]], label [[ATOMIC_CONT299]], !dbg [[DBG152]]
// LIN64:       atomic_exit313:
// LIN64-NEXT:    [[CONV314:%.*]] = trunc i64 [[CONV307]] to i32, !dbg [[DBG152]]
// LIN64-NEXT:    store i32 [[CONV314]], ptr @iv, align 4, !dbg [[DBG152]]
// LIN64-NEXT:    [[TMP189:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG155:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD315:%.*]] = load atomic i8, ptr getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1) acquire, align 1, !dbg [[DBG156:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT316:%.*]], !dbg [[DBG156]]
// LIN64:       atomic_cont316:
// LIN64-NEXT:    [[TMP190:%.*]] = phi i8 [ [[ATOMIC_LOAD315]], [[ATOMIC_EXIT313]] ], [ [[TMP194:%.*]], [[ATOMIC_CONT316]] ], !dbg [[DBG156]]
// LIN64-NEXT:    store i8 [[TMP190]], ptr [[ATOMIC_TEMP317]], align 1, !dbg [[DBG156]]
// LIN64-NEXT:    store i8 [[TMP190]], ptr [[ATOMIC_TEMP318]], align 1, !dbg [[DBG156]]
// LIN64-NEXT:    [[BF_LOAD319:%.*]] = load i8, ptr [[ATOMIC_TEMP318]], align 1, !dbg [[DBG156]]
// LIN64-NEXT:    [[BF_ASHR320:%.*]] = ashr i8 [[BF_LOAD319]], 1, !dbg [[DBG156]]
// LIN64-NEXT:    [[BF_CAST321:%.*]] = sext i8 [[BF_ASHR320]] to i64, !dbg [[DBG156]]
// LIN64-NEXT:    [[CONV322:%.*]] = sitofp i64 [[BF_CAST321]] to x86_fp80, !dbg [[DBG157:![0-9]+]]
// LIN64-NEXT:    [[ADD323:%.*]] = fadd x86_fp80 [[CONV322]], [[TMP189]], !dbg [[DBG158:![0-9]+]]
// LIN64-NEXT:    [[CONV324:%.*]] = fptosi x86_fp80 [[ADD323]] to i64, !dbg [[DBG157]]
// LIN64-NEXT:    [[TMP191:%.*]] = trunc i64 [[CONV324]] to i8, !dbg [[DBG156]]
// LIN64-NEXT:    [[BF_LOAD325:%.*]] = load i8, ptr [[ATOMIC_TEMP317]], align 1, !dbg [[DBG156]]
// LIN64-NEXT:    [[BF_VALUE326:%.*]] = and i8 [[TMP191]], 127, !dbg [[DBG156]]
// LIN64-NEXT:    [[BF_SHL327:%.*]] = shl i8 [[BF_VALUE326]], 1, !dbg [[DBG156]]
// LIN64-NEXT:    [[BF_CLEAR328:%.*]] = and i8 [[BF_LOAD325]], 1, !dbg [[DBG156]]
// LIN64-NEXT:    [[BF_SET329:%.*]] = or i8 [[BF_CLEAR328]], [[BF_SHL327]], !dbg [[DBG156]]
// LIN64-NEXT:    store i8 [[BF_SET329]], ptr [[ATOMIC_TEMP317]], align 1, !dbg [[DBG156]]
// LIN64-NEXT:    [[TMP192:%.*]] = load i8, ptr [[ATOMIC_TEMP317]], align 1, !dbg [[DBG156]]
// LIN64-NEXT:    [[TMP193:%.*]] = cmpxchg ptr getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1), i8 [[TMP190]], i8 [[TMP192]] acquire acquire, align 1, !dbg [[DBG156]]
// LIN64-NEXT:    [[TMP194]] = extractvalue { i8, i1 } [[TMP193]], 0, !dbg [[DBG156]]
// LIN64-NEXT:    [[TMP195:%.*]] = extractvalue { i8, i1 } [[TMP193]], 1, !dbg [[DBG156]]
// LIN64-NEXT:    br i1 [[TMP195]], label [[ATOMIC_EXIT330:%.*]], label [[ATOMIC_CONT316]], !dbg [[DBG156]]
// LIN64:       atomic_exit330:
// LIN64-NEXT:    [[CONV331:%.*]] = trunc i64 [[CONV324]] to i32, !dbg [[DBG156]]
// LIN64-NEXT:    store i32 [[CONV331]], ptr @iv, align 4, !dbg [[DBG156]]
// LIN64-NEXT:    [[TMP196:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG159:![0-9]+]]
// LIN64-NEXT:    [[CONV332:%.*]] = uitofp i64 [[TMP196]] to float, !dbg [[DBG159]]
// LIN64-NEXT:    [[ATOMIC_LOAD333:%.*]] = load atomic i64, ptr @float2x acquire, align 8, !dbg [[DBG160:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT334:%.*]], !dbg [[DBG160]]
// LIN64:       atomic_cont334:
// LIN64-NEXT:    [[TMP197:%.*]] = phi i64 [ [[ATOMIC_LOAD333]], [[ATOMIC_EXIT330]] ], [ [[TMP205:%.*]], [[ATOMIC_CONT334]] ], !dbg [[DBG160]]
// LIN64-NEXT:    store i64 [[TMP197]], ptr [[ATOMIC_TEMP335]], align 8, !dbg [[DBG160]]
// LIN64-NEXT:    [[TMP198:%.*]] = bitcast i64 [[TMP197]] to <2 x float>, !dbg [[DBG160]]
// LIN64-NEXT:    store <2 x float> [[TMP198]], ptr [[ATOMIC_TEMP336]], align 8, !dbg [[DBG160]]
// LIN64-NEXT:    [[TMP199:%.*]] = load <2 x float>, ptr [[ATOMIC_TEMP336]], align 8, !dbg [[DBG160]]
// LIN64-NEXT:    [[TMP200:%.*]] = extractelement <2 x float> [[TMP199]], i64 0, !dbg [[DBG160]]
// LIN64-NEXT:    [[SUB337:%.*]] = fsub float [[CONV332]], [[TMP200]], !dbg [[DBG161:![0-9]+]]
// LIN64-NEXT:    [[TMP201:%.*]] = load <2 x float>, ptr [[ATOMIC_TEMP335]], align 8, !dbg [[DBG160]]
// LIN64-NEXT:    [[TMP202:%.*]] = insertelement <2 x float> [[TMP201]], float [[SUB337]], i64 0, !dbg [[DBG160]]
// LIN64-NEXT:    store <2 x float> [[TMP202]], ptr [[ATOMIC_TEMP335]], align 8, !dbg [[DBG160]]
// LIN64-NEXT:    [[TMP203:%.*]] = load i64, ptr [[ATOMIC_TEMP335]], align 8, !dbg [[DBG160]]
// LIN64-NEXT:    [[TMP204:%.*]] = cmpxchg ptr @float2x, i64 [[TMP197]], i64 [[TMP203]] acq_rel acquire, align 8, !dbg [[DBG160]]
// LIN64-NEXT:    [[TMP205]] = extractvalue { i64, i1 } [[TMP204]], 0, !dbg [[DBG160]]
// LIN64-NEXT:    [[TMP206:%.*]] = extractvalue { i64, i1 } [[TMP204]], 1, !dbg [[DBG160]]
// LIN64-NEXT:    br i1 [[TMP206]], label [[ATOMIC_EXIT338:%.*]], label [[ATOMIC_CONT334]], !dbg [[DBG160]]
// LIN64:       atomic_exit338:
// LIN64-NEXT:    store float [[TMP200]], ptr @fv, align 4, !dbg [[DBG160]]
// LIN64-NEXT:    [[TMP207:%.*]] = load double, ptr @dv, align 8, !dbg [[DBG162:![0-9]+]]
// LIN64-NEXT:    [[TMP208:%.*]] = call i32 @llvm.read_register.i32(metadata [[META2:![0-9]+]]), !dbg [[DBG163:![0-9]+]]
// LIN64-NEXT:    [[CONV339:%.*]] = sitofp i32 [[TMP208]] to double, !dbg [[DBG164:![0-9]+]]
// LIN64-NEXT:    [[DIV340:%.*]] = fdiv double [[TMP207]], [[CONV339]], !dbg [[DBG165:![0-9]+]]
// LIN64-NEXT:    [[CONV341:%.*]] = fptosi double [[DIV340]] to i32, !dbg [[DBG162]]
// LIN64-NEXT:    call void @llvm.write_register.i32(metadata [[META2]], i32 [[CONV341]]), !dbg [[DBG163]]
// LIN64-NEXT:    store i32 [[CONV341]], ptr @iv, align 4, !dbg [[DBG163]]
// LIN64-NEXT:    [[TMP209:%.*]] = atomicrmw xchg ptr @ix, i32 5 monotonic, align 4, !dbg [[DBG166:![0-9]+]]
// LIN64-NEXT:    call void @llvm.write_register.i32(metadata [[META2]], i32 [[TMP209]]), !dbg [[DBG166]]
// LIN64-NEXT:    ret i32 0, !dbg [[DBG167:![0-9]+]]
//
//
// PPC64-LABEL: define {{[^@]+}}@main
// PPC64-SAME: () #[[ATTR0:[0-9]+]] !dbg [[DBG6:![0-9]+]] {
// PPC64-NEXT:  entry:
// PPC64-NEXT:    [[RETVAL:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca i16, align 2
// PPC64-NEXT:    [[ATOMIC_TEMP10:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP14:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP18:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP22:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP28:%.*]] = alloca double, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP32:%.*]] = alloca ppc_fp128, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP34:%.*]] = alloca ppc_fp128, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP38:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP40:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP45:%.*]] = alloca { float, float }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP47:%.*]] = alloca { float, float }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP52:%.*]] = alloca { double, double }, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP54:%.*]] = alloca { double, double }, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP64:%.*]] = alloca i8, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP74:%.*]] = alloca i8, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP82:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP89:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP93:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP95:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP107:%.*]] = alloca float, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP113:%.*]] = alloca double, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP117:%.*]] = alloca ppc_fp128, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP119:%.*]] = alloca ppc_fp128, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP123:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP125:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP135:%.*]] = alloca i16, align 2
// PPC64-NEXT:    [[ATOMIC_TEMP143:%.*]] = alloca i8, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP156:%.*]] = alloca i8, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP169:%.*]] = alloca <4 x i32>, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP171:%.*]] = alloca <4 x i32>, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP172:%.*]] = alloca <4 x i32>, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP178:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP179:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP185:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP187:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP188:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP203:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP204:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP218:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP219:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP233:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP234:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP247:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP249:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP250:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP267:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP268:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP284:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP285:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP300:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP301:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP317:%.*]] = alloca i64, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP318:%.*]] = alloca i64, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP335:%.*]] = alloca <2 x float>, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP336:%.*]] = alloca <2 x float>, align 8
// PPC64-NEXT:    store i32 0, ptr [[RETVAL]], align 4
// PPC64-NEXT:    [[TMP0:%.*]] = atomicrmw add ptr @bx, i8 1 monotonic, align 1, !dbg [[DBG10:![0-9]+]]
// PPC64-NEXT:    store i8 [[TMP0]], ptr @bv, align 1, !dbg [[DBG10]]
// PPC64-NEXT:    [[TMP1:%.*]] = atomicrmw add ptr @cx, i8 1 monotonic, align 1, !dbg [[DBG11:![0-9]+]]
// PPC64-NEXT:    [[CONV:%.*]] = sext i8 [[TMP1]] to i32, !dbg [[DBG12:![0-9]+]]
// PPC64-NEXT:    [[ADD:%.*]] = add nsw i32 [[CONV]], 1, !dbg [[DBG13:![0-9]+]]
// PPC64-NEXT:    [[CONV1:%.*]] = trunc i32 [[ADD]] to i8, !dbg [[DBG12]]
// PPC64-NEXT:    store i8 [[CONV1]], ptr @cv, align 1, !dbg [[DBG11]]
// PPC64-NEXT:    [[TMP2:%.*]] = atomicrmw sub ptr @ucx, i8 1 monotonic, align 1, !dbg [[DBG14:![0-9]+]]
// PPC64-NEXT:    store i8 [[TMP2]], ptr @ucv, align 1, !dbg [[DBG14]]
// PPC64-NEXT:    [[TMP3:%.*]] = atomicrmw sub ptr @sx, i16 1 monotonic, align 2, !dbg [[DBG15:![0-9]+]]
// PPC64-NEXT:    [[CONV2:%.*]] = sext i16 [[TMP3]] to i32, !dbg [[DBG16:![0-9]+]]
// PPC64-NEXT:    [[SUB:%.*]] = sub nsw i32 [[CONV2]], 1, !dbg [[DBG17:![0-9]+]]
// PPC64-NEXT:    [[CONV3:%.*]] = trunc i32 [[SUB]] to i16, !dbg [[DBG16]]
// PPC64-NEXT:    store i16 [[CONV3]], ptr @sv, align 2, !dbg [[DBG15]]
// PPC64-NEXT:    [[TMP4:%.*]] = load i16, ptr @usv, align 2, !dbg [[DBG18:![0-9]+]]
// PPC64-NEXT:    [[CONV4:%.*]] = zext i16 [[TMP4]] to i32, !dbg [[DBG18]]
// PPC64-NEXT:    [[ATOMIC_LOAD:%.*]] = load atomic i16, ptr @usx monotonic, align 2, !dbg [[DBG19:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT:%.*]], !dbg [[DBG19]]
// PPC64:       atomic_cont:
// PPC64-NEXT:    [[TMP5:%.*]] = phi i16 [ [[ATOMIC_LOAD]], [[ENTRY:%.*]] ], [ [[TMP8:%.*]], [[ATOMIC_CONT]] ], !dbg [[DBG19]]
// PPC64-NEXT:    [[CONV5:%.*]] = zext i16 [[TMP5]] to i32, !dbg [[DBG20:![0-9]+]]
// PPC64-NEXT:    [[ADD6:%.*]] = add nsw i32 [[CONV5]], [[CONV4]], !dbg [[DBG21:![0-9]+]]
// PPC64-NEXT:    [[CONV7:%.*]] = trunc i32 [[ADD6]] to i16, !dbg [[DBG20]]
// PPC64-NEXT:    store i16 [[CONV7]], ptr [[ATOMIC_TEMP]], align 2, !dbg [[DBG19]]
// PPC64-NEXT:    [[TMP6:%.*]] = load i16, ptr [[ATOMIC_TEMP]], align 2, !dbg [[DBG19]]
// PPC64-NEXT:    [[TMP7:%.*]] = cmpxchg ptr @usx, i16 [[TMP5]], i16 [[TMP6]] monotonic monotonic, align 2, !dbg [[DBG19]]
// PPC64-NEXT:    [[TMP8]] = extractvalue { i16, i1 } [[TMP7]], 0, !dbg [[DBG19]]
// PPC64-NEXT:    [[TMP9:%.*]] = extractvalue { i16, i1 } [[TMP7]], 1, !dbg [[DBG19]]
// PPC64-NEXT:    br i1 [[TMP9]], label [[ATOMIC_EXIT:%.*]], label [[ATOMIC_CONT]], !dbg [[DBG19]]
// PPC64:       atomic_exit:
// PPC64-NEXT:    store i16 [[CONV7]], ptr @sv, align 2, !dbg [[DBG19]]
// PPC64-NEXT:    [[TMP10:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG22:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD8:%.*]] = load atomic i32, ptr @ix monotonic, align 4, !dbg [[DBG23:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT9:%.*]], !dbg [[DBG23]]
// PPC64:       atomic_cont9:
// PPC64-NEXT:    [[TMP11:%.*]] = phi i32 [ [[ATOMIC_LOAD8]], [[ATOMIC_EXIT]] ], [ [[TMP14:%.*]], [[ATOMIC_CONT9]] ], !dbg [[DBG23]]
// PPC64-NEXT:    [[MUL:%.*]] = mul nsw i32 [[TMP11]], [[TMP10]], !dbg [[DBG24:![0-9]+]]
// PPC64-NEXT:    store i32 [[MUL]], ptr [[ATOMIC_TEMP10]], align 4, !dbg [[DBG23]]
// PPC64-NEXT:    [[TMP12:%.*]] = load i32, ptr [[ATOMIC_TEMP10]], align 4, !dbg [[DBG23]]
// PPC64-NEXT:    [[TMP13:%.*]] = cmpxchg ptr @ix, i32 [[TMP11]], i32 [[TMP12]] monotonic monotonic, align 4, !dbg [[DBG23]]
// PPC64-NEXT:    [[TMP14]] = extractvalue { i32, i1 } [[TMP13]], 0, !dbg [[DBG23]]
// PPC64-NEXT:    [[TMP15:%.*]] = extractvalue { i32, i1 } [[TMP13]], 1, !dbg [[DBG23]]
// PPC64-NEXT:    br i1 [[TMP15]], label [[ATOMIC_EXIT11:%.*]], label [[ATOMIC_CONT9]], !dbg [[DBG23]]
// PPC64:       atomic_exit11:
// PPC64-NEXT:    store i32 [[MUL]], ptr @uiv, align 4, !dbg [[DBG23]]
// PPC64-NEXT:    [[TMP16:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG25:![0-9]+]]
// PPC64-NEXT:    [[TMP17:%.*]] = atomicrmw sub ptr @uix, i32 [[TMP16]] monotonic, align 4, !dbg [[DBG26:![0-9]+]]
// PPC64-NEXT:    store i32 [[TMP17]], ptr @iv, align 4, !dbg [[DBG26]]
// PPC64-NEXT:    [[TMP18:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG27:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD12:%.*]] = load atomic i32, ptr @ix monotonic, align 4, !dbg [[DBG28:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT13:%.*]], !dbg [[DBG28]]
// PPC64:       atomic_cont13:
// PPC64-NEXT:    [[TMP19:%.*]] = phi i32 [ [[ATOMIC_LOAD12]], [[ATOMIC_EXIT11]] ], [ [[TMP22:%.*]], [[ATOMIC_CONT13]] ], !dbg [[DBG28]]
// PPC64-NEXT:    [[SHL:%.*]] = shl i32 [[TMP19]], [[TMP18]], !dbg [[DBG29:![0-9]+]]
// PPC64-NEXT:    store i32 [[SHL]], ptr [[ATOMIC_TEMP14]], align 4, !dbg [[DBG28]]
// PPC64-NEXT:    [[TMP20:%.*]] = load i32, ptr [[ATOMIC_TEMP14]], align 4, !dbg [[DBG28]]
// PPC64-NEXT:    [[TMP21:%.*]] = cmpxchg ptr @ix, i32 [[TMP19]], i32 [[TMP20]] monotonic monotonic, align 4, !dbg [[DBG28]]
// PPC64-NEXT:    [[TMP22]] = extractvalue { i32, i1 } [[TMP21]], 0, !dbg [[DBG28]]
// PPC64-NEXT:    [[TMP23:%.*]] = extractvalue { i32, i1 } [[TMP21]], 1, !dbg [[DBG28]]
// PPC64-NEXT:    br i1 [[TMP23]], label [[ATOMIC_EXIT15:%.*]], label [[ATOMIC_CONT13]], !dbg [[DBG28]]
// PPC64:       atomic_exit15:
// PPC64-NEXT:    store i32 [[SHL]], ptr @uiv, align 4, !dbg [[DBG28]]
// PPC64-NEXT:    [[TMP24:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG30:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD16:%.*]] = load atomic i32, ptr @uix monotonic, align 4, !dbg [[DBG31:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT17:%.*]], !dbg [[DBG31]]
// PPC64:       atomic_cont17:
// PPC64-NEXT:    [[TMP25:%.*]] = phi i32 [ [[ATOMIC_LOAD16]], [[ATOMIC_EXIT15]] ], [ [[TMP28:%.*]], [[ATOMIC_CONT17]] ], !dbg [[DBG31]]
// PPC64-NEXT:    [[SHR:%.*]] = lshr i32 [[TMP25]], [[TMP24]], !dbg [[DBG32:![0-9]+]]
// PPC64-NEXT:    store i32 [[SHR]], ptr [[ATOMIC_TEMP18]], align 4, !dbg [[DBG31]]
// PPC64-NEXT:    [[TMP26:%.*]] = load i32, ptr [[ATOMIC_TEMP18]], align 4, !dbg [[DBG31]]
// PPC64-NEXT:    [[TMP27:%.*]] = cmpxchg ptr @uix, i32 [[TMP25]], i32 [[TMP26]] monotonic monotonic, align 4, !dbg [[DBG31]]
// PPC64-NEXT:    [[TMP28]] = extractvalue { i32, i1 } [[TMP27]], 0, !dbg [[DBG31]]
// PPC64-NEXT:    [[TMP29:%.*]] = extractvalue { i32, i1 } [[TMP27]], 1, !dbg [[DBG31]]
// PPC64-NEXT:    br i1 [[TMP29]], label [[ATOMIC_EXIT19:%.*]], label [[ATOMIC_CONT17]], !dbg [[DBG31]]
// PPC64:       atomic_exit19:
// PPC64-NEXT:    store i32 [[SHR]], ptr @iv, align 4, !dbg [[DBG31]]
// PPC64-NEXT:    [[TMP30:%.*]] = load i64, ptr @lv, align 8, !dbg [[DBG33:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD20:%.*]] = load atomic i64, ptr @lx monotonic, align 8, !dbg [[DBG34:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT21:%.*]], !dbg [[DBG34]]
// PPC64:       atomic_cont21:
// PPC64-NEXT:    [[TMP31:%.*]] = phi i64 [ [[ATOMIC_LOAD20]], [[ATOMIC_EXIT19]] ], [ [[TMP34:%.*]], [[ATOMIC_CONT21]] ], !dbg [[DBG34]]
// PPC64-NEXT:    [[DIV:%.*]] = sdiv i64 [[TMP31]], [[TMP30]], !dbg [[DBG35:![0-9]+]]
// PPC64-NEXT:    store i64 [[DIV]], ptr [[ATOMIC_TEMP22]], align 8, !dbg [[DBG34]]
// PPC64-NEXT:    [[TMP32:%.*]] = load i64, ptr [[ATOMIC_TEMP22]], align 8, !dbg [[DBG34]]
// PPC64-NEXT:    [[TMP33:%.*]] = cmpxchg ptr @lx, i64 [[TMP31]], i64 [[TMP32]] monotonic monotonic, align 8, !dbg [[DBG34]]
// PPC64-NEXT:    [[TMP34]] = extractvalue { i64, i1 } [[TMP33]], 0, !dbg [[DBG34]]
// PPC64-NEXT:    [[TMP35:%.*]] = extractvalue { i64, i1 } [[TMP33]], 1, !dbg [[DBG34]]
// PPC64-NEXT:    br i1 [[TMP35]], label [[ATOMIC_EXIT23:%.*]], label [[ATOMIC_CONT21]], !dbg [[DBG34]]
// PPC64:       atomic_exit23:
// PPC64-NEXT:    store i64 [[TMP31]], ptr @ulv, align 8, !dbg [[DBG34]]
// PPC64-NEXT:    [[TMP36:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG36:![0-9]+]]
// PPC64-NEXT:    [[TMP37:%.*]] = atomicrmw and ptr @ulx, i64 [[TMP36]] monotonic, align 8, !dbg [[DBG37:![0-9]+]]
// PPC64-NEXT:    [[AND:%.*]] = and i64 [[TMP37]], [[TMP36]], !dbg [[DBG38:![0-9]+]]
// PPC64-NEXT:    store i64 [[AND]], ptr @lv, align 8, !dbg [[DBG37]]
// PPC64-NEXT:    [[TMP38:%.*]] = load i64, ptr @llv, align 8, !dbg [[DBG39:![0-9]+]]
// PPC64-NEXT:    [[TMP39:%.*]] = atomicrmw xor ptr @llx, i64 [[TMP38]] monotonic, align 8, !dbg [[DBG40:![0-9]+]]
// PPC64-NEXT:    [[XOR:%.*]] = xor i64 [[TMP39]], [[TMP38]], !dbg [[DBG41:![0-9]+]]
// PPC64-NEXT:    store i64 [[XOR]], ptr @ullv, align 8, !dbg [[DBG40]]
// PPC64-NEXT:    [[TMP40:%.*]] = load i64, ptr @ullv, align 8, !dbg [[DBG42:![0-9]+]]
// PPC64-NEXT:    [[TMP41:%.*]] = atomicrmw or ptr @ullx, i64 [[TMP40]] monotonic, align 8, !dbg [[DBG43:![0-9]+]]
// PPC64-NEXT:    [[OR:%.*]] = or i64 [[TMP41]], [[TMP40]], !dbg [[DBG44:![0-9]+]]
// PPC64-NEXT:    store i64 [[OR]], ptr @llv, align 8, !dbg [[DBG43]]
// PPC64-NEXT:    [[TMP42:%.*]] = load float, ptr @fv, align 4, !dbg [[DBG45:![0-9]+]]
// PPC64-NEXT:    [[TMP43:%.*]] = atomicrmw fadd ptr @fx, float [[TMP42]] monotonic, align 4, !dbg [[DBG46:![0-9]+]]
// PPC64-NEXT:    [[ADD24:%.*]] = fadd float [[TMP43]], [[TMP42]], !dbg [[DBG47:![0-9]+]]
// PPC64-NEXT:    [[CONV25:%.*]] = fpext float [[ADD24]] to double, !dbg [[DBG46]]
// PPC64-NEXT:    store double [[CONV25]], ptr @dv, align 8, !dbg [[DBG46]]
// PPC64-NEXT:    [[TMP44:%.*]] = load double, ptr @dv, align 8, !dbg [[DBG48:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD26:%.*]] = load atomic i64, ptr @dx monotonic, align 8, !dbg [[DBG49:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT27:%.*]], !dbg [[DBG49]]
// PPC64:       atomic_cont27:
// PPC64-NEXT:    [[TMP45:%.*]] = phi i64 [ [[ATOMIC_LOAD26]], [[ATOMIC_EXIT23]] ], [ [[TMP49:%.*]], [[ATOMIC_CONT27]] ], !dbg [[DBG49]]
// PPC64-NEXT:    [[TMP46:%.*]] = bitcast i64 [[TMP45]] to double, !dbg [[DBG49]]
// PPC64-NEXT:    [[SUB29:%.*]] = fsub double [[TMP44]], [[TMP46]], !dbg [[DBG50:![0-9]+]]
// PPC64-NEXT:    store double [[SUB29]], ptr [[ATOMIC_TEMP28]], align 8, !dbg [[DBG49]]
// PPC64-NEXT:    [[TMP47:%.*]] = load i64, ptr [[ATOMIC_TEMP28]], align 8, !dbg [[DBG49]]
// PPC64-NEXT:    [[TMP48:%.*]] = cmpxchg ptr @dx, i64 [[TMP45]], i64 [[TMP47]] monotonic monotonic, align 8, !dbg [[DBG49]]
// PPC64-NEXT:    [[TMP49]] = extractvalue { i64, i1 } [[TMP48]], 0, !dbg [[DBG49]]
// PPC64-NEXT:    [[TMP50:%.*]] = extractvalue { i64, i1 } [[TMP48]], 1, !dbg [[DBG49]]
// PPC64-NEXT:    br i1 [[TMP50]], label [[ATOMIC_EXIT30:%.*]], label [[ATOMIC_CONT27]], !dbg [[DBG49]]
// PPC64:       atomic_exit30:
// PPC64-NEXT:    [[CONV31:%.*]] = fptrunc double [[TMP46]] to float, !dbg [[DBG49]]
// PPC64-NEXT:    store float [[CONV31]], ptr @fv, align 4, !dbg [[DBG49]]
// PPC64-NEXT:    [[TMP51:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG51:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 16, ptr noundef @ldx, ptr noundef [[ATOMIC_TEMP32]], i32 noundef signext 0), !dbg [[DBG52:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT33:%.*]], !dbg [[DBG52]]
// PPC64:       atomic_cont33:
// PPC64-NEXT:    [[TMP52:%.*]] = load ppc_fp128, ptr [[ATOMIC_TEMP32]], align 16, !dbg [[DBG52]]
// PPC64-NEXT:    [[MUL35:%.*]] = fmul ppc_fp128 [[TMP52]], [[TMP51]], !dbg [[DBG53:![0-9]+]]
// PPC64-NEXT:    store ppc_fp128 [[MUL35]], ptr [[ATOMIC_TEMP34]], align 16, !dbg [[DBG52]]
// PPC64-NEXT:    [[CALL:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, ptr noundef @ldx, ptr noundef [[ATOMIC_TEMP32]], ptr noundef [[ATOMIC_TEMP34]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG52]]
// PPC64-NEXT:    br i1 [[CALL]], label [[ATOMIC_EXIT36:%.*]], label [[ATOMIC_CONT33]], !dbg [[DBG52]]
// PPC64:       atomic_exit36:
// PPC64-NEXT:    [[CONV37:%.*]] = fptrunc ppc_fp128 [[MUL35]] to double, !dbg [[DBG52]]
// PPC64-NEXT:    store double [[CONV37]], ptr @dv, align 8, !dbg [[DBG52]]
// PPC64-NEXT:    [[CIV_REAL:%.*]] = load i32, ptr @civ, align 4, !dbg [[DBG54:![0-9]+]]
// PPC64-NEXT:    [[CIV_IMAG:%.*]] = load i32, ptr getelementptr inbounds ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG54]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP38]], i32 noundef signext 0), !dbg [[DBG55:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT39:%.*]], !dbg [[DBG55]]
// PPC64:       atomic_cont39:
// PPC64-NEXT:    [[ATOMIC_TEMP38_REALP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP38]], i32 0, i32 0, !dbg [[DBG55]]
// PPC64-NEXT:    [[ATOMIC_TEMP38_REAL:%.*]] = load i32, ptr [[ATOMIC_TEMP38_REALP]], align 4, !dbg [[DBG55]]
// PPC64-NEXT:    [[ATOMIC_TEMP38_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP38]], i32 0, i32 1, !dbg [[DBG55]]
// PPC64-NEXT:    [[ATOMIC_TEMP38_IMAG:%.*]] = load i32, ptr [[ATOMIC_TEMP38_IMAGP]], align 4, !dbg [[DBG55]]
// PPC64-NEXT:    [[TMP53:%.*]] = mul i32 [[CIV_REAL]], [[ATOMIC_TEMP38_REAL]], !dbg [[DBG56:![0-9]+]]
// PPC64-NEXT:    [[TMP54:%.*]] = mul i32 [[CIV_IMAG]], [[ATOMIC_TEMP38_IMAG]], !dbg [[DBG56]]
// PPC64-NEXT:    [[TMP55:%.*]] = add i32 [[TMP53]], [[TMP54]], !dbg [[DBG56]]
// PPC64-NEXT:    [[TMP56:%.*]] = mul i32 [[ATOMIC_TEMP38_REAL]], [[ATOMIC_TEMP38_REAL]], !dbg [[DBG56]]
// PPC64-NEXT:    [[TMP57:%.*]] = mul i32 [[ATOMIC_TEMP38_IMAG]], [[ATOMIC_TEMP38_IMAG]], !dbg [[DBG56]]
// PPC64-NEXT:    [[TMP58:%.*]] = add i32 [[TMP56]], [[TMP57]], !dbg [[DBG56]]
// PPC64-NEXT:    [[TMP59:%.*]] = mul i32 [[CIV_IMAG]], [[ATOMIC_TEMP38_REAL]], !dbg [[DBG56]]
// PPC64-NEXT:    [[TMP60:%.*]] = mul i32 [[CIV_REAL]], [[ATOMIC_TEMP38_IMAG]], !dbg [[DBG56]]
// PPC64-NEXT:    [[TMP61:%.*]] = sub i32 [[TMP59]], [[TMP60]], !dbg [[DBG56]]
// PPC64-NEXT:    [[TMP62:%.*]] = sdiv i32 [[TMP55]], [[TMP58]], !dbg [[DBG56]]
// PPC64-NEXT:    [[TMP63:%.*]] = sdiv i32 [[TMP61]], [[TMP58]], !dbg [[DBG56]]
// PPC64-NEXT:    [[ATOMIC_TEMP40_REALP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP40]], i32 0, i32 0, !dbg [[DBG55]]
// PPC64-NEXT:    [[ATOMIC_TEMP40_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP40]], i32 0, i32 1, !dbg [[DBG55]]
// PPC64-NEXT:    store i32 [[TMP62]], ptr [[ATOMIC_TEMP40_REALP]], align 4, !dbg [[DBG55]]
// PPC64-NEXT:    store i32 [[TMP63]], ptr [[ATOMIC_TEMP40_IMAGP]], align 4, !dbg [[DBG55]]
// PPC64-NEXT:    [[CALL41:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP38]], ptr noundef [[ATOMIC_TEMP40]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG55]]
// PPC64-NEXT:    br i1 [[CALL41]], label [[ATOMIC_EXIT42:%.*]], label [[ATOMIC_CONT39]], !dbg [[DBG55]]
// PPC64:       atomic_exit42:
// PPC64-NEXT:    [[CONV43:%.*]] = sitofp i32 [[TMP62]] to float, !dbg [[DBG55]]
// PPC64-NEXT:    [[CONV44:%.*]] = sitofp i32 [[TMP63]] to float, !dbg [[DBG55]]
// PPC64-NEXT:    store float [[CONV43]], ptr @cfv, align 4, !dbg [[DBG55]]
// PPC64-NEXT:    store float [[CONV44]], ptr getelementptr inbounds ({ float, float }, ptr @cfv, i32 0, i32 1), align 4, !dbg [[DBG55]]
// PPC64-NEXT:    [[CFV_REAL:%.*]] = load float, ptr @cfv, align 4, !dbg [[DBG57:![0-9]+]]
// PPC64-NEXT:    [[CFV_IMAG:%.*]] = load float, ptr getelementptr inbounds ({ float, float }, ptr @cfv, i32 0, i32 1), align 4, !dbg [[DBG57]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cfx, ptr noundef [[ATOMIC_TEMP45]], i32 noundef signext 0), !dbg [[DBG58:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT46:%.*]], !dbg [[DBG58]]
// PPC64:       atomic_cont46:
// PPC64-NEXT:    [[ATOMIC_TEMP45_REALP:%.*]] = getelementptr inbounds { float, float }, ptr [[ATOMIC_TEMP45]], i32 0, i32 0, !dbg [[DBG58]]
// PPC64-NEXT:    [[ATOMIC_TEMP45_REAL:%.*]] = load float, ptr [[ATOMIC_TEMP45_REALP]], align 4, !dbg [[DBG58]]
// PPC64-NEXT:    [[ATOMIC_TEMP45_IMAGP:%.*]] = getelementptr inbounds { float, float }, ptr [[ATOMIC_TEMP45]], i32 0, i32 1, !dbg [[DBG58]]
// PPC64-NEXT:    [[ATOMIC_TEMP45_IMAG:%.*]] = load float, ptr [[ATOMIC_TEMP45_IMAGP]], align 4, !dbg [[DBG58]]
// PPC64-NEXT:    [[ADD_R:%.*]] = fadd float [[CFV_REAL]], [[ATOMIC_TEMP45_REAL]], !dbg [[DBG59:![0-9]+]]
// PPC64-NEXT:    [[ADD_I:%.*]] = fadd float [[CFV_IMAG]], [[ATOMIC_TEMP45_IMAG]], !dbg [[DBG59]]
// PPC64-NEXT:    [[ATOMIC_TEMP47_REALP:%.*]] = getelementptr inbounds { float, float }, ptr [[ATOMIC_TEMP47]], i32 0, i32 0, !dbg [[DBG58]]
// PPC64-NEXT:    [[ATOMIC_TEMP47_IMAGP:%.*]] = getelementptr inbounds { float, float }, ptr [[ATOMIC_TEMP47]], i32 0, i32 1, !dbg [[DBG58]]
// PPC64-NEXT:    store float [[ADD_R]], ptr [[ATOMIC_TEMP47_REALP]], align 4, !dbg [[DBG58]]
// PPC64-NEXT:    store float [[ADD_I]], ptr [[ATOMIC_TEMP47_IMAGP]], align 4, !dbg [[DBG58]]
// PPC64-NEXT:    [[CALL48:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cfx, ptr noundef [[ATOMIC_TEMP45]], ptr noundef [[ATOMIC_TEMP47]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG58]]
// PPC64-NEXT:    br i1 [[CALL48]], label [[ATOMIC_EXIT49:%.*]], label [[ATOMIC_CONT46]], !dbg [[DBG58]]
// PPC64:       atomic_exit49:
// PPC64-NEXT:    [[CONV50:%.*]] = fptosi float [[ATOMIC_TEMP45_REAL]] to i32, !dbg [[DBG58]]
// PPC64-NEXT:    [[CONV51:%.*]] = fptosi float [[ATOMIC_TEMP45_IMAG]] to i32, !dbg [[DBG58]]
// PPC64-NEXT:    store i32 [[CONV50]], ptr @civ, align 4, !dbg [[DBG58]]
// PPC64-NEXT:    store i32 [[CONV51]], ptr getelementptr inbounds ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG58]]
// PPC64-NEXT:    [[CDV_REAL:%.*]] = load double, ptr @cdv, align 8, !dbg [[DBG60:![0-9]+]]
// PPC64-NEXT:    [[CDV_IMAG:%.*]] = load double, ptr getelementptr inbounds ({ double, double }, ptr @cdv, i32 0, i32 1), align 8, !dbg [[DBG60]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 16, ptr noundef @cdx, ptr noundef [[ATOMIC_TEMP52]], i32 noundef signext 5), !dbg [[DBG61:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT53:%.*]], !dbg [[DBG61]]
// PPC64:       atomic_cont53:
// PPC64-NEXT:    [[ATOMIC_TEMP52_REALP:%.*]] = getelementptr inbounds { double, double }, ptr [[ATOMIC_TEMP52]], i32 0, i32 0, !dbg [[DBG61]]
// PPC64-NEXT:    [[ATOMIC_TEMP52_REAL:%.*]] = load double, ptr [[ATOMIC_TEMP52_REALP]], align 8, !dbg [[DBG61]]
// PPC64-NEXT:    [[ATOMIC_TEMP52_IMAGP:%.*]] = getelementptr inbounds { double, double }, ptr [[ATOMIC_TEMP52]], i32 0, i32 1, !dbg [[DBG61]]
// PPC64-NEXT:    [[ATOMIC_TEMP52_IMAG:%.*]] = load double, ptr [[ATOMIC_TEMP52_IMAGP]], align 8, !dbg [[DBG61]]
// PPC64-NEXT:    [[SUB_R:%.*]] = fsub double [[ATOMIC_TEMP52_REAL]], [[CDV_REAL]], !dbg [[DBG62:![0-9]+]]
// PPC64-NEXT:    [[SUB_I:%.*]] = fsub double [[ATOMIC_TEMP52_IMAG]], [[CDV_IMAG]], !dbg [[DBG62]]
// PPC64-NEXT:    [[ATOMIC_TEMP54_REALP:%.*]] = getelementptr inbounds { double, double }, ptr [[ATOMIC_TEMP54]], i32 0, i32 0, !dbg [[DBG61]]
// PPC64-NEXT:    [[ATOMIC_TEMP54_IMAGP:%.*]] = getelementptr inbounds { double, double }, ptr [[ATOMIC_TEMP54]], i32 0, i32 1, !dbg [[DBG61]]
// PPC64-NEXT:    store double [[SUB_R]], ptr [[ATOMIC_TEMP54_REALP]], align 8, !dbg [[DBG61]]
// PPC64-NEXT:    store double [[SUB_I]], ptr [[ATOMIC_TEMP54_IMAGP]], align 8, !dbg [[DBG61]]
// PPC64-NEXT:    [[CALL55:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, ptr noundef @cdx, ptr noundef [[ATOMIC_TEMP52]], ptr noundef [[ATOMIC_TEMP54]], i32 noundef signext 5, i32 noundef signext 5), !dbg [[DBG61]]
// PPC64-NEXT:    br i1 [[CALL55]], label [[ATOMIC_EXIT56:%.*]], label [[ATOMIC_CONT53]], !dbg [[DBG61]]
// PPC64:       atomic_exit56:
// PPC64-NEXT:    [[CONV57:%.*]] = fptrunc double [[SUB_R]] to float, !dbg [[DBG61]]
// PPC64-NEXT:    [[CONV58:%.*]] = fptrunc double [[SUB_I]] to float, !dbg [[DBG61]]
// PPC64-NEXT:    store float [[CONV57]], ptr @cfv, align 4, !dbg [[DBG61]]
// PPC64-NEXT:    store float [[CONV58]], ptr getelementptr inbounds ({ float, float }, ptr @cfv, i32 0, i32 1), align 4, !dbg [[DBG61]]
// PPC64-NEXT:    [[TMP64:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG63:![0-9]+]]
// PPC64-NEXT:    [[TOBOOL:%.*]] = trunc i8 [[TMP64]] to i1, !dbg [[DBG63]]
// PPC64-NEXT:    [[CONV59:%.*]] = zext i1 [[TOBOOL]] to i64, !dbg [[DBG63]]
// PPC64-NEXT:    [[TMP65:%.*]] = atomicrmw and ptr @ulx, i64 [[CONV59]] monotonic, align 8, !dbg [[DBG64:![0-9]+]]
// PPC64-NEXT:    [[AND60:%.*]] = and i64 [[TMP65]], [[CONV59]], !dbg [[DBG65:![0-9]+]]
// PPC64-NEXT:    store i64 [[AND60]], ptr @ulv, align 8, !dbg [[DBG64]]
// PPC64-NEXT:    [[TMP66:%.*]] = load i8, ptr @cv, align 1, !dbg [[DBG66:![0-9]+]]
// PPC64-NEXT:    [[CONV61:%.*]] = sext i8 [[TMP66]] to i32, !dbg [[DBG66]]
// PPC64-NEXT:    [[ATOMIC_LOAD62:%.*]] = load atomic i8, ptr @bx monotonic, align 1, !dbg [[DBG67:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT63:%.*]], !dbg [[DBG67]]
// PPC64:       atomic_cont63:
// PPC64-NEXT:    [[TMP67:%.*]] = phi i8 [ [[ATOMIC_LOAD62]], [[ATOMIC_EXIT56]] ], [ [[TMP70:%.*]], [[ATOMIC_CONT63]] ], !dbg [[DBG67]]
// PPC64-NEXT:    [[TOBOOL65:%.*]] = trunc i8 [[TMP67]] to i1, !dbg [[DBG67]]
// PPC64-NEXT:    [[CONV66:%.*]] = zext i1 [[TOBOOL65]] to i32, !dbg [[DBG68:![0-9]+]]
// PPC64-NEXT:    [[AND67:%.*]] = and i32 [[CONV61]], [[CONV66]], !dbg [[DBG69:![0-9]+]]
// PPC64-NEXT:    [[TOBOOL68:%.*]] = icmp ne i32 [[AND67]], 0, !dbg [[DBG66]]
// PPC64-NEXT:    [[FROMBOOL:%.*]] = zext i1 [[TOBOOL68]] to i8, !dbg [[DBG67]]
// PPC64-NEXT:    store i8 [[FROMBOOL]], ptr [[ATOMIC_TEMP64]], align 1, !dbg [[DBG67]]
// PPC64-NEXT:    [[TMP68:%.*]] = load i8, ptr [[ATOMIC_TEMP64]], align 1, !dbg [[DBG67]]
// PPC64-NEXT:    [[TMP69:%.*]] = cmpxchg ptr @bx, i8 [[TMP67]], i8 [[TMP68]] monotonic monotonic, align 1, !dbg [[DBG67]]
// PPC64-NEXT:    [[TMP70]] = extractvalue { i8, i1 } [[TMP69]], 0, !dbg [[DBG67]]
// PPC64-NEXT:    [[TMP71:%.*]] = extractvalue { i8, i1 } [[TMP69]], 1, !dbg [[DBG67]]
// PPC64-NEXT:    br i1 [[TMP71]], label [[ATOMIC_EXIT69:%.*]], label [[ATOMIC_CONT63]], !dbg [[DBG67]]
// PPC64:       atomic_exit69:
// PPC64-NEXT:    [[FROMBOOL70:%.*]] = zext i1 [[TOBOOL65]] to i8, !dbg [[DBG67]]
// PPC64-NEXT:    store i8 [[FROMBOOL70]], ptr @bv, align 1, !dbg [[DBG67]]
// PPC64-NEXT:    [[TMP72:%.*]] = load i8, ptr @ucv, align 1, !dbg [[DBG70:![0-9]+]]
// PPC64-NEXT:    [[CONV71:%.*]] = zext i8 [[TMP72]] to i32, !dbg [[DBG70]]
// PPC64-NEXT:    [[ATOMIC_LOAD72:%.*]] = load atomic i8, ptr @cx seq_cst, align 1, !dbg [[DBG71:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT73:%.*]], !dbg [[DBG71]]
// PPC64:       atomic_cont73:
// PPC64-NEXT:    [[TMP73:%.*]] = phi i8 [ [[ATOMIC_LOAD72]], [[ATOMIC_EXIT69]] ], [ [[TMP76:%.*]], [[ATOMIC_CONT73]] ], !dbg [[DBG71]]
// PPC64-NEXT:    [[CONV75:%.*]] = sext i8 [[TMP73]] to i32, !dbg [[DBG72:![0-9]+]]
// PPC64-NEXT:    [[SHR76:%.*]] = ashr i32 [[CONV75]], [[CONV71]], !dbg [[DBG73:![0-9]+]]
// PPC64-NEXT:    [[CONV77:%.*]] = trunc i32 [[SHR76]] to i8, !dbg [[DBG72]]
// PPC64-NEXT:    store i8 [[CONV77]], ptr [[ATOMIC_TEMP74]], align 1, !dbg [[DBG71]]
// PPC64-NEXT:    [[TMP74:%.*]] = load i8, ptr [[ATOMIC_TEMP74]], align 1, !dbg [[DBG71]]
// PPC64-NEXT:    [[TMP75:%.*]] = cmpxchg ptr @cx, i8 [[TMP73]], i8 [[TMP74]] seq_cst seq_cst, align 1, !dbg [[DBG71]]
// PPC64-NEXT:    [[TMP76]] = extractvalue { i8, i1 } [[TMP75]], 0, !dbg [[DBG71]]
// PPC64-NEXT:    [[TMP77:%.*]] = extractvalue { i8, i1 } [[TMP75]], 1, !dbg [[DBG71]]
// PPC64-NEXT:    br i1 [[TMP77]], label [[ATOMIC_EXIT78:%.*]], label [[ATOMIC_CONT73]], !dbg [[DBG71]]
// PPC64:       atomic_exit78:
// PPC64-NEXT:    store i8 [[CONV77]], ptr @cv, align 1, !dbg [[DBG71]]
// PPC64-NEXT:    [[TMP78:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG74:![0-9]+]]
// PPC64-NEXT:    [[CONV79:%.*]] = sext i16 [[TMP78]] to i32, !dbg [[DBG74]]
// PPC64-NEXT:    [[ATOMIC_LOAD80:%.*]] = load atomic i64, ptr @ulx monotonic, align 8, !dbg [[DBG75:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT81:%.*]], !dbg [[DBG75]]
// PPC64:       atomic_cont81:
// PPC64-NEXT:    [[TMP79:%.*]] = phi i64 [ [[ATOMIC_LOAD80]], [[ATOMIC_EXIT78]] ], [ [[TMP82:%.*]], [[ATOMIC_CONT81]] ], !dbg [[DBG75]]
// PPC64-NEXT:    [[SH_PROM:%.*]] = trunc i64 [[TMP79]] to i32, !dbg [[DBG76:![0-9]+]]
// PPC64-NEXT:    [[SHL83:%.*]] = shl i32 [[CONV79]], [[SH_PROM]], !dbg [[DBG76]]
// PPC64-NEXT:    [[CONV84:%.*]] = sext i32 [[SHL83]] to i64, !dbg [[DBG74]]
// PPC64-NEXT:    store i64 [[CONV84]], ptr [[ATOMIC_TEMP82]], align 8, !dbg [[DBG75]]
// PPC64-NEXT:    [[TMP80:%.*]] = load i64, ptr [[ATOMIC_TEMP82]], align 8, !dbg [[DBG75]]
// PPC64-NEXT:    [[TMP81:%.*]] = cmpxchg ptr @ulx, i64 [[TMP79]], i64 [[TMP80]] monotonic monotonic, align 8, !dbg [[DBG75]]
// PPC64-NEXT:    [[TMP82]] = extractvalue { i64, i1 } [[TMP81]], 0, !dbg [[DBG75]]
// PPC64-NEXT:    [[TMP83:%.*]] = extractvalue { i64, i1 } [[TMP81]], 1, !dbg [[DBG75]]
// PPC64-NEXT:    br i1 [[TMP83]], label [[ATOMIC_EXIT85:%.*]], label [[ATOMIC_CONT81]], !dbg [[DBG75]]
// PPC64:       atomic_exit85:
// PPC64-NEXT:    store i64 [[CONV84]], ptr @ulv, align 8, !dbg [[DBG75]]
// PPC64-NEXT:    [[TMP84:%.*]] = load i16, ptr @usv, align 2, !dbg [[DBG77:![0-9]+]]
// PPC64-NEXT:    [[CONV86:%.*]] = zext i16 [[TMP84]] to i64, !dbg [[DBG77]]
// PPC64-NEXT:    [[ATOMIC_LOAD87:%.*]] = load atomic i64, ptr @lx monotonic, align 8, !dbg [[DBG78:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT88:%.*]], !dbg [[DBG78]]
// PPC64:       atomic_cont88:
// PPC64-NEXT:    [[TMP85:%.*]] = phi i64 [ [[ATOMIC_LOAD87]], [[ATOMIC_EXIT85]] ], [ [[TMP88:%.*]], [[ATOMIC_CONT88]] ], !dbg [[DBG78]]
// PPC64-NEXT:    [[REM:%.*]] = srem i64 [[TMP85]], [[CONV86]], !dbg [[DBG79:![0-9]+]]
// PPC64-NEXT:    store i64 [[REM]], ptr [[ATOMIC_TEMP89]], align 8, !dbg [[DBG78]]
// PPC64-NEXT:    [[TMP86:%.*]] = load i64, ptr [[ATOMIC_TEMP89]], align 8, !dbg [[DBG78]]
// PPC64-NEXT:    [[TMP87:%.*]] = cmpxchg ptr @lx, i64 [[TMP85]], i64 [[TMP86]] monotonic monotonic, align 8, !dbg [[DBG78]]
// PPC64-NEXT:    [[TMP88]] = extractvalue { i64, i1 } [[TMP87]], 0, !dbg [[DBG78]]
// PPC64-NEXT:    [[TMP89:%.*]] = extractvalue { i64, i1 } [[TMP87]], 1, !dbg [[DBG78]]
// PPC64-NEXT:    br i1 [[TMP89]], label [[ATOMIC_EXIT90:%.*]], label [[ATOMIC_CONT88]], !dbg [[DBG78]]
// PPC64:       atomic_exit90:
// PPC64-NEXT:    store i64 [[TMP85]], ptr @lv, align 8, !dbg [[DBG78]]
// PPC64-NEXT:    [[TMP90:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG80:![0-9]+]]
// PPC64-NEXT:    [[TMP91:%.*]] = atomicrmw or ptr @uix, i32 [[TMP90]] seq_cst, align 4, !dbg [[DBG81:![0-9]+]]
// PPC64-NEXT:    [[OR91:%.*]] = or i32 [[TMP90]], [[TMP91]], !dbg [[DBG82:![0-9]+]]
// PPC64-NEXT:    store i32 [[OR91]], ptr @uiv, align 4, !dbg [[DBG81]]
// PPC64-NEXT:    [[TMP92:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG83:![0-9]+]]
// PPC64-NEXT:    [[TMP93:%.*]] = atomicrmw and ptr @ix, i32 [[TMP92]] monotonic, align 4, !dbg [[DBG84:![0-9]+]]
// PPC64-NEXT:    [[AND92:%.*]] = and i32 [[TMP93]], [[TMP92]], !dbg [[DBG85:![0-9]+]]
// PPC64-NEXT:    store i32 [[AND92]], ptr @iv, align 4, !dbg [[DBG84]]
// PPC64-NEXT:    [[TMP94:%.*]] = load i64, ptr @lv, align 8, !dbg [[DBG86:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP93]], i32 noundef signext 0), !dbg [[DBG87:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT94:%.*]], !dbg [[DBG87]]
// PPC64:       atomic_cont94:
// PPC64-NEXT:    [[ATOMIC_TEMP93_REALP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP93]], i32 0, i32 0, !dbg [[DBG87]]
// PPC64-NEXT:    [[ATOMIC_TEMP93_REAL:%.*]] = load i32, ptr [[ATOMIC_TEMP93_REALP]], align 4, !dbg [[DBG87]]
// PPC64-NEXT:    [[ATOMIC_TEMP93_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP93]], i32 0, i32 1, !dbg [[DBG87]]
// PPC64-NEXT:    [[ATOMIC_TEMP93_IMAG:%.*]] = load i32, ptr [[ATOMIC_TEMP93_IMAGP]], align 4, !dbg [[DBG87]]
// PPC64-NEXT:    [[CONV96:%.*]] = sext i32 [[ATOMIC_TEMP93_REAL]] to i64, !dbg [[DBG88:![0-9]+]]
// PPC64-NEXT:    [[CONV97:%.*]] = sext i32 [[ATOMIC_TEMP93_IMAG]] to i64, !dbg [[DBG88]]
// PPC64-NEXT:    [[ADD_R98:%.*]] = add i64 [[TMP94]], [[CONV96]], !dbg [[DBG89:![0-9]+]]
// PPC64-NEXT:    [[ADD_I99:%.*]] = add i64 0, [[CONV97]], !dbg [[DBG89]]
// PPC64-NEXT:    [[CONV100:%.*]] = trunc i64 [[ADD_R98]] to i32, !dbg [[DBG86]]
// PPC64-NEXT:    [[CONV101:%.*]] = trunc i64 [[ADD_I99]] to i32, !dbg [[DBG86]]
// PPC64-NEXT:    [[ATOMIC_TEMP95_REALP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP95]], i32 0, i32 0, !dbg [[DBG87]]
// PPC64-NEXT:    [[ATOMIC_TEMP95_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP95]], i32 0, i32 1, !dbg [[DBG87]]
// PPC64-NEXT:    store i32 [[CONV100]], ptr [[ATOMIC_TEMP95_REALP]], align 4, !dbg [[DBG87]]
// PPC64-NEXT:    store i32 [[CONV101]], ptr [[ATOMIC_TEMP95_IMAGP]], align 4, !dbg [[DBG87]]
// PPC64-NEXT:    [[CALL102:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP93]], ptr noundef [[ATOMIC_TEMP95]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG87]]
// PPC64-NEXT:    br i1 [[CALL102]], label [[ATOMIC_EXIT103:%.*]], label [[ATOMIC_CONT94]], !dbg [[DBG87]]
// PPC64:       atomic_exit103:
// PPC64-NEXT:    store i32 [[ATOMIC_TEMP93_REAL]], ptr @civ, align 4, !dbg [[DBG87]]
// PPC64-NEXT:    store i32 [[ATOMIC_TEMP93_IMAG]], ptr getelementptr inbounds ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG87]]
// PPC64-NEXT:    [[TMP95:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG90:![0-9]+]]
// PPC64-NEXT:    [[CONV104:%.*]] = uitofp i64 [[TMP95]] to float, !dbg [[DBG90]]
// PPC64-NEXT:    [[ATOMIC_LOAD105:%.*]] = load atomic i32, ptr @fx monotonic, align 4, !dbg [[DBG91:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT106:%.*]], !dbg [[DBG91]]
// PPC64:       atomic_cont106:
// PPC64-NEXT:    [[TMP96:%.*]] = phi i32 [ [[ATOMIC_LOAD105]], [[ATOMIC_EXIT103]] ], [ [[TMP100:%.*]], [[ATOMIC_CONT106]] ], !dbg [[DBG91]]
// PPC64-NEXT:    [[TMP97:%.*]] = bitcast i32 [[TMP96]] to float, !dbg [[DBG91]]
// PPC64-NEXT:    [[MUL108:%.*]] = fmul float [[TMP97]], [[CONV104]], !dbg [[DBG92:![0-9]+]]
// PPC64-NEXT:    store float [[MUL108]], ptr [[ATOMIC_TEMP107]], align 4, !dbg [[DBG91]]
// PPC64-NEXT:    [[TMP98:%.*]] = load i32, ptr [[ATOMIC_TEMP107]], align 4, !dbg [[DBG91]]
// PPC64-NEXT:    [[TMP99:%.*]] = cmpxchg ptr @fx, i32 [[TMP96]], i32 [[TMP98]] monotonic monotonic, align 4, !dbg [[DBG91]]
// PPC64-NEXT:    [[TMP100]] = extractvalue { i32, i1 } [[TMP99]], 0, !dbg [[DBG91]]
// PPC64-NEXT:    [[TMP101:%.*]] = extractvalue { i32, i1 } [[TMP99]], 1, !dbg [[DBG91]]
// PPC64-NEXT:    br i1 [[TMP101]], label [[ATOMIC_EXIT109:%.*]], label [[ATOMIC_CONT106]], !dbg [[DBG91]]
// PPC64:       atomic_exit109:
// PPC64-NEXT:    store float [[MUL108]], ptr @fv, align 4, !dbg [[DBG91]]
// PPC64-NEXT:    [[TMP102:%.*]] = load i64, ptr @llv, align 8, !dbg [[DBG93:![0-9]+]]
// PPC64-NEXT:    [[CONV110:%.*]] = sitofp i64 [[TMP102]] to double, !dbg [[DBG93]]
// PPC64-NEXT:    [[ATOMIC_LOAD111:%.*]] = load atomic i64, ptr @dx monotonic, align 8, !dbg [[DBG94:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT112:%.*]], !dbg [[DBG94]]
// PPC64:       atomic_cont112:
// PPC64-NEXT:    [[TMP103:%.*]] = phi i64 [ [[ATOMIC_LOAD111]], [[ATOMIC_EXIT109]] ], [ [[TMP107:%.*]], [[ATOMIC_CONT112]] ], !dbg [[DBG94]]
// PPC64-NEXT:    [[TMP104:%.*]] = bitcast i64 [[TMP103]] to double, !dbg [[DBG94]]
// PPC64-NEXT:    [[DIV114:%.*]] = fdiv double [[TMP104]], [[CONV110]], !dbg [[DBG95:![0-9]+]]
// PPC64-NEXT:    store double [[DIV114]], ptr [[ATOMIC_TEMP113]], align 8, !dbg [[DBG94]]
// PPC64-NEXT:    [[TMP105:%.*]] = load i64, ptr [[ATOMIC_TEMP113]], align 8, !dbg [[DBG94]]
// PPC64-NEXT:    [[TMP106:%.*]] = cmpxchg ptr @dx, i64 [[TMP103]], i64 [[TMP105]] monotonic monotonic, align 8, !dbg [[DBG94]]
// PPC64-NEXT:    [[TMP107]] = extractvalue { i64, i1 } [[TMP106]], 0, !dbg [[DBG94]]
// PPC64-NEXT:    [[TMP108:%.*]] = extractvalue { i64, i1 } [[TMP106]], 1, !dbg [[DBG94]]
// PPC64-NEXT:    br i1 [[TMP108]], label [[ATOMIC_EXIT115:%.*]], label [[ATOMIC_CONT112]], !dbg [[DBG94]]
// PPC64:       atomic_exit115:
// PPC64-NEXT:    store double [[DIV114]], ptr @dv, align 8, !dbg [[DBG94]]
// PPC64-NEXT:    [[TMP109:%.*]] = load i64, ptr @ullv, align 8, !dbg [[DBG96:![0-9]+]]
// PPC64-NEXT:    [[CONV116:%.*]] = uitofp i64 [[TMP109]] to ppc_fp128, !dbg [[DBG96]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 16, ptr noundef @ldx, ptr noundef [[ATOMIC_TEMP117]], i32 noundef signext 0), !dbg [[DBG97:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT118:%.*]], !dbg [[DBG97]]
// PPC64:       atomic_cont118:
// PPC64-NEXT:    [[TMP110:%.*]] = load ppc_fp128, ptr [[ATOMIC_TEMP117]], align 16, !dbg [[DBG97]]
// PPC64-NEXT:    [[SUB120:%.*]] = fsub ppc_fp128 [[TMP110]], [[CONV116]], !dbg [[DBG98:![0-9]+]]
// PPC64-NEXT:    store ppc_fp128 [[SUB120]], ptr [[ATOMIC_TEMP119]], align 16, !dbg [[DBG97]]
// PPC64-NEXT:    [[CALL121:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, ptr noundef @ldx, ptr noundef [[ATOMIC_TEMP117]], ptr noundef [[ATOMIC_TEMP119]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG97]]
// PPC64-NEXT:    br i1 [[CALL121]], label [[ATOMIC_EXIT122:%.*]], label [[ATOMIC_CONT118]], !dbg [[DBG97]]
// PPC64:       atomic_exit122:
// PPC64-NEXT:    store ppc_fp128 [[TMP110]], ptr @ldv, align 16, !dbg [[DBG97]]
// PPC64-NEXT:    [[TMP111:%.*]] = load float, ptr @fv, align 4, !dbg [[DBG99:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP123]], i32 noundef signext 0), !dbg [[DBG100:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT124:%.*]], !dbg [[DBG100]]
// PPC64:       atomic_cont124:
// PPC64-NEXT:    [[ATOMIC_TEMP123_REALP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP123]], i32 0, i32 0, !dbg [[DBG100]]
// PPC64-NEXT:    [[ATOMIC_TEMP123_REAL:%.*]] = load i32, ptr [[ATOMIC_TEMP123_REALP]], align 4, !dbg [[DBG100]]
// PPC64-NEXT:    [[ATOMIC_TEMP123_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP123]], i32 0, i32 1, !dbg [[DBG100]]
// PPC64-NEXT:    [[ATOMIC_TEMP123_IMAG:%.*]] = load i32, ptr [[ATOMIC_TEMP123_IMAGP]], align 4, !dbg [[DBG100]]
// PPC64-NEXT:    [[CONV126:%.*]] = sitofp i32 [[ATOMIC_TEMP123_REAL]] to float, !dbg [[DBG101:![0-9]+]]
// PPC64-NEXT:    [[CONV127:%.*]] = sitofp i32 [[ATOMIC_TEMP123_IMAG]] to float, !dbg [[DBG101]]
// PPC64-NEXT:    [[CALL128:%.*]] = call { float, float } @__divsc3(float noundef [[TMP111]], float noundef 0.000000e+00, float noundef [[CONV126]], float noundef [[CONV127]]) #[[ATTR2:[0-9]+]], !dbg [[DBG102:![0-9]+]]
// PPC64-NEXT:    [[TMP112:%.*]] = extractvalue { float, float } [[CALL128]], 0, !dbg [[DBG102]]
// PPC64-NEXT:    [[TMP113:%.*]] = extractvalue { float, float } [[CALL128]], 1, !dbg [[DBG102]]
// PPC64-NEXT:    [[CONV129:%.*]] = fptosi float [[TMP112]] to i32, !dbg [[DBG99]]
// PPC64-NEXT:    [[CONV130:%.*]] = fptosi float [[TMP113]] to i32, !dbg [[DBG99]]
// PPC64-NEXT:    [[ATOMIC_TEMP125_REALP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP125]], i32 0, i32 0, !dbg [[DBG100]]
// PPC64-NEXT:    [[ATOMIC_TEMP125_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP125]], i32 0, i32 1, !dbg [[DBG100]]
// PPC64-NEXT:    store i32 [[CONV129]], ptr [[ATOMIC_TEMP125_REALP]], align 4, !dbg [[DBG100]]
// PPC64-NEXT:    store i32 [[CONV130]], ptr [[ATOMIC_TEMP125_IMAGP]], align 4, !dbg [[DBG100]]
// PPC64-NEXT:    [[CALL131:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP123]], ptr noundef [[ATOMIC_TEMP125]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG100]]
// PPC64-NEXT:    br i1 [[CALL131]], label [[ATOMIC_EXIT132:%.*]], label [[ATOMIC_CONT124]], !dbg [[DBG100]]
// PPC64:       atomic_exit132:
// PPC64-NEXT:    store i32 [[CONV129]], ptr @civ, align 4, !dbg [[DBG100]]
// PPC64-NEXT:    store i32 [[CONV130]], ptr getelementptr inbounds ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG100]]
// PPC64-NEXT:    [[TMP114:%.*]] = load double, ptr @dv, align 8, !dbg [[DBG103:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD133:%.*]] = load atomic i16, ptr @sx monotonic, align 2, !dbg [[DBG104:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT134:%.*]], !dbg [[DBG104]]
// PPC64:       atomic_cont134:
// PPC64-NEXT:    [[TMP115:%.*]] = phi i16 [ [[ATOMIC_LOAD133]], [[ATOMIC_EXIT132]] ], [ [[TMP118:%.*]], [[ATOMIC_CONT134]] ], !dbg [[DBG104]]
// PPC64-NEXT:    [[CONV136:%.*]] = sext i16 [[TMP115]] to i32, !dbg [[DBG105:![0-9]+]]
// PPC64-NEXT:    [[CONV137:%.*]] = sitofp i32 [[CONV136]] to double, !dbg [[DBG105]]
// PPC64-NEXT:    [[ADD138:%.*]] = fadd double [[CONV137]], [[TMP114]], !dbg [[DBG106:![0-9]+]]
// PPC64-NEXT:    [[CONV139:%.*]] = fptosi double [[ADD138]] to i16, !dbg [[DBG105]]
// PPC64-NEXT:    store i16 [[CONV139]], ptr [[ATOMIC_TEMP135]], align 2, !dbg [[DBG104]]
// PPC64-NEXT:    [[TMP116:%.*]] = load i16, ptr [[ATOMIC_TEMP135]], align 2, !dbg [[DBG104]]
// PPC64-NEXT:    [[TMP117:%.*]] = cmpxchg ptr @sx, i16 [[TMP115]], i16 [[TMP116]] monotonic monotonic, align 2, !dbg [[DBG104]]
// PPC64-NEXT:    [[TMP118]] = extractvalue { i16, i1 } [[TMP117]], 0, !dbg [[DBG104]]
// PPC64-NEXT:    [[TMP119:%.*]] = extractvalue { i16, i1 } [[TMP117]], 1, !dbg [[DBG104]]
// PPC64-NEXT:    br i1 [[TMP119]], label [[ATOMIC_EXIT140:%.*]], label [[ATOMIC_CONT134]], !dbg [[DBG104]]
// PPC64:       atomic_exit140:
// PPC64-NEXT:    store i16 [[CONV139]], ptr @sv, align 2, !dbg [[DBG104]]
// PPC64-NEXT:    [[TMP120:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG107:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD141:%.*]] = load atomic i8, ptr @bx monotonic, align 1, !dbg [[DBG108:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT142:%.*]], !dbg [[DBG108]]
// PPC64:       atomic_cont142:
// PPC64-NEXT:    [[TMP121:%.*]] = phi i8 [ [[ATOMIC_LOAD141]], [[ATOMIC_EXIT140]] ], [ [[TMP124:%.*]], [[ATOMIC_CONT142]] ], !dbg [[DBG108]]
// PPC64-NEXT:    [[TOBOOL144:%.*]] = trunc i8 [[TMP121]] to i1, !dbg [[DBG108]]
// PPC64-NEXT:    [[CONV145:%.*]] = zext i1 [[TOBOOL144]] to i32, !dbg [[DBG109:![0-9]+]]
// PPC64-NEXT:    [[CONV146:%.*]] = sitofp i32 [[CONV145]] to ppc_fp128, !dbg [[DBG109]]
// PPC64-NEXT:    [[MUL147:%.*]] = fmul ppc_fp128 [[TMP120]], [[CONV146]], !dbg [[DBG110:![0-9]+]]
// PPC64-NEXT:    [[TOBOOL148:%.*]] = fcmp une ppc_fp128 [[MUL147]], 0xM00000000000000000000000000000000, !dbg [[DBG107]]
// PPC64-NEXT:    [[FROMBOOL149:%.*]] = zext i1 [[TOBOOL148]] to i8, !dbg [[DBG108]]
// PPC64-NEXT:    store i8 [[FROMBOOL149]], ptr [[ATOMIC_TEMP143]], align 1, !dbg [[DBG108]]
// PPC64-NEXT:    [[TMP122:%.*]] = load i8, ptr [[ATOMIC_TEMP143]], align 1, !dbg [[DBG108]]
// PPC64-NEXT:    [[TMP123:%.*]] = cmpxchg ptr @bx, i8 [[TMP121]], i8 [[TMP122]] monotonic monotonic, align 1, !dbg [[DBG108]]
// PPC64-NEXT:    [[TMP124]] = extractvalue { i8, i1 } [[TMP123]], 0, !dbg [[DBG108]]
// PPC64-NEXT:    [[TMP125:%.*]] = extractvalue { i8, i1 } [[TMP123]], 1, !dbg [[DBG108]]
// PPC64-NEXT:    br i1 [[TMP125]], label [[ATOMIC_EXIT150:%.*]], label [[ATOMIC_CONT142]], !dbg [[DBG108]]
// PPC64:       atomic_exit150:
// PPC64-NEXT:    [[FROMBOOL151:%.*]] = zext i1 [[TOBOOL144]] to i8, !dbg [[DBG108]]
// PPC64-NEXT:    store i8 [[FROMBOOL151]], ptr @bv, align 1, !dbg [[DBG108]]
// PPC64-NEXT:    [[CIV_REAL152:%.*]] = load i32, ptr @civ, align 4, !dbg [[DBG111:![0-9]+]]
// PPC64-NEXT:    [[CIV_IMAG153:%.*]] = load i32, ptr getelementptr inbounds ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG111]]
// PPC64-NEXT:    [[ATOMIC_LOAD154:%.*]] = load atomic i8, ptr @bx monotonic, align 1, !dbg [[DBG112:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT155:%.*]], !dbg [[DBG112]]
// PPC64:       atomic_cont155:
// PPC64-NEXT:    [[TMP126:%.*]] = phi i8 [ [[ATOMIC_LOAD154]], [[ATOMIC_EXIT150]] ], [ [[TMP129:%.*]], [[ATOMIC_CONT155]] ], !dbg [[DBG112]]
// PPC64-NEXT:    [[TOBOOL157:%.*]] = trunc i8 [[TMP126]] to i1, !dbg [[DBG112]]
// PPC64-NEXT:    [[CONV158:%.*]] = zext i1 [[TOBOOL157]] to i32, !dbg [[DBG113:![0-9]+]]
// PPC64-NEXT:    [[SUB_R159:%.*]] = sub i32 [[CIV_REAL152]], [[CONV158]], !dbg [[DBG114:![0-9]+]]
// PPC64-NEXT:    [[SUB_I160:%.*]] = sub i32 [[CIV_IMAG153]], 0, !dbg [[DBG114]]
// PPC64-NEXT:    [[TOBOOL161:%.*]] = icmp ne i32 [[SUB_R159]], 0, !dbg [[DBG111]]
// PPC64-NEXT:    [[TOBOOL162:%.*]] = icmp ne i32 [[SUB_I160]], 0, !dbg [[DBG111]]
// PPC64-NEXT:    [[TOBOOL163:%.*]] = or i1 [[TOBOOL161]], [[TOBOOL162]], !dbg [[DBG111]]
// PPC64-NEXT:    [[FROMBOOL164:%.*]] = zext i1 [[TOBOOL163]] to i8, !dbg [[DBG112]]
// PPC64-NEXT:    store i8 [[FROMBOOL164]], ptr [[ATOMIC_TEMP156]], align 1, !dbg [[DBG112]]
// PPC64-NEXT:    [[TMP127:%.*]] = load i8, ptr [[ATOMIC_TEMP156]], align 1, !dbg [[DBG112]]
// PPC64-NEXT:    [[TMP128:%.*]] = cmpxchg ptr @bx, i8 [[TMP126]], i8 [[TMP127]] monotonic monotonic, align 1, !dbg [[DBG112]]
// PPC64-NEXT:    [[TMP129]] = extractvalue { i8, i1 } [[TMP128]], 0, !dbg [[DBG112]]
// PPC64-NEXT:    [[TMP130:%.*]] = extractvalue { i8, i1 } [[TMP128]], 1, !dbg [[DBG112]]
// PPC64-NEXT:    br i1 [[TMP130]], label [[ATOMIC_EXIT165:%.*]], label [[ATOMIC_CONT155]], !dbg [[DBG112]]
// PPC64:       atomic_exit165:
// PPC64-NEXT:    [[FROMBOOL166:%.*]] = zext i1 [[TOBOOL163]] to i8, !dbg [[DBG112]]
// PPC64-NEXT:    store i8 [[FROMBOOL166]], ptr @bv, align 1, !dbg [[DBG112]]
// PPC64-NEXT:    [[TMP131:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG115:![0-9]+]]
// PPC64-NEXT:    [[TMP132:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG116:![0-9]+]]
// PPC64-NEXT:    [[TOBOOL167:%.*]] = trunc i8 [[TMP132]] to i1, !dbg [[DBG116]]
// PPC64-NEXT:    [[CONV168:%.*]] = zext i1 [[TOBOOL167]] to i32, !dbg [[DBG116]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 16, ptr noundef @int4x, ptr noundef [[ATOMIC_TEMP169]], i32 noundef signext 0), !dbg [[DBG117:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT170:%.*]], !dbg [[DBG117]]
// PPC64:       atomic_cont170:
// PPC64-NEXT:    [[TMP133:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP169]], align 16, !dbg [[DBG117]]
// PPC64-NEXT:    store <4 x i32> [[TMP133]], ptr [[ATOMIC_TEMP171]], align 16, !dbg [[DBG117]]
// PPC64-NEXT:    [[TMP134:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP169]], align 16, !dbg [[DBG117]]
// PPC64-NEXT:    store <4 x i32> [[TMP134]], ptr [[ATOMIC_TEMP172]], align 16, !dbg [[DBG117]]
// PPC64-NEXT:    [[TMP135:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP172]], align 16, !dbg [[DBG117]]
// PPC64-NEXT:    [[VECEXT:%.*]] = extractelement <4 x i32> [[TMP135]], i16 [[TMP131]], !dbg [[DBG117]]
// PPC64-NEXT:    [[OR173:%.*]] = or i32 [[VECEXT]], [[CONV168]], !dbg [[DBG118:![0-9]+]]
// PPC64-NEXT:    [[TMP136:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP171]], align 16, !dbg [[DBG117]]
// PPC64-NEXT:    [[VECINS:%.*]] = insertelement <4 x i32> [[TMP136]], i32 [[OR173]], i16 [[TMP131]], !dbg [[DBG117]]
// PPC64-NEXT:    store <4 x i32> [[VECINS]], ptr [[ATOMIC_TEMP171]], align 16, !dbg [[DBG117]]
// PPC64-NEXT:    [[CALL174:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, ptr noundef @int4x, ptr noundef [[ATOMIC_TEMP169]], ptr noundef [[ATOMIC_TEMP171]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG117]]
// PPC64-NEXT:    br i1 [[CALL174]], label [[ATOMIC_EXIT175:%.*]], label [[ATOMIC_CONT170]], !dbg [[DBG117]]
// PPC64:       atomic_exit175:
// PPC64-NEXT:    store i32 [[OR173]], ptr @iv, align 4, !dbg [[DBG117]]
// PPC64-NEXT:    [[TMP137:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG119:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD176:%.*]] = load atomic i32, ptr @bfx monotonic, align 4, !dbg [[DBG120:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT177:%.*]], !dbg [[DBG120]]
// PPC64:       atomic_cont177:
// PPC64-NEXT:    [[TMP138:%.*]] = phi i32 [ [[ATOMIC_LOAD176]], [[ATOMIC_EXIT175]] ], [ [[TMP141:%.*]], [[ATOMIC_CONT177]] ], !dbg [[DBG120]]
// PPC64-NEXT:    store i32 [[TMP138]], ptr [[ATOMIC_TEMP178]], align 4, !dbg [[DBG120]]
// PPC64-NEXT:    store i32 [[TMP138]], ptr [[ATOMIC_TEMP179]], align 4, !dbg [[DBG120]]
// PPC64-NEXT:    [[BF_LOAD:%.*]] = load i32, ptr [[ATOMIC_TEMP179]], align 4, !dbg [[DBG120]]
// PPC64-NEXT:    [[BF_ASHR:%.*]] = ashr i32 [[BF_LOAD]], 1, !dbg [[DBG120]]
// PPC64-NEXT:    [[CONV180:%.*]] = sitofp i32 [[BF_ASHR]] to ppc_fp128, !dbg [[DBG121:![0-9]+]]
// PPC64-NEXT:    [[SUB181:%.*]] = fsub ppc_fp128 [[CONV180]], [[TMP137]], !dbg [[DBG122:![0-9]+]]
// PPC64-NEXT:    [[CONV182:%.*]] = fptosi ppc_fp128 [[SUB181]] to i32, !dbg [[DBG121]]
// PPC64-NEXT:    [[BF_LOAD183:%.*]] = load i32, ptr [[ATOMIC_TEMP178]], align 4, !dbg [[DBG120]]
// PPC64-NEXT:    [[BF_VALUE:%.*]] = and i32 [[CONV182]], 2147483647, !dbg [[DBG120]]
// PPC64-NEXT:    [[BF_SHL:%.*]] = shl i32 [[BF_VALUE]], 1, !dbg [[DBG120]]
// PPC64-NEXT:    [[BF_CLEAR:%.*]] = and i32 [[BF_LOAD183]], 1, !dbg [[DBG120]]
// PPC64-NEXT:    [[BF_SET:%.*]] = or i32 [[BF_CLEAR]], [[BF_SHL]], !dbg [[DBG120]]
// PPC64-NEXT:    store i32 [[BF_SET]], ptr [[ATOMIC_TEMP178]], align 4, !dbg [[DBG120]]
// PPC64-NEXT:    [[TMP139:%.*]] = load i32, ptr [[ATOMIC_TEMP178]], align 4, !dbg [[DBG120]]
// PPC64-NEXT:    [[TMP140:%.*]] = cmpxchg ptr @bfx, i32 [[TMP138]], i32 [[TMP139]] monotonic monotonic, align 4, !dbg [[DBG120]]
// PPC64-NEXT:    [[TMP141]] = extractvalue { i32, i1 } [[TMP140]], 0, !dbg [[DBG120]]
// PPC64-NEXT:    [[TMP142:%.*]] = extractvalue { i32, i1 } [[TMP140]], 1, !dbg [[DBG120]]
// PPC64-NEXT:    br i1 [[TMP142]], label [[ATOMIC_EXIT184:%.*]], label [[ATOMIC_CONT177]], !dbg [[DBG120]]
// PPC64:       atomic_exit184:
// PPC64-NEXT:    store i32 [[CONV182]], ptr @iv, align 4, !dbg [[DBG120]]
// PPC64-NEXT:    [[TMP143:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG123:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 4, ptr noundef @bfx_packed, ptr noundef [[ATOMIC_TEMP185]], i32 noundef signext 0), !dbg [[DBG124:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT186:%.*]], !dbg [[DBG124]]
// PPC64:       atomic_cont186:
// PPC64-NEXT:    [[TMP144:%.*]] = load i32, ptr [[ATOMIC_TEMP185]], align 1, !dbg [[DBG124]]
// PPC64-NEXT:    store i32 [[TMP144]], ptr [[ATOMIC_TEMP187]], align 1, !dbg [[DBG124]]
// PPC64-NEXT:    [[TMP145:%.*]] = load i32, ptr [[ATOMIC_TEMP185]], align 1, !dbg [[DBG124]]
// PPC64-NEXT:    store i32 [[TMP145]], ptr [[ATOMIC_TEMP188]], align 4, !dbg [[DBG124]]
// PPC64-NEXT:    [[BF_LOAD189:%.*]] = load i32, ptr [[ATOMIC_TEMP188]], align 1, !dbg [[DBG124]]
// PPC64-NEXT:    [[BF_ASHR190:%.*]] = ashr i32 [[BF_LOAD189]], 1, !dbg [[DBG124]]
// PPC64-NEXT:    [[CONV191:%.*]] = sitofp i32 [[BF_ASHR190]] to ppc_fp128, !dbg [[DBG125:![0-9]+]]
// PPC64-NEXT:    [[MUL192:%.*]] = fmul ppc_fp128 [[CONV191]], [[TMP143]], !dbg [[DBG126:![0-9]+]]
// PPC64-NEXT:    [[CONV193:%.*]] = fptosi ppc_fp128 [[MUL192]] to i32, !dbg [[DBG125]]
// PPC64-NEXT:    [[BF_LOAD194:%.*]] = load i32, ptr [[ATOMIC_TEMP187]], align 1, !dbg [[DBG124]]
// PPC64-NEXT:    [[BF_VALUE195:%.*]] = and i32 [[CONV193]], 2147483647, !dbg [[DBG124]]
// PPC64-NEXT:    [[BF_SHL196:%.*]] = shl i32 [[BF_VALUE195]], 1, !dbg [[DBG124]]
// PPC64-NEXT:    [[BF_CLEAR197:%.*]] = and i32 [[BF_LOAD194]], 1, !dbg [[DBG124]]
// PPC64-NEXT:    [[BF_SET198:%.*]] = or i32 [[BF_CLEAR197]], [[BF_SHL196]], !dbg [[DBG124]]
// PPC64-NEXT:    store i32 [[BF_SET198]], ptr [[ATOMIC_TEMP187]], align 1, !dbg [[DBG124]]
// PPC64-NEXT:    [[CALL199:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 4, ptr noundef @bfx_packed, ptr noundef [[ATOMIC_TEMP185]], ptr noundef [[ATOMIC_TEMP187]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG124]]
// PPC64-NEXT:    br i1 [[CALL199]], label [[ATOMIC_EXIT200:%.*]], label [[ATOMIC_CONT186]], !dbg [[DBG124]]
// PPC64:       atomic_exit200:
// PPC64-NEXT:    store i32 [[BF_ASHR190]], ptr @iv, align 4, !dbg [[DBG124]]
// PPC64-NEXT:    [[TMP146:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG127:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD201:%.*]] = load atomic i32, ptr @bfx2 monotonic, align 4, !dbg [[DBG128:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT202:%.*]], !dbg [[DBG128]]
// PPC64:       atomic_cont202:
// PPC64-NEXT:    [[TMP147:%.*]] = phi i32 [ [[ATOMIC_LOAD201]], [[ATOMIC_EXIT200]] ], [ [[TMP150:%.*]], [[ATOMIC_CONT202]] ], !dbg [[DBG128]]
// PPC64-NEXT:    store i32 [[TMP147]], ptr [[ATOMIC_TEMP203]], align 4, !dbg [[DBG128]]
// PPC64-NEXT:    store i32 [[TMP147]], ptr [[ATOMIC_TEMP204]], align 4, !dbg [[DBG128]]
// PPC64-NEXT:    [[BF_LOAD205:%.*]] = load i32, ptr [[ATOMIC_TEMP204]], align 4, !dbg [[DBG128]]
// PPC64-NEXT:    [[BF_SHL206:%.*]] = shl i32 [[BF_LOAD205]], 31, !dbg [[DBG128]]
// PPC64-NEXT:    [[BF_ASHR207:%.*]] = ashr i32 [[BF_SHL206]], 31, !dbg [[DBG128]]
// PPC64-NEXT:    [[CONV208:%.*]] = sitofp i32 [[BF_ASHR207]] to ppc_fp128, !dbg [[DBG129:![0-9]+]]
// PPC64-NEXT:    [[SUB209:%.*]] = fsub ppc_fp128 [[CONV208]], [[TMP146]], !dbg [[DBG130:![0-9]+]]
// PPC64-NEXT:    [[CONV210:%.*]] = fptosi ppc_fp128 [[SUB209]] to i32, !dbg [[DBG129]]
// PPC64-NEXT:    [[BF_LOAD211:%.*]] = load i32, ptr [[ATOMIC_TEMP203]], align 4, !dbg [[DBG128]]
// PPC64-NEXT:    [[BF_VALUE212:%.*]] = and i32 [[CONV210]], 1, !dbg [[DBG128]]
// PPC64-NEXT:    [[BF_CLEAR213:%.*]] = and i32 [[BF_LOAD211]], -2, !dbg [[DBG128]]
// PPC64-NEXT:    [[BF_SET214:%.*]] = or i32 [[BF_CLEAR213]], [[BF_VALUE212]], !dbg [[DBG128]]
// PPC64-NEXT:    store i32 [[BF_SET214]], ptr [[ATOMIC_TEMP203]], align 4, !dbg [[DBG128]]
// PPC64-NEXT:    [[TMP148:%.*]] = load i32, ptr [[ATOMIC_TEMP203]], align 4, !dbg [[DBG128]]
// PPC64-NEXT:    [[TMP149:%.*]] = cmpxchg ptr @bfx2, i32 [[TMP147]], i32 [[TMP148]] monotonic monotonic, align 4, !dbg [[DBG128]]
// PPC64-NEXT:    [[TMP150]] = extractvalue { i32, i1 } [[TMP149]], 0, !dbg [[DBG128]]
// PPC64-NEXT:    [[TMP151:%.*]] = extractvalue { i32, i1 } [[TMP149]], 1, !dbg [[DBG128]]
// PPC64-NEXT:    br i1 [[TMP151]], label [[ATOMIC_EXIT215:%.*]], label [[ATOMIC_CONT202]], !dbg [[DBG128]]
// PPC64:       atomic_exit215:
// PPC64-NEXT:    store i32 [[CONV210]], ptr @iv, align 4, !dbg [[DBG128]]
// PPC64-NEXT:    [[TMP152:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG131:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD216:%.*]] = load atomic i8, ptr @bfx2_packed monotonic, align 1, !dbg [[DBG132:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT217:%.*]], !dbg [[DBG132]]
// PPC64:       atomic_cont217:
// PPC64-NEXT:    [[TMP153:%.*]] = phi i8 [ [[ATOMIC_LOAD216]], [[ATOMIC_EXIT215]] ], [ [[TMP157:%.*]], [[ATOMIC_CONT217]] ], !dbg [[DBG132]]
// PPC64-NEXT:    store i8 [[TMP153]], ptr [[ATOMIC_TEMP218]], align 1, !dbg [[DBG132]]
// PPC64-NEXT:    store i8 [[TMP153]], ptr [[ATOMIC_TEMP219]], align 1, !dbg [[DBG132]]
// PPC64-NEXT:    [[BF_LOAD220:%.*]] = load i8, ptr [[ATOMIC_TEMP219]], align 1, !dbg [[DBG132]]
// PPC64-NEXT:    [[BF_SHL221:%.*]] = shl i8 [[BF_LOAD220]], 7, !dbg [[DBG132]]
// PPC64-NEXT:    [[BF_ASHR222:%.*]] = ashr i8 [[BF_SHL221]], 7, !dbg [[DBG132]]
// PPC64-NEXT:    [[BF_CAST:%.*]] = sext i8 [[BF_ASHR222]] to i32, !dbg [[DBG132]]
// PPC64-NEXT:    [[CONV223:%.*]] = sitofp i32 [[BF_CAST]] to ppc_fp128, !dbg [[DBG133:![0-9]+]]
// PPC64-NEXT:    [[DIV224:%.*]] = fdiv ppc_fp128 [[TMP152]], [[CONV223]], !dbg [[DBG134:![0-9]+]]
// PPC64-NEXT:    [[CONV225:%.*]] = fptosi ppc_fp128 [[DIV224]] to i32, !dbg [[DBG131]]
// PPC64-NEXT:    [[TMP154:%.*]] = trunc i32 [[CONV225]] to i8, !dbg [[DBG132]]
// PPC64-NEXT:    [[BF_LOAD226:%.*]] = load i8, ptr [[ATOMIC_TEMP218]], align 1, !dbg [[DBG132]]
// PPC64-NEXT:    [[BF_VALUE227:%.*]] = and i8 [[TMP154]], 1, !dbg [[DBG132]]
// PPC64-NEXT:    [[BF_CLEAR228:%.*]] = and i8 [[BF_LOAD226]], -2, !dbg [[DBG132]]
// PPC64-NEXT:    [[BF_SET229:%.*]] = or i8 [[BF_CLEAR228]], [[BF_VALUE227]], !dbg [[DBG132]]
// PPC64-NEXT:    store i8 [[BF_SET229]], ptr [[ATOMIC_TEMP218]], align 1, !dbg [[DBG132]]
// PPC64-NEXT:    [[TMP155:%.*]] = load i8, ptr [[ATOMIC_TEMP218]], align 1, !dbg [[DBG132]]
// PPC64-NEXT:    [[TMP156:%.*]] = cmpxchg ptr @bfx2_packed, i8 [[TMP153]], i8 [[TMP155]] monotonic monotonic, align 1, !dbg [[DBG132]]
// PPC64-NEXT:    [[TMP157]] = extractvalue { i8, i1 } [[TMP156]], 0, !dbg [[DBG132]]
// PPC64-NEXT:    [[TMP158:%.*]] = extractvalue { i8, i1 } [[TMP156]], 1, !dbg [[DBG132]]
// PPC64-NEXT:    br i1 [[TMP158]], label [[ATOMIC_EXIT230:%.*]], label [[ATOMIC_CONT217]], !dbg [[DBG132]]
// PPC64:       atomic_exit230:
// PPC64-NEXT:    store i32 [[CONV225]], ptr @iv, align 4, !dbg [[DBG132]]
// PPC64-NEXT:    [[TMP159:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG135:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD231:%.*]] = load atomic i32, ptr @bfx3 monotonic, align 4, !dbg [[DBG136:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT232:%.*]], !dbg [[DBG136]]
// PPC64:       atomic_cont232:
// PPC64-NEXT:    [[TMP160:%.*]] = phi i32 [ [[ATOMIC_LOAD231]], [[ATOMIC_EXIT230]] ], [ [[TMP163:%.*]], [[ATOMIC_CONT232]] ], !dbg [[DBG136]]
// PPC64-NEXT:    store i32 [[TMP160]], ptr [[ATOMIC_TEMP233]], align 4, !dbg [[DBG136]]
// PPC64-NEXT:    store i32 [[TMP160]], ptr [[ATOMIC_TEMP234]], align 4, !dbg [[DBG136]]
// PPC64-NEXT:    [[BF_LOAD235:%.*]] = load i32, ptr [[ATOMIC_TEMP234]], align 4, !dbg [[DBG136]]
// PPC64-NEXT:    [[BF_SHL236:%.*]] = shl i32 [[BF_LOAD235]], 11, !dbg [[DBG136]]
// PPC64-NEXT:    [[BF_ASHR237:%.*]] = ashr i32 [[BF_SHL236]], 18, !dbg [[DBG136]]
// PPC64-NEXT:    [[CONV238:%.*]] = sitofp i32 [[BF_ASHR237]] to ppc_fp128, !dbg [[DBG137:![0-9]+]]
// PPC64-NEXT:    [[DIV239:%.*]] = fdiv ppc_fp128 [[CONV238]], [[TMP159]], !dbg [[DBG138:![0-9]+]]
// PPC64-NEXT:    [[CONV240:%.*]] = fptosi ppc_fp128 [[DIV239]] to i32, !dbg [[DBG137]]
// PPC64-NEXT:    [[BF_LOAD241:%.*]] = load i32, ptr [[ATOMIC_TEMP233]], align 4, !dbg [[DBG136]]
// PPC64-NEXT:    [[BF_VALUE242:%.*]] = and i32 [[CONV240]], 16383, !dbg [[DBG136]]
// PPC64-NEXT:    [[BF_SHL243:%.*]] = shl i32 [[BF_VALUE242]], 7, !dbg [[DBG136]]
// PPC64-NEXT:    [[BF_CLEAR244:%.*]] = and i32 [[BF_LOAD241]], -2097025, !dbg [[DBG136]]
// PPC64-NEXT:    [[BF_SET245:%.*]] = or i32 [[BF_CLEAR244]], [[BF_SHL243]], !dbg [[DBG136]]
// PPC64-NEXT:    store i32 [[BF_SET245]], ptr [[ATOMIC_TEMP233]], align 4, !dbg [[DBG136]]
// PPC64-NEXT:    [[TMP161:%.*]] = load i32, ptr [[ATOMIC_TEMP233]], align 4, !dbg [[DBG136]]
// PPC64-NEXT:    [[TMP162:%.*]] = cmpxchg ptr @bfx3, i32 [[TMP160]], i32 [[TMP161]] monotonic monotonic, align 4, !dbg [[DBG136]]
// PPC64-NEXT:    [[TMP163]] = extractvalue { i32, i1 } [[TMP162]], 0, !dbg [[DBG136]]
// PPC64-NEXT:    [[TMP164:%.*]] = extractvalue { i32, i1 } [[TMP162]], 1, !dbg [[DBG136]]
// PPC64-NEXT:    br i1 [[TMP164]], label [[ATOMIC_EXIT246:%.*]], label [[ATOMIC_CONT232]], !dbg [[DBG136]]
// PPC64:       atomic_exit246:
// PPC64-NEXT:    store i32 [[BF_ASHR237]], ptr @iv, align 4, !dbg [[DBG136]]
// PPC64-NEXT:    [[TMP165:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG139:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 3, ptr noundef @bfx3_packed, ptr noundef [[ATOMIC_TEMP247]], i32 noundef signext 0), !dbg [[DBG140:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT248:%.*]], !dbg [[DBG140]]
// PPC64:       atomic_cont248:
// PPC64-NEXT:    [[TMP166:%.*]] = load i24, ptr [[ATOMIC_TEMP247]], align 1, !dbg [[DBG140]]
// PPC64-NEXT:    store i24 [[TMP166]], ptr [[ATOMIC_TEMP249]], align 1, !dbg [[DBG140]]
// PPC64-NEXT:    [[TMP167:%.*]] = load i24, ptr [[ATOMIC_TEMP247]], align 1, !dbg [[DBG140]]
// PPC64-NEXT:    store i24 [[TMP167]], ptr [[ATOMIC_TEMP250]], align 1, !dbg [[DBG140]]
// PPC64-NEXT:    [[BF_LOAD251:%.*]] = load i24, ptr [[ATOMIC_TEMP250]], align 1, !dbg [[DBG140]]
// PPC64-NEXT:    [[BF_SHL252:%.*]] = shl i24 [[BF_LOAD251]], 3, !dbg [[DBG140]]
// PPC64-NEXT:    [[BF_ASHR253:%.*]] = ashr i24 [[BF_SHL252]], 10, !dbg [[DBG140]]
// PPC64-NEXT:    [[BF_CAST254:%.*]] = sext i24 [[BF_ASHR253]] to i32, !dbg [[DBG140]]
// PPC64-NEXT:    [[CONV255:%.*]] = sitofp i32 [[BF_CAST254]] to ppc_fp128, !dbg [[DBG141:![0-9]+]]
// PPC64-NEXT:    [[ADD256:%.*]] = fadd ppc_fp128 [[CONV255]], [[TMP165]], !dbg [[DBG142:![0-9]+]]
// PPC64-NEXT:    [[CONV257:%.*]] = fptosi ppc_fp128 [[ADD256]] to i32, !dbg [[DBG141]]
// PPC64-NEXT:    [[TMP168:%.*]] = trunc i32 [[CONV257]] to i24, !dbg [[DBG140]]
// PPC64-NEXT:    [[BF_LOAD258:%.*]] = load i24, ptr [[ATOMIC_TEMP249]], align 1, !dbg [[DBG140]]
// PPC64-NEXT:    [[BF_VALUE259:%.*]] = and i24 [[TMP168]], 16383, !dbg [[DBG140]]
// PPC64-NEXT:    [[BF_SHL260:%.*]] = shl i24 [[BF_VALUE259]], 7, !dbg [[DBG140]]
// PPC64-NEXT:    [[BF_CLEAR261:%.*]] = and i24 [[BF_LOAD258]], -2097025, !dbg [[DBG140]]
// PPC64-NEXT:    [[BF_SET262:%.*]] = or i24 [[BF_CLEAR261]], [[BF_SHL260]], !dbg [[DBG140]]
// PPC64-NEXT:    store i24 [[BF_SET262]], ptr [[ATOMIC_TEMP249]], align 1, !dbg [[DBG140]]
// PPC64-NEXT:    [[CALL263:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 3, ptr noundef @bfx3_packed, ptr noundef [[ATOMIC_TEMP247]], ptr noundef [[ATOMIC_TEMP249]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG140]]
// PPC64-NEXT:    br i1 [[CALL263]], label [[ATOMIC_EXIT264:%.*]], label [[ATOMIC_CONT248]], !dbg [[DBG140]]
// PPC64:       atomic_exit264:
// PPC64-NEXT:    store i32 [[CONV257]], ptr @iv, align 4, !dbg [[DBG140]]
// PPC64-NEXT:    [[TMP169:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG143:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD265:%.*]] = load atomic i64, ptr @bfx4 monotonic, align 8, !dbg [[DBG144:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT266:%.*]], !dbg [[DBG144]]
// PPC64:       atomic_cont266:
// PPC64-NEXT:    [[TMP170:%.*]] = phi i64 [ [[ATOMIC_LOAD265]], [[ATOMIC_EXIT264]] ], [ [[TMP174:%.*]], [[ATOMIC_CONT266]] ], !dbg [[DBG144]]
// PPC64-NEXT:    store i64 [[TMP170]], ptr [[ATOMIC_TEMP267]], align 8, !dbg [[DBG144]]
// PPC64-NEXT:    store i64 [[TMP170]], ptr [[ATOMIC_TEMP268]], align 8, !dbg [[DBG144]]
// PPC64-NEXT:    [[BF_LOAD269:%.*]] = load i64, ptr [[ATOMIC_TEMP268]], align 8, !dbg [[DBG144]]
// PPC64-NEXT:    [[BF_SHL270:%.*]] = shl i64 [[BF_LOAD269]], 48, !dbg [[DBG144]]
// PPC64-NEXT:    [[BF_ASHR271:%.*]] = ashr i64 [[BF_SHL270]], 63, !dbg [[DBG144]]
// PPC64-NEXT:    [[BF_CAST272:%.*]] = trunc i64 [[BF_ASHR271]] to i32, !dbg [[DBG144]]
// PPC64-NEXT:    [[CONV273:%.*]] = sitofp i32 [[BF_CAST272]] to ppc_fp128, !dbg [[DBG145:![0-9]+]]
// PPC64-NEXT:    [[MUL274:%.*]] = fmul ppc_fp128 [[CONV273]], [[TMP169]], !dbg [[DBG146:![0-9]+]]
// PPC64-NEXT:    [[CONV275:%.*]] = fptosi ppc_fp128 [[MUL274]] to i32, !dbg [[DBG145]]
// PPC64-NEXT:    [[TMP171:%.*]] = zext i32 [[CONV275]] to i64, !dbg [[DBG144]]
// PPC64-NEXT:    [[BF_LOAD276:%.*]] = load i64, ptr [[ATOMIC_TEMP267]], align 8, !dbg [[DBG144]]
// PPC64-NEXT:    [[BF_VALUE277:%.*]] = and i64 [[TMP171]], 1, !dbg [[DBG144]]
// PPC64-NEXT:    [[BF_SHL278:%.*]] = shl i64 [[BF_VALUE277]], 15, !dbg [[DBG144]]
// PPC64-NEXT:    [[BF_CLEAR279:%.*]] = and i64 [[BF_LOAD276]], -32769, !dbg [[DBG144]]
// PPC64-NEXT:    [[BF_SET280:%.*]] = or i64 [[BF_CLEAR279]], [[BF_SHL278]], !dbg [[DBG144]]
// PPC64-NEXT:    store i64 [[BF_SET280]], ptr [[ATOMIC_TEMP267]], align 8, !dbg [[DBG144]]
// PPC64-NEXT:    [[TMP172:%.*]] = load i64, ptr [[ATOMIC_TEMP267]], align 8, !dbg [[DBG144]]
// PPC64-NEXT:    [[TMP173:%.*]] = cmpxchg ptr @bfx4, i64 [[TMP170]], i64 [[TMP172]] monotonic monotonic, align 8, !dbg [[DBG144]]
// PPC64-NEXT:    [[TMP174]] = extractvalue { i64, i1 } [[TMP173]], 0, !dbg [[DBG144]]
// PPC64-NEXT:    [[TMP175:%.*]] = extractvalue { i64, i1 } [[TMP173]], 1, !dbg [[DBG144]]
// PPC64-NEXT:    br i1 [[TMP175]], label [[ATOMIC_EXIT281:%.*]], label [[ATOMIC_CONT266]], !dbg [[DBG144]]
// PPC64:       atomic_exit281:
// PPC64-NEXT:    store i32 [[CONV275]], ptr @iv, align 4, !dbg [[DBG144]]
// PPC64-NEXT:    [[TMP176:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG147:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD282:%.*]] = load atomic i8, ptr getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED:%.*]], ptr @bfx4_packed, i32 0, i32 1) monotonic, align 1, !dbg [[DBG148:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT283:%.*]], !dbg [[DBG148]]
// PPC64:       atomic_cont283:
// PPC64-NEXT:    [[TMP177:%.*]] = phi i8 [ [[ATOMIC_LOAD282]], [[ATOMIC_EXIT281]] ], [ [[TMP181:%.*]], [[ATOMIC_CONT283]] ], !dbg [[DBG148]]
// PPC64-NEXT:    store i8 [[TMP177]], ptr [[ATOMIC_TEMP284]], align 1, !dbg [[DBG148]]
// PPC64-NEXT:    store i8 [[TMP177]], ptr [[ATOMIC_TEMP285]], align 1, !dbg [[DBG148]]
// PPC64-NEXT:    [[BF_LOAD286:%.*]] = load i8, ptr [[ATOMIC_TEMP285]], align 1, !dbg [[DBG148]]
// PPC64-NEXT:    [[BF_ASHR287:%.*]] = ashr i8 [[BF_LOAD286]], 7, !dbg [[DBG148]]
// PPC64-NEXT:    [[BF_CAST288:%.*]] = sext i8 [[BF_ASHR287]] to i32, !dbg [[DBG148]]
// PPC64-NEXT:    [[CONV289:%.*]] = sitofp i32 [[BF_CAST288]] to ppc_fp128, !dbg [[DBG149:![0-9]+]]
// PPC64-NEXT:    [[SUB290:%.*]] = fsub ppc_fp128 [[CONV289]], [[TMP176]], !dbg [[DBG150:![0-9]+]]
// PPC64-NEXT:    [[CONV291:%.*]] = fptosi ppc_fp128 [[SUB290]] to i32, !dbg [[DBG149]]
// PPC64-NEXT:    [[TMP178:%.*]] = trunc i32 [[CONV291]] to i8, !dbg [[DBG148]]
// PPC64-NEXT:    [[BF_LOAD292:%.*]] = load i8, ptr [[ATOMIC_TEMP284]], align 1, !dbg [[DBG148]]
// PPC64-NEXT:    [[BF_VALUE293:%.*]] = and i8 [[TMP178]], 1, !dbg [[DBG148]]
// PPC64-NEXT:    [[BF_SHL294:%.*]] = shl i8 [[BF_VALUE293]], 7, !dbg [[DBG148]]
// PPC64-NEXT:    [[BF_CLEAR295:%.*]] = and i8 [[BF_LOAD292]], 127, !dbg [[DBG148]]
// PPC64-NEXT:    [[BF_SET296:%.*]] = or i8 [[BF_CLEAR295]], [[BF_SHL294]], !dbg [[DBG148]]
// PPC64-NEXT:    store i8 [[BF_SET296]], ptr [[ATOMIC_TEMP284]], align 1, !dbg [[DBG148]]
// PPC64-NEXT:    [[TMP179:%.*]] = load i8, ptr [[ATOMIC_TEMP284]], align 1, !dbg [[DBG148]]
// PPC64-NEXT:    [[TMP180:%.*]] = cmpxchg ptr getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1), i8 [[TMP177]], i8 [[TMP179]] monotonic monotonic, align 1, !dbg [[DBG148]]
// PPC64-NEXT:    [[TMP181]] = extractvalue { i8, i1 } [[TMP180]], 0, !dbg [[DBG148]]
// PPC64-NEXT:    [[TMP182:%.*]] = extractvalue { i8, i1 } [[TMP180]], 1, !dbg [[DBG148]]
// PPC64-NEXT:    br i1 [[TMP182]], label [[ATOMIC_EXIT297:%.*]], label [[ATOMIC_CONT283]], !dbg [[DBG148]]
// PPC64:       atomic_exit297:
// PPC64-NEXT:    store i32 [[BF_CAST288]], ptr @iv, align 4, !dbg [[DBG148]]
// PPC64-NEXT:    [[TMP183:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG151:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD298:%.*]] = load atomic i64, ptr @bfx4 monotonic, align 8, !dbg [[DBG152:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT299:%.*]], !dbg [[DBG152]]
// PPC64:       atomic_cont299:
// PPC64-NEXT:    [[TMP184:%.*]] = phi i64 [ [[ATOMIC_LOAD298]], [[ATOMIC_EXIT297]] ], [ [[TMP187:%.*]], [[ATOMIC_CONT299]] ], !dbg [[DBG152]]
// PPC64-NEXT:    store i64 [[TMP184]], ptr [[ATOMIC_TEMP300]], align 8, !dbg [[DBG152]]
// PPC64-NEXT:    store i64 [[TMP184]], ptr [[ATOMIC_TEMP301]], align 8, !dbg [[DBG152]]
// PPC64-NEXT:    [[BF_LOAD302:%.*]] = load i64, ptr [[ATOMIC_TEMP301]], align 8, !dbg [[DBG152]]
// PPC64-NEXT:    [[BF_SHL303:%.*]] = shl i64 [[BF_LOAD302]], 49, !dbg [[DBG152]]
// PPC64-NEXT:    [[BF_ASHR304:%.*]] = ashr i64 [[BF_SHL303]], 57, !dbg [[DBG152]]
// PPC64-NEXT:    [[CONV305:%.*]] = sitofp i64 [[BF_ASHR304]] to ppc_fp128, !dbg [[DBG153:![0-9]+]]
// PPC64-NEXT:    [[DIV306:%.*]] = fdiv ppc_fp128 [[CONV305]], [[TMP183]], !dbg [[DBG154:![0-9]+]]
// PPC64-NEXT:    [[CONV307:%.*]] = fptosi ppc_fp128 [[DIV306]] to i64, !dbg [[DBG153]]
// PPC64-NEXT:    [[BF_LOAD308:%.*]] = load i64, ptr [[ATOMIC_TEMP300]], align 8, !dbg [[DBG152]]
// PPC64-NEXT:    [[BF_VALUE309:%.*]] = and i64 [[CONV307]], 127, !dbg [[DBG152]]
// PPC64-NEXT:    [[BF_SHL310:%.*]] = shl i64 [[BF_VALUE309]], 8, !dbg [[DBG152]]
// PPC64-NEXT:    [[BF_CLEAR311:%.*]] = and i64 [[BF_LOAD308]], -32513, !dbg [[DBG152]]
// PPC64-NEXT:    [[BF_SET312:%.*]] = or i64 [[BF_CLEAR311]], [[BF_SHL310]], !dbg [[DBG152]]
// PPC64-NEXT:    store i64 [[BF_SET312]], ptr [[ATOMIC_TEMP300]], align 8, !dbg [[DBG152]]
// PPC64-NEXT:    [[TMP185:%.*]] = load i64, ptr [[ATOMIC_TEMP300]], align 8, !dbg [[DBG152]]
// PPC64-NEXT:    [[TMP186:%.*]] = cmpxchg ptr @bfx4, i64 [[TMP184]], i64 [[TMP185]] release monotonic, align 8, !dbg [[DBG152]]
// PPC64-NEXT:    [[TMP187]] = extractvalue { i64, i1 } [[TMP186]], 0, !dbg [[DBG152]]
// PPC64-NEXT:    [[TMP188:%.*]] = extractvalue { i64, i1 } [[TMP186]], 1, !dbg [[DBG152]]
// PPC64-NEXT:    br i1 [[TMP188]], label [[ATOMIC_EXIT313:%.*]], label [[ATOMIC_CONT299]], !dbg [[DBG152]]
// PPC64:       atomic_exit313:
// PPC64-NEXT:    [[CONV314:%.*]] = trunc i64 [[CONV307]] to i32, !dbg [[DBG152]]
// PPC64-NEXT:    store i32 [[CONV314]], ptr @iv, align 4, !dbg [[DBG152]]
// PPC64-NEXT:    [[TMP189:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG155:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD315:%.*]] = load atomic i8, ptr getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1) acquire, align 1, !dbg [[DBG156:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT316:%.*]], !dbg [[DBG156]]
// PPC64:       atomic_cont316:
// PPC64-NEXT:    [[TMP190:%.*]] = phi i8 [ [[ATOMIC_LOAD315]], [[ATOMIC_EXIT313]] ], [ [[TMP194:%.*]], [[ATOMIC_CONT316]] ], !dbg [[DBG156]]
// PPC64-NEXT:    store i8 [[TMP190]], ptr [[ATOMIC_TEMP317]], align 1, !dbg [[DBG156]]
// PPC64-NEXT:    store i8 [[TMP190]], ptr [[ATOMIC_TEMP318]], align 1, !dbg [[DBG156]]
// PPC64-NEXT:    [[BF_LOAD319:%.*]] = load i8, ptr [[ATOMIC_TEMP318]], align 1, !dbg [[DBG156]]
// PPC64-NEXT:    [[BF_SHL320:%.*]] = shl i8 [[BF_LOAD319]], 1, !dbg [[DBG156]]
// PPC64-NEXT:    [[BF_ASHR321:%.*]] = ashr i8 [[BF_SHL320]], 1, !dbg [[DBG156]]
// PPC64-NEXT:    [[BF_CAST322:%.*]] = sext i8 [[BF_ASHR321]] to i64, !dbg [[DBG156]]
// PPC64-NEXT:    [[CONV323:%.*]] = sitofp i64 [[BF_CAST322]] to ppc_fp128, !dbg [[DBG157:![0-9]+]]
// PPC64-NEXT:    [[ADD324:%.*]] = fadd ppc_fp128 [[CONV323]], [[TMP189]], !dbg [[DBG158:![0-9]+]]
// PPC64-NEXT:    [[CONV325:%.*]] = fptosi ppc_fp128 [[ADD324]] to i64, !dbg [[DBG157]]
// PPC64-NEXT:    [[TMP191:%.*]] = trunc i64 [[CONV325]] to i8, !dbg [[DBG156]]
// PPC64-NEXT:    [[BF_LOAD326:%.*]] = load i8, ptr [[ATOMIC_TEMP317]], align 1, !dbg [[DBG156]]
// PPC64-NEXT:    [[BF_VALUE327:%.*]] = and i8 [[TMP191]], 127, !dbg [[DBG156]]
// PPC64-NEXT:    [[BF_CLEAR328:%.*]] = and i8 [[BF_LOAD326]], -128, !dbg [[DBG156]]
// PPC64-NEXT:    [[BF_SET329:%.*]] = or i8 [[BF_CLEAR328]], [[BF_VALUE327]], !dbg [[DBG156]]
// PPC64-NEXT:    store i8 [[BF_SET329]], ptr [[ATOMIC_TEMP317]], align 1, !dbg [[DBG156]]
// PPC64-NEXT:    [[TMP192:%.*]] = load i8, ptr [[ATOMIC_TEMP317]], align 1, !dbg [[DBG156]]
// PPC64-NEXT:    [[TMP193:%.*]] = cmpxchg ptr getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1), i8 [[TMP190]], i8 [[TMP192]] acquire acquire, align 1, !dbg [[DBG156]]
// PPC64-NEXT:    [[TMP194]] = extractvalue { i8, i1 } [[TMP193]], 0, !dbg [[DBG156]]
// PPC64-NEXT:    [[TMP195:%.*]] = extractvalue { i8, i1 } [[TMP193]], 1, !dbg [[DBG156]]
// PPC64-NEXT:    br i1 [[TMP195]], label [[ATOMIC_EXIT330:%.*]], label [[ATOMIC_CONT316]], !dbg [[DBG156]]
// PPC64:       atomic_exit330:
// PPC64-NEXT:    [[CONV331:%.*]] = trunc i64 [[CONV325]] to i32, !dbg [[DBG156]]
// PPC64-NEXT:    store i32 [[CONV331]], ptr @iv, align 4, !dbg [[DBG156]]
// PPC64-NEXT:    [[TMP196:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG159:![0-9]+]]
// PPC64-NEXT:    [[CONV332:%.*]] = uitofp i64 [[TMP196]] to float, !dbg [[DBG159]]
// PPC64-NEXT:    [[ATOMIC_LOAD333:%.*]] = load atomic i64, ptr @float2x acquire, align 8, !dbg [[DBG160:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT334:%.*]], !dbg [[DBG160]]
// PPC64:       atomic_cont334:
// PPC64-NEXT:    [[TMP197:%.*]] = phi i64 [ [[ATOMIC_LOAD333]], [[ATOMIC_EXIT330]] ], [ [[TMP205:%.*]], [[ATOMIC_CONT334]] ], !dbg [[DBG160]]
// PPC64-NEXT:    store i64 [[TMP197]], ptr [[ATOMIC_TEMP335]], align 8, !dbg [[DBG160]]
// PPC64-NEXT:    [[TMP198:%.*]] = bitcast i64 [[TMP197]] to <2 x float>, !dbg [[DBG160]]
// PPC64-NEXT:    store <2 x float> [[TMP198]], ptr [[ATOMIC_TEMP336]], align 8, !dbg [[DBG160]]
// PPC64-NEXT:    [[TMP199:%.*]] = load <2 x float>, ptr [[ATOMIC_TEMP336]], align 8, !dbg [[DBG160]]
// PPC64-NEXT:    [[TMP200:%.*]] = extractelement <2 x float> [[TMP199]], i64 0, !dbg [[DBG160]]
// PPC64-NEXT:    [[SUB337:%.*]] = fsub float [[CONV332]], [[TMP200]], !dbg [[DBG161:![0-9]+]]
// PPC64-NEXT:    [[TMP201:%.*]] = load <2 x float>, ptr [[ATOMIC_TEMP335]], align 8, !dbg [[DBG160]]
// PPC64-NEXT:    [[TMP202:%.*]] = insertelement <2 x float> [[TMP201]], float [[SUB337]], i64 0, !dbg [[DBG160]]
// PPC64-NEXT:    store <2 x float> [[TMP202]], ptr [[ATOMIC_TEMP335]], align 8, !dbg [[DBG160]]
// PPC64-NEXT:    [[TMP203:%.*]] = load i64, ptr [[ATOMIC_TEMP335]], align 8, !dbg [[DBG160]]
// PPC64-NEXT:    [[TMP204:%.*]] = cmpxchg ptr @float2x, i64 [[TMP197]], i64 [[TMP203]] acq_rel acquire, align 8, !dbg [[DBG160]]
// PPC64-NEXT:    [[TMP205]] = extractvalue { i64, i1 } [[TMP204]], 0, !dbg [[DBG160]]
// PPC64-NEXT:    [[TMP206:%.*]] = extractvalue { i64, i1 } [[TMP204]], 1, !dbg [[DBG160]]
// PPC64-NEXT:    br i1 [[TMP206]], label [[ATOMIC_EXIT338:%.*]], label [[ATOMIC_CONT334]], !dbg [[DBG160]]
// PPC64:       atomic_exit338:
// PPC64-NEXT:    store float [[TMP200]], ptr @fv, align 4, !dbg [[DBG160]]
// PPC64-NEXT:    ret i32 0, !dbg [[DBG162:![0-9]+]]
//
//
// AARCH64-LABEL: define {{[^@]+}}@main
// AARCH64-SAME: () #[[ATTR0:[0-9]+]] !dbg [[DBG5:![0-9]+]] {
// AARCH64-NEXT:  entry:
// AARCH64-NEXT:    [[RETVAL:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca i16, align 2
// AARCH64-NEXT:    [[ATOMIC_TEMP10:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP14:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP18:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP22:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP28:%.*]] = alloca double, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP34:%.*]] = alloca fp128, align 16
// AARCH64-NEXT:    [[ATOMIC_TEMP38:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP40:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP44:%.*]] = alloca { float, float }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP46:%.*]] = alloca { float, float }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP51:%.*]] = alloca { double, double }, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP53:%.*]] = alloca { double, double }, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP63:%.*]] = alloca i8, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP73:%.*]] = alloca i8, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP81:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP88:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP92:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP94:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP106:%.*]] = alloca float, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP112:%.*]] = alloca double, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP116:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP118:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP128:%.*]] = alloca i16, align 2
// AARCH64-NEXT:    [[ATOMIC_TEMP136:%.*]] = alloca i8, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP149:%.*]] = alloca i8, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP164:%.*]] = alloca <4 x i32>, align 16
// AARCH64-NEXT:    [[ATOMIC_TEMP165:%.*]] = alloca <4 x i32>, align 16
// AARCH64-NEXT:    [[ATOMIC_TEMP170:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP171:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP177:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP179:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP180:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP195:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP196:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP210:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP211:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP225:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP226:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP239:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP241:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP242:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP259:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP260:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP276:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP277:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP292:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP293:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP309:%.*]] = alloca i64, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP310:%.*]] = alloca i64, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP327:%.*]] = alloca <2 x float>, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP328:%.*]] = alloca <2 x float>, align 8
// AARCH64-NEXT:    store i32 0, ptr [[RETVAL]], align 4
// AARCH64-NEXT:    [[TMP0:%.*]] = atomicrmw add ptr @bx, i8 1 monotonic, align 1, !dbg [[DBG9:![0-9]+]]
// AARCH64-NEXT:    store i8 [[TMP0]], ptr @bv, align 1, !dbg [[DBG9]]
// AARCH64-NEXT:    [[TMP1:%.*]] = atomicrmw add ptr @cx, i8 1 monotonic, align 1, !dbg [[DBG10:![0-9]+]]
// AARCH64-NEXT:    [[CONV:%.*]] = sext i8 [[TMP1]] to i32, !dbg [[DBG11:![0-9]+]]
// AARCH64-NEXT:    [[ADD:%.*]] = add nsw i32 [[CONV]], 1, !dbg [[DBG12:![0-9]+]]
// AARCH64-NEXT:    [[CONV1:%.*]] = trunc i32 [[ADD]] to i8, !dbg [[DBG11]]
// AARCH64-NEXT:    store i8 [[CONV1]], ptr @cv, align 1, !dbg [[DBG10]]
// AARCH64-NEXT:    [[TMP2:%.*]] = atomicrmw sub ptr @ucx, i8 1 monotonic, align 1, !dbg [[DBG13:![0-9]+]]
// AARCH64-NEXT:    store i8 [[TMP2]], ptr @ucv, align 1, !dbg [[DBG13]]
// AARCH64-NEXT:    [[TMP3:%.*]] = atomicrmw sub ptr @sx, i16 1 monotonic, align 2, !dbg [[DBG14:![0-9]+]]
// AARCH64-NEXT:    [[CONV2:%.*]] = sext i16 [[TMP3]] to i32, !dbg [[DBG15:![0-9]+]]
// AARCH64-NEXT:    [[SUB:%.*]] = sub nsw i32 [[CONV2]], 1, !dbg [[DBG16:![0-9]+]]
// AARCH64-NEXT:    [[CONV3:%.*]] = trunc i32 [[SUB]] to i16, !dbg [[DBG15]]
// AARCH64-NEXT:    store i16 [[CONV3]], ptr @sv, align 2, !dbg [[DBG14]]
// AARCH64-NEXT:    [[TMP4:%.*]] = load i16, ptr @usv, align 2, !dbg [[DBG17:![0-9]+]]
// AARCH64-NEXT:    [[CONV4:%.*]] = zext i16 [[TMP4]] to i32, !dbg [[DBG17]]
// AARCH64-NEXT:    [[ATOMIC_LOAD:%.*]] = load atomic i16, ptr @usx monotonic, align 2, !dbg [[DBG18:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT:%.*]], !dbg [[DBG18]]
// AARCH64:       atomic_cont:
// AARCH64-NEXT:    [[TMP5:%.*]] = phi i16 [ [[ATOMIC_LOAD]], [[ENTRY:%.*]] ], [ [[TMP8:%.*]], [[ATOMIC_CONT]] ], !dbg [[DBG18]]
// AARCH64-NEXT:    [[CONV5:%.*]] = zext i16 [[TMP5]] to i32, !dbg [[DBG19:![0-9]+]]
// AARCH64-NEXT:    [[ADD6:%.*]] = add nsw i32 [[CONV5]], [[CONV4]], !dbg [[DBG20:![0-9]+]]
// AARCH64-NEXT:    [[CONV7:%.*]] = trunc i32 [[ADD6]] to i16, !dbg [[DBG19]]
// AARCH64-NEXT:    store i16 [[CONV7]], ptr [[ATOMIC_TEMP]], align 2, !dbg [[DBG18]]
// AARCH64-NEXT:    [[TMP6:%.*]] = load i16, ptr [[ATOMIC_TEMP]], align 2, !dbg [[DBG18]]
// AARCH64-NEXT:    [[TMP7:%.*]] = cmpxchg ptr @usx, i16 [[TMP5]], i16 [[TMP6]] monotonic monotonic, align 2, !dbg [[DBG18]]
// AARCH64-NEXT:    [[TMP8]] = extractvalue { i16, i1 } [[TMP7]], 0, !dbg [[DBG18]]
// AARCH64-NEXT:    [[TMP9:%.*]] = extractvalue { i16, i1 } [[TMP7]], 1, !dbg [[DBG18]]
// AARCH64-NEXT:    br i1 [[TMP9]], label [[ATOMIC_EXIT:%.*]], label [[ATOMIC_CONT]], !dbg [[DBG18]]
// AARCH64:       atomic_exit:
// AARCH64-NEXT:    store i16 [[CONV7]], ptr @sv, align 2, !dbg [[DBG18]]
// AARCH64-NEXT:    [[TMP10:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG21:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD8:%.*]] = load atomic i32, ptr @ix monotonic, align 4, !dbg [[DBG22:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT9:%.*]], !dbg [[DBG22]]
// AARCH64:       atomic_cont9:
// AARCH64-NEXT:    [[TMP11:%.*]] = phi i32 [ [[ATOMIC_LOAD8]], [[ATOMIC_EXIT]] ], [ [[TMP14:%.*]], [[ATOMIC_CONT9]] ], !dbg [[DBG22]]
// AARCH64-NEXT:    [[MUL:%.*]] = mul nsw i32 [[TMP11]], [[TMP10]], !dbg [[DBG23:![0-9]+]]
// AARCH64-NEXT:    store i32 [[MUL]], ptr [[ATOMIC_TEMP10]], align 4, !dbg [[DBG22]]
// AARCH64-NEXT:    [[TMP12:%.*]] = load i32, ptr [[ATOMIC_TEMP10]], align 4, !dbg [[DBG22]]
// AARCH64-NEXT:    [[TMP13:%.*]] = cmpxchg ptr @ix, i32 [[TMP11]], i32 [[TMP12]] monotonic monotonic, align 4, !dbg [[DBG22]]
// AARCH64-NEXT:    [[TMP14]] = extractvalue { i32, i1 } [[TMP13]], 0, !dbg [[DBG22]]
// AARCH64-NEXT:    [[TMP15:%.*]] = extractvalue { i32, i1 } [[TMP13]], 1, !dbg [[DBG22]]
// AARCH64-NEXT:    br i1 [[TMP15]], label [[ATOMIC_EXIT11:%.*]], label [[ATOMIC_CONT9]], !dbg [[DBG22]]
// AARCH64:       atomic_exit11:
// AARCH64-NEXT:    store i32 [[MUL]], ptr @uiv, align 4, !dbg [[DBG22]]
// AARCH64-NEXT:    [[TMP16:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG24:![0-9]+]]
// AARCH64-NEXT:    [[TMP17:%.*]] = atomicrmw sub ptr @uix, i32 [[TMP16]] monotonic, align 4, !dbg [[DBG25:![0-9]+]]
// AARCH64-NEXT:    store i32 [[TMP17]], ptr @iv, align 4, !dbg [[DBG25]]
// AARCH64-NEXT:    [[TMP18:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG26:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD12:%.*]] = load atomic i32, ptr @ix monotonic, align 4, !dbg [[DBG27:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT13:%.*]], !dbg [[DBG27]]
// AARCH64:       atomic_cont13:
// AARCH64-NEXT:    [[TMP19:%.*]] = phi i32 [ [[ATOMIC_LOAD12]], [[ATOMIC_EXIT11]] ], [ [[TMP22:%.*]], [[ATOMIC_CONT13]] ], !dbg [[DBG27]]
// AARCH64-NEXT:    [[SHL:%.*]] = shl i32 [[TMP19]], [[TMP18]], !dbg [[DBG28:![0-9]+]]
// AARCH64-NEXT:    store i32 [[SHL]], ptr [[ATOMIC_TEMP14]], align 4, !dbg [[DBG27]]
// AARCH64-NEXT:    [[TMP20:%.*]] = load i32, ptr [[ATOMIC_TEMP14]], align 4, !dbg [[DBG27]]
// AARCH64-NEXT:    [[TMP21:%.*]] = cmpxchg ptr @ix, i32 [[TMP19]], i32 [[TMP20]] monotonic monotonic, align 4, !dbg [[DBG27]]
// AARCH64-NEXT:    [[TMP22]] = extractvalue { i32, i1 } [[TMP21]], 0, !dbg [[DBG27]]
// AARCH64-NEXT:    [[TMP23:%.*]] = extractvalue { i32, i1 } [[TMP21]], 1, !dbg [[DBG27]]
// AARCH64-NEXT:    br i1 [[TMP23]], label [[ATOMIC_EXIT15:%.*]], label [[ATOMIC_CONT13]], !dbg [[DBG27]]
// AARCH64:       atomic_exit15:
// AARCH64-NEXT:    store i32 [[SHL]], ptr @uiv, align 4, !dbg [[DBG27]]
// AARCH64-NEXT:    [[TMP24:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG29:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD16:%.*]] = load atomic i32, ptr @uix monotonic, align 4, !dbg [[DBG30:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT17:%.*]], !dbg [[DBG30]]
// AARCH64:       atomic_cont17:
// AARCH64-NEXT:    [[TMP25:%.*]] = phi i32 [ [[ATOMIC_LOAD16]], [[ATOMIC_EXIT15]] ], [ [[TMP28:%.*]], [[ATOMIC_CONT17]] ], !dbg [[DBG30]]
// AARCH64-NEXT:    [[SHR:%.*]] = lshr i32 [[TMP25]], [[TMP24]], !dbg [[DBG31:![0-9]+]]
// AARCH64-NEXT:    store i32 [[SHR]], ptr [[ATOMIC_TEMP18]], align 4, !dbg [[DBG30]]
// AARCH64-NEXT:    [[TMP26:%.*]] = load i32, ptr [[ATOMIC_TEMP18]], align 4, !dbg [[DBG30]]
// AARCH64-NEXT:    [[TMP27:%.*]] = cmpxchg ptr @uix, i32 [[TMP25]], i32 [[TMP26]] monotonic monotonic, align 4, !dbg [[DBG30]]
// AARCH64-NEXT:    [[TMP28]] = extractvalue { i32, i1 } [[TMP27]], 0, !dbg [[DBG30]]
// AARCH64-NEXT:    [[TMP29:%.*]] = extractvalue { i32, i1 } [[TMP27]], 1, !dbg [[DBG30]]
// AARCH64-NEXT:    br i1 [[TMP29]], label [[ATOMIC_EXIT19:%.*]], label [[ATOMIC_CONT17]], !dbg [[DBG30]]
// AARCH64:       atomic_exit19:
// AARCH64-NEXT:    store i32 [[SHR]], ptr @iv, align 4, !dbg [[DBG30]]
// AARCH64-NEXT:    [[TMP30:%.*]] = load i64, ptr @lv, align 8, !dbg [[DBG32:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD20:%.*]] = load atomic i64, ptr @lx monotonic, align 8, !dbg [[DBG33:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT21:%.*]], !dbg [[DBG33]]
// AARCH64:       atomic_cont21:
// AARCH64-NEXT:    [[TMP31:%.*]] = phi i64 [ [[ATOMIC_LOAD20]], [[ATOMIC_EXIT19]] ], [ [[TMP34:%.*]], [[ATOMIC_CONT21]] ], !dbg [[DBG33]]
// AARCH64-NEXT:    [[DIV:%.*]] = sdiv i64 [[TMP31]], [[TMP30]], !dbg [[DBG34:![0-9]+]]
// AARCH64-NEXT:    store i64 [[DIV]], ptr [[ATOMIC_TEMP22]], align 8, !dbg [[DBG33]]
// AARCH64-NEXT:    [[TMP32:%.*]] = load i64, ptr [[ATOMIC_TEMP22]], align 8, !dbg [[DBG33]]
// AARCH64-NEXT:    [[TMP33:%.*]] = cmpxchg ptr @lx, i64 [[TMP31]], i64 [[TMP32]] monotonic monotonic, align 8, !dbg [[DBG33]]
// AARCH64-NEXT:    [[TMP34]] = extractvalue { i64, i1 } [[TMP33]], 0, !dbg [[DBG33]]
// AARCH64-NEXT:    [[TMP35:%.*]] = extractvalue { i64, i1 } [[TMP33]], 1, !dbg [[DBG33]]
// AARCH64-NEXT:    br i1 [[TMP35]], label [[ATOMIC_EXIT23:%.*]], label [[ATOMIC_CONT21]], !dbg [[DBG33]]
// AARCH64:       atomic_exit23:
// AARCH64-NEXT:    store i64 [[TMP31]], ptr @ulv, align 8, !dbg [[DBG33]]
// AARCH64-NEXT:    [[TMP36:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG35:![0-9]+]]
// AARCH64-NEXT:    [[TMP37:%.*]] = atomicrmw and ptr @ulx, i64 [[TMP36]] monotonic, align 8, !dbg [[DBG36:![0-9]+]]
// AARCH64-NEXT:    [[AND:%.*]] = and i64 [[TMP37]], [[TMP36]], !dbg [[DBG37:![0-9]+]]
// AARCH64-NEXT:    store i64 [[AND]], ptr @lv, align 8, !dbg [[DBG36]]
// AARCH64-NEXT:    [[TMP38:%.*]] = load i64, ptr @llv, align 8, !dbg [[DBG38:![0-9]+]]
// AARCH64-NEXT:    [[TMP39:%.*]] = atomicrmw xor ptr @llx, i64 [[TMP38]] monotonic, align 8, !dbg [[DBG39:![0-9]+]]
// AARCH64-NEXT:    [[XOR:%.*]] = xor i64 [[TMP39]], [[TMP38]], !dbg [[DBG40:![0-9]+]]
// AARCH64-NEXT:    store i64 [[XOR]], ptr @ullv, align 8, !dbg [[DBG39]]
// AARCH64-NEXT:    [[TMP40:%.*]] = load i64, ptr @ullv, align 8, !dbg [[DBG41:![0-9]+]]
// AARCH64-NEXT:    [[TMP41:%.*]] = atomicrmw or ptr @ullx, i64 [[TMP40]] monotonic, align 8, !dbg [[DBG42:![0-9]+]]
// AARCH64-NEXT:    [[OR:%.*]] = or i64 [[TMP41]], [[TMP40]], !dbg [[DBG43:![0-9]+]]
// AARCH64-NEXT:    store i64 [[OR]], ptr @llv, align 8, !dbg [[DBG42]]
// AARCH64-NEXT:    [[TMP42:%.*]] = load float, ptr @fv, align 4, !dbg [[DBG44:![0-9]+]]
// AARCH64-NEXT:    [[TMP43:%.*]] = atomicrmw fadd ptr @fx, float [[TMP42]] monotonic, align 4, !dbg [[DBG45:![0-9]+]]
// AARCH64-NEXT:    [[ADD24:%.*]] = fadd float [[TMP43]], [[TMP42]], !dbg [[DBG46:![0-9]+]]
// AARCH64-NEXT:    [[CONV25:%.*]] = fpext float [[ADD24]] to double, !dbg [[DBG45]]
// AARCH64-NEXT:    store double [[CONV25]], ptr @dv, align 8, !dbg [[DBG45]]
// AARCH64-NEXT:    [[TMP44:%.*]] = load double, ptr @dv, align 8, !dbg [[DBG47:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD26:%.*]] = load atomic i64, ptr @dx monotonic, align 8, !dbg [[DBG48:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT27:%.*]], !dbg [[DBG48]]
// AARCH64:       atomic_cont27:
// AARCH64-NEXT:    [[TMP45:%.*]] = phi i64 [ [[ATOMIC_LOAD26]], [[ATOMIC_EXIT23]] ], [ [[TMP49:%.*]], [[ATOMIC_CONT27]] ], !dbg [[DBG48]]
// AARCH64-NEXT:    [[TMP46:%.*]] = bitcast i64 [[TMP45]] to double, !dbg [[DBG48]]
// AARCH64-NEXT:    [[SUB29:%.*]] = fsub double [[TMP44]], [[TMP46]], !dbg [[DBG49:![0-9]+]]
// AARCH64-NEXT:    store double [[SUB29]], ptr [[ATOMIC_TEMP28]], align 8, !dbg [[DBG48]]
// AARCH64-NEXT:    [[TMP47:%.*]] = load i64, ptr [[ATOMIC_TEMP28]], align 8, !dbg [[DBG48]]
// AARCH64-NEXT:    [[TMP48:%.*]] = cmpxchg ptr @dx, i64 [[TMP45]], i64 [[TMP47]] monotonic monotonic, align 8, !dbg [[DBG48]]
// AARCH64-NEXT:    [[TMP49]] = extractvalue { i64, i1 } [[TMP48]], 0, !dbg [[DBG48]]
// AARCH64-NEXT:    [[TMP50:%.*]] = extractvalue { i64, i1 } [[TMP48]], 1, !dbg [[DBG48]]
// AARCH64-NEXT:    br i1 [[TMP50]], label [[ATOMIC_EXIT30:%.*]], label [[ATOMIC_CONT27]], !dbg [[DBG48]]
// AARCH64:       atomic_exit30:
// AARCH64-NEXT:    [[CONV31:%.*]] = fptrunc double [[TMP46]] to float, !dbg [[DBG48]]
// AARCH64-NEXT:    store float [[CONV31]], ptr @fv, align 4, !dbg [[DBG48]]
// AARCH64-NEXT:    [[TMP51:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG50:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD32:%.*]] = load atomic i128, ptr @ldx monotonic, align 16, !dbg [[DBG51:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT33:%.*]], !dbg [[DBG51]]
// AARCH64:       atomic_cont33:
// AARCH64-NEXT:    [[TMP52:%.*]] = phi i128 [ [[ATOMIC_LOAD32]], [[ATOMIC_EXIT30]] ], [ [[TMP56:%.*]], [[ATOMIC_CONT33]] ], !dbg [[DBG51]]
// AARCH64-NEXT:    [[TMP53:%.*]] = bitcast i128 [[TMP52]] to fp128, !dbg [[DBG51]]
// AARCH64-NEXT:    [[MUL35:%.*]] = fmul fp128 [[TMP53]], [[TMP51]], !dbg [[DBG52:![0-9]+]]
// AARCH64-NEXT:    store fp128 [[MUL35]], ptr [[ATOMIC_TEMP34]], align 16, !dbg [[DBG51]]
// AARCH64-NEXT:    [[TMP54:%.*]] = load i128, ptr [[ATOMIC_TEMP34]], align 16, !dbg [[DBG51]]
// AARCH64-NEXT:    [[TMP55:%.*]] = cmpxchg ptr @ldx, i128 [[TMP52]], i128 [[TMP54]] monotonic monotonic, align 16, !dbg [[DBG51]]
// AARCH64-NEXT:    [[TMP56]] = extractvalue { i128, i1 } [[TMP55]], 0, !dbg [[DBG51]]
// AARCH64-NEXT:    [[TMP57:%.*]] = extractvalue { i128, i1 } [[TMP55]], 1, !dbg [[DBG51]]
// AARCH64-NEXT:    br i1 [[TMP57]], label [[ATOMIC_EXIT36:%.*]], label [[ATOMIC_CONT33]], !dbg [[DBG51]]
// AARCH64:       atomic_exit36:
// AARCH64-NEXT:    [[CONV37:%.*]] = fptrunc fp128 [[MUL35]] to double, !dbg [[DBG51]]
// AARCH64-NEXT:    store double [[CONV37]], ptr @dv, align 8, !dbg [[DBG51]]
// AARCH64-NEXT:    [[CIV_REAL:%.*]] = load i32, ptr @civ, align 4, !dbg [[DBG53:![0-9]+]]
// AARCH64-NEXT:    [[CIV_IMAG:%.*]] = load i32, ptr getelementptr inbounds ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG53]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP38]], i32 noundef 0), !dbg [[DBG54:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT39:%.*]], !dbg [[DBG54]]
// AARCH64:       atomic_cont39:
// AARCH64-NEXT:    [[ATOMIC_TEMP38_REALP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP38]], i32 0, i32 0, !dbg [[DBG54]]
// AARCH64-NEXT:    [[ATOMIC_TEMP38_REAL:%.*]] = load i32, ptr [[ATOMIC_TEMP38_REALP]], align 4, !dbg [[DBG54]]
// AARCH64-NEXT:    [[ATOMIC_TEMP38_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP38]], i32 0, i32 1, !dbg [[DBG54]]
// AARCH64-NEXT:    [[ATOMIC_TEMP38_IMAG:%.*]] = load i32, ptr [[ATOMIC_TEMP38_IMAGP]], align 4, !dbg [[DBG54]]
// AARCH64-NEXT:    [[TMP58:%.*]] = mul i32 [[CIV_REAL]], [[ATOMIC_TEMP38_REAL]], !dbg [[DBG55:![0-9]+]]
// AARCH64-NEXT:    [[TMP59:%.*]] = mul i32 [[CIV_IMAG]], [[ATOMIC_TEMP38_IMAG]], !dbg [[DBG55]]
// AARCH64-NEXT:    [[TMP60:%.*]] = add i32 [[TMP58]], [[TMP59]], !dbg [[DBG55]]
// AARCH64-NEXT:    [[TMP61:%.*]] = mul i32 [[ATOMIC_TEMP38_REAL]], [[ATOMIC_TEMP38_REAL]], !dbg [[DBG55]]
// AARCH64-NEXT:    [[TMP62:%.*]] = mul i32 [[ATOMIC_TEMP38_IMAG]], [[ATOMIC_TEMP38_IMAG]], !dbg [[DBG55]]
// AARCH64-NEXT:    [[TMP63:%.*]] = add i32 [[TMP61]], [[TMP62]], !dbg [[DBG55]]
// AARCH64-NEXT:    [[TMP64:%.*]] = mul i32 [[CIV_IMAG]], [[ATOMIC_TEMP38_REAL]], !dbg [[DBG55]]
// AARCH64-NEXT:    [[TMP65:%.*]] = mul i32 [[CIV_REAL]], [[ATOMIC_TEMP38_IMAG]], !dbg [[DBG55]]
// AARCH64-NEXT:    [[TMP66:%.*]] = sub i32 [[TMP64]], [[TMP65]], !dbg [[DBG55]]
// AARCH64-NEXT:    [[TMP67:%.*]] = sdiv i32 [[TMP60]], [[TMP63]], !dbg [[DBG55]]
// AARCH64-NEXT:    [[TMP68:%.*]] = sdiv i32 [[TMP66]], [[TMP63]], !dbg [[DBG55]]
// AARCH64-NEXT:    [[ATOMIC_TEMP40_REALP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP40]], i32 0, i32 0, !dbg [[DBG54]]
// AARCH64-NEXT:    [[ATOMIC_TEMP40_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP40]], i32 0, i32 1, !dbg [[DBG54]]
// AARCH64-NEXT:    store i32 [[TMP67]], ptr [[ATOMIC_TEMP40_REALP]], align 4, !dbg [[DBG54]]
// AARCH64-NEXT:    store i32 [[TMP68]], ptr [[ATOMIC_TEMP40_IMAGP]], align 4, !dbg [[DBG54]]
// AARCH64-NEXT:    [[CALL:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP38]], ptr noundef [[ATOMIC_TEMP40]], i32 noundef 0, i32 noundef 0), !dbg [[DBG54]]
// AARCH64-NEXT:    br i1 [[CALL]], label [[ATOMIC_EXIT41:%.*]], label [[ATOMIC_CONT39]], !dbg [[DBG54]]
// AARCH64:       atomic_exit41:
// AARCH64-NEXT:    [[CONV42:%.*]] = sitofp i32 [[TMP67]] to float, !dbg [[DBG54]]
// AARCH64-NEXT:    [[CONV43:%.*]] = sitofp i32 [[TMP68]] to float, !dbg [[DBG54]]
// AARCH64-NEXT:    store float [[CONV42]], ptr @cfv, align 4, !dbg [[DBG54]]
// AARCH64-NEXT:    store float [[CONV43]], ptr getelementptr inbounds ({ float, float }, ptr @cfv, i32 0, i32 1), align 4, !dbg [[DBG54]]
// AARCH64-NEXT:    [[CFV_REAL:%.*]] = load float, ptr @cfv, align 4, !dbg [[DBG56:![0-9]+]]
// AARCH64-NEXT:    [[CFV_IMAG:%.*]] = load float, ptr getelementptr inbounds ({ float, float }, ptr @cfv, i32 0, i32 1), align 4, !dbg [[DBG56]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cfx, ptr noundef [[ATOMIC_TEMP44]], i32 noundef 0), !dbg [[DBG57:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT45:%.*]], !dbg [[DBG57]]
// AARCH64:       atomic_cont45:
// AARCH64-NEXT:    [[ATOMIC_TEMP44_REALP:%.*]] = getelementptr inbounds { float, float }, ptr [[ATOMIC_TEMP44]], i32 0, i32 0, !dbg [[DBG57]]
// AARCH64-NEXT:    [[ATOMIC_TEMP44_REAL:%.*]] = load float, ptr [[ATOMIC_TEMP44_REALP]], align 4, !dbg [[DBG57]]
// AARCH64-NEXT:    [[ATOMIC_TEMP44_IMAGP:%.*]] = getelementptr inbounds { float, float }, ptr [[ATOMIC_TEMP44]], i32 0, i32 1, !dbg [[DBG57]]
// AARCH64-NEXT:    [[ATOMIC_TEMP44_IMAG:%.*]] = load float, ptr [[ATOMIC_TEMP44_IMAGP]], align 4, !dbg [[DBG57]]
// AARCH64-NEXT:    [[ADD_R:%.*]] = fadd float [[CFV_REAL]], [[ATOMIC_TEMP44_REAL]], !dbg [[DBG58:![0-9]+]]
// AARCH64-NEXT:    [[ADD_I:%.*]] = fadd float [[CFV_IMAG]], [[ATOMIC_TEMP44_IMAG]], !dbg [[DBG58]]
// AARCH64-NEXT:    [[ATOMIC_TEMP46_REALP:%.*]] = getelementptr inbounds { float, float }, ptr [[ATOMIC_TEMP46]], i32 0, i32 0, !dbg [[DBG57]]
// AARCH64-NEXT:    [[ATOMIC_TEMP46_IMAGP:%.*]] = getelementptr inbounds { float, float }, ptr [[ATOMIC_TEMP46]], i32 0, i32 1, !dbg [[DBG57]]
// AARCH64-NEXT:    store float [[ADD_R]], ptr [[ATOMIC_TEMP46_REALP]], align 4, !dbg [[DBG57]]
// AARCH64-NEXT:    store float [[ADD_I]], ptr [[ATOMIC_TEMP46_IMAGP]], align 4, !dbg [[DBG57]]
// AARCH64-NEXT:    [[CALL47:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cfx, ptr noundef [[ATOMIC_TEMP44]], ptr noundef [[ATOMIC_TEMP46]], i32 noundef 0, i32 noundef 0), !dbg [[DBG57]]
// AARCH64-NEXT:    br i1 [[CALL47]], label [[ATOMIC_EXIT48:%.*]], label [[ATOMIC_CONT45]], !dbg [[DBG57]]
// AARCH64:       atomic_exit48:
// AARCH64-NEXT:    [[CONV49:%.*]] = fptosi float [[ATOMIC_TEMP44_REAL]] to i32, !dbg [[DBG57]]
// AARCH64-NEXT:    [[CONV50:%.*]] = fptosi float [[ATOMIC_TEMP44_IMAG]] to i32, !dbg [[DBG57]]
// AARCH64-NEXT:    store i32 [[CONV49]], ptr @civ, align 4, !dbg [[DBG57]]
// AARCH64-NEXT:    store i32 [[CONV50]], ptr getelementptr inbounds ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG57]]
// AARCH64-NEXT:    [[CDV_REAL:%.*]] = load double, ptr @cdv, align 8, !dbg [[DBG59:![0-9]+]]
// AARCH64-NEXT:    [[CDV_IMAG:%.*]] = load double, ptr getelementptr inbounds ({ double, double }, ptr @cdv, i32 0, i32 1), align 8, !dbg [[DBG59]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 16, ptr noundef @cdx, ptr noundef [[ATOMIC_TEMP51]], i32 noundef 5), !dbg [[DBG60:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT52:%.*]], !dbg [[DBG60]]
// AARCH64:       atomic_cont52:
// AARCH64-NEXT:    [[ATOMIC_TEMP51_REALP:%.*]] = getelementptr inbounds { double, double }, ptr [[ATOMIC_TEMP51]], i32 0, i32 0, !dbg [[DBG60]]
// AARCH64-NEXT:    [[ATOMIC_TEMP51_REAL:%.*]] = load double, ptr [[ATOMIC_TEMP51_REALP]], align 8, !dbg [[DBG60]]
// AARCH64-NEXT:    [[ATOMIC_TEMP51_IMAGP:%.*]] = getelementptr inbounds { double, double }, ptr [[ATOMIC_TEMP51]], i32 0, i32 1, !dbg [[DBG60]]
// AARCH64-NEXT:    [[ATOMIC_TEMP51_IMAG:%.*]] = load double, ptr [[ATOMIC_TEMP51_IMAGP]], align 8, !dbg [[DBG60]]
// AARCH64-NEXT:    [[SUB_R:%.*]] = fsub double [[ATOMIC_TEMP51_REAL]], [[CDV_REAL]], !dbg [[DBG61:![0-9]+]]
// AARCH64-NEXT:    [[SUB_I:%.*]] = fsub double [[ATOMIC_TEMP51_IMAG]], [[CDV_IMAG]], !dbg [[DBG61]]
// AARCH64-NEXT:    [[ATOMIC_TEMP53_REALP:%.*]] = getelementptr inbounds { double, double }, ptr [[ATOMIC_TEMP53]], i32 0, i32 0, !dbg [[DBG60]]
// AARCH64-NEXT:    [[ATOMIC_TEMP53_IMAGP:%.*]] = getelementptr inbounds { double, double }, ptr [[ATOMIC_TEMP53]], i32 0, i32 1, !dbg [[DBG60]]
// AARCH64-NEXT:    store double [[SUB_R]], ptr [[ATOMIC_TEMP53_REALP]], align 8, !dbg [[DBG60]]
// AARCH64-NEXT:    store double [[SUB_I]], ptr [[ATOMIC_TEMP53_IMAGP]], align 8, !dbg [[DBG60]]
// AARCH64-NEXT:    [[CALL54:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 16, ptr noundef @cdx, ptr noundef [[ATOMIC_TEMP51]], ptr noundef [[ATOMIC_TEMP53]], i32 noundef 5, i32 noundef 5), !dbg [[DBG60]]
// AARCH64-NEXT:    br i1 [[CALL54]], label [[ATOMIC_EXIT55:%.*]], label [[ATOMIC_CONT52]], !dbg [[DBG60]]
// AARCH64:       atomic_exit55:
// AARCH64-NEXT:    [[CONV56:%.*]] = fptrunc double [[SUB_R]] to float, !dbg [[DBG60]]
// AARCH64-NEXT:    [[CONV57:%.*]] = fptrunc double [[SUB_I]] to float, !dbg [[DBG60]]
// AARCH64-NEXT:    store float [[CONV56]], ptr @cfv, align 4, !dbg [[DBG60]]
// AARCH64-NEXT:    store float [[CONV57]], ptr getelementptr inbounds ({ float, float }, ptr @cfv, i32 0, i32 1), align 4, !dbg [[DBG60]]
// AARCH64-NEXT:    [[TMP69:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG62:![0-9]+]]
// AARCH64-NEXT:    [[TOBOOL:%.*]] = trunc i8 [[TMP69]] to i1, !dbg [[DBG62]]
// AARCH64-NEXT:    [[CONV58:%.*]] = zext i1 [[TOBOOL]] to i64, !dbg [[DBG62]]
// AARCH64-NEXT:    [[TMP70:%.*]] = atomicrmw and ptr @ulx, i64 [[CONV58]] monotonic, align 8, !dbg [[DBG63:![0-9]+]]
// AARCH64-NEXT:    [[AND59:%.*]] = and i64 [[TMP70]], [[CONV58]], !dbg [[DBG64:![0-9]+]]
// AARCH64-NEXT:    store i64 [[AND59]], ptr @ulv, align 8, !dbg [[DBG63]]
// AARCH64-NEXT:    [[TMP71:%.*]] = load i8, ptr @cv, align 1, !dbg [[DBG65:![0-9]+]]
// AARCH64-NEXT:    [[CONV60:%.*]] = sext i8 [[TMP71]] to i32, !dbg [[DBG65]]
// AARCH64-NEXT:    [[ATOMIC_LOAD61:%.*]] = load atomic i8, ptr @bx monotonic, align 1, !dbg [[DBG66:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT62:%.*]], !dbg [[DBG66]]
// AARCH64:       atomic_cont62:
// AARCH64-NEXT:    [[TMP72:%.*]] = phi i8 [ [[ATOMIC_LOAD61]], [[ATOMIC_EXIT55]] ], [ [[TMP75:%.*]], [[ATOMIC_CONT62]] ], !dbg [[DBG66]]
// AARCH64-NEXT:    [[TOBOOL64:%.*]] = trunc i8 [[TMP72]] to i1, !dbg [[DBG66]]
// AARCH64-NEXT:    [[CONV65:%.*]] = zext i1 [[TOBOOL64]] to i32, !dbg [[DBG67:![0-9]+]]
// AARCH64-NEXT:    [[AND66:%.*]] = and i32 [[CONV60]], [[CONV65]], !dbg [[DBG68:![0-9]+]]
// AARCH64-NEXT:    [[TOBOOL67:%.*]] = icmp ne i32 [[AND66]], 0, !dbg [[DBG65]]
// AARCH64-NEXT:    [[FROMBOOL:%.*]] = zext i1 [[TOBOOL67]] to i8, !dbg [[DBG66]]
// AARCH64-NEXT:    store i8 [[FROMBOOL]], ptr [[ATOMIC_TEMP63]], align 1, !dbg [[DBG66]]
// AARCH64-NEXT:    [[TMP73:%.*]] = load i8, ptr [[ATOMIC_TEMP63]], align 1, !dbg [[DBG66]]
// AARCH64-NEXT:    [[TMP74:%.*]] = cmpxchg ptr @bx, i8 [[TMP72]], i8 [[TMP73]] monotonic monotonic, align 1, !dbg [[DBG66]]
// AARCH64-NEXT:    [[TMP75]] = extractvalue { i8, i1 } [[TMP74]], 0, !dbg [[DBG66]]
// AARCH64-NEXT:    [[TMP76:%.*]] = extractvalue { i8, i1 } [[TMP74]], 1, !dbg [[DBG66]]
// AARCH64-NEXT:    br i1 [[TMP76]], label [[ATOMIC_EXIT68:%.*]], label [[ATOMIC_CONT62]], !dbg [[DBG66]]
// AARCH64:       atomic_exit68:
// AARCH64-NEXT:    [[FROMBOOL69:%.*]] = zext i1 [[TOBOOL64]] to i8, !dbg [[DBG66]]
// AARCH64-NEXT:    store i8 [[FROMBOOL69]], ptr @bv, align 1, !dbg [[DBG66]]
// AARCH64-NEXT:    [[TMP77:%.*]] = load i8, ptr @ucv, align 1, !dbg [[DBG69:![0-9]+]]
// AARCH64-NEXT:    [[CONV70:%.*]] = zext i8 [[TMP77]] to i32, !dbg [[DBG69]]
// AARCH64-NEXT:    [[ATOMIC_LOAD71:%.*]] = load atomic i8, ptr @cx seq_cst, align 1, !dbg [[DBG70:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT72:%.*]], !dbg [[DBG70]]
// AARCH64:       atomic_cont72:
// AARCH64-NEXT:    [[TMP78:%.*]] = phi i8 [ [[ATOMIC_LOAD71]], [[ATOMIC_EXIT68]] ], [ [[TMP81:%.*]], [[ATOMIC_CONT72]] ], !dbg [[DBG70]]
// AARCH64-NEXT:    [[CONV74:%.*]] = sext i8 [[TMP78]] to i32, !dbg [[DBG71:![0-9]+]]
// AARCH64-NEXT:    [[SHR75:%.*]] = ashr i32 [[CONV74]], [[CONV70]], !dbg [[DBG72:![0-9]+]]
// AARCH64-NEXT:    [[CONV76:%.*]] = trunc i32 [[SHR75]] to i8, !dbg [[DBG71]]
// AARCH64-NEXT:    store i8 [[CONV76]], ptr [[ATOMIC_TEMP73]], align 1, !dbg [[DBG70]]
// AARCH64-NEXT:    [[TMP79:%.*]] = load i8, ptr [[ATOMIC_TEMP73]], align 1, !dbg [[DBG70]]
// AARCH64-NEXT:    [[TMP80:%.*]] = cmpxchg ptr @cx, i8 [[TMP78]], i8 [[TMP79]] seq_cst seq_cst, align 1, !dbg [[DBG70]]
// AARCH64-NEXT:    [[TMP81]] = extractvalue { i8, i1 } [[TMP80]], 0, !dbg [[DBG70]]
// AARCH64-NEXT:    [[TMP82:%.*]] = extractvalue { i8, i1 } [[TMP80]], 1, !dbg [[DBG70]]
// AARCH64-NEXT:    br i1 [[TMP82]], label [[ATOMIC_EXIT77:%.*]], label [[ATOMIC_CONT72]], !dbg [[DBG70]]
// AARCH64:       atomic_exit77:
// AARCH64-NEXT:    store i8 [[CONV76]], ptr @cv, align 1, !dbg [[DBG70]]
// AARCH64-NEXT:    [[TMP83:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG73:![0-9]+]]
// AARCH64-NEXT:    [[CONV78:%.*]] = sext i16 [[TMP83]] to i32, !dbg [[DBG73]]
// AARCH64-NEXT:    [[ATOMIC_LOAD79:%.*]] = load atomic i64, ptr @ulx monotonic, align 8, !dbg [[DBG74:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT80:%.*]], !dbg [[DBG74]]
// AARCH64:       atomic_cont80:
// AARCH64-NEXT:    [[TMP84:%.*]] = phi i64 [ [[ATOMIC_LOAD79]], [[ATOMIC_EXIT77]] ], [ [[TMP87:%.*]], [[ATOMIC_CONT80]] ], !dbg [[DBG74]]
// AARCH64-NEXT:    [[SH_PROM:%.*]] = trunc i64 [[TMP84]] to i32, !dbg [[DBG75:![0-9]+]]
// AARCH64-NEXT:    [[SHL82:%.*]] = shl i32 [[CONV78]], [[SH_PROM]], !dbg [[DBG75]]
// AARCH64-NEXT:    [[CONV83:%.*]] = sext i32 [[SHL82]] to i64, !dbg [[DBG73]]
// AARCH64-NEXT:    store i64 [[CONV83]], ptr [[ATOMIC_TEMP81]], align 8, !dbg [[DBG74]]
// AARCH64-NEXT:    [[TMP85:%.*]] = load i64, ptr [[ATOMIC_TEMP81]], align 8, !dbg [[DBG74]]
// AARCH64-NEXT:    [[TMP86:%.*]] = cmpxchg ptr @ulx, i64 [[TMP84]], i64 [[TMP85]] monotonic monotonic, align 8, !dbg [[DBG74]]
// AARCH64-NEXT:    [[TMP87]] = extractvalue { i64, i1 } [[TMP86]], 0, !dbg [[DBG74]]
// AARCH64-NEXT:    [[TMP88:%.*]] = extractvalue { i64, i1 } [[TMP86]], 1, !dbg [[DBG74]]
// AARCH64-NEXT:    br i1 [[TMP88]], label [[ATOMIC_EXIT84:%.*]], label [[ATOMIC_CONT80]], !dbg [[DBG74]]
// AARCH64:       atomic_exit84:
// AARCH64-NEXT:    store i64 [[CONV83]], ptr @ulv, align 8, !dbg [[DBG74]]
// AARCH64-NEXT:    [[TMP89:%.*]] = load i16, ptr @usv, align 2, !dbg [[DBG76:![0-9]+]]
// AARCH64-NEXT:    [[CONV85:%.*]] = zext i16 [[TMP89]] to i64, !dbg [[DBG76]]
// AARCH64-NEXT:    [[ATOMIC_LOAD86:%.*]] = load atomic i64, ptr @lx monotonic, align 8, !dbg [[DBG77:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT87:%.*]], !dbg [[DBG77]]
// AARCH64:       atomic_cont87:
// AARCH64-NEXT:    [[TMP90:%.*]] = phi i64 [ [[ATOMIC_LOAD86]], [[ATOMIC_EXIT84]] ], [ [[TMP93:%.*]], [[ATOMIC_CONT87]] ], !dbg [[DBG77]]
// AARCH64-NEXT:    [[REM:%.*]] = srem i64 [[TMP90]], [[CONV85]], !dbg [[DBG78:![0-9]+]]
// AARCH64-NEXT:    store i64 [[REM]], ptr [[ATOMIC_TEMP88]], align 8, !dbg [[DBG77]]
// AARCH64-NEXT:    [[TMP91:%.*]] = load i64, ptr [[ATOMIC_TEMP88]], align 8, !dbg [[DBG77]]
// AARCH64-NEXT:    [[TMP92:%.*]] = cmpxchg ptr @lx, i64 [[TMP90]], i64 [[TMP91]] monotonic monotonic, align 8, !dbg [[DBG77]]
// AARCH64-NEXT:    [[TMP93]] = extractvalue { i64, i1 } [[TMP92]], 0, !dbg [[DBG77]]
// AARCH64-NEXT:    [[TMP94:%.*]] = extractvalue { i64, i1 } [[TMP92]], 1, !dbg [[DBG77]]
// AARCH64-NEXT:    br i1 [[TMP94]], label [[ATOMIC_EXIT89:%.*]], label [[ATOMIC_CONT87]], !dbg [[DBG77]]
// AARCH64:       atomic_exit89:
// AARCH64-NEXT:    store i64 [[TMP90]], ptr @lv, align 8, !dbg [[DBG77]]
// AARCH64-NEXT:    [[TMP95:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG79:![0-9]+]]
// AARCH64-NEXT:    [[TMP96:%.*]] = atomicrmw or ptr @uix, i32 [[TMP95]] seq_cst, align 4, !dbg [[DBG80:![0-9]+]]
// AARCH64-NEXT:    [[OR90:%.*]] = or i32 [[TMP95]], [[TMP96]], !dbg [[DBG81:![0-9]+]]
// AARCH64-NEXT:    store i32 [[OR90]], ptr @uiv, align 4, !dbg [[DBG80]]
// AARCH64-NEXT:    [[TMP97:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG82:![0-9]+]]
// AARCH64-NEXT:    [[TMP98:%.*]] = atomicrmw and ptr @ix, i32 [[TMP97]] monotonic, align 4, !dbg [[DBG83:![0-9]+]]
// AARCH64-NEXT:    [[AND91:%.*]] = and i32 [[TMP98]], [[TMP97]], !dbg [[DBG84:![0-9]+]]
// AARCH64-NEXT:    store i32 [[AND91]], ptr @iv, align 4, !dbg [[DBG83]]
// AARCH64-NEXT:    [[TMP99:%.*]] = load i64, ptr @lv, align 8, !dbg [[DBG85:![0-9]+]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP92]], i32 noundef 0), !dbg [[DBG86:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT93:%.*]], !dbg [[DBG86]]
// AARCH64:       atomic_cont93:
// AARCH64-NEXT:    [[ATOMIC_TEMP92_REALP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP92]], i32 0, i32 0, !dbg [[DBG86]]
// AARCH64-NEXT:    [[ATOMIC_TEMP92_REAL:%.*]] = load i32, ptr [[ATOMIC_TEMP92_REALP]], align 4, !dbg [[DBG86]]
// AARCH64-NEXT:    [[ATOMIC_TEMP92_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP92]], i32 0, i32 1, !dbg [[DBG86]]
// AARCH64-NEXT:    [[ATOMIC_TEMP92_IMAG:%.*]] = load i32, ptr [[ATOMIC_TEMP92_IMAGP]], align 4, !dbg [[DBG86]]
// AARCH64-NEXT:    [[CONV95:%.*]] = sext i32 [[ATOMIC_TEMP92_REAL]] to i64, !dbg [[DBG87:![0-9]+]]
// AARCH64-NEXT:    [[CONV96:%.*]] = sext i32 [[ATOMIC_TEMP92_IMAG]] to i64, !dbg [[DBG87]]
// AARCH64-NEXT:    [[ADD_R97:%.*]] = add i64 [[TMP99]], [[CONV95]], !dbg [[DBG88:![0-9]+]]
// AARCH64-NEXT:    [[ADD_I98:%.*]] = add i64 0, [[CONV96]], !dbg [[DBG88]]
// AARCH64-NEXT:    [[CONV99:%.*]] = trunc i64 [[ADD_R97]] to i32, !dbg [[DBG85]]
// AARCH64-NEXT:    [[CONV100:%.*]] = trunc i64 [[ADD_I98]] to i32, !dbg [[DBG85]]
// AARCH64-NEXT:    [[ATOMIC_TEMP94_REALP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP94]], i32 0, i32 0, !dbg [[DBG86]]
// AARCH64-NEXT:    [[ATOMIC_TEMP94_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP94]], i32 0, i32 1, !dbg [[DBG86]]
// AARCH64-NEXT:    store i32 [[CONV99]], ptr [[ATOMIC_TEMP94_REALP]], align 4, !dbg [[DBG86]]
// AARCH64-NEXT:    store i32 [[CONV100]], ptr [[ATOMIC_TEMP94_IMAGP]], align 4, !dbg [[DBG86]]
// AARCH64-NEXT:    [[CALL101:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP92]], ptr noundef [[ATOMIC_TEMP94]], i32 noundef 0, i32 noundef 0), !dbg [[DBG86]]
// AARCH64-NEXT:    br i1 [[CALL101]], label [[ATOMIC_EXIT102:%.*]], label [[ATOMIC_CONT93]], !dbg [[DBG86]]
// AARCH64:       atomic_exit102:
// AARCH64-NEXT:    store i32 [[ATOMIC_TEMP92_REAL]], ptr @civ, align 4, !dbg [[DBG86]]
// AARCH64-NEXT:    store i32 [[ATOMIC_TEMP92_IMAG]], ptr getelementptr inbounds ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG86]]
// AARCH64-NEXT:    [[TMP100:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG89:![0-9]+]]
// AARCH64-NEXT:    [[CONV103:%.*]] = uitofp i64 [[TMP100]] to float, !dbg [[DBG89]]
// AARCH64-NEXT:    [[ATOMIC_LOAD104:%.*]] = load atomic i32, ptr @fx monotonic, align 4, !dbg [[DBG90:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT105:%.*]], !dbg [[DBG90]]
// AARCH64:       atomic_cont105:
// AARCH64-NEXT:    [[TMP101:%.*]] = phi i32 [ [[ATOMIC_LOAD104]], [[ATOMIC_EXIT102]] ], [ [[TMP105:%.*]], [[ATOMIC_CONT105]] ], !dbg [[DBG90]]
// AARCH64-NEXT:    [[TMP102:%.*]] = bitcast i32 [[TMP101]] to float, !dbg [[DBG90]]
// AARCH64-NEXT:    [[MUL107:%.*]] = fmul float [[TMP102]], [[CONV103]], !dbg [[DBG91:![0-9]+]]
// AARCH64-NEXT:    store float [[MUL107]], ptr [[ATOMIC_TEMP106]], align 4, !dbg [[DBG90]]
// AARCH64-NEXT:    [[TMP103:%.*]] = load i32, ptr [[ATOMIC_TEMP106]], align 4, !dbg [[DBG90]]
// AARCH64-NEXT:    [[TMP104:%.*]] = cmpxchg ptr @fx, i32 [[TMP101]], i32 [[TMP103]] monotonic monotonic, align 4, !dbg [[DBG90]]
// AARCH64-NEXT:    [[TMP105]] = extractvalue { i32, i1 } [[TMP104]], 0, !dbg [[DBG90]]
// AARCH64-NEXT:    [[TMP106:%.*]] = extractvalue { i32, i1 } [[TMP104]], 1, !dbg [[DBG90]]
// AARCH64-NEXT:    br i1 [[TMP106]], label [[ATOMIC_EXIT108:%.*]], label [[ATOMIC_CONT105]], !dbg [[DBG90]]
// AARCH64:       atomic_exit108:
// AARCH64-NEXT:    store float [[MUL107]], ptr @fv, align 4, !dbg [[DBG90]]
// AARCH64-NEXT:    [[TMP107:%.*]] = load i64, ptr @llv, align 8, !dbg [[DBG92:![0-9]+]]
// AARCH64-NEXT:    [[CONV109:%.*]] = sitofp i64 [[TMP107]] to double, !dbg [[DBG92]]
// AARCH64-NEXT:    [[ATOMIC_LOAD110:%.*]] = load atomic i64, ptr @dx monotonic, align 8, !dbg [[DBG93:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT111:%.*]], !dbg [[DBG93]]
// AARCH64:       atomic_cont111:
// AARCH64-NEXT:    [[TMP108:%.*]] = phi i64 [ [[ATOMIC_LOAD110]], [[ATOMIC_EXIT108]] ], [ [[TMP112:%.*]], [[ATOMIC_CONT111]] ], !dbg [[DBG93]]
// AARCH64-NEXT:    [[TMP109:%.*]] = bitcast i64 [[TMP108]] to double, !dbg [[DBG93]]
// AARCH64-NEXT:    [[DIV113:%.*]] = fdiv double [[TMP109]], [[CONV109]], !dbg [[DBG94:![0-9]+]]
// AARCH64-NEXT:    store double [[DIV113]], ptr [[ATOMIC_TEMP112]], align 8, !dbg [[DBG93]]
// AARCH64-NEXT:    [[TMP110:%.*]] = load i64, ptr [[ATOMIC_TEMP112]], align 8, !dbg [[DBG93]]
// AARCH64-NEXT:    [[TMP111:%.*]] = cmpxchg ptr @dx, i64 [[TMP108]], i64 [[TMP110]] monotonic monotonic, align 8, !dbg [[DBG93]]
// AARCH64-NEXT:    [[TMP112]] = extractvalue { i64, i1 } [[TMP111]], 0, !dbg [[DBG93]]
// AARCH64-NEXT:    [[TMP113:%.*]] = extractvalue { i64, i1 } [[TMP111]], 1, !dbg [[DBG93]]
// AARCH64-NEXT:    br i1 [[TMP113]], label [[ATOMIC_EXIT114:%.*]], label [[ATOMIC_CONT111]], !dbg [[DBG93]]
// AARCH64:       atomic_exit114:
// AARCH64-NEXT:    store double [[DIV113]], ptr @dv, align 8, !dbg [[DBG93]]
// AARCH64-NEXT:    [[TMP114:%.*]] = load i64, ptr @ullv, align 8, !dbg [[DBG95:![0-9]+]]
// AARCH64-NEXT:    [[CONV115:%.*]] = uitofp i64 [[TMP114]] to fp128, !dbg [[DBG95]]
// AARCH64-NEXT:    [[TMP115:%.*]] = atomicrmw fsub ptr @ldx, fp128 [[CONV115]] monotonic, align 16, !dbg [[DBG96:![0-9]+]]
// AARCH64-NEXT:    store fp128 [[TMP115]], ptr @ldv, align 16, !dbg [[DBG96]]
// AARCH64-NEXT:    [[TMP116:%.*]] = load float, ptr @fv, align 4, !dbg [[DBG97:![0-9]+]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP116]], i32 noundef 0), !dbg [[DBG98:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT117:%.*]], !dbg [[DBG98]]
// AARCH64:       atomic_cont117:
// AARCH64-NEXT:    [[ATOMIC_TEMP116_REALP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP116]], i32 0, i32 0, !dbg [[DBG98]]
// AARCH64-NEXT:    [[ATOMIC_TEMP116_REAL:%.*]] = load i32, ptr [[ATOMIC_TEMP116_REALP]], align 4, !dbg [[DBG98]]
// AARCH64-NEXT:    [[ATOMIC_TEMP116_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP116]], i32 0, i32 1, !dbg [[DBG98]]
// AARCH64-NEXT:    [[ATOMIC_TEMP116_IMAG:%.*]] = load i32, ptr [[ATOMIC_TEMP116_IMAGP]], align 4, !dbg [[DBG98]]
// AARCH64-NEXT:    [[CONV119:%.*]] = sitofp i32 [[ATOMIC_TEMP116_REAL]] to float, !dbg [[DBG99:![0-9]+]]
// AARCH64-NEXT:    [[CONV120:%.*]] = sitofp i32 [[ATOMIC_TEMP116_IMAG]] to float, !dbg [[DBG99]]
// AARCH64-NEXT:    [[CALL121:%.*]] = call { float, float } @__divsc3(float noundef [[TMP116]], float noundef 0.000000e+00, float noundef [[CONV119]], float noundef [[CONV120]]) #[[ATTR2:[0-9]+]], !dbg [[DBG100:![0-9]+]]
// AARCH64-NEXT:    [[TMP117:%.*]] = extractvalue { float, float } [[CALL121]], 0, !dbg [[DBG100]]
// AARCH64-NEXT:    [[TMP118:%.*]] = extractvalue { float, float } [[CALL121]], 1, !dbg [[DBG100]]
// AARCH64-NEXT:    [[CONV122:%.*]] = fptosi float [[TMP117]] to i32, !dbg [[DBG97]]
// AARCH64-NEXT:    [[CONV123:%.*]] = fptosi float [[TMP118]] to i32, !dbg [[DBG97]]
// AARCH64-NEXT:    [[ATOMIC_TEMP118_REALP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP118]], i32 0, i32 0, !dbg [[DBG98]]
// AARCH64-NEXT:    [[ATOMIC_TEMP118_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP118]], i32 0, i32 1, !dbg [[DBG98]]
// AARCH64-NEXT:    store i32 [[CONV122]], ptr [[ATOMIC_TEMP118_REALP]], align 4, !dbg [[DBG98]]
// AARCH64-NEXT:    store i32 [[CONV123]], ptr [[ATOMIC_TEMP118_IMAGP]], align 4, !dbg [[DBG98]]
// AARCH64-NEXT:    [[CALL124:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP116]], ptr noundef [[ATOMIC_TEMP118]], i32 noundef 0, i32 noundef 0), !dbg [[DBG98]]
// AARCH64-NEXT:    br i1 [[CALL124]], label [[ATOMIC_EXIT125:%.*]], label [[ATOMIC_CONT117]], !dbg [[DBG98]]
// AARCH64:       atomic_exit125:
// AARCH64-NEXT:    store i32 [[CONV122]], ptr @civ, align 4, !dbg [[DBG98]]
// AARCH64-NEXT:    store i32 [[CONV123]], ptr getelementptr inbounds ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG98]]
// AARCH64-NEXT:    [[TMP119:%.*]] = load double, ptr @dv, align 8, !dbg [[DBG101:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD126:%.*]] = load atomic i16, ptr @sx monotonic, align 2, !dbg [[DBG102:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT127:%.*]], !dbg [[DBG102]]
// AARCH64:       atomic_cont127:
// AARCH64-NEXT:    [[TMP120:%.*]] = phi i16 [ [[ATOMIC_LOAD126]], [[ATOMIC_EXIT125]] ], [ [[TMP123:%.*]], [[ATOMIC_CONT127]] ], !dbg [[DBG102]]
// AARCH64-NEXT:    [[CONV129:%.*]] = sext i16 [[TMP120]] to i32, !dbg [[DBG103:![0-9]+]]
// AARCH64-NEXT:    [[CONV130:%.*]] = sitofp i32 [[CONV129]] to double, !dbg [[DBG103]]
// AARCH64-NEXT:    [[ADD131:%.*]] = fadd double [[CONV130]], [[TMP119]], !dbg [[DBG104:![0-9]+]]
// AARCH64-NEXT:    [[CONV132:%.*]] = fptosi double [[ADD131]] to i16, !dbg [[DBG103]]
// AARCH64-NEXT:    store i16 [[CONV132]], ptr [[ATOMIC_TEMP128]], align 2, !dbg [[DBG102]]
// AARCH64-NEXT:    [[TMP121:%.*]] = load i16, ptr [[ATOMIC_TEMP128]], align 2, !dbg [[DBG102]]
// AARCH64-NEXT:    [[TMP122:%.*]] = cmpxchg ptr @sx, i16 [[TMP120]], i16 [[TMP121]] monotonic monotonic, align 2, !dbg [[DBG102]]
// AARCH64-NEXT:    [[TMP123]] = extractvalue { i16, i1 } [[TMP122]], 0, !dbg [[DBG102]]
// AARCH64-NEXT:    [[TMP124:%.*]] = extractvalue { i16, i1 } [[TMP122]], 1, !dbg [[DBG102]]
// AARCH64-NEXT:    br i1 [[TMP124]], label [[ATOMIC_EXIT133:%.*]], label [[ATOMIC_CONT127]], !dbg [[DBG102]]
// AARCH64:       atomic_exit133:
// AARCH64-NEXT:    store i16 [[CONV132]], ptr @sv, align 2, !dbg [[DBG102]]
// AARCH64-NEXT:    [[TMP125:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG105:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD134:%.*]] = load atomic i8, ptr @bx monotonic, align 1, !dbg [[DBG106:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT135:%.*]], !dbg [[DBG106]]
// AARCH64:       atomic_cont135:
// AARCH64-NEXT:    [[TMP126:%.*]] = phi i8 [ [[ATOMIC_LOAD134]], [[ATOMIC_EXIT133]] ], [ [[TMP129:%.*]], [[ATOMIC_CONT135]] ], !dbg [[DBG106]]
// AARCH64-NEXT:    [[TOBOOL137:%.*]] = trunc i8 [[TMP126]] to i1, !dbg [[DBG106]]
// AARCH64-NEXT:    [[CONV138:%.*]] = zext i1 [[TOBOOL137]] to i32, !dbg [[DBG107:![0-9]+]]
// AARCH64-NEXT:    [[CONV139:%.*]] = sitofp i32 [[CONV138]] to fp128, !dbg [[DBG107]]
// AARCH64-NEXT:    [[MUL140:%.*]] = fmul fp128 [[TMP125]], [[CONV139]], !dbg [[DBG108:![0-9]+]]
// AARCH64-NEXT:    [[TOBOOL141:%.*]] = fcmp une fp128 [[MUL140]], 0xL00000000000000000000000000000000, !dbg [[DBG105]]
// AARCH64-NEXT:    [[FROMBOOL142:%.*]] = zext i1 [[TOBOOL141]] to i8, !dbg [[DBG106]]
// AARCH64-NEXT:    store i8 [[FROMBOOL142]], ptr [[ATOMIC_TEMP136]], align 1, !dbg [[DBG106]]
// AARCH64-NEXT:    [[TMP127:%.*]] = load i8, ptr [[ATOMIC_TEMP136]], align 1, !dbg [[DBG106]]
// AARCH64-NEXT:    [[TMP128:%.*]] = cmpxchg ptr @bx, i8 [[TMP126]], i8 [[TMP127]] monotonic monotonic, align 1, !dbg [[DBG106]]
// AARCH64-NEXT:    [[TMP129]] = extractvalue { i8, i1 } [[TMP128]], 0, !dbg [[DBG106]]
// AARCH64-NEXT:    [[TMP130:%.*]] = extractvalue { i8, i1 } [[TMP128]], 1, !dbg [[DBG106]]
// AARCH64-NEXT:    br i1 [[TMP130]], label [[ATOMIC_EXIT143:%.*]], label [[ATOMIC_CONT135]], !dbg [[DBG106]]
// AARCH64:       atomic_exit143:
// AARCH64-NEXT:    [[FROMBOOL144:%.*]] = zext i1 [[TOBOOL137]] to i8, !dbg [[DBG106]]
// AARCH64-NEXT:    store i8 [[FROMBOOL144]], ptr @bv, align 1, !dbg [[DBG106]]
// AARCH64-NEXT:    [[CIV_REAL145:%.*]] = load i32, ptr @civ, align 4, !dbg [[DBG109:![0-9]+]]
// AARCH64-NEXT:    [[CIV_IMAG146:%.*]] = load i32, ptr getelementptr inbounds ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG109]]
// AARCH64-NEXT:    [[ATOMIC_LOAD147:%.*]] = load atomic i8, ptr @bx monotonic, align 1, !dbg [[DBG110:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT148:%.*]], !dbg [[DBG110]]
// AARCH64:       atomic_cont148:
// AARCH64-NEXT:    [[TMP131:%.*]] = phi i8 [ [[ATOMIC_LOAD147]], [[ATOMIC_EXIT143]] ], [ [[TMP134:%.*]], [[ATOMIC_CONT148]] ], !dbg [[DBG110]]
// AARCH64-NEXT:    [[TOBOOL150:%.*]] = trunc i8 [[TMP131]] to i1, !dbg [[DBG110]]
// AARCH64-NEXT:    [[CONV151:%.*]] = zext i1 [[TOBOOL150]] to i32, !dbg [[DBG111:![0-9]+]]
// AARCH64-NEXT:    [[SUB_R152:%.*]] = sub i32 [[CIV_REAL145]], [[CONV151]], !dbg [[DBG112:![0-9]+]]
// AARCH64-NEXT:    [[SUB_I153:%.*]] = sub i32 [[CIV_IMAG146]], 0, !dbg [[DBG112]]
// AARCH64-NEXT:    [[TOBOOL154:%.*]] = icmp ne i32 [[SUB_R152]], 0, !dbg [[DBG109]]
// AARCH64-NEXT:    [[TOBOOL155:%.*]] = icmp ne i32 [[SUB_I153]], 0, !dbg [[DBG109]]
// AARCH64-NEXT:    [[TOBOOL156:%.*]] = or i1 [[TOBOOL154]], [[TOBOOL155]], !dbg [[DBG109]]
// AARCH64-NEXT:    [[FROMBOOL157:%.*]] = zext i1 [[TOBOOL156]] to i8, !dbg [[DBG110]]
// AARCH64-NEXT:    store i8 [[FROMBOOL157]], ptr [[ATOMIC_TEMP149]], align 1, !dbg [[DBG110]]
// AARCH64-NEXT:    [[TMP132:%.*]] = load i8, ptr [[ATOMIC_TEMP149]], align 1, !dbg [[DBG110]]
// AARCH64-NEXT:    [[TMP133:%.*]] = cmpxchg ptr @bx, i8 [[TMP131]], i8 [[TMP132]] monotonic monotonic, align 1, !dbg [[DBG110]]
// AARCH64-NEXT:    [[TMP134]] = extractvalue { i8, i1 } [[TMP133]], 0, !dbg [[DBG110]]
// AARCH64-NEXT:    [[TMP135:%.*]] = extractvalue { i8, i1 } [[TMP133]], 1, !dbg [[DBG110]]
// AARCH64-NEXT:    br i1 [[TMP135]], label [[ATOMIC_EXIT158:%.*]], label [[ATOMIC_CONT148]], !dbg [[DBG110]]
// AARCH64:       atomic_exit158:
// AARCH64-NEXT:    [[FROMBOOL159:%.*]] = zext i1 [[TOBOOL156]] to i8, !dbg [[DBG110]]
// AARCH64-NEXT:    store i8 [[FROMBOOL159]], ptr @bv, align 1, !dbg [[DBG110]]
// AARCH64-NEXT:    [[TMP136:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG113:![0-9]+]]
// AARCH64-NEXT:    [[TMP137:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG114:![0-9]+]]
// AARCH64-NEXT:    [[TOBOOL160:%.*]] = trunc i8 [[TMP137]] to i1, !dbg [[DBG114]]
// AARCH64-NEXT:    [[CONV161:%.*]] = zext i1 [[TOBOOL160]] to i32, !dbg [[DBG114]]
// AARCH64-NEXT:    [[ATOMIC_LOAD162:%.*]] = load atomic i128, ptr @int4x monotonic, align 16, !dbg [[DBG115:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT163:%.*]], !dbg [[DBG115]]
// AARCH64:       atomic_cont163:
// AARCH64-NEXT:    [[TMP138:%.*]] = phi i128 [ [[ATOMIC_LOAD162]], [[ATOMIC_EXIT158]] ], [ [[TMP144:%.*]], [[ATOMIC_CONT163]] ], !dbg [[DBG115]]
// AARCH64-NEXT:    store i128 [[TMP138]], ptr [[ATOMIC_TEMP164]], align 16, !dbg [[DBG115]]
// AARCH64-NEXT:    [[TMP139:%.*]] = bitcast i128 [[TMP138]] to <4 x i32>, !dbg [[DBG115]]
// AARCH64-NEXT:    store <4 x i32> [[TMP139]], ptr [[ATOMIC_TEMP165]], align 16, !dbg [[DBG115]]
// AARCH64-NEXT:    [[TMP140:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP165]], align 16, !dbg [[DBG115]]
// AARCH64-NEXT:    [[VECEXT:%.*]] = extractelement <4 x i32> [[TMP140]], i16 [[TMP136]], !dbg [[DBG115]]
// AARCH64-NEXT:    [[OR166:%.*]] = or i32 [[VECEXT]], [[CONV161]], !dbg [[DBG116:![0-9]+]]
// AARCH64-NEXT:    [[TMP141:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP164]], align 16, !dbg [[DBG115]]
// AARCH64-NEXT:    [[VECINS:%.*]] = insertelement <4 x i32> [[TMP141]], i32 [[OR166]], i16 [[TMP136]], !dbg [[DBG115]]
// AARCH64-NEXT:    store <4 x i32> [[VECINS]], ptr [[ATOMIC_TEMP164]], align 16, !dbg [[DBG115]]
// AARCH64-NEXT:    [[TMP142:%.*]] = load i128, ptr [[ATOMIC_TEMP164]], align 16, !dbg [[DBG115]]
// AARCH64-NEXT:    [[TMP143:%.*]] = cmpxchg ptr @int4x, i128 [[TMP138]], i128 [[TMP142]] monotonic monotonic, align 16, !dbg [[DBG115]]
// AARCH64-NEXT:    [[TMP144]] = extractvalue { i128, i1 } [[TMP143]], 0, !dbg [[DBG115]]
// AARCH64-NEXT:    [[TMP145:%.*]] = extractvalue { i128, i1 } [[TMP143]], 1, !dbg [[DBG115]]
// AARCH64-NEXT:    br i1 [[TMP145]], label [[ATOMIC_EXIT167:%.*]], label [[ATOMIC_CONT163]], !dbg [[DBG115]]
// AARCH64:       atomic_exit167:
// AARCH64-NEXT:    store i32 [[OR166]], ptr @iv, align 4, !dbg [[DBG115]]
// AARCH64-NEXT:    [[TMP146:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG117:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD168:%.*]] = load atomic i32, ptr getelementptr (i8, ptr @bfx, i64 4) monotonic, align 4, !dbg [[DBG118:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT169:%.*]], !dbg [[DBG118]]
// AARCH64:       atomic_cont169:
// AARCH64-NEXT:    [[TMP147:%.*]] = phi i32 [ [[ATOMIC_LOAD168]], [[ATOMIC_EXIT167]] ], [ [[TMP150:%.*]], [[ATOMIC_CONT169]] ], !dbg [[DBG118]]
// AARCH64-NEXT:    store i32 [[TMP147]], ptr [[ATOMIC_TEMP170]], align 4, !dbg [[DBG118]]
// AARCH64-NEXT:    store i32 [[TMP147]], ptr [[ATOMIC_TEMP171]], align 4, !dbg [[DBG118]]
// AARCH64-NEXT:    [[BF_LOAD:%.*]] = load i32, ptr [[ATOMIC_TEMP171]], align 4, !dbg [[DBG118]]
// AARCH64-NEXT:    [[BF_SHL:%.*]] = shl i32 [[BF_LOAD]], 1, !dbg [[DBG118]]
// AARCH64-NEXT:    [[BF_ASHR:%.*]] = ashr i32 [[BF_SHL]], 1, !dbg [[DBG118]]
// AARCH64-NEXT:    [[CONV172:%.*]] = sitofp i32 [[BF_ASHR]] to fp128, !dbg [[DBG119:![0-9]+]]
// AARCH64-NEXT:    [[SUB173:%.*]] = fsub fp128 [[CONV172]], [[TMP146]], !dbg [[DBG120:![0-9]+]]
// AARCH64-NEXT:    [[CONV174:%.*]] = fptosi fp128 [[SUB173]] to i32, !dbg [[DBG119]]
// AARCH64-NEXT:    [[BF_LOAD175:%.*]] = load i32, ptr [[ATOMIC_TEMP170]], align 4, !dbg [[DBG118]]
// AARCH64-NEXT:    [[BF_VALUE:%.*]] = and i32 [[CONV174]], 2147483647, !dbg [[DBG118]]
// AARCH64-NEXT:    [[BF_CLEAR:%.*]] = and i32 [[BF_LOAD175]], -2147483648, !dbg [[DBG118]]
// AARCH64-NEXT:    [[BF_SET:%.*]] = or i32 [[BF_CLEAR]], [[BF_VALUE]], !dbg [[DBG118]]
// AARCH64-NEXT:    store i32 [[BF_SET]], ptr [[ATOMIC_TEMP170]], align 4, !dbg [[DBG118]]
// AARCH64-NEXT:    [[TMP148:%.*]] = load i32, ptr [[ATOMIC_TEMP170]], align 4, !dbg [[DBG118]]
// AARCH64-NEXT:    [[TMP149:%.*]] = cmpxchg ptr getelementptr (i8, ptr @bfx, i64 4), i32 [[TMP147]], i32 [[TMP148]] monotonic monotonic, align 4, !dbg [[DBG118]]
// AARCH64-NEXT:    [[TMP150]] = extractvalue { i32, i1 } [[TMP149]], 0, !dbg [[DBG118]]
// AARCH64-NEXT:    [[TMP151:%.*]] = extractvalue { i32, i1 } [[TMP149]], 1, !dbg [[DBG118]]
// AARCH64-NEXT:    br i1 [[TMP151]], label [[ATOMIC_EXIT176:%.*]], label [[ATOMIC_CONT169]], !dbg [[DBG118]]
// AARCH64:       atomic_exit176:
// AARCH64-NEXT:    store i32 [[CONV174]], ptr @iv, align 4, !dbg [[DBG118]]
// AARCH64-NEXT:    [[TMP152:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG121:![0-9]+]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 4, ptr noundef getelementptr (i8, ptr @bfx_packed, i64 4), ptr noundef [[ATOMIC_TEMP177]], i32 noundef 0), !dbg [[DBG122:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT178:%.*]], !dbg [[DBG122]]
// AARCH64:       atomic_cont178:
// AARCH64-NEXT:    [[TMP153:%.*]] = load i32, ptr [[ATOMIC_TEMP177]], align 1, !dbg [[DBG122]]
// AARCH64-NEXT:    store i32 [[TMP153]], ptr [[ATOMIC_TEMP179]], align 1, !dbg [[DBG122]]
// AARCH64-NEXT:    [[TMP154:%.*]] = load i32, ptr [[ATOMIC_TEMP177]], align 1, !dbg [[DBG122]]
// AARCH64-NEXT:    store i32 [[TMP154]], ptr [[ATOMIC_TEMP180]], align 4, !dbg [[DBG122]]
// AARCH64-NEXT:    [[BF_LOAD181:%.*]] = load i32, ptr [[ATOMIC_TEMP180]], align 1, !dbg [[DBG122]]
// AARCH64-NEXT:    [[BF_SHL182:%.*]] = shl i32 [[BF_LOAD181]], 1, !dbg [[DBG122]]
// AARCH64-NEXT:    [[BF_ASHR183:%.*]] = ashr i32 [[BF_SHL182]], 1, !dbg [[DBG122]]
// AARCH64-NEXT:    [[CONV184:%.*]] = sitofp i32 [[BF_ASHR183]] to fp128, !dbg [[DBG123:![0-9]+]]
// AARCH64-NEXT:    [[MUL185:%.*]] = fmul fp128 [[CONV184]], [[TMP152]], !dbg [[DBG124:![0-9]+]]
// AARCH64-NEXT:    [[CONV186:%.*]] = fptosi fp128 [[MUL185]] to i32, !dbg [[DBG123]]
// AARCH64-NEXT:    [[BF_LOAD187:%.*]] = load i32, ptr [[ATOMIC_TEMP179]], align 1, !dbg [[DBG122]]
// AARCH64-NEXT:    [[BF_VALUE188:%.*]] = and i32 [[CONV186]], 2147483647, !dbg [[DBG122]]
// AARCH64-NEXT:    [[BF_CLEAR189:%.*]] = and i32 [[BF_LOAD187]], -2147483648, !dbg [[DBG122]]
// AARCH64-NEXT:    [[BF_SET190:%.*]] = or i32 [[BF_CLEAR189]], [[BF_VALUE188]], !dbg [[DBG122]]
// AARCH64-NEXT:    store i32 [[BF_SET190]], ptr [[ATOMIC_TEMP179]], align 1, !dbg [[DBG122]]
// AARCH64-NEXT:    [[CALL191:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 4, ptr noundef getelementptr (i8, ptr @bfx_packed, i64 4), ptr noundef [[ATOMIC_TEMP177]], ptr noundef [[ATOMIC_TEMP179]], i32 noundef 0, i32 noundef 0), !dbg [[DBG122]]
// AARCH64-NEXT:    br i1 [[CALL191]], label [[ATOMIC_EXIT192:%.*]], label [[ATOMIC_CONT178]], !dbg [[DBG122]]
// AARCH64:       atomic_exit192:
// AARCH64-NEXT:    store i32 [[BF_ASHR183]], ptr @iv, align 4, !dbg [[DBG122]]
// AARCH64-NEXT:    [[TMP155:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG125:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD193:%.*]] = load atomic i32, ptr @bfx2 monotonic, align 4, !dbg [[DBG126:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT194:%.*]], !dbg [[DBG126]]
// AARCH64:       atomic_cont194:
// AARCH64-NEXT:    [[TMP156:%.*]] = phi i32 [ [[ATOMIC_LOAD193]], [[ATOMIC_EXIT192]] ], [ [[TMP159:%.*]], [[ATOMIC_CONT194]] ], !dbg [[DBG126]]
// AARCH64-NEXT:    store i32 [[TMP156]], ptr [[ATOMIC_TEMP195]], align 4, !dbg [[DBG126]]
// AARCH64-NEXT:    store i32 [[TMP156]], ptr [[ATOMIC_TEMP196]], align 4, !dbg [[DBG126]]
// AARCH64-NEXT:    [[BF_LOAD197:%.*]] = load i32, ptr [[ATOMIC_TEMP196]], align 4, !dbg [[DBG126]]
// AARCH64-NEXT:    [[BF_ASHR198:%.*]] = ashr i32 [[BF_LOAD197]], 31, !dbg [[DBG126]]
// AARCH64-NEXT:    [[CONV199:%.*]] = sitofp i32 [[BF_ASHR198]] to fp128, !dbg [[DBG127:![0-9]+]]
// AARCH64-NEXT:    [[SUB200:%.*]] = fsub fp128 [[CONV199]], [[TMP155]], !dbg [[DBG128:![0-9]+]]
// AARCH64-NEXT:    [[CONV201:%.*]] = fptosi fp128 [[SUB200]] to i32, !dbg [[DBG127]]
// AARCH64-NEXT:    [[BF_LOAD202:%.*]] = load i32, ptr [[ATOMIC_TEMP195]], align 4, !dbg [[DBG126]]
// AARCH64-NEXT:    [[BF_VALUE203:%.*]] = and i32 [[CONV201]], 1, !dbg [[DBG126]]
// AARCH64-NEXT:    [[BF_SHL204:%.*]] = shl i32 [[BF_VALUE203]], 31, !dbg [[DBG126]]
// AARCH64-NEXT:    [[BF_CLEAR205:%.*]] = and i32 [[BF_LOAD202]], 2147483647, !dbg [[DBG126]]
// AARCH64-NEXT:    [[BF_SET206:%.*]] = or i32 [[BF_CLEAR205]], [[BF_SHL204]], !dbg [[DBG126]]
// AARCH64-NEXT:    store i32 [[BF_SET206]], ptr [[ATOMIC_TEMP195]], align 4, !dbg [[DBG126]]
// AARCH64-NEXT:    [[TMP157:%.*]] = load i32, ptr [[ATOMIC_TEMP195]], align 4, !dbg [[DBG126]]
// AARCH64-NEXT:    [[TMP158:%.*]] = cmpxchg ptr @bfx2, i32 [[TMP156]], i32 [[TMP157]] monotonic monotonic, align 4, !dbg [[DBG126]]
// AARCH64-NEXT:    [[TMP159]] = extractvalue { i32, i1 } [[TMP158]], 0, !dbg [[DBG126]]
// AARCH64-NEXT:    [[TMP160:%.*]] = extractvalue { i32, i1 } [[TMP158]], 1, !dbg [[DBG126]]
// AARCH64-NEXT:    br i1 [[TMP160]], label [[ATOMIC_EXIT207:%.*]], label [[ATOMIC_CONT194]], !dbg [[DBG126]]
// AARCH64:       atomic_exit207:
// AARCH64-NEXT:    store i32 [[CONV201]], ptr @iv, align 4, !dbg [[DBG126]]
// AARCH64-NEXT:    [[TMP161:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG129:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD208:%.*]] = load atomic i8, ptr getelementptr (i8, ptr @bfx2_packed, i64 3) monotonic, align 1, !dbg [[DBG130:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT209:%.*]], !dbg [[DBG130]]
// AARCH64:       atomic_cont209:
// AARCH64-NEXT:    [[TMP162:%.*]] = phi i8 [ [[ATOMIC_LOAD208]], [[ATOMIC_EXIT207]] ], [ [[TMP166:%.*]], [[ATOMIC_CONT209]] ], !dbg [[DBG130]]
// AARCH64-NEXT:    store i8 [[TMP162]], ptr [[ATOMIC_TEMP210]], align 1, !dbg [[DBG130]]
// AARCH64-NEXT:    store i8 [[TMP162]], ptr [[ATOMIC_TEMP211]], align 1, !dbg [[DBG130]]
// AARCH64-NEXT:    [[BF_LOAD212:%.*]] = load i8, ptr [[ATOMIC_TEMP211]], align 1, !dbg [[DBG130]]
// AARCH64-NEXT:    [[BF_ASHR213:%.*]] = ashr i8 [[BF_LOAD212]], 7, !dbg [[DBG130]]
// AARCH64-NEXT:    [[BF_CAST:%.*]] = sext i8 [[BF_ASHR213]] to i32, !dbg [[DBG130]]
// AARCH64-NEXT:    [[CONV214:%.*]] = sitofp i32 [[BF_CAST]] to fp128, !dbg [[DBG131:![0-9]+]]
// AARCH64-NEXT:    [[DIV215:%.*]] = fdiv fp128 [[TMP161]], [[CONV214]], !dbg [[DBG132:![0-9]+]]
// AARCH64-NEXT:    [[CONV216:%.*]] = fptosi fp128 [[DIV215]] to i32, !dbg [[DBG129]]
// AARCH64-NEXT:    [[TMP163:%.*]] = trunc i32 [[CONV216]] to i8, !dbg [[DBG130]]
// AARCH64-NEXT:    [[BF_LOAD217:%.*]] = load i8, ptr [[ATOMIC_TEMP210]], align 1, !dbg [[DBG130]]
// AARCH64-NEXT:    [[BF_VALUE218:%.*]] = and i8 [[TMP163]], 1, !dbg [[DBG130]]
// AARCH64-NEXT:    [[BF_SHL219:%.*]] = shl i8 [[BF_VALUE218]], 7, !dbg [[DBG130]]
// AARCH64-NEXT:    [[BF_CLEAR220:%.*]] = and i8 [[BF_LOAD217]], 127, !dbg [[DBG130]]
// AARCH64-NEXT:    [[BF_SET221:%.*]] = or i8 [[BF_CLEAR220]], [[BF_SHL219]], !dbg [[DBG130]]
// AARCH64-NEXT:    store i8 [[BF_SET221]], ptr [[ATOMIC_TEMP210]], align 1, !dbg [[DBG130]]
// AARCH64-NEXT:    [[TMP164:%.*]] = load i8, ptr [[ATOMIC_TEMP210]], align 1, !dbg [[DBG130]]
// AARCH64-NEXT:    [[TMP165:%.*]] = cmpxchg ptr getelementptr (i8, ptr @bfx2_packed, i64 3), i8 [[TMP162]], i8 [[TMP164]] monotonic monotonic, align 1, !dbg [[DBG130]]
// AARCH64-NEXT:    [[TMP166]] = extractvalue { i8, i1 } [[TMP165]], 0, !dbg [[DBG130]]
// AARCH64-NEXT:    [[TMP167:%.*]] = extractvalue { i8, i1 } [[TMP165]], 1, !dbg [[DBG130]]
// AARCH64-NEXT:    br i1 [[TMP167]], label [[ATOMIC_EXIT222:%.*]], label [[ATOMIC_CONT209]], !dbg [[DBG130]]
// AARCH64:       atomic_exit222:
// AARCH64-NEXT:    store i32 [[CONV216]], ptr @iv, align 4, !dbg [[DBG130]]
// AARCH64-NEXT:    [[TMP168:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG133:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD223:%.*]] = load atomic i32, ptr @bfx3 monotonic, align 4, !dbg [[DBG134:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT224:%.*]], !dbg [[DBG134]]
// AARCH64:       atomic_cont224:
// AARCH64-NEXT:    [[TMP169:%.*]] = phi i32 [ [[ATOMIC_LOAD223]], [[ATOMIC_EXIT222]] ], [ [[TMP172:%.*]], [[ATOMIC_CONT224]] ], !dbg [[DBG134]]
// AARCH64-NEXT:    store i32 [[TMP169]], ptr [[ATOMIC_TEMP225]], align 4, !dbg [[DBG134]]
// AARCH64-NEXT:    store i32 [[TMP169]], ptr [[ATOMIC_TEMP226]], align 4, !dbg [[DBG134]]
// AARCH64-NEXT:    [[BF_LOAD227:%.*]] = load i32, ptr [[ATOMIC_TEMP226]], align 4, !dbg [[DBG134]]
// AARCH64-NEXT:    [[BF_SHL228:%.*]] = shl i32 [[BF_LOAD227]], 7, !dbg [[DBG134]]
// AARCH64-NEXT:    [[BF_ASHR229:%.*]] = ashr i32 [[BF_SHL228]], 18, !dbg [[DBG134]]
// AARCH64-NEXT:    [[CONV230:%.*]] = sitofp i32 [[BF_ASHR229]] to fp128, !dbg [[DBG135:![0-9]+]]
// AARCH64-NEXT:    [[DIV231:%.*]] = fdiv fp128 [[CONV230]], [[TMP168]], !dbg [[DBG136:![0-9]+]]
// AARCH64-NEXT:    [[CONV232:%.*]] = fptosi fp128 [[DIV231]] to i32, !dbg [[DBG135]]
// AARCH64-NEXT:    [[BF_LOAD233:%.*]] = load i32, ptr [[ATOMIC_TEMP225]], align 4, !dbg [[DBG134]]
// AARCH64-NEXT:    [[BF_VALUE234:%.*]] = and i32 [[CONV232]], 16383, !dbg [[DBG134]]
// AARCH64-NEXT:    [[BF_SHL235:%.*]] = shl i32 [[BF_VALUE234]], 11, !dbg [[DBG134]]
// AARCH64-NEXT:    [[BF_CLEAR236:%.*]] = and i32 [[BF_LOAD233]], -33552385, !dbg [[DBG134]]
// AARCH64-NEXT:    [[BF_SET237:%.*]] = or i32 [[BF_CLEAR236]], [[BF_SHL235]], !dbg [[DBG134]]
// AARCH64-NEXT:    store i32 [[BF_SET237]], ptr [[ATOMIC_TEMP225]], align 4, !dbg [[DBG134]]
// AARCH64-NEXT:    [[TMP170:%.*]] = load i32, ptr [[ATOMIC_TEMP225]], align 4, !dbg [[DBG134]]
// AARCH64-NEXT:    [[TMP171:%.*]] = cmpxchg ptr @bfx3, i32 [[TMP169]], i32 [[TMP170]] monotonic monotonic, align 4, !dbg [[DBG134]]
// AARCH64-NEXT:    [[TMP172]] = extractvalue { i32, i1 } [[TMP171]], 0, !dbg [[DBG134]]
// AARCH64-NEXT:    [[TMP173:%.*]] = extractvalue { i32, i1 } [[TMP171]], 1, !dbg [[DBG134]]
// AARCH64-NEXT:    br i1 [[TMP173]], label [[ATOMIC_EXIT238:%.*]], label [[ATOMIC_CONT224]], !dbg [[DBG134]]
// AARCH64:       atomic_exit238:
// AARCH64-NEXT:    store i32 [[BF_ASHR229]], ptr @iv, align 4, !dbg [[DBG134]]
// AARCH64-NEXT:    [[TMP174:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG137:![0-9]+]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 3, ptr noundef getelementptr (i8, ptr @bfx3_packed, i64 1), ptr noundef [[ATOMIC_TEMP239]], i32 noundef 0), !dbg [[DBG138:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT240:%.*]], !dbg [[DBG138]]
// AARCH64:       atomic_cont240:
// AARCH64-NEXT:    [[TMP175:%.*]] = load i24, ptr [[ATOMIC_TEMP239]], align 1, !dbg [[DBG138]]
// AARCH64-NEXT:    store i24 [[TMP175]], ptr [[ATOMIC_TEMP241]], align 1, !dbg [[DBG138]]
// AARCH64-NEXT:    [[TMP176:%.*]] = load i24, ptr [[ATOMIC_TEMP239]], align 1, !dbg [[DBG138]]
// AARCH64-NEXT:    store i24 [[TMP176]], ptr [[ATOMIC_TEMP242]], align 1, !dbg [[DBG138]]
// AARCH64-NEXT:    [[BF_LOAD243:%.*]] = load i24, ptr [[ATOMIC_TEMP242]], align 1, !dbg [[DBG138]]
// AARCH64-NEXT:    [[BF_SHL244:%.*]] = shl i24 [[BF_LOAD243]], 7, !dbg [[DBG138]]
// AARCH64-NEXT:    [[BF_ASHR245:%.*]] = ashr i24 [[BF_SHL244]], 10, !dbg [[DBG138]]
// AARCH64-NEXT:    [[BF_CAST246:%.*]] = sext i24 [[BF_ASHR245]] to i32, !dbg [[DBG138]]
// AARCH64-NEXT:    [[CONV247:%.*]] = sitofp i32 [[BF_CAST246]] to fp128, !dbg [[DBG139:![0-9]+]]
// AARCH64-NEXT:    [[ADD248:%.*]] = fadd fp128 [[CONV247]], [[TMP174]], !dbg [[DBG140:![0-9]+]]
// AARCH64-NEXT:    [[CONV249:%.*]] = fptosi fp128 [[ADD248]] to i32, !dbg [[DBG139]]
// AARCH64-NEXT:    [[TMP177:%.*]] = trunc i32 [[CONV249]] to i24, !dbg [[DBG138]]
// AARCH64-NEXT:    [[BF_LOAD250:%.*]] = load i24, ptr [[ATOMIC_TEMP241]], align 1, !dbg [[DBG138]]
// AARCH64-NEXT:    [[BF_VALUE251:%.*]] = and i24 [[TMP177]], 16383, !dbg [[DBG138]]
// AARCH64-NEXT:    [[BF_SHL252:%.*]] = shl i24 [[BF_VALUE251]], 3, !dbg [[DBG138]]
// AARCH64-NEXT:    [[BF_CLEAR253:%.*]] = and i24 [[BF_LOAD250]], -131065, !dbg [[DBG138]]
// AARCH64-NEXT:    [[BF_SET254:%.*]] = or i24 [[BF_CLEAR253]], [[BF_SHL252]], !dbg [[DBG138]]
// AARCH64-NEXT:    store i24 [[BF_SET254]], ptr [[ATOMIC_TEMP241]], align 1, !dbg [[DBG138]]
// AARCH64-NEXT:    [[CALL255:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 3, ptr noundef getelementptr (i8, ptr @bfx3_packed, i64 1), ptr noundef [[ATOMIC_TEMP239]], ptr noundef [[ATOMIC_TEMP241]], i32 noundef 0, i32 noundef 0), !dbg [[DBG138]]
// AARCH64-NEXT:    br i1 [[CALL255]], label [[ATOMIC_EXIT256:%.*]], label [[ATOMIC_CONT240]], !dbg [[DBG138]]
// AARCH64:       atomic_exit256:
// AARCH64-NEXT:    store i32 [[CONV249]], ptr @iv, align 4, !dbg [[DBG138]]
// AARCH64-NEXT:    [[TMP178:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG141:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD257:%.*]] = load atomic i64, ptr @bfx4 monotonic, align 8, !dbg [[DBG142:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT258:%.*]], !dbg [[DBG142]]
// AARCH64:       atomic_cont258:
// AARCH64-NEXT:    [[TMP179:%.*]] = phi i64 [ [[ATOMIC_LOAD257]], [[ATOMIC_EXIT256]] ], [ [[TMP183:%.*]], [[ATOMIC_CONT258]] ], !dbg [[DBG142]]
// AARCH64-NEXT:    store i64 [[TMP179]], ptr [[ATOMIC_TEMP259]], align 8, !dbg [[DBG142]]
// AARCH64-NEXT:    store i64 [[TMP179]], ptr [[ATOMIC_TEMP260]], align 8, !dbg [[DBG142]]
// AARCH64-NEXT:    [[BF_LOAD261:%.*]] = load i64, ptr [[ATOMIC_TEMP260]], align 8, !dbg [[DBG142]]
// AARCH64-NEXT:    [[BF_SHL262:%.*]] = shl i64 [[BF_LOAD261]], 47, !dbg [[DBG142]]
// AARCH64-NEXT:    [[BF_ASHR263:%.*]] = ashr i64 [[BF_SHL262]], 63, !dbg [[DBG142]]
// AARCH64-NEXT:    [[BF_CAST264:%.*]] = trunc i64 [[BF_ASHR263]] to i32, !dbg [[DBG142]]
// AARCH64-NEXT:    [[CONV265:%.*]] = sitofp i32 [[BF_CAST264]] to fp128, !dbg [[DBG143:![0-9]+]]
// AARCH64-NEXT:    [[MUL266:%.*]] = fmul fp128 [[CONV265]], [[TMP178]], !dbg [[DBG144:![0-9]+]]
// AARCH64-NEXT:    [[CONV267:%.*]] = fptosi fp128 [[MUL266]] to i32, !dbg [[DBG143]]
// AARCH64-NEXT:    [[TMP180:%.*]] = zext i32 [[CONV267]] to i64, !dbg [[DBG142]]
// AARCH64-NEXT:    [[BF_LOAD268:%.*]] = load i64, ptr [[ATOMIC_TEMP259]], align 8, !dbg [[DBG142]]
// AARCH64-NEXT:    [[BF_VALUE269:%.*]] = and i64 [[TMP180]], 1, !dbg [[DBG142]]
// AARCH64-NEXT:    [[BF_SHL270:%.*]] = shl i64 [[BF_VALUE269]], 16, !dbg [[DBG142]]
// AARCH64-NEXT:    [[BF_CLEAR271:%.*]] = and i64 [[BF_LOAD268]], -65537, !dbg [[DBG142]]
// AARCH64-NEXT:    [[BF_SET272:%.*]] = or i64 [[BF_CLEAR271]], [[BF_SHL270]], !dbg [[DBG142]]
// AARCH64-NEXT:    store i64 [[BF_SET272]], ptr [[ATOMIC_TEMP259]], align 8, !dbg [[DBG142]]
// AARCH64-NEXT:    [[TMP181:%.*]] = load i64, ptr [[ATOMIC_TEMP259]], align 8, !dbg [[DBG142]]
// AARCH64-NEXT:    [[TMP182:%.*]] = cmpxchg ptr @bfx4, i64 [[TMP179]], i64 [[TMP181]] monotonic monotonic, align 8, !dbg [[DBG142]]
// AARCH64-NEXT:    [[TMP183]] = extractvalue { i64, i1 } [[TMP182]], 0, !dbg [[DBG142]]
// AARCH64-NEXT:    [[TMP184:%.*]] = extractvalue { i64, i1 } [[TMP182]], 1, !dbg [[DBG142]]
// AARCH64-NEXT:    br i1 [[TMP184]], label [[ATOMIC_EXIT273:%.*]], label [[ATOMIC_CONT258]], !dbg [[DBG142]]
// AARCH64:       atomic_exit273:
// AARCH64-NEXT:    store i32 [[CONV267]], ptr @iv, align 4, !dbg [[DBG142]]
// AARCH64-NEXT:    [[TMP185:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG145:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD274:%.*]] = load atomic i8, ptr getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED:%.*]], ptr @bfx4_packed, i32 0, i32 1) monotonic, align 1, !dbg [[DBG146:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT275:%.*]], !dbg [[DBG146]]
// AARCH64:       atomic_cont275:
// AARCH64-NEXT:    [[TMP186:%.*]] = phi i8 [ [[ATOMIC_LOAD274]], [[ATOMIC_EXIT273]] ], [ [[TMP190:%.*]], [[ATOMIC_CONT275]] ], !dbg [[DBG146]]
// AARCH64-NEXT:    store i8 [[TMP186]], ptr [[ATOMIC_TEMP276]], align 1, !dbg [[DBG146]]
// AARCH64-NEXT:    store i8 [[TMP186]], ptr [[ATOMIC_TEMP277]], align 1, !dbg [[DBG146]]
// AARCH64-NEXT:    [[BF_LOAD278:%.*]] = load i8, ptr [[ATOMIC_TEMP277]], align 1, !dbg [[DBG146]]
// AARCH64-NEXT:    [[BF_SHL279:%.*]] = shl i8 [[BF_LOAD278]], 7, !dbg [[DBG146]]
// AARCH64-NEXT:    [[BF_ASHR280:%.*]] = ashr i8 [[BF_SHL279]], 7, !dbg [[DBG146]]
// AARCH64-NEXT:    [[BF_CAST281:%.*]] = sext i8 [[BF_ASHR280]] to i32, !dbg [[DBG146]]
// AARCH64-NEXT:    [[CONV282:%.*]] = sitofp i32 [[BF_CAST281]] to fp128, !dbg [[DBG147:![0-9]+]]
// AARCH64-NEXT:    [[SUB283:%.*]] = fsub fp128 [[CONV282]], [[TMP185]], !dbg [[DBG148:![0-9]+]]
// AARCH64-NEXT:    [[CONV284:%.*]] = fptosi fp128 [[SUB283]] to i32, !dbg [[DBG147]]
// AARCH64-NEXT:    [[TMP187:%.*]] = trunc i32 [[CONV284]] to i8, !dbg [[DBG146]]
// AARCH64-NEXT:    [[BF_LOAD285:%.*]] = load i8, ptr [[ATOMIC_TEMP276]], align 1, !dbg [[DBG146]]
// AARCH64-NEXT:    [[BF_VALUE286:%.*]] = and i8 [[TMP187]], 1, !dbg [[DBG146]]
// AARCH64-NEXT:    [[BF_CLEAR287:%.*]] = and i8 [[BF_LOAD285]], -2, !dbg [[DBG146]]
// AARCH64-NEXT:    [[BF_SET288:%.*]] = or i8 [[BF_CLEAR287]], [[BF_VALUE286]], !dbg [[DBG146]]
// AARCH64-NEXT:    store i8 [[BF_SET288]], ptr [[ATOMIC_TEMP276]], align 1, !dbg [[DBG146]]
// AARCH64-NEXT:    [[TMP188:%.*]] = load i8, ptr [[ATOMIC_TEMP276]], align 1, !dbg [[DBG146]]
// AARCH64-NEXT:    [[TMP189:%.*]] = cmpxchg ptr getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1), i8 [[TMP186]], i8 [[TMP188]] monotonic monotonic, align 1, !dbg [[DBG146]]
// AARCH64-NEXT:    [[TMP190]] = extractvalue { i8, i1 } [[TMP189]], 0, !dbg [[DBG146]]
// AARCH64-NEXT:    [[TMP191:%.*]] = extractvalue { i8, i1 } [[TMP189]], 1, !dbg [[DBG146]]
// AARCH64-NEXT:    br i1 [[TMP191]], label [[ATOMIC_EXIT289:%.*]], label [[ATOMIC_CONT275]], !dbg [[DBG146]]
// AARCH64:       atomic_exit289:
// AARCH64-NEXT:    store i32 [[BF_CAST281]], ptr @iv, align 4, !dbg [[DBG146]]
// AARCH64-NEXT:    [[TMP192:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG149:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD290:%.*]] = load atomic i64, ptr @bfx4 monotonic, align 8, !dbg [[DBG150:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT291:%.*]], !dbg [[DBG150]]
// AARCH64:       atomic_cont291:
// AARCH64-NEXT:    [[TMP193:%.*]] = phi i64 [ [[ATOMIC_LOAD290]], [[ATOMIC_EXIT289]] ], [ [[TMP196:%.*]], [[ATOMIC_CONT291]] ], !dbg [[DBG150]]
// AARCH64-NEXT:    store i64 [[TMP193]], ptr [[ATOMIC_TEMP292]], align 8, !dbg [[DBG150]]
// AARCH64-NEXT:    store i64 [[TMP193]], ptr [[ATOMIC_TEMP293]], align 8, !dbg [[DBG150]]
// AARCH64-NEXT:    [[BF_LOAD294:%.*]] = load i64, ptr [[ATOMIC_TEMP293]], align 8, !dbg [[DBG150]]
// AARCH64-NEXT:    [[BF_SHL295:%.*]] = shl i64 [[BF_LOAD294]], 40, !dbg [[DBG150]]
// AARCH64-NEXT:    [[BF_ASHR296:%.*]] = ashr i64 [[BF_SHL295]], 57, !dbg [[DBG150]]
// AARCH64-NEXT:    [[CONV297:%.*]] = sitofp i64 [[BF_ASHR296]] to fp128, !dbg [[DBG151:![0-9]+]]
// AARCH64-NEXT:    [[DIV298:%.*]] = fdiv fp128 [[CONV297]], [[TMP192]], !dbg [[DBG152:![0-9]+]]
// AARCH64-NEXT:    [[CONV299:%.*]] = fptosi fp128 [[DIV298]] to i64, !dbg [[DBG151]]
// AARCH64-NEXT:    [[BF_LOAD300:%.*]] = load i64, ptr [[ATOMIC_TEMP292]], align 8, !dbg [[DBG150]]
// AARCH64-NEXT:    [[BF_VALUE301:%.*]] = and i64 [[CONV299]], 127, !dbg [[DBG150]]
// AARCH64-NEXT:    [[BF_SHL302:%.*]] = shl i64 [[BF_VALUE301]], 17, !dbg [[DBG150]]
// AARCH64-NEXT:    [[BF_CLEAR303:%.*]] = and i64 [[BF_LOAD300]], -16646145, !dbg [[DBG150]]
// AARCH64-NEXT:    [[BF_SET304:%.*]] = or i64 [[BF_CLEAR303]], [[BF_SHL302]], !dbg [[DBG150]]
// AARCH64-NEXT:    store i64 [[BF_SET304]], ptr [[ATOMIC_TEMP292]], align 8, !dbg [[DBG150]]
// AARCH64-NEXT:    [[TMP194:%.*]] = load i64, ptr [[ATOMIC_TEMP292]], align 8, !dbg [[DBG150]]
// AARCH64-NEXT:    [[TMP195:%.*]] = cmpxchg ptr @bfx4, i64 [[TMP193]], i64 [[TMP194]] release monotonic, align 8, !dbg [[DBG150]]
// AARCH64-NEXT:    [[TMP196]] = extractvalue { i64, i1 } [[TMP195]], 0, !dbg [[DBG150]]
// AARCH64-NEXT:    [[TMP197:%.*]] = extractvalue { i64, i1 } [[TMP195]], 1, !dbg [[DBG150]]
// AARCH64-NEXT:    br i1 [[TMP197]], label [[ATOMIC_EXIT305:%.*]], label [[ATOMIC_CONT291]], !dbg [[DBG150]]
// AARCH64:       atomic_exit305:
// AARCH64-NEXT:    [[CONV306:%.*]] = trunc i64 [[CONV299]] to i32, !dbg [[DBG150]]
// AARCH64-NEXT:    store i32 [[CONV306]], ptr @iv, align 4, !dbg [[DBG150]]
// AARCH64-NEXT:    [[TMP198:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG153:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD307:%.*]] = load atomic i8, ptr getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1) acquire, align 1, !dbg [[DBG154:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT308:%.*]], !dbg [[DBG154]]
// AARCH64:       atomic_cont308:
// AARCH64-NEXT:    [[TMP199:%.*]] = phi i8 [ [[ATOMIC_LOAD307]], [[ATOMIC_EXIT305]] ], [ [[TMP203:%.*]], [[ATOMIC_CONT308]] ], !dbg [[DBG154]]
// AARCH64-NEXT:    store i8 [[TMP199]], ptr [[ATOMIC_TEMP309]], align 1, !dbg [[DBG154]]
// AARCH64-NEXT:    store i8 [[TMP199]], ptr [[ATOMIC_TEMP310]], align 1, !dbg [[DBG154]]
// AARCH64-NEXT:    [[BF_LOAD311:%.*]] = load i8, ptr [[ATOMIC_TEMP310]], align 1, !dbg [[DBG154]]
// AARCH64-NEXT:    [[BF_ASHR312:%.*]] = ashr i8 [[BF_LOAD311]], 1, !dbg [[DBG154]]
// AARCH64-NEXT:    [[BF_CAST313:%.*]] = sext i8 [[BF_ASHR312]] to i64, !dbg [[DBG154]]
// AARCH64-NEXT:    [[CONV314:%.*]] = sitofp i64 [[BF_CAST313]] to fp128, !dbg [[DBG155:![0-9]+]]
// AARCH64-NEXT:    [[ADD315:%.*]] = fadd fp128 [[CONV314]], [[TMP198]], !dbg [[DBG156:![0-9]+]]
// AARCH64-NEXT:    [[CONV316:%.*]] = fptosi fp128 [[ADD315]] to i64, !dbg [[DBG155]]
// AARCH64-NEXT:    [[TMP200:%.*]] = trunc i64 [[CONV316]] to i8, !dbg [[DBG154]]
// AARCH64-NEXT:    [[BF_LOAD317:%.*]] = load i8, ptr [[ATOMIC_TEMP309]], align 1, !dbg [[DBG154]]
// AARCH64-NEXT:    [[BF_VALUE318:%.*]] = and i8 [[TMP200]], 127, !dbg [[DBG154]]
// AARCH64-NEXT:    [[BF_SHL319:%.*]] = shl i8 [[BF_VALUE318]], 1, !dbg [[DBG154]]
// AARCH64-NEXT:    [[BF_CLEAR320:%.*]] = and i8 [[BF_LOAD317]], 1, !dbg [[DBG154]]
// AARCH64-NEXT:    [[BF_SET321:%.*]] = or i8 [[BF_CLEAR320]], [[BF_SHL319]], !dbg [[DBG154]]
// AARCH64-NEXT:    store i8 [[BF_SET321]], ptr [[ATOMIC_TEMP309]], align 1, !dbg [[DBG154]]
// AARCH64-NEXT:    [[TMP201:%.*]] = load i8, ptr [[ATOMIC_TEMP309]], align 1, !dbg [[DBG154]]
// AARCH64-NEXT:    [[TMP202:%.*]] = cmpxchg ptr getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1), i8 [[TMP199]], i8 [[TMP201]] acquire acquire, align 1, !dbg [[DBG154]]
// AARCH64-NEXT:    [[TMP203]] = extractvalue { i8, i1 } [[TMP202]], 0, !dbg [[DBG154]]
// AARCH64-NEXT:    [[TMP204:%.*]] = extractvalue { i8, i1 } [[TMP202]], 1, !dbg [[DBG154]]
// AARCH64-NEXT:    br i1 [[TMP204]], label [[ATOMIC_EXIT322:%.*]], label [[ATOMIC_CONT308]], !dbg [[DBG154]]
// AARCH64:       atomic_exit322:
// AARCH64-NEXT:    [[CONV323:%.*]] = trunc i64 [[CONV316]] to i32, !dbg [[DBG154]]
// AARCH64-NEXT:    store i32 [[CONV323]], ptr @iv, align 4, !dbg [[DBG154]]
// AARCH64-NEXT:    [[TMP205:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG157:![0-9]+]]
// AARCH64-NEXT:    [[CONV324:%.*]] = uitofp i64 [[TMP205]] to float, !dbg [[DBG157]]
// AARCH64-NEXT:    [[ATOMIC_LOAD325:%.*]] = load atomic i64, ptr @float2x acquire, align 8, !dbg [[DBG158:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT326:%.*]], !dbg [[DBG158]]
// AARCH64:       atomic_cont326:
// AARCH64-NEXT:    [[TMP206:%.*]] = phi i64 [ [[ATOMIC_LOAD325]], [[ATOMIC_EXIT322]] ], [ [[TMP214:%.*]], [[ATOMIC_CONT326]] ], !dbg [[DBG158]]
// AARCH64-NEXT:    store i64 [[TMP206]], ptr [[ATOMIC_TEMP327]], align 8, !dbg [[DBG158]]
// AARCH64-NEXT:    [[TMP207:%.*]] = bitcast i64 [[TMP206]] to <2 x float>, !dbg [[DBG158]]
// AARCH64-NEXT:    store <2 x float> [[TMP207]], ptr [[ATOMIC_TEMP328]], align 8, !dbg [[DBG158]]
// AARCH64-NEXT:    [[TMP208:%.*]] = load <2 x float>, ptr [[ATOMIC_TEMP328]], align 8, !dbg [[DBG158]]
// AARCH64-NEXT:    [[TMP209:%.*]] = extractelement <2 x float> [[TMP208]], i64 0, !dbg [[DBG158]]
// AARCH64-NEXT:    [[SUB329:%.*]] = fsub float [[CONV324]], [[TMP209]], !dbg [[DBG159:![0-9]+]]
// AARCH64-NEXT:    [[TMP210:%.*]] = load <2 x float>, ptr [[ATOMIC_TEMP327]], align 8, !dbg [[DBG158]]
// AARCH64-NEXT:    [[TMP211:%.*]] = insertelement <2 x float> [[TMP210]], float [[SUB329]], i64 0, !dbg [[DBG158]]
// AARCH64-NEXT:    store <2 x float> [[TMP211]], ptr [[ATOMIC_TEMP327]], align 8, !dbg [[DBG158]]
// AARCH64-NEXT:    [[TMP212:%.*]] = load i64, ptr [[ATOMIC_TEMP327]], align 8, !dbg [[DBG158]]
// AARCH64-NEXT:    [[TMP213:%.*]] = cmpxchg ptr @float2x, i64 [[TMP206]], i64 [[TMP212]] acq_rel acquire, align 8, !dbg [[DBG158]]
// AARCH64-NEXT:    [[TMP214]] = extractvalue { i64, i1 } [[TMP213]], 0, !dbg [[DBG158]]
// AARCH64-NEXT:    [[TMP215:%.*]] = extractvalue { i64, i1 } [[TMP213]], 1, !dbg [[DBG158]]
// AARCH64-NEXT:    br i1 [[TMP215]], label [[ATOMIC_EXIT330:%.*]], label [[ATOMIC_CONT326]], !dbg [[DBG158]]
// AARCH64:       atomic_exit330:
// AARCH64-NEXT:    store float [[TMP209]], ptr @fv, align 4, !dbg [[DBG158]]
// AARCH64-NEXT:    ret i32 0, !dbg [[DBG160:![0-9]+]]
//
