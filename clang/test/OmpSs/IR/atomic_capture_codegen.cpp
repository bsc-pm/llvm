// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --function-signature --include-generated-funcs
// RUN: %clang_cc1 -x c -no-opaque-pointers -triple x86_64-gnu-linux -verify -fompss-2 -disable-llvm-passes -ferror-limit 100 %s -S -emit-llvm -o - | FileCheck %s --check-prefixes=LIN64
// RUN: %clang_cc1 -x c -no-opaque-pointers -triple ppc64 -verify -fompss-2 -disable-llvm-passes -ferror-limit 100 %s -S -emit-llvm -o - | FileCheck %s --check-prefixes=PPC64
// RUN: %clang_cc1 -x c -no-opaque-pointers -triple aarch64 -verify -fompss-2 -disable-llvm-passes -ferror-limit 100 %s -S -emit-llvm -o - | FileCheck %s --check-prefixes=AARCH64
// expected-no-diagnostics
#ifndef HEADER
#define HEADER

_Bool bv, bx;
char cv, cx;
unsigned char ucv, ucx;
short sv, sx;
unsigned short usv, usx;
int iv, ix;
unsigned int uiv, uix;
long lv, lx;
unsigned long ulv, ulx;
long long llv, llx;
unsigned long long ullv, ullx;
float fv, fx;
double dv, dx;
long double ldv, ldx;
_Complex int civ, cix;
_Complex float cfv, cfx;
_Complex double cdv, cdx;

typedef int int4 __attribute__((__vector_size__(16)));
int4 int4x;

struct BitFields {
  int : 32;
  int a : 31;
} bfx;

struct BitFields_packed {
  int : 32;
  int a : 31;
} __attribute__ ((__packed__)) bfx_packed;

struct BitFields2 {
  int : 31;
  int a : 1;
} bfx2;

struct BitFields2_packed {
  int : 31;
  int a : 1;
} __attribute__ ((__packed__)) bfx2_packed;

struct BitFields3 {
  int : 11;
  int a : 14;
} bfx3;

struct BitFields3_packed {
  int : 11;
  int a : 14;
} __attribute__ ((__packed__)) bfx3_packed;

struct BitFields4 {
  short : 16;
  int a: 1;
  long b : 7;
} bfx4;

struct BitFields4_packed {
  short : 16;
  int a: 1;
  long b : 7;
} __attribute__ ((__packed__)) bfx4_packed;

typedef float float2 __attribute__((ext_vector_type(2)));
float2 float2x;

#if defined(__x86_64__)
// Register "0" is currently an invalid register for global register variables.
// Use "esp" instead of "0".
// register int rix __asm__("0");
register int rix __asm__("esp");
#endif

int main(void) {
#pragma oss atomic capture
  bv = bx++;
#pragma oss atomic capture
  cv = ++cx;
#pragma oss atomic capture
  ucv = ucx--;
#pragma oss atomic capture
  sv = --sx;
#pragma oss atomic capture
  sv = usx += usv;
#pragma oss atomic capture
  uiv = ix *= iv;
#pragma oss atomic capture
  {iv = uix; uix -= uiv;}
#pragma oss atomic capture
  {ix <<= iv; uiv = ix;}
#pragma oss atomic capture
  iv = uix >>= uiv;
#pragma oss atomic capture
  {ulv = lx; lx /= lv;}
#pragma oss atomic capture
  {ulx &= ulv; lv = ulx;}
#pragma oss atomic capture
  ullv = llx ^= llv;
#pragma oss atomic capture
  llv = ullx |= ullv;
#pragma oss atomic capture
  dv = fx = fx + fv;
#pragma oss atomic capture
  {fv = dx; dx = dv - dx;}
#pragma oss atomic capture
  {ldx = ldx * ldv; dv = ldx;}
// <Skip checks for complex calculations>
#pragma oss atomic capture
  cfv = cix = civ / cix;
// <Skip checks for complex calculations>
#pragma oss atomic capture
  {civ = cfx; cfx = cfv + cfx;}
// <Skip checks for complex calculations>
#pragma oss atomic capture seq_cst
  {cdx = cdx - cdv; cfv = cdx;}
#pragma oss atomic capture
  ulv = ulx = ulx & bv;
#pragma oss atomic capture
  {bv = bx; bx = cv & bx;}
#pragma oss atomic capture, seq_cst
  {cx = cx >> ucv; cv = cx;}
#pragma oss atomic capture
  ulv = ulx = sv << ulx;
#pragma oss atomic capture
  {lv = lx; lx = lx % usv;}
#pragma oss atomic seq_cst, capture
  {uix = iv | uix; uiv = uix;}
#pragma oss atomic capture
  iv = ix = ix & uiv;
// <Skip checks for complex calculations>
#pragma oss atomic capture
  {civ = cix; cix = lv + cix;}
#pragma oss atomic capture
  {fx = fx * ulv; fv = fx;}
#pragma oss atomic capture
  dv = dx /= llv;
#pragma oss atomic capture
  {ldv = ldx; ldx -= ullv;}
// <Skip checks for complex calculations>
#pragma oss atomic capture
  {cix = fv / cix; civ = cix;}
#pragma oss atomic capture
  sv = sx = sx + dv;
#pragma oss atomic capture
  {bv = bx; bx = ldv * bx;}
#pragma oss atomic capture
  {bx = civ - bx; bv = bx;}
#pragma oss atomic capture
  {int4x[sv] |= bv; iv = int4x[sv];}
#pragma oss atomic capture
  iv = bfx.a = bfx.a - ldv;
#pragma oss atomic capture
  {iv = bfx_packed.a; bfx_packed.a *= ldv;}
#pragma oss atomic capture
  {bfx2.a -= ldv; iv = bfx2.a;}
#pragma oss atomic capture
  iv = bfx2_packed.a = ldv / bfx2_packed.a;
#pragma oss atomic capture
  {iv = bfx3.a; bfx3.a /= ldv;}
#pragma oss atomic capture
  {bfx3_packed.a += ldv; iv = bfx3_packed.a;}
#pragma oss atomic relaxed capture
  iv = bfx4.a = bfx4.a * ldv;
#pragma oss atomic capture relaxed
  {iv = bfx4_packed.a; bfx4_packed.a -= ldv;}
#pragma oss atomic capture release
  {bfx4.b /= ldv; iv = bfx4.b;}
#pragma oss atomic capture acquire
  iv = bfx4_packed.b += ldv;
#pragma oss atomic capture acq_rel
  {fv = float2x.x; float2x.x = ulv - float2x.x;}
#if defined(__x86_64__)
#pragma oss atomic capture seq_cst
  {rix = dv / rix; iv = rix;}
#pragma oss atomic capture
  {rix = ix; ix = 5;}
#endif
  return 0;
}
#endif
// LIN64-LABEL: define {{[^@]+}}@main
// LIN64-SAME: () #[[ATTR0:[0-9]+]] !dbg [[DBG6:![0-9]+]] {
// LIN64-NEXT:  entry:
// LIN64-NEXT:    [[RETVAL:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca i16, align 2
// LIN64-NEXT:    [[ATOMIC_TEMP10:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP14:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP18:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP22:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP28:%.*]] = alloca double, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP32:%.*]] = alloca x86_fp80, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP34:%.*]] = alloca x86_fp80, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP38:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP40:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP45:%.*]] = alloca { float, float }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP47:%.*]] = alloca { float, float }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP52:%.*]] = alloca { double, double }, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP54:%.*]] = alloca { double, double }, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP64:%.*]] = alloca i8, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP74:%.*]] = alloca i8, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP82:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP89:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP93:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP95:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP107:%.*]] = alloca float, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP113:%.*]] = alloca double, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP117:%.*]] = alloca x86_fp80, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP119:%.*]] = alloca x86_fp80, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP123:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP125:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[COERCE:%.*]] = alloca { float, float }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP135:%.*]] = alloca i16, align 2
// LIN64-NEXT:    [[ATOMIC_TEMP143:%.*]] = alloca i8, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP156:%.*]] = alloca i8, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP169:%.*]] = alloca <4 x i32>, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP171:%.*]] = alloca <4 x i32>, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP172:%.*]] = alloca <4 x i32>, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP178:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP179:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP185:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP187:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP188:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP203:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP204:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP218:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP219:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP233:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP234:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP247:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP249:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP250:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP267:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP268:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP284:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP285:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP300:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP301:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP317:%.*]] = alloca i64, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP318:%.*]] = alloca i64, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP335:%.*]] = alloca <2 x float>, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP336:%.*]] = alloca <2 x float>, align 8
// LIN64-NEXT:    store i32 0, i32* [[RETVAL]], align 4
// LIN64-NEXT:    [[TMP0:%.*]] = atomicrmw add i8* @bx, i8 1 monotonic, align 1, !dbg [[DBG10:![0-9]+]]
// LIN64-NEXT:    store i8 [[TMP0]], i8* @bv, align 1, !dbg [[DBG10]]
// LIN64-NEXT:    [[TMP1:%.*]] = atomicrmw add i8* @cx, i8 1 monotonic, align 1, !dbg [[DBG11:![0-9]+]]
// LIN64-NEXT:    [[CONV:%.*]] = sext i8 [[TMP1]] to i32, !dbg [[DBG12:![0-9]+]]
// LIN64-NEXT:    [[ADD:%.*]] = add nsw i32 [[CONV]], 1, !dbg [[DBG13:![0-9]+]]
// LIN64-NEXT:    [[CONV1:%.*]] = trunc i32 [[ADD]] to i8, !dbg [[DBG12]]
// LIN64-NEXT:    store i8 [[CONV1]], i8* @cv, align 1, !dbg [[DBG11]]
// LIN64-NEXT:    [[TMP2:%.*]] = atomicrmw sub i8* @ucx, i8 1 monotonic, align 1, !dbg [[DBG14:![0-9]+]]
// LIN64-NEXT:    store i8 [[TMP2]], i8* @ucv, align 1, !dbg [[DBG14]]
// LIN64-NEXT:    [[TMP3:%.*]] = atomicrmw sub i16* @sx, i16 1 monotonic, align 2, !dbg [[DBG15:![0-9]+]]
// LIN64-NEXT:    [[CONV2:%.*]] = sext i16 [[TMP3]] to i32, !dbg [[DBG16:![0-9]+]]
// LIN64-NEXT:    [[SUB:%.*]] = sub nsw i32 [[CONV2]], 1, !dbg [[DBG17:![0-9]+]]
// LIN64-NEXT:    [[CONV3:%.*]] = trunc i32 [[SUB]] to i16, !dbg [[DBG16]]
// LIN64-NEXT:    store i16 [[CONV3]], i16* @sv, align 2, !dbg [[DBG15]]
// LIN64-NEXT:    [[TMP4:%.*]] = load i16, i16* @usv, align 2, !dbg [[DBG18:![0-9]+]]
// LIN64-NEXT:    [[CONV4:%.*]] = zext i16 [[TMP4]] to i32, !dbg [[DBG18]]
// LIN64-NEXT:    [[ATOMIC_LOAD:%.*]] = load atomic i16, i16* @usx monotonic, align 2, !dbg [[DBG19:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT:%.*]], !dbg [[DBG19]]
// LIN64:       atomic_cont:
// LIN64-NEXT:    [[TMP5:%.*]] = phi i16 [ [[ATOMIC_LOAD]], [[ENTRY:%.*]] ], [ [[TMP8:%.*]], [[ATOMIC_CONT]] ], !dbg [[DBG19]]
// LIN64-NEXT:    [[CONV5:%.*]] = zext i16 [[TMP5]] to i32, !dbg [[DBG20:![0-9]+]]
// LIN64-NEXT:    [[ADD6:%.*]] = add nsw i32 [[CONV5]], [[CONV4]], !dbg [[DBG21:![0-9]+]]
// LIN64-NEXT:    [[CONV7:%.*]] = trunc i32 [[ADD6]] to i16, !dbg [[DBG20]]
// LIN64-NEXT:    store i16 [[CONV7]], i16* [[ATOMIC_TEMP]], align 2, !dbg [[DBG19]]
// LIN64-NEXT:    [[TMP6:%.*]] = load i16, i16* [[ATOMIC_TEMP]], align 2, !dbg [[DBG19]]
// LIN64-NEXT:    [[TMP7:%.*]] = cmpxchg i16* @usx, i16 [[TMP5]], i16 [[TMP6]] monotonic monotonic, align 2, !dbg [[DBG19]]
// LIN64-NEXT:    [[TMP8]] = extractvalue { i16, i1 } [[TMP7]], 0, !dbg [[DBG19]]
// LIN64-NEXT:    [[TMP9:%.*]] = extractvalue { i16, i1 } [[TMP7]], 1, !dbg [[DBG19]]
// LIN64-NEXT:    br i1 [[TMP9]], label [[ATOMIC_EXIT:%.*]], label [[ATOMIC_CONT]], !dbg [[DBG19]]
// LIN64:       atomic_exit:
// LIN64-NEXT:    store i16 [[CONV7]], i16* @sv, align 2, !dbg [[DBG19]]
// LIN64-NEXT:    [[TMP10:%.*]] = load i32, i32* @iv, align 4, !dbg [[DBG22:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD8:%.*]] = load atomic i32, i32* @ix monotonic, align 4, !dbg [[DBG23:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT9:%.*]], !dbg [[DBG23]]
// LIN64:       atomic_cont9:
// LIN64-NEXT:    [[TMP11:%.*]] = phi i32 [ [[ATOMIC_LOAD8]], [[ATOMIC_EXIT]] ], [ [[TMP14:%.*]], [[ATOMIC_CONT9]] ], !dbg [[DBG23]]
// LIN64-NEXT:    [[MUL:%.*]] = mul nsw i32 [[TMP11]], [[TMP10]], !dbg [[DBG24:![0-9]+]]
// LIN64-NEXT:    store i32 [[MUL]], i32* [[ATOMIC_TEMP10]], align 4, !dbg [[DBG23]]
// LIN64-NEXT:    [[TMP12:%.*]] = load i32, i32* [[ATOMIC_TEMP10]], align 4, !dbg [[DBG23]]
// LIN64-NEXT:    [[TMP13:%.*]] = cmpxchg i32* @ix, i32 [[TMP11]], i32 [[TMP12]] monotonic monotonic, align 4, !dbg [[DBG23]]
// LIN64-NEXT:    [[TMP14]] = extractvalue { i32, i1 } [[TMP13]], 0, !dbg [[DBG23]]
// LIN64-NEXT:    [[TMP15:%.*]] = extractvalue { i32, i1 } [[TMP13]], 1, !dbg [[DBG23]]
// LIN64-NEXT:    br i1 [[TMP15]], label [[ATOMIC_EXIT11:%.*]], label [[ATOMIC_CONT9]], !dbg [[DBG23]]
// LIN64:       atomic_exit11:
// LIN64-NEXT:    store i32 [[MUL]], i32* @uiv, align 4, !dbg [[DBG23]]
// LIN64-NEXT:    [[TMP16:%.*]] = load i32, i32* @uiv, align 4, !dbg [[DBG25:![0-9]+]]
// LIN64-NEXT:    [[TMP17:%.*]] = atomicrmw sub i32* @uix, i32 [[TMP16]] monotonic, align 4, !dbg [[DBG26:![0-9]+]]
// LIN64-NEXT:    store i32 [[TMP17]], i32* @iv, align 4, !dbg [[DBG26]]
// LIN64-NEXT:    [[TMP18:%.*]] = load i32, i32* @iv, align 4, !dbg [[DBG27:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD12:%.*]] = load atomic i32, i32* @ix monotonic, align 4, !dbg [[DBG28:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT13:%.*]], !dbg [[DBG28]]
// LIN64:       atomic_cont13:
// LIN64-NEXT:    [[TMP19:%.*]] = phi i32 [ [[ATOMIC_LOAD12]], [[ATOMIC_EXIT11]] ], [ [[TMP22:%.*]], [[ATOMIC_CONT13]] ], !dbg [[DBG28]]
// LIN64-NEXT:    [[SHL:%.*]] = shl i32 [[TMP19]], [[TMP18]], !dbg [[DBG29:![0-9]+]]
// LIN64-NEXT:    store i32 [[SHL]], i32* [[ATOMIC_TEMP14]], align 4, !dbg [[DBG28]]
// LIN64-NEXT:    [[TMP20:%.*]] = load i32, i32* [[ATOMIC_TEMP14]], align 4, !dbg [[DBG28]]
// LIN64-NEXT:    [[TMP21:%.*]] = cmpxchg i32* @ix, i32 [[TMP19]], i32 [[TMP20]] monotonic monotonic, align 4, !dbg [[DBG28]]
// LIN64-NEXT:    [[TMP22]] = extractvalue { i32, i1 } [[TMP21]], 0, !dbg [[DBG28]]
// LIN64-NEXT:    [[TMP23:%.*]] = extractvalue { i32, i1 } [[TMP21]], 1, !dbg [[DBG28]]
// LIN64-NEXT:    br i1 [[TMP23]], label [[ATOMIC_EXIT15:%.*]], label [[ATOMIC_CONT13]], !dbg [[DBG28]]
// LIN64:       atomic_exit15:
// LIN64-NEXT:    store i32 [[SHL]], i32* @uiv, align 4, !dbg [[DBG28]]
// LIN64-NEXT:    [[TMP24:%.*]] = load i32, i32* @uiv, align 4, !dbg [[DBG30:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD16:%.*]] = load atomic i32, i32* @uix monotonic, align 4, !dbg [[DBG31:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT17:%.*]], !dbg [[DBG31]]
// LIN64:       atomic_cont17:
// LIN64-NEXT:    [[TMP25:%.*]] = phi i32 [ [[ATOMIC_LOAD16]], [[ATOMIC_EXIT15]] ], [ [[TMP28:%.*]], [[ATOMIC_CONT17]] ], !dbg [[DBG31]]
// LIN64-NEXT:    [[SHR:%.*]] = lshr i32 [[TMP25]], [[TMP24]], !dbg [[DBG32:![0-9]+]]
// LIN64-NEXT:    store i32 [[SHR]], i32* [[ATOMIC_TEMP18]], align 4, !dbg [[DBG31]]
// LIN64-NEXT:    [[TMP26:%.*]] = load i32, i32* [[ATOMIC_TEMP18]], align 4, !dbg [[DBG31]]
// LIN64-NEXT:    [[TMP27:%.*]] = cmpxchg i32* @uix, i32 [[TMP25]], i32 [[TMP26]] monotonic monotonic, align 4, !dbg [[DBG31]]
// LIN64-NEXT:    [[TMP28]] = extractvalue { i32, i1 } [[TMP27]], 0, !dbg [[DBG31]]
// LIN64-NEXT:    [[TMP29:%.*]] = extractvalue { i32, i1 } [[TMP27]], 1, !dbg [[DBG31]]
// LIN64-NEXT:    br i1 [[TMP29]], label [[ATOMIC_EXIT19:%.*]], label [[ATOMIC_CONT17]], !dbg [[DBG31]]
// LIN64:       atomic_exit19:
// LIN64-NEXT:    store i32 [[SHR]], i32* @iv, align 4, !dbg [[DBG31]]
// LIN64-NEXT:    [[TMP30:%.*]] = load i64, i64* @lv, align 8, !dbg [[DBG33:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD20:%.*]] = load atomic i64, i64* @lx monotonic, align 8, !dbg [[DBG34:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT21:%.*]], !dbg [[DBG34]]
// LIN64:       atomic_cont21:
// LIN64-NEXT:    [[TMP31:%.*]] = phi i64 [ [[ATOMIC_LOAD20]], [[ATOMIC_EXIT19]] ], [ [[TMP34:%.*]], [[ATOMIC_CONT21]] ], !dbg [[DBG34]]
// LIN64-NEXT:    [[DIV:%.*]] = sdiv i64 [[TMP31]], [[TMP30]], !dbg [[DBG35:![0-9]+]]
// LIN64-NEXT:    store i64 [[DIV]], i64* [[ATOMIC_TEMP22]], align 8, !dbg [[DBG34]]
// LIN64-NEXT:    [[TMP32:%.*]] = load i64, i64* [[ATOMIC_TEMP22]], align 8, !dbg [[DBG34]]
// LIN64-NEXT:    [[TMP33:%.*]] = cmpxchg i64* @lx, i64 [[TMP31]], i64 [[TMP32]] monotonic monotonic, align 8, !dbg [[DBG34]]
// LIN64-NEXT:    [[TMP34]] = extractvalue { i64, i1 } [[TMP33]], 0, !dbg [[DBG34]]
// LIN64-NEXT:    [[TMP35:%.*]] = extractvalue { i64, i1 } [[TMP33]], 1, !dbg [[DBG34]]
// LIN64-NEXT:    br i1 [[TMP35]], label [[ATOMIC_EXIT23:%.*]], label [[ATOMIC_CONT21]], !dbg [[DBG34]]
// LIN64:       atomic_exit23:
// LIN64-NEXT:    store i64 [[TMP31]], i64* @ulv, align 8, !dbg [[DBG34]]
// LIN64-NEXT:    [[TMP36:%.*]] = load i64, i64* @ulv, align 8, !dbg [[DBG36:![0-9]+]]
// LIN64-NEXT:    [[TMP37:%.*]] = atomicrmw and i64* @ulx, i64 [[TMP36]] monotonic, align 8, !dbg [[DBG37:![0-9]+]]
// LIN64-NEXT:    [[AND:%.*]] = and i64 [[TMP37]], [[TMP36]], !dbg [[DBG38:![0-9]+]]
// LIN64-NEXT:    store i64 [[AND]], i64* @lv, align 8, !dbg [[DBG37]]
// LIN64-NEXT:    [[TMP38:%.*]] = load i64, i64* @llv, align 8, !dbg [[DBG39:![0-9]+]]
// LIN64-NEXT:    [[TMP39:%.*]] = atomicrmw xor i64* @llx, i64 [[TMP38]] monotonic, align 8, !dbg [[DBG40:![0-9]+]]
// LIN64-NEXT:    [[XOR:%.*]] = xor i64 [[TMP39]], [[TMP38]], !dbg [[DBG41:![0-9]+]]
// LIN64-NEXT:    store i64 [[XOR]], i64* @ullv, align 8, !dbg [[DBG40]]
// LIN64-NEXT:    [[TMP40:%.*]] = load i64, i64* @ullv, align 8, !dbg [[DBG42:![0-9]+]]
// LIN64-NEXT:    [[TMP41:%.*]] = atomicrmw or i64* @ullx, i64 [[TMP40]] monotonic, align 8, !dbg [[DBG43:![0-9]+]]
// LIN64-NEXT:    [[OR:%.*]] = or i64 [[TMP41]], [[TMP40]], !dbg [[DBG44:![0-9]+]]
// LIN64-NEXT:    store i64 [[OR]], i64* @llv, align 8, !dbg [[DBG43]]
// LIN64-NEXT:    [[TMP42:%.*]] = load float, float* @fv, align 4, !dbg [[DBG45:![0-9]+]]
// LIN64-NEXT:    [[TMP43:%.*]] = atomicrmw fadd float* @fx, float [[TMP42]] monotonic, align 4, !dbg [[DBG46:![0-9]+]]
// LIN64-NEXT:    [[ADD24:%.*]] = fadd float [[TMP43]], [[TMP42]], !dbg [[DBG47:![0-9]+]]
// LIN64-NEXT:    [[CONV25:%.*]] = fpext float [[ADD24]] to double, !dbg [[DBG46]]
// LIN64-NEXT:    store double [[CONV25]], double* @dv, align 8, !dbg [[DBG46]]
// LIN64-NEXT:    [[TMP44:%.*]] = load double, double* @dv, align 8, !dbg [[DBG48:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD26:%.*]] = load atomic i64, i64* bitcast (double* @dx to i64*) monotonic, align 8, !dbg [[DBG49:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT27:%.*]], !dbg [[DBG49]]
// LIN64:       atomic_cont27:
// LIN64-NEXT:    [[TMP45:%.*]] = phi i64 [ [[ATOMIC_LOAD26]], [[ATOMIC_EXIT23]] ], [ [[TMP50:%.*]], [[ATOMIC_CONT27]] ], !dbg [[DBG49]]
// LIN64-NEXT:    [[TMP46:%.*]] = bitcast double* [[ATOMIC_TEMP28]] to i64*, !dbg [[DBG49]]
// LIN64-NEXT:    [[TMP47:%.*]] = bitcast i64 [[TMP45]] to double, !dbg [[DBG49]]
// LIN64-NEXT:    [[SUB29:%.*]] = fsub double [[TMP44]], [[TMP47]], !dbg [[DBG50:![0-9]+]]
// LIN64-NEXT:    store double [[SUB29]], double* [[ATOMIC_TEMP28]], align 8, !dbg [[DBG49]]
// LIN64-NEXT:    [[TMP48:%.*]] = load i64, i64* [[TMP46]], align 8, !dbg [[DBG49]]
// LIN64-NEXT:    [[TMP49:%.*]] = cmpxchg i64* bitcast (double* @dx to i64*), i64 [[TMP45]], i64 [[TMP48]] monotonic monotonic, align 8, !dbg [[DBG49]]
// LIN64-NEXT:    [[TMP50]] = extractvalue { i64, i1 } [[TMP49]], 0, !dbg [[DBG49]]
// LIN64-NEXT:    [[TMP51:%.*]] = extractvalue { i64, i1 } [[TMP49]], 1, !dbg [[DBG49]]
// LIN64-NEXT:    br i1 [[TMP51]], label [[ATOMIC_EXIT30:%.*]], label [[ATOMIC_CONT27]], !dbg [[DBG49]]
// LIN64:       atomic_exit30:
// LIN64-NEXT:    [[CONV31:%.*]] = fptrunc double [[TMP47]] to float, !dbg [[DBG49]]
// LIN64-NEXT:    store float [[CONV31]], float* @fv, align 4, !dbg [[DBG49]]
// LIN64-NEXT:    [[TMP52:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG51:![0-9]+]]
// LIN64-NEXT:    [[TMP53:%.*]] = bitcast x86_fp80* [[ATOMIC_TEMP32]] to i8*, !dbg [[DBG52:![0-9]+]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 16, i8* noundef bitcast (x86_fp80* @ldx to i8*), i8* noundef [[TMP53]], i32 noundef 0), !dbg [[DBG52]]
// LIN64-NEXT:    br label [[ATOMIC_CONT33:%.*]], !dbg [[DBG52]]
// LIN64:       atomic_cont33:
// LIN64-NEXT:    [[TMP54:%.*]] = load x86_fp80, x86_fp80* [[ATOMIC_TEMP32]], align 16, !dbg [[DBG52]]
// LIN64-NEXT:    store x86_fp80 [[TMP54]], x86_fp80* [[ATOMIC_TEMP34]], align 16, !dbg [[DBG52]]
// LIN64-NEXT:    [[TMP55:%.*]] = load x86_fp80, x86_fp80* [[ATOMIC_TEMP32]], align 16, !dbg [[DBG52]]
// LIN64-NEXT:    [[MUL35:%.*]] = fmul x86_fp80 [[TMP55]], [[TMP52]], !dbg [[DBG53:![0-9]+]]
// LIN64-NEXT:    store x86_fp80 [[MUL35]], x86_fp80* [[ATOMIC_TEMP34]], align 16, !dbg [[DBG52]]
// LIN64-NEXT:    [[TMP56:%.*]] = bitcast x86_fp80* [[ATOMIC_TEMP32]] to i8*, !dbg [[DBG52]]
// LIN64-NEXT:    [[TMP57:%.*]] = bitcast x86_fp80* [[ATOMIC_TEMP34]] to i8*, !dbg [[DBG52]]
// LIN64-NEXT:    [[CALL:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, i8* noundef bitcast (x86_fp80* @ldx to i8*), i8* noundef [[TMP56]], i8* noundef [[TMP57]], i32 noundef 0, i32 noundef 0), !dbg [[DBG52]]
// LIN64-NEXT:    br i1 [[CALL]], label [[ATOMIC_EXIT36:%.*]], label [[ATOMIC_CONT33]], !dbg [[DBG52]]
// LIN64:       atomic_exit36:
// LIN64-NEXT:    [[CONV37:%.*]] = fptrunc x86_fp80 [[MUL35]] to double, !dbg [[DBG52]]
// LIN64-NEXT:    store double [[CONV37]], double* @dv, align 8, !dbg [[DBG52]]
// LIN64-NEXT:    [[CIV_REAL:%.*]] = load i32, i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 0), align 4, !dbg [[DBG54:![0-9]+]]
// LIN64-NEXT:    [[CIV_IMAG:%.*]] = load i32, i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 1), align 4, !dbg [[DBG54]]
// LIN64-NEXT:    [[TMP58:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP38]] to i8*, !dbg [[DBG55:![0-9]+]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP58]], i32 noundef 0), !dbg [[DBG55]]
// LIN64-NEXT:    br label [[ATOMIC_CONT39:%.*]], !dbg [[DBG55]]
// LIN64:       atomic_cont39:
// LIN64-NEXT:    [[ATOMIC_TEMP38_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP38]], i32 0, i32 0, !dbg [[DBG55]]
// LIN64-NEXT:    [[ATOMIC_TEMP38_REAL:%.*]] = load i32, i32* [[ATOMIC_TEMP38_REALP]], align 4, !dbg [[DBG55]]
// LIN64-NEXT:    [[ATOMIC_TEMP38_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP38]], i32 0, i32 1, !dbg [[DBG55]]
// LIN64-NEXT:    [[ATOMIC_TEMP38_IMAG:%.*]] = load i32, i32* [[ATOMIC_TEMP38_IMAGP]], align 4, !dbg [[DBG55]]
// LIN64-NEXT:    [[TMP59:%.*]] = mul i32 [[CIV_REAL]], [[ATOMIC_TEMP38_REAL]], !dbg [[DBG56:![0-9]+]]
// LIN64-NEXT:    [[TMP60:%.*]] = mul i32 [[CIV_IMAG]], [[ATOMIC_TEMP38_IMAG]], !dbg [[DBG56]]
// LIN64-NEXT:    [[TMP61:%.*]] = add i32 [[TMP59]], [[TMP60]], !dbg [[DBG56]]
// LIN64-NEXT:    [[TMP62:%.*]] = mul i32 [[ATOMIC_TEMP38_REAL]], [[ATOMIC_TEMP38_REAL]], !dbg [[DBG56]]
// LIN64-NEXT:    [[TMP63:%.*]] = mul i32 [[ATOMIC_TEMP38_IMAG]], [[ATOMIC_TEMP38_IMAG]], !dbg [[DBG56]]
// LIN64-NEXT:    [[TMP64:%.*]] = add i32 [[TMP62]], [[TMP63]], !dbg [[DBG56]]
// LIN64-NEXT:    [[TMP65:%.*]] = mul i32 [[CIV_IMAG]], [[ATOMIC_TEMP38_REAL]], !dbg [[DBG56]]
// LIN64-NEXT:    [[TMP66:%.*]] = mul i32 [[CIV_REAL]], [[ATOMIC_TEMP38_IMAG]], !dbg [[DBG56]]
// LIN64-NEXT:    [[TMP67:%.*]] = sub i32 [[TMP65]], [[TMP66]], !dbg [[DBG56]]
// LIN64-NEXT:    [[TMP68:%.*]] = sdiv i32 [[TMP61]], [[TMP64]], !dbg [[DBG56]]
// LIN64-NEXT:    [[TMP69:%.*]] = sdiv i32 [[TMP67]], [[TMP64]], !dbg [[DBG56]]
// LIN64-NEXT:    [[ATOMIC_TEMP40_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP40]], i32 0, i32 0, !dbg [[DBG55]]
// LIN64-NEXT:    [[ATOMIC_TEMP40_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP40]], i32 0, i32 1, !dbg [[DBG55]]
// LIN64-NEXT:    store i32 [[TMP68]], i32* [[ATOMIC_TEMP40_REALP]], align 4, !dbg [[DBG55]]
// LIN64-NEXT:    store i32 [[TMP69]], i32* [[ATOMIC_TEMP40_IMAGP]], align 4, !dbg [[DBG55]]
// LIN64-NEXT:    [[TMP70:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP38]] to i8*, !dbg [[DBG55]]
// LIN64-NEXT:    [[TMP71:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP40]] to i8*, !dbg [[DBG55]]
// LIN64-NEXT:    [[CALL41:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP70]], i8* noundef [[TMP71]], i32 noundef 0, i32 noundef 0), !dbg [[DBG55]]
// LIN64-NEXT:    br i1 [[CALL41]], label [[ATOMIC_EXIT42:%.*]], label [[ATOMIC_CONT39]], !dbg [[DBG55]]
// LIN64:       atomic_exit42:
// LIN64-NEXT:    [[CONV43:%.*]] = sitofp i32 [[TMP68]] to float, !dbg [[DBG55]]
// LIN64-NEXT:    [[CONV44:%.*]] = sitofp i32 [[TMP69]] to float, !dbg [[DBG55]]
// LIN64-NEXT:    store float [[CONV43]], float* getelementptr inbounds ({ float, float }, { float, float }* @cfv, i32 0, i32 0), align 4, !dbg [[DBG55]]
// LIN64-NEXT:    store float [[CONV44]], float* getelementptr inbounds ({ float, float }, { float, float }* @cfv, i32 0, i32 1), align 4, !dbg [[DBG55]]
// LIN64-NEXT:    [[CFV_REAL:%.*]] = load float, float* getelementptr inbounds ({ float, float }, { float, float }* @cfv, i32 0, i32 0), align 4, !dbg [[DBG57:![0-9]+]]
// LIN64-NEXT:    [[CFV_IMAG:%.*]] = load float, float* getelementptr inbounds ({ float, float }, { float, float }* @cfv, i32 0, i32 1), align 4, !dbg [[DBG57]]
// LIN64-NEXT:    [[TMP72:%.*]] = bitcast { float, float }* [[ATOMIC_TEMP45]] to i8*, !dbg [[DBG58:![0-9]+]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 8, i8* noundef bitcast ({ float, float }* @cfx to i8*), i8* noundef [[TMP72]], i32 noundef 0), !dbg [[DBG58]]
// LIN64-NEXT:    br label [[ATOMIC_CONT46:%.*]], !dbg [[DBG58]]
// LIN64:       atomic_cont46:
// LIN64-NEXT:    [[ATOMIC_TEMP45_REALP:%.*]] = getelementptr inbounds { float, float }, { float, float }* [[ATOMIC_TEMP45]], i32 0, i32 0, !dbg [[DBG58]]
// LIN64-NEXT:    [[ATOMIC_TEMP45_REAL:%.*]] = load float, float* [[ATOMIC_TEMP45_REALP]], align 4, !dbg [[DBG58]]
// LIN64-NEXT:    [[ATOMIC_TEMP45_IMAGP:%.*]] = getelementptr inbounds { float, float }, { float, float }* [[ATOMIC_TEMP45]], i32 0, i32 1, !dbg [[DBG58]]
// LIN64-NEXT:    [[ATOMIC_TEMP45_IMAG:%.*]] = load float, float* [[ATOMIC_TEMP45_IMAGP]], align 4, !dbg [[DBG58]]
// LIN64-NEXT:    [[ADD_R:%.*]] = fadd float [[CFV_REAL]], [[ATOMIC_TEMP45_REAL]], !dbg [[DBG59:![0-9]+]]
// LIN64-NEXT:    [[ADD_I:%.*]] = fadd float [[CFV_IMAG]], [[ATOMIC_TEMP45_IMAG]], !dbg [[DBG59]]
// LIN64-NEXT:    [[ATOMIC_TEMP47_REALP:%.*]] = getelementptr inbounds { float, float }, { float, float }* [[ATOMIC_TEMP47]], i32 0, i32 0, !dbg [[DBG58]]
// LIN64-NEXT:    [[ATOMIC_TEMP47_IMAGP:%.*]] = getelementptr inbounds { float, float }, { float, float }* [[ATOMIC_TEMP47]], i32 0, i32 1, !dbg [[DBG58]]
// LIN64-NEXT:    store float [[ADD_R]], float* [[ATOMIC_TEMP47_REALP]], align 4, !dbg [[DBG58]]
// LIN64-NEXT:    store float [[ADD_I]], float* [[ATOMIC_TEMP47_IMAGP]], align 4, !dbg [[DBG58]]
// LIN64-NEXT:    [[TMP73:%.*]] = bitcast { float, float }* [[ATOMIC_TEMP45]] to i8*, !dbg [[DBG58]]
// LIN64-NEXT:    [[TMP74:%.*]] = bitcast { float, float }* [[ATOMIC_TEMP47]] to i8*, !dbg [[DBG58]]
// LIN64-NEXT:    [[CALL48:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, i8* noundef bitcast ({ float, float }* @cfx to i8*), i8* noundef [[TMP73]], i8* noundef [[TMP74]], i32 noundef 0, i32 noundef 0), !dbg [[DBG58]]
// LIN64-NEXT:    br i1 [[CALL48]], label [[ATOMIC_EXIT49:%.*]], label [[ATOMIC_CONT46]], !dbg [[DBG58]]
// LIN64:       atomic_exit49:
// LIN64-NEXT:    [[CONV50:%.*]] = fptosi float [[ATOMIC_TEMP45_REAL]] to i32, !dbg [[DBG58]]
// LIN64-NEXT:    [[CONV51:%.*]] = fptosi float [[ATOMIC_TEMP45_IMAG]] to i32, !dbg [[DBG58]]
// LIN64-NEXT:    store i32 [[CONV50]], i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 0), align 4, !dbg [[DBG58]]
// LIN64-NEXT:    store i32 [[CONV51]], i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 1), align 4, !dbg [[DBG58]]
// LIN64-NEXT:    [[CDV_REAL:%.*]] = load double, double* getelementptr inbounds ({ double, double }, { double, double }* @cdv, i32 0, i32 0), align 8, !dbg [[DBG60:![0-9]+]]
// LIN64-NEXT:    [[CDV_IMAG:%.*]] = load double, double* getelementptr inbounds ({ double, double }, { double, double }* @cdv, i32 0, i32 1), align 8, !dbg [[DBG60]]
// LIN64-NEXT:    [[TMP75:%.*]] = bitcast { double, double }* [[ATOMIC_TEMP52]] to i8*, !dbg [[DBG61:![0-9]+]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 16, i8* noundef bitcast ({ double, double }* @cdx to i8*), i8* noundef [[TMP75]], i32 noundef 5), !dbg [[DBG61]]
// LIN64-NEXT:    br label [[ATOMIC_CONT53:%.*]], !dbg [[DBG61]]
// LIN64:       atomic_cont53:
// LIN64-NEXT:    [[ATOMIC_TEMP52_REALP:%.*]] = getelementptr inbounds { double, double }, { double, double }* [[ATOMIC_TEMP52]], i32 0, i32 0, !dbg [[DBG61]]
// LIN64-NEXT:    [[ATOMIC_TEMP52_REAL:%.*]] = load double, double* [[ATOMIC_TEMP52_REALP]], align 8, !dbg [[DBG61]]
// LIN64-NEXT:    [[ATOMIC_TEMP52_IMAGP:%.*]] = getelementptr inbounds { double, double }, { double, double }* [[ATOMIC_TEMP52]], i32 0, i32 1, !dbg [[DBG61]]
// LIN64-NEXT:    [[ATOMIC_TEMP52_IMAG:%.*]] = load double, double* [[ATOMIC_TEMP52_IMAGP]], align 8, !dbg [[DBG61]]
// LIN64-NEXT:    [[SUB_R:%.*]] = fsub double [[ATOMIC_TEMP52_REAL]], [[CDV_REAL]], !dbg [[DBG62:![0-9]+]]
// LIN64-NEXT:    [[SUB_I:%.*]] = fsub double [[ATOMIC_TEMP52_IMAG]], [[CDV_IMAG]], !dbg [[DBG62]]
// LIN64-NEXT:    [[ATOMIC_TEMP54_REALP:%.*]] = getelementptr inbounds { double, double }, { double, double }* [[ATOMIC_TEMP54]], i32 0, i32 0, !dbg [[DBG61]]
// LIN64-NEXT:    [[ATOMIC_TEMP54_IMAGP:%.*]] = getelementptr inbounds { double, double }, { double, double }* [[ATOMIC_TEMP54]], i32 0, i32 1, !dbg [[DBG61]]
// LIN64-NEXT:    store double [[SUB_R]], double* [[ATOMIC_TEMP54_REALP]], align 8, !dbg [[DBG61]]
// LIN64-NEXT:    store double [[SUB_I]], double* [[ATOMIC_TEMP54_IMAGP]], align 8, !dbg [[DBG61]]
// LIN64-NEXT:    [[TMP76:%.*]] = bitcast { double, double }* [[ATOMIC_TEMP52]] to i8*, !dbg [[DBG61]]
// LIN64-NEXT:    [[TMP77:%.*]] = bitcast { double, double }* [[ATOMIC_TEMP54]] to i8*, !dbg [[DBG61]]
// LIN64-NEXT:    [[CALL55:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, i8* noundef bitcast ({ double, double }* @cdx to i8*), i8* noundef [[TMP76]], i8* noundef [[TMP77]], i32 noundef 5, i32 noundef 5), !dbg [[DBG61]]
// LIN64-NEXT:    br i1 [[CALL55]], label [[ATOMIC_EXIT56:%.*]], label [[ATOMIC_CONT53]], !dbg [[DBG61]]
// LIN64:       atomic_exit56:
// LIN64-NEXT:    [[CONV57:%.*]] = fptrunc double [[SUB_R]] to float, !dbg [[DBG61]]
// LIN64-NEXT:    [[CONV58:%.*]] = fptrunc double [[SUB_I]] to float, !dbg [[DBG61]]
// LIN64-NEXT:    store float [[CONV57]], float* getelementptr inbounds ({ float, float }, { float, float }* @cfv, i32 0, i32 0), align 4, !dbg [[DBG61]]
// LIN64-NEXT:    store float [[CONV58]], float* getelementptr inbounds ({ float, float }, { float, float }* @cfv, i32 0, i32 1), align 4, !dbg [[DBG61]]
// LIN64-NEXT:    [[TMP78:%.*]] = load i8, i8* @bv, align 1, !dbg [[DBG63:![0-9]+]]
// LIN64-NEXT:    [[TOBOOL:%.*]] = trunc i8 [[TMP78]] to i1, !dbg [[DBG63]]
// LIN64-NEXT:    [[CONV59:%.*]] = zext i1 [[TOBOOL]] to i64, !dbg [[DBG63]]
// LIN64-NEXT:    [[TMP79:%.*]] = atomicrmw and i64* @ulx, i64 [[CONV59]] monotonic, align 8, !dbg [[DBG64:![0-9]+]]
// LIN64-NEXT:    [[AND60:%.*]] = and i64 [[TMP79]], [[CONV59]], !dbg [[DBG65:![0-9]+]]
// LIN64-NEXT:    store i64 [[AND60]], i64* @ulv, align 8, !dbg [[DBG64]]
// LIN64-NEXT:    [[TMP80:%.*]] = load i8, i8* @cv, align 1, !dbg [[DBG66:![0-9]+]]
// LIN64-NEXT:    [[CONV61:%.*]] = sext i8 [[TMP80]] to i32, !dbg [[DBG66]]
// LIN64-NEXT:    [[ATOMIC_LOAD62:%.*]] = load atomic i8, i8* @bx monotonic, align 1, !dbg [[DBG67:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT63:%.*]], !dbg [[DBG67]]
// LIN64:       atomic_cont63:
// LIN64-NEXT:    [[TMP81:%.*]] = phi i8 [ [[ATOMIC_LOAD62]], [[ATOMIC_EXIT56]] ], [ [[TMP84:%.*]], [[ATOMIC_CONT63]] ], !dbg [[DBG67]]
// LIN64-NEXT:    [[TOBOOL65:%.*]] = trunc i8 [[TMP81]] to i1, !dbg [[DBG67]]
// LIN64-NEXT:    [[CONV66:%.*]] = zext i1 [[TOBOOL65]] to i32, !dbg [[DBG68:![0-9]+]]
// LIN64-NEXT:    [[AND67:%.*]] = and i32 [[CONV61]], [[CONV66]], !dbg [[DBG69:![0-9]+]]
// LIN64-NEXT:    [[TOBOOL68:%.*]] = icmp ne i32 [[AND67]], 0, !dbg [[DBG66]]
// LIN64-NEXT:    [[FROMBOOL:%.*]] = zext i1 [[TOBOOL68]] to i8, !dbg [[DBG67]]
// LIN64-NEXT:    store i8 [[FROMBOOL]], i8* [[ATOMIC_TEMP64]], align 1, !dbg [[DBG67]]
// LIN64-NEXT:    [[TMP82:%.*]] = load i8, i8* [[ATOMIC_TEMP64]], align 1, !dbg [[DBG67]]
// LIN64-NEXT:    [[TMP83:%.*]] = cmpxchg i8* @bx, i8 [[TMP81]], i8 [[TMP82]] monotonic monotonic, align 1, !dbg [[DBG67]]
// LIN64-NEXT:    [[TMP84]] = extractvalue { i8, i1 } [[TMP83]], 0, !dbg [[DBG67]]
// LIN64-NEXT:    [[TMP85:%.*]] = extractvalue { i8, i1 } [[TMP83]], 1, !dbg [[DBG67]]
// LIN64-NEXT:    br i1 [[TMP85]], label [[ATOMIC_EXIT69:%.*]], label [[ATOMIC_CONT63]], !dbg [[DBG67]]
// LIN64:       atomic_exit69:
// LIN64-NEXT:    [[FROMBOOL70:%.*]] = zext i1 [[TOBOOL65]] to i8, !dbg [[DBG67]]
// LIN64-NEXT:    store i8 [[FROMBOOL70]], i8* @bv, align 1, !dbg [[DBG67]]
// LIN64-NEXT:    [[TMP86:%.*]] = load i8, i8* @ucv, align 1, !dbg [[DBG70:![0-9]+]]
// LIN64-NEXT:    [[CONV71:%.*]] = zext i8 [[TMP86]] to i32, !dbg [[DBG70]]
// LIN64-NEXT:    [[ATOMIC_LOAD72:%.*]] = load atomic i8, i8* @cx seq_cst, align 1, !dbg [[DBG71:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT73:%.*]], !dbg [[DBG71]]
// LIN64:       atomic_cont73:
// LIN64-NEXT:    [[TMP87:%.*]] = phi i8 [ [[ATOMIC_LOAD72]], [[ATOMIC_EXIT69]] ], [ [[TMP90:%.*]], [[ATOMIC_CONT73]] ], !dbg [[DBG71]]
// LIN64-NEXT:    [[CONV75:%.*]] = sext i8 [[TMP87]] to i32, !dbg [[DBG72:![0-9]+]]
// LIN64-NEXT:    [[SHR76:%.*]] = ashr i32 [[CONV75]], [[CONV71]], !dbg [[DBG73:![0-9]+]]
// LIN64-NEXT:    [[CONV77:%.*]] = trunc i32 [[SHR76]] to i8, !dbg [[DBG72]]
// LIN64-NEXT:    store i8 [[CONV77]], i8* [[ATOMIC_TEMP74]], align 1, !dbg [[DBG71]]
// LIN64-NEXT:    [[TMP88:%.*]] = load i8, i8* [[ATOMIC_TEMP74]], align 1, !dbg [[DBG71]]
// LIN64-NEXT:    [[TMP89:%.*]] = cmpxchg i8* @cx, i8 [[TMP87]], i8 [[TMP88]] seq_cst seq_cst, align 1, !dbg [[DBG71]]
// LIN64-NEXT:    [[TMP90]] = extractvalue { i8, i1 } [[TMP89]], 0, !dbg [[DBG71]]
// LIN64-NEXT:    [[TMP91:%.*]] = extractvalue { i8, i1 } [[TMP89]], 1, !dbg [[DBG71]]
// LIN64-NEXT:    br i1 [[TMP91]], label [[ATOMIC_EXIT78:%.*]], label [[ATOMIC_CONT73]], !dbg [[DBG71]]
// LIN64:       atomic_exit78:
// LIN64-NEXT:    store i8 [[CONV77]], i8* @cv, align 1, !dbg [[DBG71]]
// LIN64-NEXT:    [[TMP92:%.*]] = load i16, i16* @sv, align 2, !dbg [[DBG74:![0-9]+]]
// LIN64-NEXT:    [[CONV79:%.*]] = sext i16 [[TMP92]] to i32, !dbg [[DBG74]]
// LIN64-NEXT:    [[ATOMIC_LOAD80:%.*]] = load atomic i64, i64* @ulx monotonic, align 8, !dbg [[DBG75:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT81:%.*]], !dbg [[DBG75]]
// LIN64:       atomic_cont81:
// LIN64-NEXT:    [[TMP93:%.*]] = phi i64 [ [[ATOMIC_LOAD80]], [[ATOMIC_EXIT78]] ], [ [[TMP96:%.*]], [[ATOMIC_CONT81]] ], !dbg [[DBG75]]
// LIN64-NEXT:    [[SH_PROM:%.*]] = trunc i64 [[TMP93]] to i32, !dbg [[DBG76:![0-9]+]]
// LIN64-NEXT:    [[SHL83:%.*]] = shl i32 [[CONV79]], [[SH_PROM]], !dbg [[DBG76]]
// LIN64-NEXT:    [[CONV84:%.*]] = sext i32 [[SHL83]] to i64, !dbg [[DBG74]]
// LIN64-NEXT:    store i64 [[CONV84]], i64* [[ATOMIC_TEMP82]], align 8, !dbg [[DBG75]]
// LIN64-NEXT:    [[TMP94:%.*]] = load i64, i64* [[ATOMIC_TEMP82]], align 8, !dbg [[DBG75]]
// LIN64-NEXT:    [[TMP95:%.*]] = cmpxchg i64* @ulx, i64 [[TMP93]], i64 [[TMP94]] monotonic monotonic, align 8, !dbg [[DBG75]]
// LIN64-NEXT:    [[TMP96]] = extractvalue { i64, i1 } [[TMP95]], 0, !dbg [[DBG75]]
// LIN64-NEXT:    [[TMP97:%.*]] = extractvalue { i64, i1 } [[TMP95]], 1, !dbg [[DBG75]]
// LIN64-NEXT:    br i1 [[TMP97]], label [[ATOMIC_EXIT85:%.*]], label [[ATOMIC_CONT81]], !dbg [[DBG75]]
// LIN64:       atomic_exit85:
// LIN64-NEXT:    store i64 [[CONV84]], i64* @ulv, align 8, !dbg [[DBG75]]
// LIN64-NEXT:    [[TMP98:%.*]] = load i16, i16* @usv, align 2, !dbg [[DBG77:![0-9]+]]
// LIN64-NEXT:    [[CONV86:%.*]] = zext i16 [[TMP98]] to i64, !dbg [[DBG77]]
// LIN64-NEXT:    [[ATOMIC_LOAD87:%.*]] = load atomic i64, i64* @lx monotonic, align 8, !dbg [[DBG78:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT88:%.*]], !dbg [[DBG78]]
// LIN64:       atomic_cont88:
// LIN64-NEXT:    [[TMP99:%.*]] = phi i64 [ [[ATOMIC_LOAD87]], [[ATOMIC_EXIT85]] ], [ [[TMP102:%.*]], [[ATOMIC_CONT88]] ], !dbg [[DBG78]]
// LIN64-NEXT:    [[REM:%.*]] = srem i64 [[TMP99]], [[CONV86]], !dbg [[DBG79:![0-9]+]]
// LIN64-NEXT:    store i64 [[REM]], i64* [[ATOMIC_TEMP89]], align 8, !dbg [[DBG78]]
// LIN64-NEXT:    [[TMP100:%.*]] = load i64, i64* [[ATOMIC_TEMP89]], align 8, !dbg [[DBG78]]
// LIN64-NEXT:    [[TMP101:%.*]] = cmpxchg i64* @lx, i64 [[TMP99]], i64 [[TMP100]] monotonic monotonic, align 8, !dbg [[DBG78]]
// LIN64-NEXT:    [[TMP102]] = extractvalue { i64, i1 } [[TMP101]], 0, !dbg [[DBG78]]
// LIN64-NEXT:    [[TMP103:%.*]] = extractvalue { i64, i1 } [[TMP101]], 1, !dbg [[DBG78]]
// LIN64-NEXT:    br i1 [[TMP103]], label [[ATOMIC_EXIT90:%.*]], label [[ATOMIC_CONT88]], !dbg [[DBG78]]
// LIN64:       atomic_exit90:
// LIN64-NEXT:    store i64 [[TMP99]], i64* @lv, align 8, !dbg [[DBG78]]
// LIN64-NEXT:    [[TMP104:%.*]] = load i32, i32* @iv, align 4, !dbg [[DBG80:![0-9]+]]
// LIN64-NEXT:    [[TMP105:%.*]] = atomicrmw or i32* @uix, i32 [[TMP104]] seq_cst, align 4, !dbg [[DBG81:![0-9]+]]
// LIN64-NEXT:    [[OR91:%.*]] = or i32 [[TMP104]], [[TMP105]], !dbg [[DBG82:![0-9]+]]
// LIN64-NEXT:    store i32 [[OR91]], i32* @uiv, align 4, !dbg [[DBG81]]
// LIN64-NEXT:    [[TMP106:%.*]] = load i32, i32* @uiv, align 4, !dbg [[DBG83:![0-9]+]]
// LIN64-NEXT:    [[TMP107:%.*]] = atomicrmw and i32* @ix, i32 [[TMP106]] monotonic, align 4, !dbg [[DBG84:![0-9]+]]
// LIN64-NEXT:    [[AND92:%.*]] = and i32 [[TMP107]], [[TMP106]], !dbg [[DBG85:![0-9]+]]
// LIN64-NEXT:    store i32 [[AND92]], i32* @iv, align 4, !dbg [[DBG84]]
// LIN64-NEXT:    [[TMP108:%.*]] = load i64, i64* @lv, align 8, !dbg [[DBG86:![0-9]+]]
// LIN64-NEXT:    [[TMP109:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP93]] to i8*, !dbg [[DBG87:![0-9]+]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP109]], i32 noundef 0), !dbg [[DBG87]]
// LIN64-NEXT:    br label [[ATOMIC_CONT94:%.*]], !dbg [[DBG87]]
// LIN64:       atomic_cont94:
// LIN64-NEXT:    [[ATOMIC_TEMP93_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP93]], i32 0, i32 0, !dbg [[DBG87]]
// LIN64-NEXT:    [[ATOMIC_TEMP93_REAL:%.*]] = load i32, i32* [[ATOMIC_TEMP93_REALP]], align 4, !dbg [[DBG87]]
// LIN64-NEXT:    [[ATOMIC_TEMP93_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP93]], i32 0, i32 1, !dbg [[DBG87]]
// LIN64-NEXT:    [[ATOMIC_TEMP93_IMAG:%.*]] = load i32, i32* [[ATOMIC_TEMP93_IMAGP]], align 4, !dbg [[DBG87]]
// LIN64-NEXT:    [[CONV96:%.*]] = sext i32 [[ATOMIC_TEMP93_REAL]] to i64, !dbg [[DBG88:![0-9]+]]
// LIN64-NEXT:    [[CONV97:%.*]] = sext i32 [[ATOMIC_TEMP93_IMAG]] to i64, !dbg [[DBG88]]
// LIN64-NEXT:    [[ADD_R98:%.*]] = add i64 [[TMP108]], [[CONV96]], !dbg [[DBG89:![0-9]+]]
// LIN64-NEXT:    [[ADD_I99:%.*]] = add i64 0, [[CONV97]], !dbg [[DBG89]]
// LIN64-NEXT:    [[CONV100:%.*]] = trunc i64 [[ADD_R98]] to i32, !dbg [[DBG86]]
// LIN64-NEXT:    [[CONV101:%.*]] = trunc i64 [[ADD_I99]] to i32, !dbg [[DBG86]]
// LIN64-NEXT:    [[ATOMIC_TEMP95_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP95]], i32 0, i32 0, !dbg [[DBG87]]
// LIN64-NEXT:    [[ATOMIC_TEMP95_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP95]], i32 0, i32 1, !dbg [[DBG87]]
// LIN64-NEXT:    store i32 [[CONV100]], i32* [[ATOMIC_TEMP95_REALP]], align 4, !dbg [[DBG87]]
// LIN64-NEXT:    store i32 [[CONV101]], i32* [[ATOMIC_TEMP95_IMAGP]], align 4, !dbg [[DBG87]]
// LIN64-NEXT:    [[TMP110:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP93]] to i8*, !dbg [[DBG87]]
// LIN64-NEXT:    [[TMP111:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP95]] to i8*, !dbg [[DBG87]]
// LIN64-NEXT:    [[CALL102:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP110]], i8* noundef [[TMP111]], i32 noundef 0, i32 noundef 0), !dbg [[DBG87]]
// LIN64-NEXT:    br i1 [[CALL102]], label [[ATOMIC_EXIT103:%.*]], label [[ATOMIC_CONT94]], !dbg [[DBG87]]
// LIN64:       atomic_exit103:
// LIN64-NEXT:    store i32 [[ATOMIC_TEMP93_REAL]], i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 0), align 4, !dbg [[DBG87]]
// LIN64-NEXT:    store i32 [[ATOMIC_TEMP93_IMAG]], i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 1), align 4, !dbg [[DBG87]]
// LIN64-NEXT:    [[TMP112:%.*]] = load i64, i64* @ulv, align 8, !dbg [[DBG90:![0-9]+]]
// LIN64-NEXT:    [[CONV104:%.*]] = uitofp i64 [[TMP112]] to float, !dbg [[DBG90]]
// LIN64-NEXT:    [[ATOMIC_LOAD105:%.*]] = load atomic i32, i32* bitcast (float* @fx to i32*) monotonic, align 4, !dbg [[DBG91:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT106:%.*]], !dbg [[DBG91]]
// LIN64:       atomic_cont106:
// LIN64-NEXT:    [[TMP113:%.*]] = phi i32 [ [[ATOMIC_LOAD105]], [[ATOMIC_EXIT103]] ], [ [[TMP118:%.*]], [[ATOMIC_CONT106]] ], !dbg [[DBG91]]
// LIN64-NEXT:    [[TMP114:%.*]] = bitcast float* [[ATOMIC_TEMP107]] to i32*, !dbg [[DBG91]]
// LIN64-NEXT:    [[TMP115:%.*]] = bitcast i32 [[TMP113]] to float, !dbg [[DBG91]]
// LIN64-NEXT:    [[MUL108:%.*]] = fmul float [[TMP115]], [[CONV104]], !dbg [[DBG92:![0-9]+]]
// LIN64-NEXT:    store float [[MUL108]], float* [[ATOMIC_TEMP107]], align 4, !dbg [[DBG91]]
// LIN64-NEXT:    [[TMP116:%.*]] = load i32, i32* [[TMP114]], align 4, !dbg [[DBG91]]
// LIN64-NEXT:    [[TMP117:%.*]] = cmpxchg i32* bitcast (float* @fx to i32*), i32 [[TMP113]], i32 [[TMP116]] monotonic monotonic, align 4, !dbg [[DBG91]]
// LIN64-NEXT:    [[TMP118]] = extractvalue { i32, i1 } [[TMP117]], 0, !dbg [[DBG91]]
// LIN64-NEXT:    [[TMP119:%.*]] = extractvalue { i32, i1 } [[TMP117]], 1, !dbg [[DBG91]]
// LIN64-NEXT:    br i1 [[TMP119]], label [[ATOMIC_EXIT109:%.*]], label [[ATOMIC_CONT106]], !dbg [[DBG91]]
// LIN64:       atomic_exit109:
// LIN64-NEXT:    store float [[MUL108]], float* @fv, align 4, !dbg [[DBG91]]
// LIN64-NEXT:    [[TMP120:%.*]] = load i64, i64* @llv, align 8, !dbg [[DBG93:![0-9]+]]
// LIN64-NEXT:    [[CONV110:%.*]] = sitofp i64 [[TMP120]] to double, !dbg [[DBG93]]
// LIN64-NEXT:    [[ATOMIC_LOAD111:%.*]] = load atomic i64, i64* bitcast (double* @dx to i64*) monotonic, align 8, !dbg [[DBG94:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT112:%.*]], !dbg [[DBG94]]
// LIN64:       atomic_cont112:
// LIN64-NEXT:    [[TMP121:%.*]] = phi i64 [ [[ATOMIC_LOAD111]], [[ATOMIC_EXIT109]] ], [ [[TMP126:%.*]], [[ATOMIC_CONT112]] ], !dbg [[DBG94]]
// LIN64-NEXT:    [[TMP122:%.*]] = bitcast double* [[ATOMIC_TEMP113]] to i64*, !dbg [[DBG94]]
// LIN64-NEXT:    [[TMP123:%.*]] = bitcast i64 [[TMP121]] to double, !dbg [[DBG94]]
// LIN64-NEXT:    [[DIV114:%.*]] = fdiv double [[TMP123]], [[CONV110]], !dbg [[DBG95:![0-9]+]]
// LIN64-NEXT:    store double [[DIV114]], double* [[ATOMIC_TEMP113]], align 8, !dbg [[DBG94]]
// LIN64-NEXT:    [[TMP124:%.*]] = load i64, i64* [[TMP122]], align 8, !dbg [[DBG94]]
// LIN64-NEXT:    [[TMP125:%.*]] = cmpxchg i64* bitcast (double* @dx to i64*), i64 [[TMP121]], i64 [[TMP124]] monotonic monotonic, align 8, !dbg [[DBG94]]
// LIN64-NEXT:    [[TMP126]] = extractvalue { i64, i1 } [[TMP125]], 0, !dbg [[DBG94]]
// LIN64-NEXT:    [[TMP127:%.*]] = extractvalue { i64, i1 } [[TMP125]], 1, !dbg [[DBG94]]
// LIN64-NEXT:    br i1 [[TMP127]], label [[ATOMIC_EXIT115:%.*]], label [[ATOMIC_CONT112]], !dbg [[DBG94]]
// LIN64:       atomic_exit115:
// LIN64-NEXT:    store double [[DIV114]], double* @dv, align 8, !dbg [[DBG94]]
// LIN64-NEXT:    [[TMP128:%.*]] = load i64, i64* @ullv, align 8, !dbg [[DBG96:![0-9]+]]
// LIN64-NEXT:    [[CONV116:%.*]] = uitofp i64 [[TMP128]] to x86_fp80, !dbg [[DBG96]]
// LIN64-NEXT:    [[TMP129:%.*]] = bitcast x86_fp80* [[ATOMIC_TEMP117]] to i8*, !dbg [[DBG97:![0-9]+]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 16, i8* noundef bitcast (x86_fp80* @ldx to i8*), i8* noundef [[TMP129]], i32 noundef 0), !dbg [[DBG97]]
// LIN64-NEXT:    br label [[ATOMIC_CONT118:%.*]], !dbg [[DBG97]]
// LIN64:       atomic_cont118:
// LIN64-NEXT:    [[TMP130:%.*]] = load x86_fp80, x86_fp80* [[ATOMIC_TEMP117]], align 16, !dbg [[DBG97]]
// LIN64-NEXT:    store x86_fp80 [[TMP130]], x86_fp80* [[ATOMIC_TEMP119]], align 16, !dbg [[DBG97]]
// LIN64-NEXT:    [[TMP131:%.*]] = load x86_fp80, x86_fp80* [[ATOMIC_TEMP117]], align 16, !dbg [[DBG97]]
// LIN64-NEXT:    [[SUB120:%.*]] = fsub x86_fp80 [[TMP131]], [[CONV116]], !dbg [[DBG98:![0-9]+]]
// LIN64-NEXT:    store x86_fp80 [[SUB120]], x86_fp80* [[ATOMIC_TEMP119]], align 16, !dbg [[DBG97]]
// LIN64-NEXT:    [[TMP132:%.*]] = bitcast x86_fp80* [[ATOMIC_TEMP117]] to i8*, !dbg [[DBG97]]
// LIN64-NEXT:    [[TMP133:%.*]] = bitcast x86_fp80* [[ATOMIC_TEMP119]] to i8*, !dbg [[DBG97]]
// LIN64-NEXT:    [[CALL121:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, i8* noundef bitcast (x86_fp80* @ldx to i8*), i8* noundef [[TMP132]], i8* noundef [[TMP133]], i32 noundef 0, i32 noundef 0), !dbg [[DBG97]]
// LIN64-NEXT:    br i1 [[CALL121]], label [[ATOMIC_EXIT122:%.*]], label [[ATOMIC_CONT118]], !dbg [[DBG97]]
// LIN64:       atomic_exit122:
// LIN64-NEXT:    store x86_fp80 [[TMP131]], x86_fp80* @ldv, align 16, !dbg [[DBG97]]
// LIN64-NEXT:    [[TMP134:%.*]] = load float, float* @fv, align 4, !dbg [[DBG99:![0-9]+]]
// LIN64-NEXT:    [[TMP135:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP123]] to i8*, !dbg [[DBG100:![0-9]+]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP135]], i32 noundef 0), !dbg [[DBG100]]
// LIN64-NEXT:    br label [[ATOMIC_CONT124:%.*]], !dbg [[DBG100]]
// LIN64:       atomic_cont124:
// LIN64-NEXT:    [[ATOMIC_TEMP123_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP123]], i32 0, i32 0, !dbg [[DBG100]]
// LIN64-NEXT:    [[ATOMIC_TEMP123_REAL:%.*]] = load i32, i32* [[ATOMIC_TEMP123_REALP]], align 4, !dbg [[DBG100]]
// LIN64-NEXT:    [[ATOMIC_TEMP123_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP123]], i32 0, i32 1, !dbg [[DBG100]]
// LIN64-NEXT:    [[ATOMIC_TEMP123_IMAG:%.*]] = load i32, i32* [[ATOMIC_TEMP123_IMAGP]], align 4, !dbg [[DBG100]]
// LIN64-NEXT:    [[CONV126:%.*]] = sitofp i32 [[ATOMIC_TEMP123_REAL]] to float, !dbg [[DBG101:![0-9]+]]
// LIN64-NEXT:    [[CONV127:%.*]] = sitofp i32 [[ATOMIC_TEMP123_IMAG]] to float, !dbg [[DBG101]]
// LIN64-NEXT:    [[CALL128:%.*]] = call <2 x float> @__divsc3(float noundef [[TMP134]], float noundef 0.000000e+00, float noundef [[CONV126]], float noundef [[CONV127]]) #[[ATTR4:[0-9]+]], !dbg [[DBG102:![0-9]+]]
// LIN64-NEXT:    [[TMP136:%.*]] = bitcast { float, float }* [[COERCE]] to <2 x float>*, !dbg [[DBG102]]
// LIN64-NEXT:    store <2 x float> [[CALL128]], <2 x float>* [[TMP136]], align 4, !dbg [[DBG102]]
// LIN64-NEXT:    [[COERCE_REALP:%.*]] = getelementptr inbounds { float, float }, { float, float }* [[COERCE]], i32 0, i32 0, !dbg [[DBG102]]
// LIN64-NEXT:    [[COERCE_REAL:%.*]] = load float, float* [[COERCE_REALP]], align 4, !dbg [[DBG102]]
// LIN64-NEXT:    [[COERCE_IMAGP:%.*]] = getelementptr inbounds { float, float }, { float, float }* [[COERCE]], i32 0, i32 1, !dbg [[DBG102]]
// LIN64-NEXT:    [[COERCE_IMAG:%.*]] = load float, float* [[COERCE_IMAGP]], align 4, !dbg [[DBG102]]
// LIN64-NEXT:    [[CONV129:%.*]] = fptosi float [[COERCE_REAL]] to i32, !dbg [[DBG99]]
// LIN64-NEXT:    [[CONV130:%.*]] = fptosi float [[COERCE_IMAG]] to i32, !dbg [[DBG99]]
// LIN64-NEXT:    [[ATOMIC_TEMP125_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP125]], i32 0, i32 0, !dbg [[DBG100]]
// LIN64-NEXT:    [[ATOMIC_TEMP125_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP125]], i32 0, i32 1, !dbg [[DBG100]]
// LIN64-NEXT:    store i32 [[CONV129]], i32* [[ATOMIC_TEMP125_REALP]], align 4, !dbg [[DBG100]]
// LIN64-NEXT:    store i32 [[CONV130]], i32* [[ATOMIC_TEMP125_IMAGP]], align 4, !dbg [[DBG100]]
// LIN64-NEXT:    [[TMP137:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP123]] to i8*, !dbg [[DBG100]]
// LIN64-NEXT:    [[TMP138:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP125]] to i8*, !dbg [[DBG100]]
// LIN64-NEXT:    [[CALL131:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP137]], i8* noundef [[TMP138]], i32 noundef 0, i32 noundef 0), !dbg [[DBG100]]
// LIN64-NEXT:    br i1 [[CALL131]], label [[ATOMIC_EXIT132:%.*]], label [[ATOMIC_CONT124]], !dbg [[DBG100]]
// LIN64:       atomic_exit132:
// LIN64-NEXT:    store i32 [[CONV129]], i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 0), align 4, !dbg [[DBG100]]
// LIN64-NEXT:    store i32 [[CONV130]], i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 1), align 4, !dbg [[DBG100]]
// LIN64-NEXT:    [[TMP139:%.*]] = load double, double* @dv, align 8, !dbg [[DBG103:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD133:%.*]] = load atomic i16, i16* @sx monotonic, align 2, !dbg [[DBG104:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT134:%.*]], !dbg [[DBG104]]
// LIN64:       atomic_cont134:
// LIN64-NEXT:    [[TMP140:%.*]] = phi i16 [ [[ATOMIC_LOAD133]], [[ATOMIC_EXIT132]] ], [ [[TMP143:%.*]], [[ATOMIC_CONT134]] ], !dbg [[DBG104]]
// LIN64-NEXT:    [[CONV136:%.*]] = sext i16 [[TMP140]] to i32, !dbg [[DBG105:![0-9]+]]
// LIN64-NEXT:    [[CONV137:%.*]] = sitofp i32 [[CONV136]] to double, !dbg [[DBG105]]
// LIN64-NEXT:    [[ADD138:%.*]] = fadd double [[CONV137]], [[TMP139]], !dbg [[DBG106:![0-9]+]]
// LIN64-NEXT:    [[CONV139:%.*]] = fptosi double [[ADD138]] to i16, !dbg [[DBG105]]
// LIN64-NEXT:    store i16 [[CONV139]], i16* [[ATOMIC_TEMP135]], align 2, !dbg [[DBG104]]
// LIN64-NEXT:    [[TMP141:%.*]] = load i16, i16* [[ATOMIC_TEMP135]], align 2, !dbg [[DBG104]]
// LIN64-NEXT:    [[TMP142:%.*]] = cmpxchg i16* @sx, i16 [[TMP140]], i16 [[TMP141]] monotonic monotonic, align 2, !dbg [[DBG104]]
// LIN64-NEXT:    [[TMP143]] = extractvalue { i16, i1 } [[TMP142]], 0, !dbg [[DBG104]]
// LIN64-NEXT:    [[TMP144:%.*]] = extractvalue { i16, i1 } [[TMP142]], 1, !dbg [[DBG104]]
// LIN64-NEXT:    br i1 [[TMP144]], label [[ATOMIC_EXIT140:%.*]], label [[ATOMIC_CONT134]], !dbg [[DBG104]]
// LIN64:       atomic_exit140:
// LIN64-NEXT:    store i16 [[CONV139]], i16* @sv, align 2, !dbg [[DBG104]]
// LIN64-NEXT:    [[TMP145:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG107:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD141:%.*]] = load atomic i8, i8* @bx monotonic, align 1, !dbg [[DBG108:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT142:%.*]], !dbg [[DBG108]]
// LIN64:       atomic_cont142:
// LIN64-NEXT:    [[TMP146:%.*]] = phi i8 [ [[ATOMIC_LOAD141]], [[ATOMIC_EXIT140]] ], [ [[TMP149:%.*]], [[ATOMIC_CONT142]] ], !dbg [[DBG108]]
// LIN64-NEXT:    [[TOBOOL144:%.*]] = trunc i8 [[TMP146]] to i1, !dbg [[DBG108]]
// LIN64-NEXT:    [[CONV145:%.*]] = zext i1 [[TOBOOL144]] to i32, !dbg [[DBG109:![0-9]+]]
// LIN64-NEXT:    [[CONV146:%.*]] = sitofp i32 [[CONV145]] to x86_fp80, !dbg [[DBG109]]
// LIN64-NEXT:    [[MUL147:%.*]] = fmul x86_fp80 [[TMP145]], [[CONV146]], !dbg [[DBG110:![0-9]+]]
// LIN64-NEXT:    [[TOBOOL148:%.*]] = fcmp une x86_fp80 [[MUL147]], 0xK00000000000000000000, !dbg [[DBG107]]
// LIN64-NEXT:    [[FROMBOOL149:%.*]] = zext i1 [[TOBOOL148]] to i8, !dbg [[DBG108]]
// LIN64-NEXT:    store i8 [[FROMBOOL149]], i8* [[ATOMIC_TEMP143]], align 1, !dbg [[DBG108]]
// LIN64-NEXT:    [[TMP147:%.*]] = load i8, i8* [[ATOMIC_TEMP143]], align 1, !dbg [[DBG108]]
// LIN64-NEXT:    [[TMP148:%.*]] = cmpxchg i8* @bx, i8 [[TMP146]], i8 [[TMP147]] monotonic monotonic, align 1, !dbg [[DBG108]]
// LIN64-NEXT:    [[TMP149]] = extractvalue { i8, i1 } [[TMP148]], 0, !dbg [[DBG108]]
// LIN64-NEXT:    [[TMP150:%.*]] = extractvalue { i8, i1 } [[TMP148]], 1, !dbg [[DBG108]]
// LIN64-NEXT:    br i1 [[TMP150]], label [[ATOMIC_EXIT150:%.*]], label [[ATOMIC_CONT142]], !dbg [[DBG108]]
// LIN64:       atomic_exit150:
// LIN64-NEXT:    [[FROMBOOL151:%.*]] = zext i1 [[TOBOOL144]] to i8, !dbg [[DBG108]]
// LIN64-NEXT:    store i8 [[FROMBOOL151]], i8* @bv, align 1, !dbg [[DBG108]]
// LIN64-NEXT:    [[CIV_REAL152:%.*]] = load i32, i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 0), align 4, !dbg [[DBG111:![0-9]+]]
// LIN64-NEXT:    [[CIV_IMAG153:%.*]] = load i32, i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 1), align 4, !dbg [[DBG111]]
// LIN64-NEXT:    [[ATOMIC_LOAD154:%.*]] = load atomic i8, i8* @bx monotonic, align 1, !dbg [[DBG112:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT155:%.*]], !dbg [[DBG112]]
// LIN64:       atomic_cont155:
// LIN64-NEXT:    [[TMP151:%.*]] = phi i8 [ [[ATOMIC_LOAD154]], [[ATOMIC_EXIT150]] ], [ [[TMP154:%.*]], [[ATOMIC_CONT155]] ], !dbg [[DBG112]]
// LIN64-NEXT:    [[TOBOOL157:%.*]] = trunc i8 [[TMP151]] to i1, !dbg [[DBG112]]
// LIN64-NEXT:    [[CONV158:%.*]] = zext i1 [[TOBOOL157]] to i32, !dbg [[DBG113:![0-9]+]]
// LIN64-NEXT:    [[SUB_R159:%.*]] = sub i32 [[CIV_REAL152]], [[CONV158]], !dbg [[DBG114:![0-9]+]]
// LIN64-NEXT:    [[SUB_I160:%.*]] = sub i32 [[CIV_IMAG153]], 0, !dbg [[DBG114]]
// LIN64-NEXT:    [[TOBOOL161:%.*]] = icmp ne i32 [[SUB_R159]], 0, !dbg [[DBG111]]
// LIN64-NEXT:    [[TOBOOL162:%.*]] = icmp ne i32 [[SUB_I160]], 0, !dbg [[DBG111]]
// LIN64-NEXT:    [[TOBOOL163:%.*]] = or i1 [[TOBOOL161]], [[TOBOOL162]], !dbg [[DBG111]]
// LIN64-NEXT:    [[FROMBOOL164:%.*]] = zext i1 [[TOBOOL163]] to i8, !dbg [[DBG112]]
// LIN64-NEXT:    store i8 [[FROMBOOL164]], i8* [[ATOMIC_TEMP156]], align 1, !dbg [[DBG112]]
// LIN64-NEXT:    [[TMP152:%.*]] = load i8, i8* [[ATOMIC_TEMP156]], align 1, !dbg [[DBG112]]
// LIN64-NEXT:    [[TMP153:%.*]] = cmpxchg i8* @bx, i8 [[TMP151]], i8 [[TMP152]] monotonic monotonic, align 1, !dbg [[DBG112]]
// LIN64-NEXT:    [[TMP154]] = extractvalue { i8, i1 } [[TMP153]], 0, !dbg [[DBG112]]
// LIN64-NEXT:    [[TMP155:%.*]] = extractvalue { i8, i1 } [[TMP153]], 1, !dbg [[DBG112]]
// LIN64-NEXT:    br i1 [[TMP155]], label [[ATOMIC_EXIT165:%.*]], label [[ATOMIC_CONT155]], !dbg [[DBG112]]
// LIN64:       atomic_exit165:
// LIN64-NEXT:    [[FROMBOOL166:%.*]] = zext i1 [[TOBOOL163]] to i8, !dbg [[DBG112]]
// LIN64-NEXT:    store i8 [[FROMBOOL166]], i8* @bv, align 1, !dbg [[DBG112]]
// LIN64-NEXT:    [[TMP156:%.*]] = load i16, i16* @sv, align 2, !dbg [[DBG115:![0-9]+]]
// LIN64-NEXT:    [[TMP157:%.*]] = load i8, i8* @bv, align 1, !dbg [[DBG116:![0-9]+]]
// LIN64-NEXT:    [[TOBOOL167:%.*]] = trunc i8 [[TMP157]] to i1, !dbg [[DBG116]]
// LIN64-NEXT:    [[CONV168:%.*]] = zext i1 [[TOBOOL167]] to i32, !dbg [[DBG116]]
// LIN64-NEXT:    [[TMP158:%.*]] = bitcast <4 x i32>* [[ATOMIC_TEMP169]] to i8*, !dbg [[DBG117:![0-9]+]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 16, i8* noundef bitcast (<4 x i32>* @int4x to i8*), i8* noundef [[TMP158]], i32 noundef 0), !dbg [[DBG117]]
// LIN64-NEXT:    br label [[ATOMIC_CONT170:%.*]], !dbg [[DBG117]]
// LIN64:       atomic_cont170:
// LIN64-NEXT:    [[TMP159:%.*]] = load <4 x i32>, <4 x i32>* [[ATOMIC_TEMP169]], align 16, !dbg [[DBG117]]
// LIN64-NEXT:    store <4 x i32> [[TMP159]], <4 x i32>* [[ATOMIC_TEMP171]], align 16, !dbg [[DBG117]]
// LIN64-NEXT:    [[TMP160:%.*]] = load <4 x i32>, <4 x i32>* [[ATOMIC_TEMP169]], align 16, !dbg [[DBG117]]
// LIN64-NEXT:    store <4 x i32> [[TMP160]], <4 x i32>* [[ATOMIC_TEMP172]], align 16, !dbg [[DBG117]]
// LIN64-NEXT:    [[TMP161:%.*]] = load <4 x i32>, <4 x i32>* [[ATOMIC_TEMP172]], align 16, !dbg [[DBG117]]
// LIN64-NEXT:    [[VECEXT:%.*]] = extractelement <4 x i32> [[TMP161]], i16 [[TMP156]], !dbg [[DBG117]]
// LIN64-NEXT:    [[OR173:%.*]] = or i32 [[VECEXT]], [[CONV168]], !dbg [[DBG118:![0-9]+]]
// LIN64-NEXT:    [[TMP162:%.*]] = load <4 x i32>, <4 x i32>* [[ATOMIC_TEMP171]], align 16, !dbg [[DBG117]]
// LIN64-NEXT:    [[VECINS:%.*]] = insertelement <4 x i32> [[TMP162]], i32 [[OR173]], i16 [[TMP156]], !dbg [[DBG117]]
// LIN64-NEXT:    store <4 x i32> [[VECINS]], <4 x i32>* [[ATOMIC_TEMP171]], align 16, !dbg [[DBG117]]
// LIN64-NEXT:    [[TMP163:%.*]] = bitcast <4 x i32>* [[ATOMIC_TEMP169]] to i8*, !dbg [[DBG117]]
// LIN64-NEXT:    [[TMP164:%.*]] = bitcast <4 x i32>* [[ATOMIC_TEMP171]] to i8*, !dbg [[DBG117]]
// LIN64-NEXT:    [[CALL174:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, i8* noundef bitcast (<4 x i32>* @int4x to i8*), i8* noundef [[TMP163]], i8* noundef [[TMP164]], i32 noundef 0, i32 noundef 0), !dbg [[DBG117]]
// LIN64-NEXT:    br i1 [[CALL174]], label [[ATOMIC_EXIT175:%.*]], label [[ATOMIC_CONT170]], !dbg [[DBG117]]
// LIN64:       atomic_exit175:
// LIN64-NEXT:    store i32 [[OR173]], i32* @iv, align 4, !dbg [[DBG117]]
// LIN64-NEXT:    [[TMP165:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG119:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD176:%.*]] = load atomic i32, i32* bitcast (i8* getelementptr (i8, i8* bitcast (%struct.BitFields* @bfx to i8*), i64 4) to i32*) monotonic, align 4, !dbg [[DBG120:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT177:%.*]], !dbg [[DBG120]]
// LIN64:       atomic_cont177:
// LIN64-NEXT:    [[TMP166:%.*]] = phi i32 [ [[ATOMIC_LOAD176]], [[ATOMIC_EXIT175]] ], [ [[TMP169:%.*]], [[ATOMIC_CONT177]] ], !dbg [[DBG120]]
// LIN64-NEXT:    store i32 [[TMP166]], i32* [[ATOMIC_TEMP178]], align 4, !dbg [[DBG120]]
// LIN64-NEXT:    store i32 [[TMP166]], i32* [[ATOMIC_TEMP179]], align 4, !dbg [[DBG120]]
// LIN64-NEXT:    [[BF_LOAD:%.*]] = load i32, i32* [[ATOMIC_TEMP179]], align 4, !dbg [[DBG120]]
// LIN64-NEXT:    [[BF_SHL:%.*]] = shl i32 [[BF_LOAD]], 1, !dbg [[DBG120]]
// LIN64-NEXT:    [[BF_ASHR:%.*]] = ashr i32 [[BF_SHL]], 1, !dbg [[DBG120]]
// LIN64-NEXT:    [[CONV180:%.*]] = sitofp i32 [[BF_ASHR]] to x86_fp80, !dbg [[DBG121:![0-9]+]]
// LIN64-NEXT:    [[SUB181:%.*]] = fsub x86_fp80 [[CONV180]], [[TMP165]], !dbg [[DBG122:![0-9]+]]
// LIN64-NEXT:    [[CONV182:%.*]] = fptosi x86_fp80 [[SUB181]] to i32, !dbg [[DBG121]]
// LIN64-NEXT:    [[BF_LOAD183:%.*]] = load i32, i32* [[ATOMIC_TEMP178]], align 4, !dbg [[DBG120]]
// LIN64-NEXT:    [[BF_VALUE:%.*]] = and i32 [[CONV182]], 2147483647, !dbg [[DBG120]]
// LIN64-NEXT:    [[BF_CLEAR:%.*]] = and i32 [[BF_LOAD183]], -2147483648, !dbg [[DBG120]]
// LIN64-NEXT:    [[BF_SET:%.*]] = or i32 [[BF_CLEAR]], [[BF_VALUE]], !dbg [[DBG120]]
// LIN64-NEXT:    store i32 [[BF_SET]], i32* [[ATOMIC_TEMP178]], align 4, !dbg [[DBG120]]
// LIN64-NEXT:    [[TMP167:%.*]] = load i32, i32* [[ATOMIC_TEMP178]], align 4, !dbg [[DBG120]]
// LIN64-NEXT:    [[TMP168:%.*]] = cmpxchg i32* bitcast (i8* getelementptr (i8, i8* bitcast (%struct.BitFields* @bfx to i8*), i64 4) to i32*), i32 [[TMP166]], i32 [[TMP167]] monotonic monotonic, align 4, !dbg [[DBG120]]
// LIN64-NEXT:    [[TMP169]] = extractvalue { i32, i1 } [[TMP168]], 0, !dbg [[DBG120]]
// LIN64-NEXT:    [[TMP170:%.*]] = extractvalue { i32, i1 } [[TMP168]], 1, !dbg [[DBG120]]
// LIN64-NEXT:    br i1 [[TMP170]], label [[ATOMIC_EXIT184:%.*]], label [[ATOMIC_CONT177]], !dbg [[DBG120]]
// LIN64:       atomic_exit184:
// LIN64-NEXT:    store i32 [[CONV182]], i32* @iv, align 4, !dbg [[DBG120]]
// LIN64-NEXT:    [[TMP171:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG123:![0-9]+]]
// LIN64-NEXT:    [[TMP172:%.*]] = bitcast i32* [[ATOMIC_TEMP185]] to i8*, !dbg [[DBG124:![0-9]+]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 4, i8* noundef getelementptr (i8, i8* bitcast (%struct.BitFields_packed* @bfx_packed to i8*), i64 4), i8* noundef [[TMP172]], i32 noundef 0), !dbg [[DBG124]]
// LIN64-NEXT:    br label [[ATOMIC_CONT186:%.*]], !dbg [[DBG124]]
// LIN64:       atomic_cont186:
// LIN64-NEXT:    [[TMP173:%.*]] = load i32, i32* [[ATOMIC_TEMP185]], align 1, !dbg [[DBG124]]
// LIN64-NEXT:    store i32 [[TMP173]], i32* [[ATOMIC_TEMP187]], align 1, !dbg [[DBG124]]
// LIN64-NEXT:    [[TMP174:%.*]] = load i32, i32* [[ATOMIC_TEMP185]], align 1, !dbg [[DBG124]]
// LIN64-NEXT:    store i32 [[TMP174]], i32* [[ATOMIC_TEMP188]], align 4, !dbg [[DBG124]]
// LIN64-NEXT:    [[BF_LOAD189:%.*]] = load i32, i32* [[ATOMIC_TEMP188]], align 1, !dbg [[DBG124]]
// LIN64-NEXT:    [[BF_SHL190:%.*]] = shl i32 [[BF_LOAD189]], 1, !dbg [[DBG124]]
// LIN64-NEXT:    [[BF_ASHR191:%.*]] = ashr i32 [[BF_SHL190]], 1, !dbg [[DBG124]]
// LIN64-NEXT:    [[CONV192:%.*]] = sitofp i32 [[BF_ASHR191]] to x86_fp80, !dbg [[DBG125:![0-9]+]]
// LIN64-NEXT:    [[MUL193:%.*]] = fmul x86_fp80 [[CONV192]], [[TMP171]], !dbg [[DBG126:![0-9]+]]
// LIN64-NEXT:    [[CONV194:%.*]] = fptosi x86_fp80 [[MUL193]] to i32, !dbg [[DBG125]]
// LIN64-NEXT:    [[BF_LOAD195:%.*]] = load i32, i32* [[ATOMIC_TEMP187]], align 1, !dbg [[DBG124]]
// LIN64-NEXT:    [[BF_VALUE196:%.*]] = and i32 [[CONV194]], 2147483647, !dbg [[DBG124]]
// LIN64-NEXT:    [[BF_CLEAR197:%.*]] = and i32 [[BF_LOAD195]], -2147483648, !dbg [[DBG124]]
// LIN64-NEXT:    [[BF_SET198:%.*]] = or i32 [[BF_CLEAR197]], [[BF_VALUE196]], !dbg [[DBG124]]
// LIN64-NEXT:    store i32 [[BF_SET198]], i32* [[ATOMIC_TEMP187]], align 1, !dbg [[DBG124]]
// LIN64-NEXT:    [[TMP175:%.*]] = bitcast i32* [[ATOMIC_TEMP185]] to i8*, !dbg [[DBG124]]
// LIN64-NEXT:    [[TMP176:%.*]] = bitcast i32* [[ATOMIC_TEMP187]] to i8*, !dbg [[DBG124]]
// LIN64-NEXT:    [[CALL199:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 4, i8* noundef getelementptr (i8, i8* bitcast (%struct.BitFields_packed* @bfx_packed to i8*), i64 4), i8* noundef [[TMP175]], i8* noundef [[TMP176]], i32 noundef 0, i32 noundef 0), !dbg [[DBG124]]
// LIN64-NEXT:    br i1 [[CALL199]], label [[ATOMIC_EXIT200:%.*]], label [[ATOMIC_CONT186]], !dbg [[DBG124]]
// LIN64:       atomic_exit200:
// LIN64-NEXT:    store i32 [[BF_ASHR191]], i32* @iv, align 4, !dbg [[DBG124]]
// LIN64-NEXT:    [[TMP177:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG127:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD201:%.*]] = load atomic i32, i32* getelementptr inbounds ([[STRUCT_BITFIELDS2:%.*]], %struct.BitFields2* @bfx2, i32 0, i32 0) monotonic, align 4, !dbg [[DBG128:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT202:%.*]], !dbg [[DBG128]]
// LIN64:       atomic_cont202:
// LIN64-NEXT:    [[TMP178:%.*]] = phi i32 [ [[ATOMIC_LOAD201]], [[ATOMIC_EXIT200]] ], [ [[TMP181:%.*]], [[ATOMIC_CONT202]] ], !dbg [[DBG128]]
// LIN64-NEXT:    store i32 [[TMP178]], i32* [[ATOMIC_TEMP203]], align 4, !dbg [[DBG128]]
// LIN64-NEXT:    store i32 [[TMP178]], i32* [[ATOMIC_TEMP204]], align 4, !dbg [[DBG128]]
// LIN64-NEXT:    [[BF_LOAD205:%.*]] = load i32, i32* [[ATOMIC_TEMP204]], align 4, !dbg [[DBG128]]
// LIN64-NEXT:    [[BF_ASHR206:%.*]] = ashr i32 [[BF_LOAD205]], 31, !dbg [[DBG128]]
// LIN64-NEXT:    [[CONV207:%.*]] = sitofp i32 [[BF_ASHR206]] to x86_fp80, !dbg [[DBG129:![0-9]+]]
// LIN64-NEXT:    [[SUB208:%.*]] = fsub x86_fp80 [[CONV207]], [[TMP177]], !dbg [[DBG130:![0-9]+]]
// LIN64-NEXT:    [[CONV209:%.*]] = fptosi x86_fp80 [[SUB208]] to i32, !dbg [[DBG129]]
// LIN64-NEXT:    [[BF_LOAD210:%.*]] = load i32, i32* [[ATOMIC_TEMP203]], align 4, !dbg [[DBG128]]
// LIN64-NEXT:    [[BF_VALUE211:%.*]] = and i32 [[CONV209]], 1, !dbg [[DBG128]]
// LIN64-NEXT:    [[BF_SHL212:%.*]] = shl i32 [[BF_VALUE211]], 31, !dbg [[DBG128]]
// LIN64-NEXT:    [[BF_CLEAR213:%.*]] = and i32 [[BF_LOAD210]], 2147483647, !dbg [[DBG128]]
// LIN64-NEXT:    [[BF_SET214:%.*]] = or i32 [[BF_CLEAR213]], [[BF_SHL212]], !dbg [[DBG128]]
// LIN64-NEXT:    store i32 [[BF_SET214]], i32* [[ATOMIC_TEMP203]], align 4, !dbg [[DBG128]]
// LIN64-NEXT:    [[TMP179:%.*]] = load i32, i32* [[ATOMIC_TEMP203]], align 4, !dbg [[DBG128]]
// LIN64-NEXT:    [[TMP180:%.*]] = cmpxchg i32* getelementptr inbounds ([[STRUCT_BITFIELDS2]], %struct.BitFields2* @bfx2, i32 0, i32 0), i32 [[TMP178]], i32 [[TMP179]] monotonic monotonic, align 4, !dbg [[DBG128]]
// LIN64-NEXT:    [[TMP181]] = extractvalue { i32, i1 } [[TMP180]], 0, !dbg [[DBG128]]
// LIN64-NEXT:    [[TMP182:%.*]] = extractvalue { i32, i1 } [[TMP180]], 1, !dbg [[DBG128]]
// LIN64-NEXT:    br i1 [[TMP182]], label [[ATOMIC_EXIT215:%.*]], label [[ATOMIC_CONT202]], !dbg [[DBG128]]
// LIN64:       atomic_exit215:
// LIN64-NEXT:    store i32 [[CONV209]], i32* @iv, align 4, !dbg [[DBG128]]
// LIN64-NEXT:    [[TMP183:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG131:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD216:%.*]] = load atomic i8, i8* getelementptr (i8, i8* bitcast (%struct.BitFields2_packed* @bfx2_packed to i8*), i64 3) monotonic, align 1, !dbg [[DBG132:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT217:%.*]], !dbg [[DBG132]]
// LIN64:       atomic_cont217:
// LIN64-NEXT:    [[TMP184:%.*]] = phi i8 [ [[ATOMIC_LOAD216]], [[ATOMIC_EXIT215]] ], [ [[TMP190:%.*]], [[ATOMIC_CONT217]] ], !dbg [[DBG132]]
// LIN64-NEXT:    [[TMP185:%.*]] = bitcast i32* [[ATOMIC_TEMP218]] to i8*, !dbg [[DBG132]]
// LIN64-NEXT:    store i8 [[TMP184]], i8* [[TMP185]], align 1, !dbg [[DBG132]]
// LIN64-NEXT:    [[TMP186:%.*]] = bitcast i32* [[ATOMIC_TEMP219]] to i8*, !dbg [[DBG132]]
// LIN64-NEXT:    store i8 [[TMP184]], i8* [[TMP186]], align 1, !dbg [[DBG132]]
// LIN64-NEXT:    [[BF_LOAD220:%.*]] = load i8, i8* [[TMP186]], align 1, !dbg [[DBG132]]
// LIN64-NEXT:    [[BF_ASHR221:%.*]] = ashr i8 [[BF_LOAD220]], 7, !dbg [[DBG132]]
// LIN64-NEXT:    [[BF_CAST:%.*]] = sext i8 [[BF_ASHR221]] to i32, !dbg [[DBG132]]
// LIN64-NEXT:    [[CONV222:%.*]] = sitofp i32 [[BF_CAST]] to x86_fp80, !dbg [[DBG133:![0-9]+]]
// LIN64-NEXT:    [[DIV223:%.*]] = fdiv x86_fp80 [[TMP183]], [[CONV222]], !dbg [[DBG134:![0-9]+]]
// LIN64-NEXT:    [[CONV224:%.*]] = fptosi x86_fp80 [[DIV223]] to i32, !dbg [[DBG131]]
// LIN64-NEXT:    [[TMP187:%.*]] = trunc i32 [[CONV224]] to i8, !dbg [[DBG132]]
// LIN64-NEXT:    [[BF_LOAD225:%.*]] = load i8, i8* [[TMP185]], align 1, !dbg [[DBG132]]
// LIN64-NEXT:    [[BF_VALUE226:%.*]] = and i8 [[TMP187]], 1, !dbg [[DBG132]]
// LIN64-NEXT:    [[BF_SHL227:%.*]] = shl i8 [[BF_VALUE226]], 7, !dbg [[DBG132]]
// LIN64-NEXT:    [[BF_CLEAR228:%.*]] = and i8 [[BF_LOAD225]], 127, !dbg [[DBG132]]
// LIN64-NEXT:    [[BF_SET229:%.*]] = or i8 [[BF_CLEAR228]], [[BF_SHL227]], !dbg [[DBG132]]
// LIN64-NEXT:    store i8 [[BF_SET229]], i8* [[TMP185]], align 1, !dbg [[DBG132]]
// LIN64-NEXT:    [[TMP188:%.*]] = load i8, i8* [[TMP185]], align 1, !dbg [[DBG132]]
// LIN64-NEXT:    [[TMP189:%.*]] = cmpxchg i8* getelementptr (i8, i8* bitcast (%struct.BitFields2_packed* @bfx2_packed to i8*), i64 3), i8 [[TMP184]], i8 [[TMP188]] monotonic monotonic, align 1, !dbg [[DBG132]]
// LIN64-NEXT:    [[TMP190]] = extractvalue { i8, i1 } [[TMP189]], 0, !dbg [[DBG132]]
// LIN64-NEXT:    [[TMP191:%.*]] = extractvalue { i8, i1 } [[TMP189]], 1, !dbg [[DBG132]]
// LIN64-NEXT:    br i1 [[TMP191]], label [[ATOMIC_EXIT230:%.*]], label [[ATOMIC_CONT217]], !dbg [[DBG132]]
// LIN64:       atomic_exit230:
// LIN64-NEXT:    store i32 [[CONV224]], i32* @iv, align 4, !dbg [[DBG132]]
// LIN64-NEXT:    [[TMP192:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG135:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD231:%.*]] = load atomic i32, i32* getelementptr inbounds ([[STRUCT_BITFIELDS3:%.*]], %struct.BitFields3* @bfx3, i32 0, i32 0) monotonic, align 4, !dbg [[DBG136:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT232:%.*]], !dbg [[DBG136]]
// LIN64:       atomic_cont232:
// LIN64-NEXT:    [[TMP193:%.*]] = phi i32 [ [[ATOMIC_LOAD231]], [[ATOMIC_EXIT230]] ], [ [[TMP196:%.*]], [[ATOMIC_CONT232]] ], !dbg [[DBG136]]
// LIN64-NEXT:    store i32 [[TMP193]], i32* [[ATOMIC_TEMP233]], align 4, !dbg [[DBG136]]
// LIN64-NEXT:    store i32 [[TMP193]], i32* [[ATOMIC_TEMP234]], align 4, !dbg [[DBG136]]
// LIN64-NEXT:    [[BF_LOAD235:%.*]] = load i32, i32* [[ATOMIC_TEMP234]], align 4, !dbg [[DBG136]]
// LIN64-NEXT:    [[BF_SHL236:%.*]] = shl i32 [[BF_LOAD235]], 7, !dbg [[DBG136]]
// LIN64-NEXT:    [[BF_ASHR237:%.*]] = ashr i32 [[BF_SHL236]], 18, !dbg [[DBG136]]
// LIN64-NEXT:    [[CONV238:%.*]] = sitofp i32 [[BF_ASHR237]] to x86_fp80, !dbg [[DBG137:![0-9]+]]
// LIN64-NEXT:    [[DIV239:%.*]] = fdiv x86_fp80 [[CONV238]], [[TMP192]], !dbg [[DBG138:![0-9]+]]
// LIN64-NEXT:    [[CONV240:%.*]] = fptosi x86_fp80 [[DIV239]] to i32, !dbg [[DBG137]]
// LIN64-NEXT:    [[BF_LOAD241:%.*]] = load i32, i32* [[ATOMIC_TEMP233]], align 4, !dbg [[DBG136]]
// LIN64-NEXT:    [[BF_VALUE242:%.*]] = and i32 [[CONV240]], 16383, !dbg [[DBG136]]
// LIN64-NEXT:    [[BF_SHL243:%.*]] = shl i32 [[BF_VALUE242]], 11, !dbg [[DBG136]]
// LIN64-NEXT:    [[BF_CLEAR244:%.*]] = and i32 [[BF_LOAD241]], -33552385, !dbg [[DBG136]]
// LIN64-NEXT:    [[BF_SET245:%.*]] = or i32 [[BF_CLEAR244]], [[BF_SHL243]], !dbg [[DBG136]]
// LIN64-NEXT:    store i32 [[BF_SET245]], i32* [[ATOMIC_TEMP233]], align 4, !dbg [[DBG136]]
// LIN64-NEXT:    [[TMP194:%.*]] = load i32, i32* [[ATOMIC_TEMP233]], align 4, !dbg [[DBG136]]
// LIN64-NEXT:    [[TMP195:%.*]] = cmpxchg i32* getelementptr inbounds ([[STRUCT_BITFIELDS3]], %struct.BitFields3* @bfx3, i32 0, i32 0), i32 [[TMP193]], i32 [[TMP194]] monotonic monotonic, align 4, !dbg [[DBG136]]
// LIN64-NEXT:    [[TMP196]] = extractvalue { i32, i1 } [[TMP195]], 0, !dbg [[DBG136]]
// LIN64-NEXT:    [[TMP197:%.*]] = extractvalue { i32, i1 } [[TMP195]], 1, !dbg [[DBG136]]
// LIN64-NEXT:    br i1 [[TMP197]], label [[ATOMIC_EXIT246:%.*]], label [[ATOMIC_CONT232]], !dbg [[DBG136]]
// LIN64:       atomic_exit246:
// LIN64-NEXT:    store i32 [[BF_ASHR237]], i32* @iv, align 4, !dbg [[DBG136]]
// LIN64-NEXT:    [[TMP198:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG139:![0-9]+]]
// LIN64-NEXT:    [[TMP199:%.*]] = bitcast i32* [[ATOMIC_TEMP247]] to i24*, !dbg [[DBG140:![0-9]+]]
// LIN64-NEXT:    [[TMP200:%.*]] = bitcast i24* [[TMP199]] to i8*, !dbg [[DBG140]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 3, i8* noundef getelementptr (i8, i8* bitcast (%struct.BitFields3_packed* @bfx3_packed to i8*), i64 1), i8* noundef [[TMP200]], i32 noundef 0), !dbg [[DBG140]]
// LIN64-NEXT:    br label [[ATOMIC_CONT248:%.*]], !dbg [[DBG140]]
// LIN64:       atomic_cont248:
// LIN64-NEXT:    [[TMP201:%.*]] = bitcast i32* [[ATOMIC_TEMP249]] to i24*, !dbg [[DBG140]]
// LIN64-NEXT:    [[TMP202:%.*]] = load i24, i24* [[TMP199]], align 1, !dbg [[DBG140]]
// LIN64-NEXT:    store i24 [[TMP202]], i24* [[TMP201]], align 1, !dbg [[DBG140]]
// LIN64-NEXT:    [[TMP203:%.*]] = load i24, i24* [[TMP199]], align 1, !dbg [[DBG140]]
// LIN64-NEXT:    [[TMP204:%.*]] = bitcast i32* [[ATOMIC_TEMP250]] to i24*, !dbg [[DBG140]]
// LIN64-NEXT:    store i24 [[TMP203]], i24* [[TMP204]], align 1, !dbg [[DBG140]]
// LIN64-NEXT:    [[BF_LOAD251:%.*]] = load i24, i24* [[TMP204]], align 1, !dbg [[DBG140]]
// LIN64-NEXT:    [[BF_SHL252:%.*]] = shl i24 [[BF_LOAD251]], 7, !dbg [[DBG140]]
// LIN64-NEXT:    [[BF_ASHR253:%.*]] = ashr i24 [[BF_SHL252]], 10, !dbg [[DBG140]]
// LIN64-NEXT:    [[BF_CAST254:%.*]] = sext i24 [[BF_ASHR253]] to i32, !dbg [[DBG140]]
// LIN64-NEXT:    [[CONV255:%.*]] = sitofp i32 [[BF_CAST254]] to x86_fp80, !dbg [[DBG141:![0-9]+]]
// LIN64-NEXT:    [[ADD256:%.*]] = fadd x86_fp80 [[CONV255]], [[TMP198]], !dbg [[DBG142:![0-9]+]]
// LIN64-NEXT:    [[CONV257:%.*]] = fptosi x86_fp80 [[ADD256]] to i32, !dbg [[DBG141]]
// LIN64-NEXT:    [[TMP205:%.*]] = trunc i32 [[CONV257]] to i24, !dbg [[DBG140]]
// LIN64-NEXT:    [[BF_LOAD258:%.*]] = load i24, i24* [[TMP201]], align 1, !dbg [[DBG140]]
// LIN64-NEXT:    [[BF_VALUE259:%.*]] = and i24 [[TMP205]], 16383, !dbg [[DBG140]]
// LIN64-NEXT:    [[BF_SHL260:%.*]] = shl i24 [[BF_VALUE259]], 3, !dbg [[DBG140]]
// LIN64-NEXT:    [[BF_CLEAR261:%.*]] = and i24 [[BF_LOAD258]], -131065, !dbg [[DBG140]]
// LIN64-NEXT:    [[BF_SET262:%.*]] = or i24 [[BF_CLEAR261]], [[BF_SHL260]], !dbg [[DBG140]]
// LIN64-NEXT:    store i24 [[BF_SET262]], i24* [[TMP201]], align 1, !dbg [[DBG140]]
// LIN64-NEXT:    [[TMP206:%.*]] = bitcast i24* [[TMP199]] to i8*, !dbg [[DBG140]]
// LIN64-NEXT:    [[TMP207:%.*]] = bitcast i24* [[TMP201]] to i8*, !dbg [[DBG140]]
// LIN64-NEXT:    [[CALL263:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 3, i8* noundef getelementptr (i8, i8* bitcast (%struct.BitFields3_packed* @bfx3_packed to i8*), i64 1), i8* noundef [[TMP206]], i8* noundef [[TMP207]], i32 noundef 0, i32 noundef 0), !dbg [[DBG140]]
// LIN64-NEXT:    br i1 [[CALL263]], label [[ATOMIC_EXIT264:%.*]], label [[ATOMIC_CONT248]], !dbg [[DBG140]]
// LIN64:       atomic_exit264:
// LIN64-NEXT:    store i32 [[CONV257]], i32* @iv, align 4, !dbg [[DBG140]]
// LIN64-NEXT:    [[TMP208:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG143:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD265:%.*]] = load atomic i64, i64* bitcast (%struct.BitFields4* @bfx4 to i64*) monotonic, align 8, !dbg [[DBG144:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT266:%.*]], !dbg [[DBG144]]
// LIN64:       atomic_cont266:
// LIN64-NEXT:    [[TMP209:%.*]] = phi i64 [ [[ATOMIC_LOAD265]], [[ATOMIC_EXIT264]] ], [ [[TMP213:%.*]], [[ATOMIC_CONT266]] ], !dbg [[DBG144]]
// LIN64-NEXT:    store i64 [[TMP209]], i64* [[ATOMIC_TEMP267]], align 8, !dbg [[DBG144]]
// LIN64-NEXT:    store i64 [[TMP209]], i64* [[ATOMIC_TEMP268]], align 8, !dbg [[DBG144]]
// LIN64-NEXT:    [[BF_LOAD269:%.*]] = load i64, i64* [[ATOMIC_TEMP268]], align 8, !dbg [[DBG144]]
// LIN64-NEXT:    [[BF_SHL270:%.*]] = shl i64 [[BF_LOAD269]], 47, !dbg [[DBG144]]
// LIN64-NEXT:    [[BF_ASHR271:%.*]] = ashr i64 [[BF_SHL270]], 63, !dbg [[DBG144]]
// LIN64-NEXT:    [[BF_CAST272:%.*]] = trunc i64 [[BF_ASHR271]] to i32, !dbg [[DBG144]]
// LIN64-NEXT:    [[CONV273:%.*]] = sitofp i32 [[BF_CAST272]] to x86_fp80, !dbg [[DBG145:![0-9]+]]
// LIN64-NEXT:    [[MUL274:%.*]] = fmul x86_fp80 [[CONV273]], [[TMP208]], !dbg [[DBG146:![0-9]+]]
// LIN64-NEXT:    [[CONV275:%.*]] = fptosi x86_fp80 [[MUL274]] to i32, !dbg [[DBG145]]
// LIN64-NEXT:    [[TMP210:%.*]] = zext i32 [[CONV275]] to i64, !dbg [[DBG144]]
// LIN64-NEXT:    [[BF_LOAD276:%.*]] = load i64, i64* [[ATOMIC_TEMP267]], align 8, !dbg [[DBG144]]
// LIN64-NEXT:    [[BF_VALUE277:%.*]] = and i64 [[TMP210]], 1, !dbg [[DBG144]]
// LIN64-NEXT:    [[BF_SHL278:%.*]] = shl i64 [[BF_VALUE277]], 16, !dbg [[DBG144]]
// LIN64-NEXT:    [[BF_CLEAR279:%.*]] = and i64 [[BF_LOAD276]], -65537, !dbg [[DBG144]]
// LIN64-NEXT:    [[BF_SET280:%.*]] = or i64 [[BF_CLEAR279]], [[BF_SHL278]], !dbg [[DBG144]]
// LIN64-NEXT:    store i64 [[BF_SET280]], i64* [[ATOMIC_TEMP267]], align 8, !dbg [[DBG144]]
// LIN64-NEXT:    [[TMP211:%.*]] = load i64, i64* [[ATOMIC_TEMP267]], align 8, !dbg [[DBG144]]
// LIN64-NEXT:    [[TMP212:%.*]] = cmpxchg i64* bitcast (%struct.BitFields4* @bfx4 to i64*), i64 [[TMP209]], i64 [[TMP211]] monotonic monotonic, align 8, !dbg [[DBG144]]
// LIN64-NEXT:    [[TMP213]] = extractvalue { i64, i1 } [[TMP212]], 0, !dbg [[DBG144]]
// LIN64-NEXT:    [[TMP214:%.*]] = extractvalue { i64, i1 } [[TMP212]], 1, !dbg [[DBG144]]
// LIN64-NEXT:    br i1 [[TMP214]], label [[ATOMIC_EXIT281:%.*]], label [[ATOMIC_CONT266]], !dbg [[DBG144]]
// LIN64:       atomic_exit281:
// LIN64-NEXT:    store i32 [[CONV275]], i32* @iv, align 4, !dbg [[DBG144]]
// LIN64-NEXT:    [[TMP215:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG147:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD282:%.*]] = load atomic i8, i8* getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED:%.*]], %struct.BitFields4_packed* @bfx4_packed, i32 0, i32 0, i64 2) monotonic, align 1, !dbg [[DBG148:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT283:%.*]], !dbg [[DBG148]]
// LIN64:       atomic_cont283:
// LIN64-NEXT:    [[TMP216:%.*]] = phi i8 [ [[ATOMIC_LOAD282]], [[ATOMIC_EXIT281]] ], [ [[TMP222:%.*]], [[ATOMIC_CONT283]] ], !dbg [[DBG148]]
// LIN64-NEXT:    [[TMP217:%.*]] = bitcast i32* [[ATOMIC_TEMP284]] to i8*, !dbg [[DBG148]]
// LIN64-NEXT:    store i8 [[TMP216]], i8* [[TMP217]], align 1, !dbg [[DBG148]]
// LIN64-NEXT:    [[TMP218:%.*]] = bitcast i32* [[ATOMIC_TEMP285]] to i8*, !dbg [[DBG148]]
// LIN64-NEXT:    store i8 [[TMP216]], i8* [[TMP218]], align 1, !dbg [[DBG148]]
// LIN64-NEXT:    [[BF_LOAD286:%.*]] = load i8, i8* [[TMP218]], align 1, !dbg [[DBG148]]
// LIN64-NEXT:    [[BF_SHL287:%.*]] = shl i8 [[BF_LOAD286]], 7, !dbg [[DBG148]]
// LIN64-NEXT:    [[BF_ASHR288:%.*]] = ashr i8 [[BF_SHL287]], 7, !dbg [[DBG148]]
// LIN64-NEXT:    [[BF_CAST289:%.*]] = sext i8 [[BF_ASHR288]] to i32, !dbg [[DBG148]]
// LIN64-NEXT:    [[CONV290:%.*]] = sitofp i32 [[BF_CAST289]] to x86_fp80, !dbg [[DBG149:![0-9]+]]
// LIN64-NEXT:    [[SUB291:%.*]] = fsub x86_fp80 [[CONV290]], [[TMP215]], !dbg [[DBG150:![0-9]+]]
// LIN64-NEXT:    [[CONV292:%.*]] = fptosi x86_fp80 [[SUB291]] to i32, !dbg [[DBG149]]
// LIN64-NEXT:    [[TMP219:%.*]] = trunc i32 [[CONV292]] to i8, !dbg [[DBG148]]
// LIN64-NEXT:    [[BF_LOAD293:%.*]] = load i8, i8* [[TMP217]], align 1, !dbg [[DBG148]]
// LIN64-NEXT:    [[BF_VALUE294:%.*]] = and i8 [[TMP219]], 1, !dbg [[DBG148]]
// LIN64-NEXT:    [[BF_CLEAR295:%.*]] = and i8 [[BF_LOAD293]], -2, !dbg [[DBG148]]
// LIN64-NEXT:    [[BF_SET296:%.*]] = or i8 [[BF_CLEAR295]], [[BF_VALUE294]], !dbg [[DBG148]]
// LIN64-NEXT:    store i8 [[BF_SET296]], i8* [[TMP217]], align 1, !dbg [[DBG148]]
// LIN64-NEXT:    [[TMP220:%.*]] = load i8, i8* [[TMP217]], align 1, !dbg [[DBG148]]
// LIN64-NEXT:    [[TMP221:%.*]] = cmpxchg i8* getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED]], %struct.BitFields4_packed* @bfx4_packed, i32 0, i32 0, i64 2), i8 [[TMP216]], i8 [[TMP220]] monotonic monotonic, align 1, !dbg [[DBG148]]
// LIN64-NEXT:    [[TMP222]] = extractvalue { i8, i1 } [[TMP221]], 0, !dbg [[DBG148]]
// LIN64-NEXT:    [[TMP223:%.*]] = extractvalue { i8, i1 } [[TMP221]], 1, !dbg [[DBG148]]
// LIN64-NEXT:    br i1 [[TMP223]], label [[ATOMIC_EXIT297:%.*]], label [[ATOMIC_CONT283]], !dbg [[DBG148]]
// LIN64:       atomic_exit297:
// LIN64-NEXT:    store i32 [[BF_CAST289]], i32* @iv, align 4, !dbg [[DBG148]]
// LIN64-NEXT:    [[TMP224:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG151:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD298:%.*]] = load atomic i64, i64* bitcast (%struct.BitFields4* @bfx4 to i64*) monotonic, align 8, !dbg [[DBG152:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT299:%.*]], !dbg [[DBG152]]
// LIN64:       atomic_cont299:
// LIN64-NEXT:    [[TMP225:%.*]] = phi i64 [ [[ATOMIC_LOAD298]], [[ATOMIC_EXIT297]] ], [ [[TMP228:%.*]], [[ATOMIC_CONT299]] ], !dbg [[DBG152]]
// LIN64-NEXT:    store i64 [[TMP225]], i64* [[ATOMIC_TEMP300]], align 8, !dbg [[DBG152]]
// LIN64-NEXT:    store i64 [[TMP225]], i64* [[ATOMIC_TEMP301]], align 8, !dbg [[DBG152]]
// LIN64-NEXT:    [[BF_LOAD302:%.*]] = load i64, i64* [[ATOMIC_TEMP301]], align 8, !dbg [[DBG152]]
// LIN64-NEXT:    [[BF_SHL303:%.*]] = shl i64 [[BF_LOAD302]], 40, !dbg [[DBG152]]
// LIN64-NEXT:    [[BF_ASHR304:%.*]] = ashr i64 [[BF_SHL303]], 57, !dbg [[DBG152]]
// LIN64-NEXT:    [[CONV305:%.*]] = sitofp i64 [[BF_ASHR304]] to x86_fp80, !dbg [[DBG153:![0-9]+]]
// LIN64-NEXT:    [[DIV306:%.*]] = fdiv x86_fp80 [[CONV305]], [[TMP224]], !dbg [[DBG154:![0-9]+]]
// LIN64-NEXT:    [[CONV307:%.*]] = fptosi x86_fp80 [[DIV306]] to i64, !dbg [[DBG153]]
// LIN64-NEXT:    [[BF_LOAD308:%.*]] = load i64, i64* [[ATOMIC_TEMP300]], align 8, !dbg [[DBG152]]
// LIN64-NEXT:    [[BF_VALUE309:%.*]] = and i64 [[CONV307]], 127, !dbg [[DBG152]]
// LIN64-NEXT:    [[BF_SHL310:%.*]] = shl i64 [[BF_VALUE309]], 17, !dbg [[DBG152]]
// LIN64-NEXT:    [[BF_CLEAR311:%.*]] = and i64 [[BF_LOAD308]], -16646145, !dbg [[DBG152]]
// LIN64-NEXT:    [[BF_SET312:%.*]] = or i64 [[BF_CLEAR311]], [[BF_SHL310]], !dbg [[DBG152]]
// LIN64-NEXT:    store i64 [[BF_SET312]], i64* [[ATOMIC_TEMP300]], align 8, !dbg [[DBG152]]
// LIN64-NEXT:    [[TMP226:%.*]] = load i64, i64* [[ATOMIC_TEMP300]], align 8, !dbg [[DBG152]]
// LIN64-NEXT:    [[TMP227:%.*]] = cmpxchg i64* bitcast (%struct.BitFields4* @bfx4 to i64*), i64 [[TMP225]], i64 [[TMP226]] release monotonic, align 8, !dbg [[DBG152]]
// LIN64-NEXT:    [[TMP228]] = extractvalue { i64, i1 } [[TMP227]], 0, !dbg [[DBG152]]
// LIN64-NEXT:    [[TMP229:%.*]] = extractvalue { i64, i1 } [[TMP227]], 1, !dbg [[DBG152]]
// LIN64-NEXT:    br i1 [[TMP229]], label [[ATOMIC_EXIT313:%.*]], label [[ATOMIC_CONT299]], !dbg [[DBG152]]
// LIN64:       atomic_exit313:
// LIN64-NEXT:    [[CONV314:%.*]] = trunc i64 [[CONV307]] to i32, !dbg [[DBG152]]
// LIN64-NEXT:    store i32 [[CONV314]], i32* @iv, align 4, !dbg [[DBG152]]
// LIN64-NEXT:    [[TMP230:%.*]] = load x86_fp80, x86_fp80* @ldv, align 16, !dbg [[DBG155:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD315:%.*]] = load atomic i8, i8* getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED]], %struct.BitFields4_packed* @bfx4_packed, i32 0, i32 0, i64 2) acquire, align 1, !dbg [[DBG156:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT316:%.*]], !dbg [[DBG156]]
// LIN64:       atomic_cont316:
// LIN64-NEXT:    [[TMP231:%.*]] = phi i8 [ [[ATOMIC_LOAD315]], [[ATOMIC_EXIT313]] ], [ [[TMP237:%.*]], [[ATOMIC_CONT316]] ], !dbg [[DBG156]]
// LIN64-NEXT:    [[TMP232:%.*]] = bitcast i64* [[ATOMIC_TEMP317]] to i8*, !dbg [[DBG156]]
// LIN64-NEXT:    store i8 [[TMP231]], i8* [[TMP232]], align 1, !dbg [[DBG156]]
// LIN64-NEXT:    [[TMP233:%.*]] = bitcast i64* [[ATOMIC_TEMP318]] to i8*, !dbg [[DBG156]]
// LIN64-NEXT:    store i8 [[TMP231]], i8* [[TMP233]], align 1, !dbg [[DBG156]]
// LIN64-NEXT:    [[BF_LOAD319:%.*]] = load i8, i8* [[TMP233]], align 1, !dbg [[DBG156]]
// LIN64-NEXT:    [[BF_ASHR320:%.*]] = ashr i8 [[BF_LOAD319]], 1, !dbg [[DBG156]]
// LIN64-NEXT:    [[BF_CAST321:%.*]] = sext i8 [[BF_ASHR320]] to i64, !dbg [[DBG156]]
// LIN64-NEXT:    [[CONV322:%.*]] = sitofp i64 [[BF_CAST321]] to x86_fp80, !dbg [[DBG157:![0-9]+]]
// LIN64-NEXT:    [[ADD323:%.*]] = fadd x86_fp80 [[CONV322]], [[TMP230]], !dbg [[DBG158:![0-9]+]]
// LIN64-NEXT:    [[CONV324:%.*]] = fptosi x86_fp80 [[ADD323]] to i64, !dbg [[DBG157]]
// LIN64-NEXT:    [[TMP234:%.*]] = trunc i64 [[CONV324]] to i8, !dbg [[DBG156]]
// LIN64-NEXT:    [[BF_LOAD325:%.*]] = load i8, i8* [[TMP232]], align 1, !dbg [[DBG156]]
// LIN64-NEXT:    [[BF_VALUE326:%.*]] = and i8 [[TMP234]], 127, !dbg [[DBG156]]
// LIN64-NEXT:    [[BF_SHL327:%.*]] = shl i8 [[BF_VALUE326]], 1, !dbg [[DBG156]]
// LIN64-NEXT:    [[BF_CLEAR328:%.*]] = and i8 [[BF_LOAD325]], 1, !dbg [[DBG156]]
// LIN64-NEXT:    [[BF_SET329:%.*]] = or i8 [[BF_CLEAR328]], [[BF_SHL327]], !dbg [[DBG156]]
// LIN64-NEXT:    store i8 [[BF_SET329]], i8* [[TMP232]], align 1, !dbg [[DBG156]]
// LIN64-NEXT:    [[TMP235:%.*]] = load i8, i8* [[TMP232]], align 1, !dbg [[DBG156]]
// LIN64-NEXT:    [[TMP236:%.*]] = cmpxchg i8* getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED]], %struct.BitFields4_packed* @bfx4_packed, i32 0, i32 0, i64 2), i8 [[TMP231]], i8 [[TMP235]] acquire acquire, align 1, !dbg [[DBG156]]
// LIN64-NEXT:    [[TMP237]] = extractvalue { i8, i1 } [[TMP236]], 0, !dbg [[DBG156]]
// LIN64-NEXT:    [[TMP238:%.*]] = extractvalue { i8, i1 } [[TMP236]], 1, !dbg [[DBG156]]
// LIN64-NEXT:    br i1 [[TMP238]], label [[ATOMIC_EXIT330:%.*]], label [[ATOMIC_CONT316]], !dbg [[DBG156]]
// LIN64:       atomic_exit330:
// LIN64-NEXT:    [[CONV331:%.*]] = trunc i64 [[CONV324]] to i32, !dbg [[DBG156]]
// LIN64-NEXT:    store i32 [[CONV331]], i32* @iv, align 4, !dbg [[DBG156]]
// LIN64-NEXT:    [[TMP239:%.*]] = load i64, i64* @ulv, align 8, !dbg [[DBG159:![0-9]+]]
// LIN64-NEXT:    [[CONV332:%.*]] = uitofp i64 [[TMP239]] to float, !dbg [[DBG159]]
// LIN64-NEXT:    [[ATOMIC_LOAD333:%.*]] = load atomic i64, i64* bitcast (<2 x float>* @float2x to i64*) acquire, align 8, !dbg [[DBG160:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT334:%.*]], !dbg [[DBG160]]
// LIN64:       atomic_cont334:
// LIN64-NEXT:    [[TMP240:%.*]] = phi i64 [ [[ATOMIC_LOAD333]], [[ATOMIC_EXIT330]] ], [ [[TMP249:%.*]], [[ATOMIC_CONT334]] ], !dbg [[DBG160]]
// LIN64-NEXT:    [[TMP241:%.*]] = bitcast <2 x float>* [[ATOMIC_TEMP335]] to i64*, !dbg [[DBG160]]
// LIN64-NEXT:    store i64 [[TMP240]], i64* [[TMP241]], align 8, !dbg [[DBG160]]
// LIN64-NEXT:    [[TMP242:%.*]] = bitcast i64 [[TMP240]] to <2 x float>, !dbg [[DBG160]]
// LIN64-NEXT:    store <2 x float> [[TMP242]], <2 x float>* [[ATOMIC_TEMP336]], align 8, !dbg [[DBG160]]
// LIN64-NEXT:    [[TMP243:%.*]] = load <2 x float>, <2 x float>* [[ATOMIC_TEMP336]], align 8, !dbg [[DBG160]]
// LIN64-NEXT:    [[TMP244:%.*]] = extractelement <2 x float> [[TMP243]], i64 0, !dbg [[DBG160]]
// LIN64-NEXT:    [[SUB337:%.*]] = fsub float [[CONV332]], [[TMP244]], !dbg [[DBG161:![0-9]+]]
// LIN64-NEXT:    [[TMP245:%.*]] = load <2 x float>, <2 x float>* [[ATOMIC_TEMP335]], align 8, !dbg [[DBG160]]
// LIN64-NEXT:    [[TMP246:%.*]] = insertelement <2 x float> [[TMP245]], float [[SUB337]], i64 0, !dbg [[DBG160]]
// LIN64-NEXT:    store <2 x float> [[TMP246]], <2 x float>* [[ATOMIC_TEMP335]], align 8, !dbg [[DBG160]]
// LIN64-NEXT:    [[TMP247:%.*]] = load i64, i64* [[TMP241]], align 8, !dbg [[DBG160]]
// LIN64-NEXT:    [[TMP248:%.*]] = cmpxchg i64* bitcast (<2 x float>* @float2x to i64*), i64 [[TMP240]], i64 [[TMP247]] acq_rel acquire, align 8, !dbg [[DBG160]]
// LIN64-NEXT:    [[TMP249]] = extractvalue { i64, i1 } [[TMP248]], 0, !dbg [[DBG160]]
// LIN64-NEXT:    [[TMP250:%.*]] = extractvalue { i64, i1 } [[TMP248]], 1, !dbg [[DBG160]]
// LIN64-NEXT:    br i1 [[TMP250]], label [[ATOMIC_EXIT338:%.*]], label [[ATOMIC_CONT334]], !dbg [[DBG160]]
// LIN64:       atomic_exit338:
// LIN64-NEXT:    store float [[TMP244]], float* @fv, align 4, !dbg [[DBG160]]
// LIN64-NEXT:    [[TMP251:%.*]] = load double, double* @dv, align 8, !dbg [[DBG162:![0-9]+]]
// LIN64-NEXT:    [[TMP252:%.*]] = call i32 @llvm.read_register.i32(metadata [[META2:![0-9]+]]), !dbg [[DBG163:![0-9]+]]
// LIN64-NEXT:    [[CONV339:%.*]] = sitofp i32 [[TMP252]] to double, !dbg [[DBG164:![0-9]+]]
// LIN64-NEXT:    [[DIV340:%.*]] = fdiv double [[TMP251]], [[CONV339]], !dbg [[DBG165:![0-9]+]]
// LIN64-NEXT:    [[CONV341:%.*]] = fptosi double [[DIV340]] to i32, !dbg [[DBG162]]
// LIN64-NEXT:    call void @llvm.write_register.i32(metadata [[META2]], i32 [[CONV341]]), !dbg [[DBG163]]
// LIN64-NEXT:    store i32 [[CONV341]], i32* @iv, align 4, !dbg [[DBG163]]
// LIN64-NEXT:    [[TMP253:%.*]] = atomicrmw xchg i32* @ix, i32 5 monotonic, align 4, !dbg [[DBG166:![0-9]+]]
// LIN64-NEXT:    call void @llvm.write_register.i32(metadata [[META2]], i32 [[TMP253]]), !dbg [[DBG166]]
// LIN64-NEXT:    ret i32 0, !dbg [[DBG167:![0-9]+]]
//
//
// PPC64-LABEL: define {{[^@]+}}@main
// PPC64-SAME: () #[[ATTR0:[0-9]+]] !dbg [[DBG5:![0-9]+]] {
// PPC64-NEXT:  entry:
// PPC64-NEXT:    [[RETVAL:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca i16, align 2
// PPC64-NEXT:    [[ATOMIC_TEMP10:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP14:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP18:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP22:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP28:%.*]] = alloca double, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP32:%.*]] = alloca ppc_fp128, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP34:%.*]] = alloca ppc_fp128, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP38:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP40:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP45:%.*]] = alloca { float, float }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP47:%.*]] = alloca { float, float }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP52:%.*]] = alloca { double, double }, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP54:%.*]] = alloca { double, double }, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP64:%.*]] = alloca i8, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP74:%.*]] = alloca i8, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP82:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP89:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP93:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP95:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP107:%.*]] = alloca float, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP113:%.*]] = alloca double, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP117:%.*]] = alloca ppc_fp128, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP119:%.*]] = alloca ppc_fp128, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP123:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP125:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP135:%.*]] = alloca i16, align 2
// PPC64-NEXT:    [[ATOMIC_TEMP143:%.*]] = alloca i8, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP156:%.*]] = alloca i8, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP169:%.*]] = alloca <4 x i32>, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP171:%.*]] = alloca <4 x i32>, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP172:%.*]] = alloca <4 x i32>, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP178:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP179:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP185:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP187:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP188:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP203:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP204:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP218:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP219:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP233:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP234:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP247:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP249:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP250:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP267:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP268:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP284:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP285:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP300:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP301:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP317:%.*]] = alloca i64, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP318:%.*]] = alloca i64, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP335:%.*]] = alloca <2 x float>, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP336:%.*]] = alloca <2 x float>, align 8
// PPC64-NEXT:    store i32 0, i32* [[RETVAL]], align 4
// PPC64-NEXT:    [[TMP0:%.*]] = atomicrmw add i8* @bx, i8 1 monotonic, align 1, !dbg [[DBG9:![0-9]+]]
// PPC64-NEXT:    store i8 [[TMP0]], i8* @bv, align 1, !dbg [[DBG9]]
// PPC64-NEXT:    [[TMP1:%.*]] = atomicrmw add i8* @cx, i8 1 monotonic, align 1, !dbg [[DBG10:![0-9]+]]
// PPC64-NEXT:    [[CONV:%.*]] = sext i8 [[TMP1]] to i32, !dbg [[DBG11:![0-9]+]]
// PPC64-NEXT:    [[ADD:%.*]] = add nsw i32 [[CONV]], 1, !dbg [[DBG12:![0-9]+]]
// PPC64-NEXT:    [[CONV1:%.*]] = trunc i32 [[ADD]] to i8, !dbg [[DBG11]]
// PPC64-NEXT:    store i8 [[CONV1]], i8* @cv, align 1, !dbg [[DBG10]]
// PPC64-NEXT:    [[TMP2:%.*]] = atomicrmw sub i8* @ucx, i8 1 monotonic, align 1, !dbg [[DBG13:![0-9]+]]
// PPC64-NEXT:    store i8 [[TMP2]], i8* @ucv, align 1, !dbg [[DBG13]]
// PPC64-NEXT:    [[TMP3:%.*]] = atomicrmw sub i16* @sx, i16 1 monotonic, align 2, !dbg [[DBG14:![0-9]+]]
// PPC64-NEXT:    [[CONV2:%.*]] = sext i16 [[TMP3]] to i32, !dbg [[DBG15:![0-9]+]]
// PPC64-NEXT:    [[SUB:%.*]] = sub nsw i32 [[CONV2]], 1, !dbg [[DBG16:![0-9]+]]
// PPC64-NEXT:    [[CONV3:%.*]] = trunc i32 [[SUB]] to i16, !dbg [[DBG15]]
// PPC64-NEXT:    store i16 [[CONV3]], i16* @sv, align 2, !dbg [[DBG14]]
// PPC64-NEXT:    [[TMP4:%.*]] = load i16, i16* @usv, align 2, !dbg [[DBG17:![0-9]+]]
// PPC64-NEXT:    [[CONV4:%.*]] = zext i16 [[TMP4]] to i32, !dbg [[DBG17]]
// PPC64-NEXT:    [[ATOMIC_LOAD:%.*]] = load atomic i16, i16* @usx monotonic, align 2, !dbg [[DBG18:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT:%.*]], !dbg [[DBG18]]
// PPC64:       atomic_cont:
// PPC64-NEXT:    [[TMP5:%.*]] = phi i16 [ [[ATOMIC_LOAD]], [[ENTRY:%.*]] ], [ [[TMP8:%.*]], [[ATOMIC_CONT]] ], !dbg [[DBG18]]
// PPC64-NEXT:    [[CONV5:%.*]] = zext i16 [[TMP5]] to i32, !dbg [[DBG19:![0-9]+]]
// PPC64-NEXT:    [[ADD6:%.*]] = add nsw i32 [[CONV5]], [[CONV4]], !dbg [[DBG20:![0-9]+]]
// PPC64-NEXT:    [[CONV7:%.*]] = trunc i32 [[ADD6]] to i16, !dbg [[DBG19]]
// PPC64-NEXT:    store i16 [[CONV7]], i16* [[ATOMIC_TEMP]], align 2, !dbg [[DBG18]]
// PPC64-NEXT:    [[TMP6:%.*]] = load i16, i16* [[ATOMIC_TEMP]], align 2, !dbg [[DBG18]]
// PPC64-NEXT:    [[TMP7:%.*]] = cmpxchg i16* @usx, i16 [[TMP5]], i16 [[TMP6]] monotonic monotonic, align 2, !dbg [[DBG18]]
// PPC64-NEXT:    [[TMP8]] = extractvalue { i16, i1 } [[TMP7]], 0, !dbg [[DBG18]]
// PPC64-NEXT:    [[TMP9:%.*]] = extractvalue { i16, i1 } [[TMP7]], 1, !dbg [[DBG18]]
// PPC64-NEXT:    br i1 [[TMP9]], label [[ATOMIC_EXIT:%.*]], label [[ATOMIC_CONT]], !dbg [[DBG18]]
// PPC64:       atomic_exit:
// PPC64-NEXT:    store i16 [[CONV7]], i16* @sv, align 2, !dbg [[DBG18]]
// PPC64-NEXT:    [[TMP10:%.*]] = load i32, i32* @iv, align 4, !dbg [[DBG21:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD8:%.*]] = load atomic i32, i32* @ix monotonic, align 4, !dbg [[DBG22:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT9:%.*]], !dbg [[DBG22]]
// PPC64:       atomic_cont9:
// PPC64-NEXT:    [[TMP11:%.*]] = phi i32 [ [[ATOMIC_LOAD8]], [[ATOMIC_EXIT]] ], [ [[TMP14:%.*]], [[ATOMIC_CONT9]] ], !dbg [[DBG22]]
// PPC64-NEXT:    [[MUL:%.*]] = mul nsw i32 [[TMP11]], [[TMP10]], !dbg [[DBG23:![0-9]+]]
// PPC64-NEXT:    store i32 [[MUL]], i32* [[ATOMIC_TEMP10]], align 4, !dbg [[DBG22]]
// PPC64-NEXT:    [[TMP12:%.*]] = load i32, i32* [[ATOMIC_TEMP10]], align 4, !dbg [[DBG22]]
// PPC64-NEXT:    [[TMP13:%.*]] = cmpxchg i32* @ix, i32 [[TMP11]], i32 [[TMP12]] monotonic monotonic, align 4, !dbg [[DBG22]]
// PPC64-NEXT:    [[TMP14]] = extractvalue { i32, i1 } [[TMP13]], 0, !dbg [[DBG22]]
// PPC64-NEXT:    [[TMP15:%.*]] = extractvalue { i32, i1 } [[TMP13]], 1, !dbg [[DBG22]]
// PPC64-NEXT:    br i1 [[TMP15]], label [[ATOMIC_EXIT11:%.*]], label [[ATOMIC_CONT9]], !dbg [[DBG22]]
// PPC64:       atomic_exit11:
// PPC64-NEXT:    store i32 [[MUL]], i32* @uiv, align 4, !dbg [[DBG22]]
// PPC64-NEXT:    [[TMP16:%.*]] = load i32, i32* @uiv, align 4, !dbg [[DBG24:![0-9]+]]
// PPC64-NEXT:    [[TMP17:%.*]] = atomicrmw sub i32* @uix, i32 [[TMP16]] monotonic, align 4, !dbg [[DBG25:![0-9]+]]
// PPC64-NEXT:    store i32 [[TMP17]], i32* @iv, align 4, !dbg [[DBG25]]
// PPC64-NEXT:    [[TMP18:%.*]] = load i32, i32* @iv, align 4, !dbg [[DBG26:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD12:%.*]] = load atomic i32, i32* @ix monotonic, align 4, !dbg [[DBG27:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT13:%.*]], !dbg [[DBG27]]
// PPC64:       atomic_cont13:
// PPC64-NEXT:    [[TMP19:%.*]] = phi i32 [ [[ATOMIC_LOAD12]], [[ATOMIC_EXIT11]] ], [ [[TMP22:%.*]], [[ATOMIC_CONT13]] ], !dbg [[DBG27]]
// PPC64-NEXT:    [[SHL:%.*]] = shl i32 [[TMP19]], [[TMP18]], !dbg [[DBG28:![0-9]+]]
// PPC64-NEXT:    store i32 [[SHL]], i32* [[ATOMIC_TEMP14]], align 4, !dbg [[DBG27]]
// PPC64-NEXT:    [[TMP20:%.*]] = load i32, i32* [[ATOMIC_TEMP14]], align 4, !dbg [[DBG27]]
// PPC64-NEXT:    [[TMP21:%.*]] = cmpxchg i32* @ix, i32 [[TMP19]], i32 [[TMP20]] monotonic monotonic, align 4, !dbg [[DBG27]]
// PPC64-NEXT:    [[TMP22]] = extractvalue { i32, i1 } [[TMP21]], 0, !dbg [[DBG27]]
// PPC64-NEXT:    [[TMP23:%.*]] = extractvalue { i32, i1 } [[TMP21]], 1, !dbg [[DBG27]]
// PPC64-NEXT:    br i1 [[TMP23]], label [[ATOMIC_EXIT15:%.*]], label [[ATOMIC_CONT13]], !dbg [[DBG27]]
// PPC64:       atomic_exit15:
// PPC64-NEXT:    store i32 [[SHL]], i32* @uiv, align 4, !dbg [[DBG27]]
// PPC64-NEXT:    [[TMP24:%.*]] = load i32, i32* @uiv, align 4, !dbg [[DBG29:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD16:%.*]] = load atomic i32, i32* @uix monotonic, align 4, !dbg [[DBG30:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT17:%.*]], !dbg [[DBG30]]
// PPC64:       atomic_cont17:
// PPC64-NEXT:    [[TMP25:%.*]] = phi i32 [ [[ATOMIC_LOAD16]], [[ATOMIC_EXIT15]] ], [ [[TMP28:%.*]], [[ATOMIC_CONT17]] ], !dbg [[DBG30]]
// PPC64-NEXT:    [[SHR:%.*]] = lshr i32 [[TMP25]], [[TMP24]], !dbg [[DBG31:![0-9]+]]
// PPC64-NEXT:    store i32 [[SHR]], i32* [[ATOMIC_TEMP18]], align 4, !dbg [[DBG30]]
// PPC64-NEXT:    [[TMP26:%.*]] = load i32, i32* [[ATOMIC_TEMP18]], align 4, !dbg [[DBG30]]
// PPC64-NEXT:    [[TMP27:%.*]] = cmpxchg i32* @uix, i32 [[TMP25]], i32 [[TMP26]] monotonic monotonic, align 4, !dbg [[DBG30]]
// PPC64-NEXT:    [[TMP28]] = extractvalue { i32, i1 } [[TMP27]], 0, !dbg [[DBG30]]
// PPC64-NEXT:    [[TMP29:%.*]] = extractvalue { i32, i1 } [[TMP27]], 1, !dbg [[DBG30]]
// PPC64-NEXT:    br i1 [[TMP29]], label [[ATOMIC_EXIT19:%.*]], label [[ATOMIC_CONT17]], !dbg [[DBG30]]
// PPC64:       atomic_exit19:
// PPC64-NEXT:    store i32 [[SHR]], i32* @iv, align 4, !dbg [[DBG30]]
// PPC64-NEXT:    [[TMP30:%.*]] = load i64, i64* @lv, align 8, !dbg [[DBG32:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD20:%.*]] = load atomic i64, i64* @lx monotonic, align 8, !dbg [[DBG33:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT21:%.*]], !dbg [[DBG33]]
// PPC64:       atomic_cont21:
// PPC64-NEXT:    [[TMP31:%.*]] = phi i64 [ [[ATOMIC_LOAD20]], [[ATOMIC_EXIT19]] ], [ [[TMP34:%.*]], [[ATOMIC_CONT21]] ], !dbg [[DBG33]]
// PPC64-NEXT:    [[DIV:%.*]] = sdiv i64 [[TMP31]], [[TMP30]], !dbg [[DBG34:![0-9]+]]
// PPC64-NEXT:    store i64 [[DIV]], i64* [[ATOMIC_TEMP22]], align 8, !dbg [[DBG33]]
// PPC64-NEXT:    [[TMP32:%.*]] = load i64, i64* [[ATOMIC_TEMP22]], align 8, !dbg [[DBG33]]
// PPC64-NEXT:    [[TMP33:%.*]] = cmpxchg i64* @lx, i64 [[TMP31]], i64 [[TMP32]] monotonic monotonic, align 8, !dbg [[DBG33]]
// PPC64-NEXT:    [[TMP34]] = extractvalue { i64, i1 } [[TMP33]], 0, !dbg [[DBG33]]
// PPC64-NEXT:    [[TMP35:%.*]] = extractvalue { i64, i1 } [[TMP33]], 1, !dbg [[DBG33]]
// PPC64-NEXT:    br i1 [[TMP35]], label [[ATOMIC_EXIT23:%.*]], label [[ATOMIC_CONT21]], !dbg [[DBG33]]
// PPC64:       atomic_exit23:
// PPC64-NEXT:    store i64 [[TMP31]], i64* @ulv, align 8, !dbg [[DBG33]]
// PPC64-NEXT:    [[TMP36:%.*]] = load i64, i64* @ulv, align 8, !dbg [[DBG35:![0-9]+]]
// PPC64-NEXT:    [[TMP37:%.*]] = atomicrmw and i64* @ulx, i64 [[TMP36]] monotonic, align 8, !dbg [[DBG36:![0-9]+]]
// PPC64-NEXT:    [[AND:%.*]] = and i64 [[TMP37]], [[TMP36]], !dbg [[DBG37:![0-9]+]]
// PPC64-NEXT:    store i64 [[AND]], i64* @lv, align 8, !dbg [[DBG36]]
// PPC64-NEXT:    [[TMP38:%.*]] = load i64, i64* @llv, align 8, !dbg [[DBG38:![0-9]+]]
// PPC64-NEXT:    [[TMP39:%.*]] = atomicrmw xor i64* @llx, i64 [[TMP38]] monotonic, align 8, !dbg [[DBG39:![0-9]+]]
// PPC64-NEXT:    [[XOR:%.*]] = xor i64 [[TMP39]], [[TMP38]], !dbg [[DBG40:![0-9]+]]
// PPC64-NEXT:    store i64 [[XOR]], i64* @ullv, align 8, !dbg [[DBG39]]
// PPC64-NEXT:    [[TMP40:%.*]] = load i64, i64* @ullv, align 8, !dbg [[DBG41:![0-9]+]]
// PPC64-NEXT:    [[TMP41:%.*]] = atomicrmw or i64* @ullx, i64 [[TMP40]] monotonic, align 8, !dbg [[DBG42:![0-9]+]]
// PPC64-NEXT:    [[OR:%.*]] = or i64 [[TMP41]], [[TMP40]], !dbg [[DBG43:![0-9]+]]
// PPC64-NEXT:    store i64 [[OR]], i64* @llv, align 8, !dbg [[DBG42]]
// PPC64-NEXT:    [[TMP42:%.*]] = load float, float* @fv, align 4, !dbg [[DBG44:![0-9]+]]
// PPC64-NEXT:    [[TMP43:%.*]] = atomicrmw fadd float* @fx, float [[TMP42]] monotonic, align 4, !dbg [[DBG45:![0-9]+]]
// PPC64-NEXT:    [[ADD24:%.*]] = fadd float [[TMP43]], [[TMP42]], !dbg [[DBG46:![0-9]+]]
// PPC64-NEXT:    [[CONV25:%.*]] = fpext float [[ADD24]] to double, !dbg [[DBG45]]
// PPC64-NEXT:    store double [[CONV25]], double* @dv, align 8, !dbg [[DBG45]]
// PPC64-NEXT:    [[TMP44:%.*]] = load double, double* @dv, align 8, !dbg [[DBG47:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD26:%.*]] = load atomic i64, i64* bitcast (double* @dx to i64*) monotonic, align 8, !dbg [[DBG48:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT27:%.*]], !dbg [[DBG48]]
// PPC64:       atomic_cont27:
// PPC64-NEXT:    [[TMP45:%.*]] = phi i64 [ [[ATOMIC_LOAD26]], [[ATOMIC_EXIT23]] ], [ [[TMP50:%.*]], [[ATOMIC_CONT27]] ], !dbg [[DBG48]]
// PPC64-NEXT:    [[TMP46:%.*]] = bitcast double* [[ATOMIC_TEMP28]] to i64*, !dbg [[DBG48]]
// PPC64-NEXT:    [[TMP47:%.*]] = bitcast i64 [[TMP45]] to double, !dbg [[DBG48]]
// PPC64-NEXT:    [[SUB29:%.*]] = fsub double [[TMP44]], [[TMP47]], !dbg [[DBG49:![0-9]+]]
// PPC64-NEXT:    store double [[SUB29]], double* [[ATOMIC_TEMP28]], align 8, !dbg [[DBG48]]
// PPC64-NEXT:    [[TMP48:%.*]] = load i64, i64* [[TMP46]], align 8, !dbg [[DBG48]]
// PPC64-NEXT:    [[TMP49:%.*]] = cmpxchg i64* bitcast (double* @dx to i64*), i64 [[TMP45]], i64 [[TMP48]] monotonic monotonic, align 8, !dbg [[DBG48]]
// PPC64-NEXT:    [[TMP50]] = extractvalue { i64, i1 } [[TMP49]], 0, !dbg [[DBG48]]
// PPC64-NEXT:    [[TMP51:%.*]] = extractvalue { i64, i1 } [[TMP49]], 1, !dbg [[DBG48]]
// PPC64-NEXT:    br i1 [[TMP51]], label [[ATOMIC_EXIT30:%.*]], label [[ATOMIC_CONT27]], !dbg [[DBG48]]
// PPC64:       atomic_exit30:
// PPC64-NEXT:    [[CONV31:%.*]] = fptrunc double [[TMP47]] to float, !dbg [[DBG48]]
// PPC64-NEXT:    store float [[CONV31]], float* @fv, align 4, !dbg [[DBG48]]
// PPC64-NEXT:    [[TMP52:%.*]] = load ppc_fp128, ppc_fp128* @ldv, align 16, !dbg [[DBG50:![0-9]+]]
// PPC64-NEXT:    [[TMP53:%.*]] = bitcast ppc_fp128* [[ATOMIC_TEMP32]] to i8*, !dbg [[DBG51:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 16, i8* noundef bitcast (ppc_fp128* @ldx to i8*), i8* noundef [[TMP53]], i32 noundef signext 0), !dbg [[DBG51]]
// PPC64-NEXT:    br label [[ATOMIC_CONT33:%.*]], !dbg [[DBG51]]
// PPC64:       atomic_cont33:
// PPC64-NEXT:    [[TMP54:%.*]] = load ppc_fp128, ppc_fp128* [[ATOMIC_TEMP32]], align 16, !dbg [[DBG51]]
// PPC64-NEXT:    [[MUL35:%.*]] = fmul ppc_fp128 [[TMP54]], [[TMP52]], !dbg [[DBG52:![0-9]+]]
// PPC64-NEXT:    store ppc_fp128 [[MUL35]], ppc_fp128* [[ATOMIC_TEMP34]], align 16, !dbg [[DBG51]]
// PPC64-NEXT:    [[TMP55:%.*]] = bitcast ppc_fp128* [[ATOMIC_TEMP32]] to i8*, !dbg [[DBG51]]
// PPC64-NEXT:    [[TMP56:%.*]] = bitcast ppc_fp128* [[ATOMIC_TEMP34]] to i8*, !dbg [[DBG51]]
// PPC64-NEXT:    [[CALL:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, i8* noundef bitcast (ppc_fp128* @ldx to i8*), i8* noundef [[TMP55]], i8* noundef [[TMP56]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG51]]
// PPC64-NEXT:    br i1 [[CALL]], label [[ATOMIC_EXIT36:%.*]], label [[ATOMIC_CONT33]], !dbg [[DBG51]]
// PPC64:       atomic_exit36:
// PPC64-NEXT:    [[CONV37:%.*]] = fptrunc ppc_fp128 [[MUL35]] to double, !dbg [[DBG51]]
// PPC64-NEXT:    store double [[CONV37]], double* @dv, align 8, !dbg [[DBG51]]
// PPC64-NEXT:    [[CIV_REAL:%.*]] = load i32, i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 0), align 4, !dbg [[DBG53:![0-9]+]]
// PPC64-NEXT:    [[CIV_IMAG:%.*]] = load i32, i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 1), align 4, !dbg [[DBG53]]
// PPC64-NEXT:    [[TMP57:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP38]] to i8*, !dbg [[DBG54:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP57]], i32 noundef signext 0), !dbg [[DBG54]]
// PPC64-NEXT:    br label [[ATOMIC_CONT39:%.*]], !dbg [[DBG54]]
// PPC64:       atomic_cont39:
// PPC64-NEXT:    [[ATOMIC_TEMP38_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP38]], i32 0, i32 0, !dbg [[DBG54]]
// PPC64-NEXT:    [[ATOMIC_TEMP38_REAL:%.*]] = load i32, i32* [[ATOMIC_TEMP38_REALP]], align 4, !dbg [[DBG54]]
// PPC64-NEXT:    [[ATOMIC_TEMP38_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP38]], i32 0, i32 1, !dbg [[DBG54]]
// PPC64-NEXT:    [[ATOMIC_TEMP38_IMAG:%.*]] = load i32, i32* [[ATOMIC_TEMP38_IMAGP]], align 4, !dbg [[DBG54]]
// PPC64-NEXT:    [[TMP58:%.*]] = mul i32 [[CIV_REAL]], [[ATOMIC_TEMP38_REAL]], !dbg [[DBG55:![0-9]+]]
// PPC64-NEXT:    [[TMP59:%.*]] = mul i32 [[CIV_IMAG]], [[ATOMIC_TEMP38_IMAG]], !dbg [[DBG55]]
// PPC64-NEXT:    [[TMP60:%.*]] = add i32 [[TMP58]], [[TMP59]], !dbg [[DBG55]]
// PPC64-NEXT:    [[TMP61:%.*]] = mul i32 [[ATOMIC_TEMP38_REAL]], [[ATOMIC_TEMP38_REAL]], !dbg [[DBG55]]
// PPC64-NEXT:    [[TMP62:%.*]] = mul i32 [[ATOMIC_TEMP38_IMAG]], [[ATOMIC_TEMP38_IMAG]], !dbg [[DBG55]]
// PPC64-NEXT:    [[TMP63:%.*]] = add i32 [[TMP61]], [[TMP62]], !dbg [[DBG55]]
// PPC64-NEXT:    [[TMP64:%.*]] = mul i32 [[CIV_IMAG]], [[ATOMIC_TEMP38_REAL]], !dbg [[DBG55]]
// PPC64-NEXT:    [[TMP65:%.*]] = mul i32 [[CIV_REAL]], [[ATOMIC_TEMP38_IMAG]], !dbg [[DBG55]]
// PPC64-NEXT:    [[TMP66:%.*]] = sub i32 [[TMP64]], [[TMP65]], !dbg [[DBG55]]
// PPC64-NEXT:    [[TMP67:%.*]] = sdiv i32 [[TMP60]], [[TMP63]], !dbg [[DBG55]]
// PPC64-NEXT:    [[TMP68:%.*]] = sdiv i32 [[TMP66]], [[TMP63]], !dbg [[DBG55]]
// PPC64-NEXT:    [[ATOMIC_TEMP40_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP40]], i32 0, i32 0, !dbg [[DBG54]]
// PPC64-NEXT:    [[ATOMIC_TEMP40_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP40]], i32 0, i32 1, !dbg [[DBG54]]
// PPC64-NEXT:    store i32 [[TMP67]], i32* [[ATOMIC_TEMP40_REALP]], align 4, !dbg [[DBG54]]
// PPC64-NEXT:    store i32 [[TMP68]], i32* [[ATOMIC_TEMP40_IMAGP]], align 4, !dbg [[DBG54]]
// PPC64-NEXT:    [[TMP69:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP38]] to i8*, !dbg [[DBG54]]
// PPC64-NEXT:    [[TMP70:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP40]] to i8*, !dbg [[DBG54]]
// PPC64-NEXT:    [[CALL41:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP69]], i8* noundef [[TMP70]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG54]]
// PPC64-NEXT:    br i1 [[CALL41]], label [[ATOMIC_EXIT42:%.*]], label [[ATOMIC_CONT39]], !dbg [[DBG54]]
// PPC64:       atomic_exit42:
// PPC64-NEXT:    [[CONV43:%.*]] = sitofp i32 [[TMP67]] to float, !dbg [[DBG54]]
// PPC64-NEXT:    [[CONV44:%.*]] = sitofp i32 [[TMP68]] to float, !dbg [[DBG54]]
// PPC64-NEXT:    store float [[CONV43]], float* getelementptr inbounds ({ float, float }, { float, float }* @cfv, i32 0, i32 0), align 4, !dbg [[DBG54]]
// PPC64-NEXT:    store float [[CONV44]], float* getelementptr inbounds ({ float, float }, { float, float }* @cfv, i32 0, i32 1), align 4, !dbg [[DBG54]]
// PPC64-NEXT:    [[CFV_REAL:%.*]] = load float, float* getelementptr inbounds ({ float, float }, { float, float }* @cfv, i32 0, i32 0), align 4, !dbg [[DBG56:![0-9]+]]
// PPC64-NEXT:    [[CFV_IMAG:%.*]] = load float, float* getelementptr inbounds ({ float, float }, { float, float }* @cfv, i32 0, i32 1), align 4, !dbg [[DBG56]]
// PPC64-NEXT:    [[TMP71:%.*]] = bitcast { float, float }* [[ATOMIC_TEMP45]] to i8*, !dbg [[DBG57:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 8, i8* noundef bitcast ({ float, float }* @cfx to i8*), i8* noundef [[TMP71]], i32 noundef signext 0), !dbg [[DBG57]]
// PPC64-NEXT:    br label [[ATOMIC_CONT46:%.*]], !dbg [[DBG57]]
// PPC64:       atomic_cont46:
// PPC64-NEXT:    [[ATOMIC_TEMP45_REALP:%.*]] = getelementptr inbounds { float, float }, { float, float }* [[ATOMIC_TEMP45]], i32 0, i32 0, !dbg [[DBG57]]
// PPC64-NEXT:    [[ATOMIC_TEMP45_REAL:%.*]] = load float, float* [[ATOMIC_TEMP45_REALP]], align 4, !dbg [[DBG57]]
// PPC64-NEXT:    [[ATOMIC_TEMP45_IMAGP:%.*]] = getelementptr inbounds { float, float }, { float, float }* [[ATOMIC_TEMP45]], i32 0, i32 1, !dbg [[DBG57]]
// PPC64-NEXT:    [[ATOMIC_TEMP45_IMAG:%.*]] = load float, float* [[ATOMIC_TEMP45_IMAGP]], align 4, !dbg [[DBG57]]
// PPC64-NEXT:    [[ADD_R:%.*]] = fadd float [[CFV_REAL]], [[ATOMIC_TEMP45_REAL]], !dbg [[DBG58:![0-9]+]]
// PPC64-NEXT:    [[ADD_I:%.*]] = fadd float [[CFV_IMAG]], [[ATOMIC_TEMP45_IMAG]], !dbg [[DBG58]]
// PPC64-NEXT:    [[ATOMIC_TEMP47_REALP:%.*]] = getelementptr inbounds { float, float }, { float, float }* [[ATOMIC_TEMP47]], i32 0, i32 0, !dbg [[DBG57]]
// PPC64-NEXT:    [[ATOMIC_TEMP47_IMAGP:%.*]] = getelementptr inbounds { float, float }, { float, float }* [[ATOMIC_TEMP47]], i32 0, i32 1, !dbg [[DBG57]]
// PPC64-NEXT:    store float [[ADD_R]], float* [[ATOMIC_TEMP47_REALP]], align 4, !dbg [[DBG57]]
// PPC64-NEXT:    store float [[ADD_I]], float* [[ATOMIC_TEMP47_IMAGP]], align 4, !dbg [[DBG57]]
// PPC64-NEXT:    [[TMP72:%.*]] = bitcast { float, float }* [[ATOMIC_TEMP45]] to i8*, !dbg [[DBG57]]
// PPC64-NEXT:    [[TMP73:%.*]] = bitcast { float, float }* [[ATOMIC_TEMP47]] to i8*, !dbg [[DBG57]]
// PPC64-NEXT:    [[CALL48:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, i8* noundef bitcast ({ float, float }* @cfx to i8*), i8* noundef [[TMP72]], i8* noundef [[TMP73]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG57]]
// PPC64-NEXT:    br i1 [[CALL48]], label [[ATOMIC_EXIT49:%.*]], label [[ATOMIC_CONT46]], !dbg [[DBG57]]
// PPC64:       atomic_exit49:
// PPC64-NEXT:    [[CONV50:%.*]] = fptosi float [[ATOMIC_TEMP45_REAL]] to i32, !dbg [[DBG57]]
// PPC64-NEXT:    [[CONV51:%.*]] = fptosi float [[ATOMIC_TEMP45_IMAG]] to i32, !dbg [[DBG57]]
// PPC64-NEXT:    store i32 [[CONV50]], i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 0), align 4, !dbg [[DBG57]]
// PPC64-NEXT:    store i32 [[CONV51]], i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 1), align 4, !dbg [[DBG57]]
// PPC64-NEXT:    [[CDV_REAL:%.*]] = load double, double* getelementptr inbounds ({ double, double }, { double, double }* @cdv, i32 0, i32 0), align 8, !dbg [[DBG59:![0-9]+]]
// PPC64-NEXT:    [[CDV_IMAG:%.*]] = load double, double* getelementptr inbounds ({ double, double }, { double, double }* @cdv, i32 0, i32 1), align 8, !dbg [[DBG59]]
// PPC64-NEXT:    [[TMP74:%.*]] = bitcast { double, double }* [[ATOMIC_TEMP52]] to i8*, !dbg [[DBG60:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 16, i8* noundef bitcast ({ double, double }* @cdx to i8*), i8* noundef [[TMP74]], i32 noundef signext 5), !dbg [[DBG60]]
// PPC64-NEXT:    br label [[ATOMIC_CONT53:%.*]], !dbg [[DBG60]]
// PPC64:       atomic_cont53:
// PPC64-NEXT:    [[ATOMIC_TEMP52_REALP:%.*]] = getelementptr inbounds { double, double }, { double, double }* [[ATOMIC_TEMP52]], i32 0, i32 0, !dbg [[DBG60]]
// PPC64-NEXT:    [[ATOMIC_TEMP52_REAL:%.*]] = load double, double* [[ATOMIC_TEMP52_REALP]], align 8, !dbg [[DBG60]]
// PPC64-NEXT:    [[ATOMIC_TEMP52_IMAGP:%.*]] = getelementptr inbounds { double, double }, { double, double }* [[ATOMIC_TEMP52]], i32 0, i32 1, !dbg [[DBG60]]
// PPC64-NEXT:    [[ATOMIC_TEMP52_IMAG:%.*]] = load double, double* [[ATOMIC_TEMP52_IMAGP]], align 8, !dbg [[DBG60]]
// PPC64-NEXT:    [[SUB_R:%.*]] = fsub double [[ATOMIC_TEMP52_REAL]], [[CDV_REAL]], !dbg [[DBG61:![0-9]+]]
// PPC64-NEXT:    [[SUB_I:%.*]] = fsub double [[ATOMIC_TEMP52_IMAG]], [[CDV_IMAG]], !dbg [[DBG61]]
// PPC64-NEXT:    [[ATOMIC_TEMP54_REALP:%.*]] = getelementptr inbounds { double, double }, { double, double }* [[ATOMIC_TEMP54]], i32 0, i32 0, !dbg [[DBG60]]
// PPC64-NEXT:    [[ATOMIC_TEMP54_IMAGP:%.*]] = getelementptr inbounds { double, double }, { double, double }* [[ATOMIC_TEMP54]], i32 0, i32 1, !dbg [[DBG60]]
// PPC64-NEXT:    store double [[SUB_R]], double* [[ATOMIC_TEMP54_REALP]], align 8, !dbg [[DBG60]]
// PPC64-NEXT:    store double [[SUB_I]], double* [[ATOMIC_TEMP54_IMAGP]], align 8, !dbg [[DBG60]]
// PPC64-NEXT:    [[TMP75:%.*]] = bitcast { double, double }* [[ATOMIC_TEMP52]] to i8*, !dbg [[DBG60]]
// PPC64-NEXT:    [[TMP76:%.*]] = bitcast { double, double }* [[ATOMIC_TEMP54]] to i8*, !dbg [[DBG60]]
// PPC64-NEXT:    [[CALL55:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, i8* noundef bitcast ({ double, double }* @cdx to i8*), i8* noundef [[TMP75]], i8* noundef [[TMP76]], i32 noundef signext 5, i32 noundef signext 5), !dbg [[DBG60]]
// PPC64-NEXT:    br i1 [[CALL55]], label [[ATOMIC_EXIT56:%.*]], label [[ATOMIC_CONT53]], !dbg [[DBG60]]
// PPC64:       atomic_exit56:
// PPC64-NEXT:    [[CONV57:%.*]] = fptrunc double [[SUB_R]] to float, !dbg [[DBG60]]
// PPC64-NEXT:    [[CONV58:%.*]] = fptrunc double [[SUB_I]] to float, !dbg [[DBG60]]
// PPC64-NEXT:    store float [[CONV57]], float* getelementptr inbounds ({ float, float }, { float, float }* @cfv, i32 0, i32 0), align 4, !dbg [[DBG60]]
// PPC64-NEXT:    store float [[CONV58]], float* getelementptr inbounds ({ float, float }, { float, float }* @cfv, i32 0, i32 1), align 4, !dbg [[DBG60]]
// PPC64-NEXT:    [[TMP77:%.*]] = load i8, i8* @bv, align 1, !dbg [[DBG62:![0-9]+]]
// PPC64-NEXT:    [[TOBOOL:%.*]] = trunc i8 [[TMP77]] to i1, !dbg [[DBG62]]
// PPC64-NEXT:    [[CONV59:%.*]] = zext i1 [[TOBOOL]] to i64, !dbg [[DBG62]]
// PPC64-NEXT:    [[TMP78:%.*]] = atomicrmw and i64* @ulx, i64 [[CONV59]] monotonic, align 8, !dbg [[DBG63:![0-9]+]]
// PPC64-NEXT:    [[AND60:%.*]] = and i64 [[TMP78]], [[CONV59]], !dbg [[DBG64:![0-9]+]]
// PPC64-NEXT:    store i64 [[AND60]], i64* @ulv, align 8, !dbg [[DBG63]]
// PPC64-NEXT:    [[TMP79:%.*]] = load i8, i8* @cv, align 1, !dbg [[DBG65:![0-9]+]]
// PPC64-NEXT:    [[CONV61:%.*]] = sext i8 [[TMP79]] to i32, !dbg [[DBG65]]
// PPC64-NEXT:    [[ATOMIC_LOAD62:%.*]] = load atomic i8, i8* @bx monotonic, align 1, !dbg [[DBG66:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT63:%.*]], !dbg [[DBG66]]
// PPC64:       atomic_cont63:
// PPC64-NEXT:    [[TMP80:%.*]] = phi i8 [ [[ATOMIC_LOAD62]], [[ATOMIC_EXIT56]] ], [ [[TMP83:%.*]], [[ATOMIC_CONT63]] ], !dbg [[DBG66]]
// PPC64-NEXT:    [[TOBOOL65:%.*]] = trunc i8 [[TMP80]] to i1, !dbg [[DBG66]]
// PPC64-NEXT:    [[CONV66:%.*]] = zext i1 [[TOBOOL65]] to i32, !dbg [[DBG67:![0-9]+]]
// PPC64-NEXT:    [[AND67:%.*]] = and i32 [[CONV61]], [[CONV66]], !dbg [[DBG68:![0-9]+]]
// PPC64-NEXT:    [[TOBOOL68:%.*]] = icmp ne i32 [[AND67]], 0, !dbg [[DBG65]]
// PPC64-NEXT:    [[FROMBOOL:%.*]] = zext i1 [[TOBOOL68]] to i8, !dbg [[DBG66]]
// PPC64-NEXT:    store i8 [[FROMBOOL]], i8* [[ATOMIC_TEMP64]], align 1, !dbg [[DBG66]]
// PPC64-NEXT:    [[TMP81:%.*]] = load i8, i8* [[ATOMIC_TEMP64]], align 1, !dbg [[DBG66]]
// PPC64-NEXT:    [[TMP82:%.*]] = cmpxchg i8* @bx, i8 [[TMP80]], i8 [[TMP81]] monotonic monotonic, align 1, !dbg [[DBG66]]
// PPC64-NEXT:    [[TMP83]] = extractvalue { i8, i1 } [[TMP82]], 0, !dbg [[DBG66]]
// PPC64-NEXT:    [[TMP84:%.*]] = extractvalue { i8, i1 } [[TMP82]], 1, !dbg [[DBG66]]
// PPC64-NEXT:    br i1 [[TMP84]], label [[ATOMIC_EXIT69:%.*]], label [[ATOMIC_CONT63]], !dbg [[DBG66]]
// PPC64:       atomic_exit69:
// PPC64-NEXT:    [[FROMBOOL70:%.*]] = zext i1 [[TOBOOL65]] to i8, !dbg [[DBG66]]
// PPC64-NEXT:    store i8 [[FROMBOOL70]], i8* @bv, align 1, !dbg [[DBG66]]
// PPC64-NEXT:    [[TMP85:%.*]] = load i8, i8* @ucv, align 1, !dbg [[DBG69:![0-9]+]]
// PPC64-NEXT:    [[CONV71:%.*]] = zext i8 [[TMP85]] to i32, !dbg [[DBG69]]
// PPC64-NEXT:    [[ATOMIC_LOAD72:%.*]] = load atomic i8, i8* @cx seq_cst, align 1, !dbg [[DBG70:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT73:%.*]], !dbg [[DBG70]]
// PPC64:       atomic_cont73:
// PPC64-NEXT:    [[TMP86:%.*]] = phi i8 [ [[ATOMIC_LOAD72]], [[ATOMIC_EXIT69]] ], [ [[TMP89:%.*]], [[ATOMIC_CONT73]] ], !dbg [[DBG70]]
// PPC64-NEXT:    [[CONV75:%.*]] = sext i8 [[TMP86]] to i32, !dbg [[DBG71:![0-9]+]]
// PPC64-NEXT:    [[SHR76:%.*]] = ashr i32 [[CONV75]], [[CONV71]], !dbg [[DBG72:![0-9]+]]
// PPC64-NEXT:    [[CONV77:%.*]] = trunc i32 [[SHR76]] to i8, !dbg [[DBG71]]
// PPC64-NEXT:    store i8 [[CONV77]], i8* [[ATOMIC_TEMP74]], align 1, !dbg [[DBG70]]
// PPC64-NEXT:    [[TMP87:%.*]] = load i8, i8* [[ATOMIC_TEMP74]], align 1, !dbg [[DBG70]]
// PPC64-NEXT:    [[TMP88:%.*]] = cmpxchg i8* @cx, i8 [[TMP86]], i8 [[TMP87]] seq_cst seq_cst, align 1, !dbg [[DBG70]]
// PPC64-NEXT:    [[TMP89]] = extractvalue { i8, i1 } [[TMP88]], 0, !dbg [[DBG70]]
// PPC64-NEXT:    [[TMP90:%.*]] = extractvalue { i8, i1 } [[TMP88]], 1, !dbg [[DBG70]]
// PPC64-NEXT:    br i1 [[TMP90]], label [[ATOMIC_EXIT78:%.*]], label [[ATOMIC_CONT73]], !dbg [[DBG70]]
// PPC64:       atomic_exit78:
// PPC64-NEXT:    store i8 [[CONV77]], i8* @cv, align 1, !dbg [[DBG70]]
// PPC64-NEXT:    [[TMP91:%.*]] = load i16, i16* @sv, align 2, !dbg [[DBG73:![0-9]+]]
// PPC64-NEXT:    [[CONV79:%.*]] = sext i16 [[TMP91]] to i32, !dbg [[DBG73]]
// PPC64-NEXT:    [[ATOMIC_LOAD80:%.*]] = load atomic i64, i64* @ulx monotonic, align 8, !dbg [[DBG74:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT81:%.*]], !dbg [[DBG74]]
// PPC64:       atomic_cont81:
// PPC64-NEXT:    [[TMP92:%.*]] = phi i64 [ [[ATOMIC_LOAD80]], [[ATOMIC_EXIT78]] ], [ [[TMP95:%.*]], [[ATOMIC_CONT81]] ], !dbg [[DBG74]]
// PPC64-NEXT:    [[SH_PROM:%.*]] = trunc i64 [[TMP92]] to i32, !dbg [[DBG75:![0-9]+]]
// PPC64-NEXT:    [[SHL83:%.*]] = shl i32 [[CONV79]], [[SH_PROM]], !dbg [[DBG75]]
// PPC64-NEXT:    [[CONV84:%.*]] = sext i32 [[SHL83]] to i64, !dbg [[DBG73]]
// PPC64-NEXT:    store i64 [[CONV84]], i64* [[ATOMIC_TEMP82]], align 8, !dbg [[DBG74]]
// PPC64-NEXT:    [[TMP93:%.*]] = load i64, i64* [[ATOMIC_TEMP82]], align 8, !dbg [[DBG74]]
// PPC64-NEXT:    [[TMP94:%.*]] = cmpxchg i64* @ulx, i64 [[TMP92]], i64 [[TMP93]] monotonic monotonic, align 8, !dbg [[DBG74]]
// PPC64-NEXT:    [[TMP95]] = extractvalue { i64, i1 } [[TMP94]], 0, !dbg [[DBG74]]
// PPC64-NEXT:    [[TMP96:%.*]] = extractvalue { i64, i1 } [[TMP94]], 1, !dbg [[DBG74]]
// PPC64-NEXT:    br i1 [[TMP96]], label [[ATOMIC_EXIT85:%.*]], label [[ATOMIC_CONT81]], !dbg [[DBG74]]
// PPC64:       atomic_exit85:
// PPC64-NEXT:    store i64 [[CONV84]], i64* @ulv, align 8, !dbg [[DBG74]]
// PPC64-NEXT:    [[TMP97:%.*]] = load i16, i16* @usv, align 2, !dbg [[DBG76:![0-9]+]]
// PPC64-NEXT:    [[CONV86:%.*]] = zext i16 [[TMP97]] to i64, !dbg [[DBG76]]
// PPC64-NEXT:    [[ATOMIC_LOAD87:%.*]] = load atomic i64, i64* @lx monotonic, align 8, !dbg [[DBG77:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT88:%.*]], !dbg [[DBG77]]
// PPC64:       atomic_cont88:
// PPC64-NEXT:    [[TMP98:%.*]] = phi i64 [ [[ATOMIC_LOAD87]], [[ATOMIC_EXIT85]] ], [ [[TMP101:%.*]], [[ATOMIC_CONT88]] ], !dbg [[DBG77]]
// PPC64-NEXT:    [[REM:%.*]] = srem i64 [[TMP98]], [[CONV86]], !dbg [[DBG78:![0-9]+]]
// PPC64-NEXT:    store i64 [[REM]], i64* [[ATOMIC_TEMP89]], align 8, !dbg [[DBG77]]
// PPC64-NEXT:    [[TMP99:%.*]] = load i64, i64* [[ATOMIC_TEMP89]], align 8, !dbg [[DBG77]]
// PPC64-NEXT:    [[TMP100:%.*]] = cmpxchg i64* @lx, i64 [[TMP98]], i64 [[TMP99]] monotonic monotonic, align 8, !dbg [[DBG77]]
// PPC64-NEXT:    [[TMP101]] = extractvalue { i64, i1 } [[TMP100]], 0, !dbg [[DBG77]]
// PPC64-NEXT:    [[TMP102:%.*]] = extractvalue { i64, i1 } [[TMP100]], 1, !dbg [[DBG77]]
// PPC64-NEXT:    br i1 [[TMP102]], label [[ATOMIC_EXIT90:%.*]], label [[ATOMIC_CONT88]], !dbg [[DBG77]]
// PPC64:       atomic_exit90:
// PPC64-NEXT:    store i64 [[TMP98]], i64* @lv, align 8, !dbg [[DBG77]]
// PPC64-NEXT:    [[TMP103:%.*]] = load i32, i32* @iv, align 4, !dbg [[DBG79:![0-9]+]]
// PPC64-NEXT:    [[TMP104:%.*]] = atomicrmw or i32* @uix, i32 [[TMP103]] seq_cst, align 4, !dbg [[DBG80:![0-9]+]]
// PPC64-NEXT:    [[OR91:%.*]] = or i32 [[TMP103]], [[TMP104]], !dbg [[DBG81:![0-9]+]]
// PPC64-NEXT:    store i32 [[OR91]], i32* @uiv, align 4, !dbg [[DBG80]]
// PPC64-NEXT:    [[TMP105:%.*]] = load i32, i32* @uiv, align 4, !dbg [[DBG82:![0-9]+]]
// PPC64-NEXT:    [[TMP106:%.*]] = atomicrmw and i32* @ix, i32 [[TMP105]] monotonic, align 4, !dbg [[DBG83:![0-9]+]]
// PPC64-NEXT:    [[AND92:%.*]] = and i32 [[TMP106]], [[TMP105]], !dbg [[DBG84:![0-9]+]]
// PPC64-NEXT:    store i32 [[AND92]], i32* @iv, align 4, !dbg [[DBG83]]
// PPC64-NEXT:    [[TMP107:%.*]] = load i64, i64* @lv, align 8, !dbg [[DBG85:![0-9]+]]
// PPC64-NEXT:    [[TMP108:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP93]] to i8*, !dbg [[DBG86:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP108]], i32 noundef signext 0), !dbg [[DBG86]]
// PPC64-NEXT:    br label [[ATOMIC_CONT94:%.*]], !dbg [[DBG86]]
// PPC64:       atomic_cont94:
// PPC64-NEXT:    [[ATOMIC_TEMP93_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP93]], i32 0, i32 0, !dbg [[DBG86]]
// PPC64-NEXT:    [[ATOMIC_TEMP93_REAL:%.*]] = load i32, i32* [[ATOMIC_TEMP93_REALP]], align 4, !dbg [[DBG86]]
// PPC64-NEXT:    [[ATOMIC_TEMP93_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP93]], i32 0, i32 1, !dbg [[DBG86]]
// PPC64-NEXT:    [[ATOMIC_TEMP93_IMAG:%.*]] = load i32, i32* [[ATOMIC_TEMP93_IMAGP]], align 4, !dbg [[DBG86]]
// PPC64-NEXT:    [[CONV96:%.*]] = sext i32 [[ATOMIC_TEMP93_REAL]] to i64, !dbg [[DBG87:![0-9]+]]
// PPC64-NEXT:    [[CONV97:%.*]] = sext i32 [[ATOMIC_TEMP93_IMAG]] to i64, !dbg [[DBG87]]
// PPC64-NEXT:    [[ADD_R98:%.*]] = add i64 [[TMP107]], [[CONV96]], !dbg [[DBG88:![0-9]+]]
// PPC64-NEXT:    [[ADD_I99:%.*]] = add i64 0, [[CONV97]], !dbg [[DBG88]]
// PPC64-NEXT:    [[CONV100:%.*]] = trunc i64 [[ADD_R98]] to i32, !dbg [[DBG85]]
// PPC64-NEXT:    [[CONV101:%.*]] = trunc i64 [[ADD_I99]] to i32, !dbg [[DBG85]]
// PPC64-NEXT:    [[ATOMIC_TEMP95_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP95]], i32 0, i32 0, !dbg [[DBG86]]
// PPC64-NEXT:    [[ATOMIC_TEMP95_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP95]], i32 0, i32 1, !dbg [[DBG86]]
// PPC64-NEXT:    store i32 [[CONV100]], i32* [[ATOMIC_TEMP95_REALP]], align 4, !dbg [[DBG86]]
// PPC64-NEXT:    store i32 [[CONV101]], i32* [[ATOMIC_TEMP95_IMAGP]], align 4, !dbg [[DBG86]]
// PPC64-NEXT:    [[TMP109:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP93]] to i8*, !dbg [[DBG86]]
// PPC64-NEXT:    [[TMP110:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP95]] to i8*, !dbg [[DBG86]]
// PPC64-NEXT:    [[CALL102:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP109]], i8* noundef [[TMP110]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG86]]
// PPC64-NEXT:    br i1 [[CALL102]], label [[ATOMIC_EXIT103:%.*]], label [[ATOMIC_CONT94]], !dbg [[DBG86]]
// PPC64:       atomic_exit103:
// PPC64-NEXT:    store i32 [[ATOMIC_TEMP93_REAL]], i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 0), align 4, !dbg [[DBG86]]
// PPC64-NEXT:    store i32 [[ATOMIC_TEMP93_IMAG]], i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 1), align 4, !dbg [[DBG86]]
// PPC64-NEXT:    [[TMP111:%.*]] = load i64, i64* @ulv, align 8, !dbg [[DBG89:![0-9]+]]
// PPC64-NEXT:    [[CONV104:%.*]] = uitofp i64 [[TMP111]] to float, !dbg [[DBG89]]
// PPC64-NEXT:    [[ATOMIC_LOAD105:%.*]] = load atomic i32, i32* bitcast (float* @fx to i32*) monotonic, align 4, !dbg [[DBG90:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT106:%.*]], !dbg [[DBG90]]
// PPC64:       atomic_cont106:
// PPC64-NEXT:    [[TMP112:%.*]] = phi i32 [ [[ATOMIC_LOAD105]], [[ATOMIC_EXIT103]] ], [ [[TMP117:%.*]], [[ATOMIC_CONT106]] ], !dbg [[DBG90]]
// PPC64-NEXT:    [[TMP113:%.*]] = bitcast float* [[ATOMIC_TEMP107]] to i32*, !dbg [[DBG90]]
// PPC64-NEXT:    [[TMP114:%.*]] = bitcast i32 [[TMP112]] to float, !dbg [[DBG90]]
// PPC64-NEXT:    [[MUL108:%.*]] = fmul float [[TMP114]], [[CONV104]], !dbg [[DBG91:![0-9]+]]
// PPC64-NEXT:    store float [[MUL108]], float* [[ATOMIC_TEMP107]], align 4, !dbg [[DBG90]]
// PPC64-NEXT:    [[TMP115:%.*]] = load i32, i32* [[TMP113]], align 4, !dbg [[DBG90]]
// PPC64-NEXT:    [[TMP116:%.*]] = cmpxchg i32* bitcast (float* @fx to i32*), i32 [[TMP112]], i32 [[TMP115]] monotonic monotonic, align 4, !dbg [[DBG90]]
// PPC64-NEXT:    [[TMP117]] = extractvalue { i32, i1 } [[TMP116]], 0, !dbg [[DBG90]]
// PPC64-NEXT:    [[TMP118:%.*]] = extractvalue { i32, i1 } [[TMP116]], 1, !dbg [[DBG90]]
// PPC64-NEXT:    br i1 [[TMP118]], label [[ATOMIC_EXIT109:%.*]], label [[ATOMIC_CONT106]], !dbg [[DBG90]]
// PPC64:       atomic_exit109:
// PPC64-NEXT:    store float [[MUL108]], float* @fv, align 4, !dbg [[DBG90]]
// PPC64-NEXT:    [[TMP119:%.*]] = load i64, i64* @llv, align 8, !dbg [[DBG92:![0-9]+]]
// PPC64-NEXT:    [[CONV110:%.*]] = sitofp i64 [[TMP119]] to double, !dbg [[DBG92]]
// PPC64-NEXT:    [[ATOMIC_LOAD111:%.*]] = load atomic i64, i64* bitcast (double* @dx to i64*) monotonic, align 8, !dbg [[DBG93:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT112:%.*]], !dbg [[DBG93]]
// PPC64:       atomic_cont112:
// PPC64-NEXT:    [[TMP120:%.*]] = phi i64 [ [[ATOMIC_LOAD111]], [[ATOMIC_EXIT109]] ], [ [[TMP125:%.*]], [[ATOMIC_CONT112]] ], !dbg [[DBG93]]
// PPC64-NEXT:    [[TMP121:%.*]] = bitcast double* [[ATOMIC_TEMP113]] to i64*, !dbg [[DBG93]]
// PPC64-NEXT:    [[TMP122:%.*]] = bitcast i64 [[TMP120]] to double, !dbg [[DBG93]]
// PPC64-NEXT:    [[DIV114:%.*]] = fdiv double [[TMP122]], [[CONV110]], !dbg [[DBG94:![0-9]+]]
// PPC64-NEXT:    store double [[DIV114]], double* [[ATOMIC_TEMP113]], align 8, !dbg [[DBG93]]
// PPC64-NEXT:    [[TMP123:%.*]] = load i64, i64* [[TMP121]], align 8, !dbg [[DBG93]]
// PPC64-NEXT:    [[TMP124:%.*]] = cmpxchg i64* bitcast (double* @dx to i64*), i64 [[TMP120]], i64 [[TMP123]] monotonic monotonic, align 8, !dbg [[DBG93]]
// PPC64-NEXT:    [[TMP125]] = extractvalue { i64, i1 } [[TMP124]], 0, !dbg [[DBG93]]
// PPC64-NEXT:    [[TMP126:%.*]] = extractvalue { i64, i1 } [[TMP124]], 1, !dbg [[DBG93]]
// PPC64-NEXT:    br i1 [[TMP126]], label [[ATOMIC_EXIT115:%.*]], label [[ATOMIC_CONT112]], !dbg [[DBG93]]
// PPC64:       atomic_exit115:
// PPC64-NEXT:    store double [[DIV114]], double* @dv, align 8, !dbg [[DBG93]]
// PPC64-NEXT:    [[TMP127:%.*]] = load i64, i64* @ullv, align 8, !dbg [[DBG95:![0-9]+]]
// PPC64-NEXT:    [[CONV116:%.*]] = uitofp i64 [[TMP127]] to ppc_fp128, !dbg [[DBG95]]
// PPC64-NEXT:    [[TMP128:%.*]] = bitcast ppc_fp128* [[ATOMIC_TEMP117]] to i8*, !dbg [[DBG96:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 16, i8* noundef bitcast (ppc_fp128* @ldx to i8*), i8* noundef [[TMP128]], i32 noundef signext 0), !dbg [[DBG96]]
// PPC64-NEXT:    br label [[ATOMIC_CONT118:%.*]], !dbg [[DBG96]]
// PPC64:       atomic_cont118:
// PPC64-NEXT:    [[TMP129:%.*]] = load ppc_fp128, ppc_fp128* [[ATOMIC_TEMP117]], align 16, !dbg [[DBG96]]
// PPC64-NEXT:    [[SUB120:%.*]] = fsub ppc_fp128 [[TMP129]], [[CONV116]], !dbg [[DBG97:![0-9]+]]
// PPC64-NEXT:    store ppc_fp128 [[SUB120]], ppc_fp128* [[ATOMIC_TEMP119]], align 16, !dbg [[DBG96]]
// PPC64-NEXT:    [[TMP130:%.*]] = bitcast ppc_fp128* [[ATOMIC_TEMP117]] to i8*, !dbg [[DBG96]]
// PPC64-NEXT:    [[TMP131:%.*]] = bitcast ppc_fp128* [[ATOMIC_TEMP119]] to i8*, !dbg [[DBG96]]
// PPC64-NEXT:    [[CALL121:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, i8* noundef bitcast (ppc_fp128* @ldx to i8*), i8* noundef [[TMP130]], i8* noundef [[TMP131]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG96]]
// PPC64-NEXT:    br i1 [[CALL121]], label [[ATOMIC_EXIT122:%.*]], label [[ATOMIC_CONT118]], !dbg [[DBG96]]
// PPC64:       atomic_exit122:
// PPC64-NEXT:    store ppc_fp128 [[TMP129]], ppc_fp128* @ldv, align 16, !dbg [[DBG96]]
// PPC64-NEXT:    [[TMP132:%.*]] = load float, float* @fv, align 4, !dbg [[DBG98:![0-9]+]]
// PPC64-NEXT:    [[TMP133:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP123]] to i8*, !dbg [[DBG99:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP133]], i32 noundef signext 0), !dbg [[DBG99]]
// PPC64-NEXT:    br label [[ATOMIC_CONT124:%.*]], !dbg [[DBG99]]
// PPC64:       atomic_cont124:
// PPC64-NEXT:    [[ATOMIC_TEMP123_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP123]], i32 0, i32 0, !dbg [[DBG99]]
// PPC64-NEXT:    [[ATOMIC_TEMP123_REAL:%.*]] = load i32, i32* [[ATOMIC_TEMP123_REALP]], align 4, !dbg [[DBG99]]
// PPC64-NEXT:    [[ATOMIC_TEMP123_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP123]], i32 0, i32 1, !dbg [[DBG99]]
// PPC64-NEXT:    [[ATOMIC_TEMP123_IMAG:%.*]] = load i32, i32* [[ATOMIC_TEMP123_IMAGP]], align 4, !dbg [[DBG99]]
// PPC64-NEXT:    [[CONV126:%.*]] = sitofp i32 [[ATOMIC_TEMP123_REAL]] to float, !dbg [[DBG100:![0-9]+]]
// PPC64-NEXT:    [[CONV127:%.*]] = sitofp i32 [[ATOMIC_TEMP123_IMAG]] to float, !dbg [[DBG100]]
// PPC64-NEXT:    [[CALL128:%.*]] = call { float, float } @__divsc3(float noundef [[TMP132]], float noundef 0.000000e+00, float noundef [[CONV126]], float noundef [[CONV127]]) #[[ATTR2:[0-9]+]], !dbg [[DBG101:![0-9]+]]
// PPC64-NEXT:    [[TMP134:%.*]] = extractvalue { float, float } [[CALL128]], 0, !dbg [[DBG101]]
// PPC64-NEXT:    [[TMP135:%.*]] = extractvalue { float, float } [[CALL128]], 1, !dbg [[DBG101]]
// PPC64-NEXT:    [[CONV129:%.*]] = fptosi float [[TMP134]] to i32, !dbg [[DBG98]]
// PPC64-NEXT:    [[CONV130:%.*]] = fptosi float [[TMP135]] to i32, !dbg [[DBG98]]
// PPC64-NEXT:    [[ATOMIC_TEMP125_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP125]], i32 0, i32 0, !dbg [[DBG99]]
// PPC64-NEXT:    [[ATOMIC_TEMP125_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP125]], i32 0, i32 1, !dbg [[DBG99]]
// PPC64-NEXT:    store i32 [[CONV129]], i32* [[ATOMIC_TEMP125_REALP]], align 4, !dbg [[DBG99]]
// PPC64-NEXT:    store i32 [[CONV130]], i32* [[ATOMIC_TEMP125_IMAGP]], align 4, !dbg [[DBG99]]
// PPC64-NEXT:    [[TMP136:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP123]] to i8*, !dbg [[DBG99]]
// PPC64-NEXT:    [[TMP137:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP125]] to i8*, !dbg [[DBG99]]
// PPC64-NEXT:    [[CALL131:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP136]], i8* noundef [[TMP137]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG99]]
// PPC64-NEXT:    br i1 [[CALL131]], label [[ATOMIC_EXIT132:%.*]], label [[ATOMIC_CONT124]], !dbg [[DBG99]]
// PPC64:       atomic_exit132:
// PPC64-NEXT:    store i32 [[CONV129]], i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 0), align 4, !dbg [[DBG99]]
// PPC64-NEXT:    store i32 [[CONV130]], i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 1), align 4, !dbg [[DBG99]]
// PPC64-NEXT:    [[TMP138:%.*]] = load double, double* @dv, align 8, !dbg [[DBG102:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD133:%.*]] = load atomic i16, i16* @sx monotonic, align 2, !dbg [[DBG103:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT134:%.*]], !dbg [[DBG103]]
// PPC64:       atomic_cont134:
// PPC64-NEXT:    [[TMP139:%.*]] = phi i16 [ [[ATOMIC_LOAD133]], [[ATOMIC_EXIT132]] ], [ [[TMP142:%.*]], [[ATOMIC_CONT134]] ], !dbg [[DBG103]]
// PPC64-NEXT:    [[CONV136:%.*]] = sext i16 [[TMP139]] to i32, !dbg [[DBG104:![0-9]+]]
// PPC64-NEXT:    [[CONV137:%.*]] = sitofp i32 [[CONV136]] to double, !dbg [[DBG104]]
// PPC64-NEXT:    [[ADD138:%.*]] = fadd double [[CONV137]], [[TMP138]], !dbg [[DBG105:![0-9]+]]
// PPC64-NEXT:    [[CONV139:%.*]] = fptosi double [[ADD138]] to i16, !dbg [[DBG104]]
// PPC64-NEXT:    store i16 [[CONV139]], i16* [[ATOMIC_TEMP135]], align 2, !dbg [[DBG103]]
// PPC64-NEXT:    [[TMP140:%.*]] = load i16, i16* [[ATOMIC_TEMP135]], align 2, !dbg [[DBG103]]
// PPC64-NEXT:    [[TMP141:%.*]] = cmpxchg i16* @sx, i16 [[TMP139]], i16 [[TMP140]] monotonic monotonic, align 2, !dbg [[DBG103]]
// PPC64-NEXT:    [[TMP142]] = extractvalue { i16, i1 } [[TMP141]], 0, !dbg [[DBG103]]
// PPC64-NEXT:    [[TMP143:%.*]] = extractvalue { i16, i1 } [[TMP141]], 1, !dbg [[DBG103]]
// PPC64-NEXT:    br i1 [[TMP143]], label [[ATOMIC_EXIT140:%.*]], label [[ATOMIC_CONT134]], !dbg [[DBG103]]
// PPC64:       atomic_exit140:
// PPC64-NEXT:    store i16 [[CONV139]], i16* @sv, align 2, !dbg [[DBG103]]
// PPC64-NEXT:    [[TMP144:%.*]] = load ppc_fp128, ppc_fp128* @ldv, align 16, !dbg [[DBG106:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD141:%.*]] = load atomic i8, i8* @bx monotonic, align 1, !dbg [[DBG107:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT142:%.*]], !dbg [[DBG107]]
// PPC64:       atomic_cont142:
// PPC64-NEXT:    [[TMP145:%.*]] = phi i8 [ [[ATOMIC_LOAD141]], [[ATOMIC_EXIT140]] ], [ [[TMP148:%.*]], [[ATOMIC_CONT142]] ], !dbg [[DBG107]]
// PPC64-NEXT:    [[TOBOOL144:%.*]] = trunc i8 [[TMP145]] to i1, !dbg [[DBG107]]
// PPC64-NEXT:    [[CONV145:%.*]] = zext i1 [[TOBOOL144]] to i32, !dbg [[DBG108:![0-9]+]]
// PPC64-NEXT:    [[CONV146:%.*]] = sitofp i32 [[CONV145]] to ppc_fp128, !dbg [[DBG108]]
// PPC64-NEXT:    [[MUL147:%.*]] = fmul ppc_fp128 [[TMP144]], [[CONV146]], !dbg [[DBG109:![0-9]+]]
// PPC64-NEXT:    [[TOBOOL148:%.*]] = fcmp une ppc_fp128 [[MUL147]], 0xM00000000000000000000000000000000, !dbg [[DBG106]]
// PPC64-NEXT:    [[FROMBOOL149:%.*]] = zext i1 [[TOBOOL148]] to i8, !dbg [[DBG107]]
// PPC64-NEXT:    store i8 [[FROMBOOL149]], i8* [[ATOMIC_TEMP143]], align 1, !dbg [[DBG107]]
// PPC64-NEXT:    [[TMP146:%.*]] = load i8, i8* [[ATOMIC_TEMP143]], align 1, !dbg [[DBG107]]
// PPC64-NEXT:    [[TMP147:%.*]] = cmpxchg i8* @bx, i8 [[TMP145]], i8 [[TMP146]] monotonic monotonic, align 1, !dbg [[DBG107]]
// PPC64-NEXT:    [[TMP148]] = extractvalue { i8, i1 } [[TMP147]], 0, !dbg [[DBG107]]
// PPC64-NEXT:    [[TMP149:%.*]] = extractvalue { i8, i1 } [[TMP147]], 1, !dbg [[DBG107]]
// PPC64-NEXT:    br i1 [[TMP149]], label [[ATOMIC_EXIT150:%.*]], label [[ATOMIC_CONT142]], !dbg [[DBG107]]
// PPC64:       atomic_exit150:
// PPC64-NEXT:    [[FROMBOOL151:%.*]] = zext i1 [[TOBOOL144]] to i8, !dbg [[DBG107]]
// PPC64-NEXT:    store i8 [[FROMBOOL151]], i8* @bv, align 1, !dbg [[DBG107]]
// PPC64-NEXT:    [[CIV_REAL152:%.*]] = load i32, i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 0), align 4, !dbg [[DBG110:![0-9]+]]
// PPC64-NEXT:    [[CIV_IMAG153:%.*]] = load i32, i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 1), align 4, !dbg [[DBG110]]
// PPC64-NEXT:    [[ATOMIC_LOAD154:%.*]] = load atomic i8, i8* @bx monotonic, align 1, !dbg [[DBG111:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT155:%.*]], !dbg [[DBG111]]
// PPC64:       atomic_cont155:
// PPC64-NEXT:    [[TMP150:%.*]] = phi i8 [ [[ATOMIC_LOAD154]], [[ATOMIC_EXIT150]] ], [ [[TMP153:%.*]], [[ATOMIC_CONT155]] ], !dbg [[DBG111]]
// PPC64-NEXT:    [[TOBOOL157:%.*]] = trunc i8 [[TMP150]] to i1, !dbg [[DBG111]]
// PPC64-NEXT:    [[CONV158:%.*]] = zext i1 [[TOBOOL157]] to i32, !dbg [[DBG112:![0-9]+]]
// PPC64-NEXT:    [[SUB_R159:%.*]] = sub i32 [[CIV_REAL152]], [[CONV158]], !dbg [[DBG113:![0-9]+]]
// PPC64-NEXT:    [[SUB_I160:%.*]] = sub i32 [[CIV_IMAG153]], 0, !dbg [[DBG113]]
// PPC64-NEXT:    [[TOBOOL161:%.*]] = icmp ne i32 [[SUB_R159]], 0, !dbg [[DBG110]]
// PPC64-NEXT:    [[TOBOOL162:%.*]] = icmp ne i32 [[SUB_I160]], 0, !dbg [[DBG110]]
// PPC64-NEXT:    [[TOBOOL163:%.*]] = or i1 [[TOBOOL161]], [[TOBOOL162]], !dbg [[DBG110]]
// PPC64-NEXT:    [[FROMBOOL164:%.*]] = zext i1 [[TOBOOL163]] to i8, !dbg [[DBG111]]
// PPC64-NEXT:    store i8 [[FROMBOOL164]], i8* [[ATOMIC_TEMP156]], align 1, !dbg [[DBG111]]
// PPC64-NEXT:    [[TMP151:%.*]] = load i8, i8* [[ATOMIC_TEMP156]], align 1, !dbg [[DBG111]]
// PPC64-NEXT:    [[TMP152:%.*]] = cmpxchg i8* @bx, i8 [[TMP150]], i8 [[TMP151]] monotonic monotonic, align 1, !dbg [[DBG111]]
// PPC64-NEXT:    [[TMP153]] = extractvalue { i8, i1 } [[TMP152]], 0, !dbg [[DBG111]]
// PPC64-NEXT:    [[TMP154:%.*]] = extractvalue { i8, i1 } [[TMP152]], 1, !dbg [[DBG111]]
// PPC64-NEXT:    br i1 [[TMP154]], label [[ATOMIC_EXIT165:%.*]], label [[ATOMIC_CONT155]], !dbg [[DBG111]]
// PPC64:       atomic_exit165:
// PPC64-NEXT:    [[FROMBOOL166:%.*]] = zext i1 [[TOBOOL163]] to i8, !dbg [[DBG111]]
// PPC64-NEXT:    store i8 [[FROMBOOL166]], i8* @bv, align 1, !dbg [[DBG111]]
// PPC64-NEXT:    [[TMP155:%.*]] = load i16, i16* @sv, align 2, !dbg [[DBG114:![0-9]+]]
// PPC64-NEXT:    [[TMP156:%.*]] = load i8, i8* @bv, align 1, !dbg [[DBG115:![0-9]+]]
// PPC64-NEXT:    [[TOBOOL167:%.*]] = trunc i8 [[TMP156]] to i1, !dbg [[DBG115]]
// PPC64-NEXT:    [[CONV168:%.*]] = zext i1 [[TOBOOL167]] to i32, !dbg [[DBG115]]
// PPC64-NEXT:    [[TMP157:%.*]] = bitcast <4 x i32>* [[ATOMIC_TEMP169]] to i8*, !dbg [[DBG116:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 16, i8* noundef bitcast (<4 x i32>* @int4x to i8*), i8* noundef [[TMP157]], i32 noundef signext 0), !dbg [[DBG116]]
// PPC64-NEXT:    br label [[ATOMIC_CONT170:%.*]], !dbg [[DBG116]]
// PPC64:       atomic_cont170:
// PPC64-NEXT:    [[TMP158:%.*]] = load <4 x i32>, <4 x i32>* [[ATOMIC_TEMP169]], align 16, !dbg [[DBG116]]
// PPC64-NEXT:    store <4 x i32> [[TMP158]], <4 x i32>* [[ATOMIC_TEMP171]], align 16, !dbg [[DBG116]]
// PPC64-NEXT:    [[TMP159:%.*]] = load <4 x i32>, <4 x i32>* [[ATOMIC_TEMP169]], align 16, !dbg [[DBG116]]
// PPC64-NEXT:    store <4 x i32> [[TMP159]], <4 x i32>* [[ATOMIC_TEMP172]], align 16, !dbg [[DBG116]]
// PPC64-NEXT:    [[TMP160:%.*]] = load <4 x i32>, <4 x i32>* [[ATOMIC_TEMP172]], align 16, !dbg [[DBG116]]
// PPC64-NEXT:    [[VECEXT:%.*]] = extractelement <4 x i32> [[TMP160]], i16 [[TMP155]], !dbg [[DBG116]]
// PPC64-NEXT:    [[OR173:%.*]] = or i32 [[VECEXT]], [[CONV168]], !dbg [[DBG117:![0-9]+]]
// PPC64-NEXT:    [[TMP161:%.*]] = load <4 x i32>, <4 x i32>* [[ATOMIC_TEMP171]], align 16, !dbg [[DBG116]]
// PPC64-NEXT:    [[VECINS:%.*]] = insertelement <4 x i32> [[TMP161]], i32 [[OR173]], i16 [[TMP155]], !dbg [[DBG116]]
// PPC64-NEXT:    store <4 x i32> [[VECINS]], <4 x i32>* [[ATOMIC_TEMP171]], align 16, !dbg [[DBG116]]
// PPC64-NEXT:    [[TMP162:%.*]] = bitcast <4 x i32>* [[ATOMIC_TEMP169]] to i8*, !dbg [[DBG116]]
// PPC64-NEXT:    [[TMP163:%.*]] = bitcast <4 x i32>* [[ATOMIC_TEMP171]] to i8*, !dbg [[DBG116]]
// PPC64-NEXT:    [[CALL174:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, i8* noundef bitcast (<4 x i32>* @int4x to i8*), i8* noundef [[TMP162]], i8* noundef [[TMP163]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG116]]
// PPC64-NEXT:    br i1 [[CALL174]], label [[ATOMIC_EXIT175:%.*]], label [[ATOMIC_CONT170]], !dbg [[DBG116]]
// PPC64:       atomic_exit175:
// PPC64-NEXT:    store i32 [[OR173]], i32* @iv, align 4, !dbg [[DBG116]]
// PPC64-NEXT:    [[TMP164:%.*]] = load ppc_fp128, ppc_fp128* @ldv, align 16, !dbg [[DBG118:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD176:%.*]] = load atomic i32, i32* bitcast (%struct.BitFields* @bfx to i32*) monotonic, align 4, !dbg [[DBG119:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT177:%.*]], !dbg [[DBG119]]
// PPC64:       atomic_cont177:
// PPC64-NEXT:    [[TMP165:%.*]] = phi i32 [ [[ATOMIC_LOAD176]], [[ATOMIC_EXIT175]] ], [ [[TMP168:%.*]], [[ATOMIC_CONT177]] ], !dbg [[DBG119]]
// PPC64-NEXT:    store i32 [[TMP165]], i32* [[ATOMIC_TEMP178]], align 4, !dbg [[DBG119]]
// PPC64-NEXT:    store i32 [[TMP165]], i32* [[ATOMIC_TEMP179]], align 4, !dbg [[DBG119]]
// PPC64-NEXT:    [[BF_LOAD:%.*]] = load i32, i32* [[ATOMIC_TEMP179]], align 4, !dbg [[DBG119]]
// PPC64-NEXT:    [[BF_ASHR:%.*]] = ashr i32 [[BF_LOAD]], 1, !dbg [[DBG119]]
// PPC64-NEXT:    [[CONV180:%.*]] = sitofp i32 [[BF_ASHR]] to ppc_fp128, !dbg [[DBG120:![0-9]+]]
// PPC64-NEXT:    [[SUB181:%.*]] = fsub ppc_fp128 [[CONV180]], [[TMP164]], !dbg [[DBG121:![0-9]+]]
// PPC64-NEXT:    [[CONV182:%.*]] = fptosi ppc_fp128 [[SUB181]] to i32, !dbg [[DBG120]]
// PPC64-NEXT:    [[BF_LOAD183:%.*]] = load i32, i32* [[ATOMIC_TEMP178]], align 4, !dbg [[DBG119]]
// PPC64-NEXT:    [[BF_VALUE:%.*]] = and i32 [[CONV182]], 2147483647, !dbg [[DBG119]]
// PPC64-NEXT:    [[BF_SHL:%.*]] = shl i32 [[BF_VALUE]], 1, !dbg [[DBG119]]
// PPC64-NEXT:    [[BF_CLEAR:%.*]] = and i32 [[BF_LOAD183]], 1, !dbg [[DBG119]]
// PPC64-NEXT:    [[BF_SET:%.*]] = or i32 [[BF_CLEAR]], [[BF_SHL]], !dbg [[DBG119]]
// PPC64-NEXT:    store i32 [[BF_SET]], i32* [[ATOMIC_TEMP178]], align 4, !dbg [[DBG119]]
// PPC64-NEXT:    [[TMP166:%.*]] = load i32, i32* [[ATOMIC_TEMP178]], align 4, !dbg [[DBG119]]
// PPC64-NEXT:    [[TMP167:%.*]] = cmpxchg i32* bitcast (%struct.BitFields* @bfx to i32*), i32 [[TMP165]], i32 [[TMP166]] monotonic monotonic, align 4, !dbg [[DBG119]]
// PPC64-NEXT:    [[TMP168]] = extractvalue { i32, i1 } [[TMP167]], 0, !dbg [[DBG119]]
// PPC64-NEXT:    [[TMP169:%.*]] = extractvalue { i32, i1 } [[TMP167]], 1, !dbg [[DBG119]]
// PPC64-NEXT:    br i1 [[TMP169]], label [[ATOMIC_EXIT184:%.*]], label [[ATOMIC_CONT177]], !dbg [[DBG119]]
// PPC64:       atomic_exit184:
// PPC64-NEXT:    store i32 [[CONV182]], i32* @iv, align 4, !dbg [[DBG119]]
// PPC64-NEXT:    [[TMP170:%.*]] = load ppc_fp128, ppc_fp128* @ldv, align 16, !dbg [[DBG122:![0-9]+]]
// PPC64-NEXT:    [[TMP171:%.*]] = bitcast i32* [[ATOMIC_TEMP185]] to i8*, !dbg [[DBG123:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 4, i8* noundef bitcast (%struct.BitFields_packed* @bfx_packed to i8*), i8* noundef [[TMP171]], i32 noundef signext 0), !dbg [[DBG123]]
// PPC64-NEXT:    br label [[ATOMIC_CONT186:%.*]], !dbg [[DBG123]]
// PPC64:       atomic_cont186:
// PPC64-NEXT:    [[TMP172:%.*]] = load i32, i32* [[ATOMIC_TEMP185]], align 1, !dbg [[DBG123]]
// PPC64-NEXT:    store i32 [[TMP172]], i32* [[ATOMIC_TEMP187]], align 1, !dbg [[DBG123]]
// PPC64-NEXT:    [[TMP173:%.*]] = load i32, i32* [[ATOMIC_TEMP185]], align 1, !dbg [[DBG123]]
// PPC64-NEXT:    store i32 [[TMP173]], i32* [[ATOMIC_TEMP188]], align 4, !dbg [[DBG123]]
// PPC64-NEXT:    [[BF_LOAD189:%.*]] = load i32, i32* [[ATOMIC_TEMP188]], align 1, !dbg [[DBG123]]
// PPC64-NEXT:    [[BF_ASHR190:%.*]] = ashr i32 [[BF_LOAD189]], 1, !dbg [[DBG123]]
// PPC64-NEXT:    [[CONV191:%.*]] = sitofp i32 [[BF_ASHR190]] to ppc_fp128, !dbg [[DBG124:![0-9]+]]
// PPC64-NEXT:    [[MUL192:%.*]] = fmul ppc_fp128 [[CONV191]], [[TMP170]], !dbg [[DBG125:![0-9]+]]
// PPC64-NEXT:    [[CONV193:%.*]] = fptosi ppc_fp128 [[MUL192]] to i32, !dbg [[DBG124]]
// PPC64-NEXT:    [[BF_LOAD194:%.*]] = load i32, i32* [[ATOMIC_TEMP187]], align 1, !dbg [[DBG123]]
// PPC64-NEXT:    [[BF_VALUE195:%.*]] = and i32 [[CONV193]], 2147483647, !dbg [[DBG123]]
// PPC64-NEXT:    [[BF_SHL196:%.*]] = shl i32 [[BF_VALUE195]], 1, !dbg [[DBG123]]
// PPC64-NEXT:    [[BF_CLEAR197:%.*]] = and i32 [[BF_LOAD194]], 1, !dbg [[DBG123]]
// PPC64-NEXT:    [[BF_SET198:%.*]] = or i32 [[BF_CLEAR197]], [[BF_SHL196]], !dbg [[DBG123]]
// PPC64-NEXT:    store i32 [[BF_SET198]], i32* [[ATOMIC_TEMP187]], align 1, !dbg [[DBG123]]
// PPC64-NEXT:    [[TMP174:%.*]] = bitcast i32* [[ATOMIC_TEMP185]] to i8*, !dbg [[DBG123]]
// PPC64-NEXT:    [[TMP175:%.*]] = bitcast i32* [[ATOMIC_TEMP187]] to i8*, !dbg [[DBG123]]
// PPC64-NEXT:    [[CALL199:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 4, i8* noundef bitcast (%struct.BitFields_packed* @bfx_packed to i8*), i8* noundef [[TMP174]], i8* noundef [[TMP175]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG123]]
// PPC64-NEXT:    br i1 [[CALL199]], label [[ATOMIC_EXIT200:%.*]], label [[ATOMIC_CONT186]], !dbg [[DBG123]]
// PPC64:       atomic_exit200:
// PPC64-NEXT:    store i32 [[BF_ASHR190]], i32* @iv, align 4, !dbg [[DBG123]]
// PPC64-NEXT:    [[TMP176:%.*]] = load ppc_fp128, ppc_fp128* @ldv, align 16, !dbg [[DBG126:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD201:%.*]] = load atomic i32, i32* getelementptr inbounds ([[STRUCT_BITFIELDS2:%.*]], %struct.BitFields2* @bfx2, i32 0, i32 0) monotonic, align 4, !dbg [[DBG127:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT202:%.*]], !dbg [[DBG127]]
// PPC64:       atomic_cont202:
// PPC64-NEXT:    [[TMP177:%.*]] = phi i32 [ [[ATOMIC_LOAD201]], [[ATOMIC_EXIT200]] ], [ [[TMP180:%.*]], [[ATOMIC_CONT202]] ], !dbg [[DBG127]]
// PPC64-NEXT:    store i32 [[TMP177]], i32* [[ATOMIC_TEMP203]], align 4, !dbg [[DBG127]]
// PPC64-NEXT:    store i32 [[TMP177]], i32* [[ATOMIC_TEMP204]], align 4, !dbg [[DBG127]]
// PPC64-NEXT:    [[BF_LOAD205:%.*]] = load i32, i32* [[ATOMIC_TEMP204]], align 4, !dbg [[DBG127]]
// PPC64-NEXT:    [[BF_SHL206:%.*]] = shl i32 [[BF_LOAD205]], 31, !dbg [[DBG127]]
// PPC64-NEXT:    [[BF_ASHR207:%.*]] = ashr i32 [[BF_SHL206]], 31, !dbg [[DBG127]]
// PPC64-NEXT:    [[CONV208:%.*]] = sitofp i32 [[BF_ASHR207]] to ppc_fp128, !dbg [[DBG128:![0-9]+]]
// PPC64-NEXT:    [[SUB209:%.*]] = fsub ppc_fp128 [[CONV208]], [[TMP176]], !dbg [[DBG129:![0-9]+]]
// PPC64-NEXT:    [[CONV210:%.*]] = fptosi ppc_fp128 [[SUB209]] to i32, !dbg [[DBG128]]
// PPC64-NEXT:    [[BF_LOAD211:%.*]] = load i32, i32* [[ATOMIC_TEMP203]], align 4, !dbg [[DBG127]]
// PPC64-NEXT:    [[BF_VALUE212:%.*]] = and i32 [[CONV210]], 1, !dbg [[DBG127]]
// PPC64-NEXT:    [[BF_CLEAR213:%.*]] = and i32 [[BF_LOAD211]], -2, !dbg [[DBG127]]
// PPC64-NEXT:    [[BF_SET214:%.*]] = or i32 [[BF_CLEAR213]], [[BF_VALUE212]], !dbg [[DBG127]]
// PPC64-NEXT:    store i32 [[BF_SET214]], i32* [[ATOMIC_TEMP203]], align 4, !dbg [[DBG127]]
// PPC64-NEXT:    [[TMP178:%.*]] = load i32, i32* [[ATOMIC_TEMP203]], align 4, !dbg [[DBG127]]
// PPC64-NEXT:    [[TMP179:%.*]] = cmpxchg i32* getelementptr inbounds ([[STRUCT_BITFIELDS2]], %struct.BitFields2* @bfx2, i32 0, i32 0), i32 [[TMP177]], i32 [[TMP178]] monotonic monotonic, align 4, !dbg [[DBG127]]
// PPC64-NEXT:    [[TMP180]] = extractvalue { i32, i1 } [[TMP179]], 0, !dbg [[DBG127]]
// PPC64-NEXT:    [[TMP181:%.*]] = extractvalue { i32, i1 } [[TMP179]], 1, !dbg [[DBG127]]
// PPC64-NEXT:    br i1 [[TMP181]], label [[ATOMIC_EXIT215:%.*]], label [[ATOMIC_CONT202]], !dbg [[DBG127]]
// PPC64:       atomic_exit215:
// PPC64-NEXT:    store i32 [[CONV210]], i32* @iv, align 4, !dbg [[DBG127]]
// PPC64-NEXT:    [[TMP182:%.*]] = load ppc_fp128, ppc_fp128* @ldv, align 16, !dbg [[DBG130:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD216:%.*]] = load atomic i8, i8* bitcast (%struct.BitFields2_packed* @bfx2_packed to i8*) monotonic, align 1, !dbg [[DBG131:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT217:%.*]], !dbg [[DBG131]]
// PPC64:       atomic_cont217:
// PPC64-NEXT:    [[TMP183:%.*]] = phi i8 [ [[ATOMIC_LOAD216]], [[ATOMIC_EXIT215]] ], [ [[TMP189:%.*]], [[ATOMIC_CONT217]] ], !dbg [[DBG131]]
// PPC64-NEXT:    [[TMP184:%.*]] = bitcast i32* [[ATOMIC_TEMP218]] to i8*, !dbg [[DBG131]]
// PPC64-NEXT:    store i8 [[TMP183]], i8* [[TMP184]], align 1, !dbg [[DBG131]]
// PPC64-NEXT:    [[TMP185:%.*]] = bitcast i32* [[ATOMIC_TEMP219]] to i8*, !dbg [[DBG131]]
// PPC64-NEXT:    store i8 [[TMP183]], i8* [[TMP185]], align 1, !dbg [[DBG131]]
// PPC64-NEXT:    [[BF_LOAD220:%.*]] = load i8, i8* [[TMP185]], align 1, !dbg [[DBG131]]
// PPC64-NEXT:    [[BF_SHL221:%.*]] = shl i8 [[BF_LOAD220]], 7, !dbg [[DBG131]]
// PPC64-NEXT:    [[BF_ASHR222:%.*]] = ashr i8 [[BF_SHL221]], 7, !dbg [[DBG131]]
// PPC64-NEXT:    [[BF_CAST:%.*]] = sext i8 [[BF_ASHR222]] to i32, !dbg [[DBG131]]
// PPC64-NEXT:    [[CONV223:%.*]] = sitofp i32 [[BF_CAST]] to ppc_fp128, !dbg [[DBG132:![0-9]+]]
// PPC64-NEXT:    [[DIV224:%.*]] = fdiv ppc_fp128 [[TMP182]], [[CONV223]], !dbg [[DBG133:![0-9]+]]
// PPC64-NEXT:    [[CONV225:%.*]] = fptosi ppc_fp128 [[DIV224]] to i32, !dbg [[DBG130]]
// PPC64-NEXT:    [[TMP186:%.*]] = trunc i32 [[CONV225]] to i8, !dbg [[DBG131]]
// PPC64-NEXT:    [[BF_LOAD226:%.*]] = load i8, i8* [[TMP184]], align 1, !dbg [[DBG131]]
// PPC64-NEXT:    [[BF_VALUE227:%.*]] = and i8 [[TMP186]], 1, !dbg [[DBG131]]
// PPC64-NEXT:    [[BF_CLEAR228:%.*]] = and i8 [[BF_LOAD226]], -2, !dbg [[DBG131]]
// PPC64-NEXT:    [[BF_SET229:%.*]] = or i8 [[BF_CLEAR228]], [[BF_VALUE227]], !dbg [[DBG131]]
// PPC64-NEXT:    store i8 [[BF_SET229]], i8* [[TMP184]], align 1, !dbg [[DBG131]]
// PPC64-NEXT:    [[TMP187:%.*]] = load i8, i8* [[TMP184]], align 1, !dbg [[DBG131]]
// PPC64-NEXT:    [[TMP188:%.*]] = cmpxchg i8* bitcast (%struct.BitFields2_packed* @bfx2_packed to i8*), i8 [[TMP183]], i8 [[TMP187]] monotonic monotonic, align 1, !dbg [[DBG131]]
// PPC64-NEXT:    [[TMP189]] = extractvalue { i8, i1 } [[TMP188]], 0, !dbg [[DBG131]]
// PPC64-NEXT:    [[TMP190:%.*]] = extractvalue { i8, i1 } [[TMP188]], 1, !dbg [[DBG131]]
// PPC64-NEXT:    br i1 [[TMP190]], label [[ATOMIC_EXIT230:%.*]], label [[ATOMIC_CONT217]], !dbg [[DBG131]]
// PPC64:       atomic_exit230:
// PPC64-NEXT:    store i32 [[CONV225]], i32* @iv, align 4, !dbg [[DBG131]]
// PPC64-NEXT:    [[TMP191:%.*]] = load ppc_fp128, ppc_fp128* @ldv, align 16, !dbg [[DBG134:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD231:%.*]] = load atomic i32, i32* getelementptr inbounds ([[STRUCT_BITFIELDS3:%.*]], %struct.BitFields3* @bfx3, i32 0, i32 0) monotonic, align 4, !dbg [[DBG135:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT232:%.*]], !dbg [[DBG135]]
// PPC64:       atomic_cont232:
// PPC64-NEXT:    [[TMP192:%.*]] = phi i32 [ [[ATOMIC_LOAD231]], [[ATOMIC_EXIT230]] ], [ [[TMP195:%.*]], [[ATOMIC_CONT232]] ], !dbg [[DBG135]]
// PPC64-NEXT:    store i32 [[TMP192]], i32* [[ATOMIC_TEMP233]], align 4, !dbg [[DBG135]]
// PPC64-NEXT:    store i32 [[TMP192]], i32* [[ATOMIC_TEMP234]], align 4, !dbg [[DBG135]]
// PPC64-NEXT:    [[BF_LOAD235:%.*]] = load i32, i32* [[ATOMIC_TEMP234]], align 4, !dbg [[DBG135]]
// PPC64-NEXT:    [[BF_SHL236:%.*]] = shl i32 [[BF_LOAD235]], 11, !dbg [[DBG135]]
// PPC64-NEXT:    [[BF_ASHR237:%.*]] = ashr i32 [[BF_SHL236]], 18, !dbg [[DBG135]]
// PPC64-NEXT:    [[CONV238:%.*]] = sitofp i32 [[BF_ASHR237]] to ppc_fp128, !dbg [[DBG136:![0-9]+]]
// PPC64-NEXT:    [[DIV239:%.*]] = fdiv ppc_fp128 [[CONV238]], [[TMP191]], !dbg [[DBG137:![0-9]+]]
// PPC64-NEXT:    [[CONV240:%.*]] = fptosi ppc_fp128 [[DIV239]] to i32, !dbg [[DBG136]]
// PPC64-NEXT:    [[BF_LOAD241:%.*]] = load i32, i32* [[ATOMIC_TEMP233]], align 4, !dbg [[DBG135]]
// PPC64-NEXT:    [[BF_VALUE242:%.*]] = and i32 [[CONV240]], 16383, !dbg [[DBG135]]
// PPC64-NEXT:    [[BF_SHL243:%.*]] = shl i32 [[BF_VALUE242]], 7, !dbg [[DBG135]]
// PPC64-NEXT:    [[BF_CLEAR244:%.*]] = and i32 [[BF_LOAD241]], -2097025, !dbg [[DBG135]]
// PPC64-NEXT:    [[BF_SET245:%.*]] = or i32 [[BF_CLEAR244]], [[BF_SHL243]], !dbg [[DBG135]]
// PPC64-NEXT:    store i32 [[BF_SET245]], i32* [[ATOMIC_TEMP233]], align 4, !dbg [[DBG135]]
// PPC64-NEXT:    [[TMP193:%.*]] = load i32, i32* [[ATOMIC_TEMP233]], align 4, !dbg [[DBG135]]
// PPC64-NEXT:    [[TMP194:%.*]] = cmpxchg i32* getelementptr inbounds ([[STRUCT_BITFIELDS3]], %struct.BitFields3* @bfx3, i32 0, i32 0), i32 [[TMP192]], i32 [[TMP193]] monotonic monotonic, align 4, !dbg [[DBG135]]
// PPC64-NEXT:    [[TMP195]] = extractvalue { i32, i1 } [[TMP194]], 0, !dbg [[DBG135]]
// PPC64-NEXT:    [[TMP196:%.*]] = extractvalue { i32, i1 } [[TMP194]], 1, !dbg [[DBG135]]
// PPC64-NEXT:    br i1 [[TMP196]], label [[ATOMIC_EXIT246:%.*]], label [[ATOMIC_CONT232]], !dbg [[DBG135]]
// PPC64:       atomic_exit246:
// PPC64-NEXT:    store i32 [[BF_ASHR237]], i32* @iv, align 4, !dbg [[DBG135]]
// PPC64-NEXT:    [[TMP197:%.*]] = load ppc_fp128, ppc_fp128* @ldv, align 16, !dbg [[DBG138:![0-9]+]]
// PPC64-NEXT:    [[TMP198:%.*]] = bitcast i32* [[ATOMIC_TEMP247]] to i24*, !dbg [[DBG139:![0-9]+]]
// PPC64-NEXT:    [[TMP199:%.*]] = bitcast i24* [[TMP198]] to i8*, !dbg [[DBG139]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 3, i8* noundef bitcast (%struct.BitFields3_packed* @bfx3_packed to i8*), i8* noundef [[TMP199]], i32 noundef signext 0), !dbg [[DBG139]]
// PPC64-NEXT:    br label [[ATOMIC_CONT248:%.*]], !dbg [[DBG139]]
// PPC64:       atomic_cont248:
// PPC64-NEXT:    [[TMP200:%.*]] = bitcast i32* [[ATOMIC_TEMP249]] to i24*, !dbg [[DBG139]]
// PPC64-NEXT:    [[TMP201:%.*]] = load i24, i24* [[TMP198]], align 1, !dbg [[DBG139]]
// PPC64-NEXT:    store i24 [[TMP201]], i24* [[TMP200]], align 1, !dbg [[DBG139]]
// PPC64-NEXT:    [[TMP202:%.*]] = load i24, i24* [[TMP198]], align 1, !dbg [[DBG139]]
// PPC64-NEXT:    [[TMP203:%.*]] = bitcast i32* [[ATOMIC_TEMP250]] to i24*, !dbg [[DBG139]]
// PPC64-NEXT:    store i24 [[TMP202]], i24* [[TMP203]], align 1, !dbg [[DBG139]]
// PPC64-NEXT:    [[BF_LOAD251:%.*]] = load i24, i24* [[TMP203]], align 1, !dbg [[DBG139]]
// PPC64-NEXT:    [[BF_SHL252:%.*]] = shl i24 [[BF_LOAD251]], 3, !dbg [[DBG139]]
// PPC64-NEXT:    [[BF_ASHR253:%.*]] = ashr i24 [[BF_SHL252]], 10, !dbg [[DBG139]]
// PPC64-NEXT:    [[BF_CAST254:%.*]] = sext i24 [[BF_ASHR253]] to i32, !dbg [[DBG139]]
// PPC64-NEXT:    [[CONV255:%.*]] = sitofp i32 [[BF_CAST254]] to ppc_fp128, !dbg [[DBG140:![0-9]+]]
// PPC64-NEXT:    [[ADD256:%.*]] = fadd ppc_fp128 [[CONV255]], [[TMP197]], !dbg [[DBG141:![0-9]+]]
// PPC64-NEXT:    [[CONV257:%.*]] = fptosi ppc_fp128 [[ADD256]] to i32, !dbg [[DBG140]]
// PPC64-NEXT:    [[TMP204:%.*]] = trunc i32 [[CONV257]] to i24, !dbg [[DBG139]]
// PPC64-NEXT:    [[BF_LOAD258:%.*]] = load i24, i24* [[TMP200]], align 1, !dbg [[DBG139]]
// PPC64-NEXT:    [[BF_VALUE259:%.*]] = and i24 [[TMP204]], 16383, !dbg [[DBG139]]
// PPC64-NEXT:    [[BF_SHL260:%.*]] = shl i24 [[BF_VALUE259]], 7, !dbg [[DBG139]]
// PPC64-NEXT:    [[BF_CLEAR261:%.*]] = and i24 [[BF_LOAD258]], -2097025, !dbg [[DBG139]]
// PPC64-NEXT:    [[BF_SET262:%.*]] = or i24 [[BF_CLEAR261]], [[BF_SHL260]], !dbg [[DBG139]]
// PPC64-NEXT:    store i24 [[BF_SET262]], i24* [[TMP200]], align 1, !dbg [[DBG139]]
// PPC64-NEXT:    [[TMP205:%.*]] = bitcast i24* [[TMP198]] to i8*, !dbg [[DBG139]]
// PPC64-NEXT:    [[TMP206:%.*]] = bitcast i24* [[TMP200]] to i8*, !dbg [[DBG139]]
// PPC64-NEXT:    [[CALL263:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 3, i8* noundef bitcast (%struct.BitFields3_packed* @bfx3_packed to i8*), i8* noundef [[TMP205]], i8* noundef [[TMP206]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG139]]
// PPC64-NEXT:    br i1 [[CALL263]], label [[ATOMIC_EXIT264:%.*]], label [[ATOMIC_CONT248]], !dbg [[DBG139]]
// PPC64:       atomic_exit264:
// PPC64-NEXT:    store i32 [[CONV257]], i32* @iv, align 4, !dbg [[DBG139]]
// PPC64-NEXT:    [[TMP207:%.*]] = load ppc_fp128, ppc_fp128* @ldv, align 16, !dbg [[DBG142:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD265:%.*]] = load atomic i64, i64* bitcast (%struct.BitFields4* @bfx4 to i64*) monotonic, align 8, !dbg [[DBG143:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT266:%.*]], !dbg [[DBG143]]
// PPC64:       atomic_cont266:
// PPC64-NEXT:    [[TMP208:%.*]] = phi i64 [ [[ATOMIC_LOAD265]], [[ATOMIC_EXIT264]] ], [ [[TMP212:%.*]], [[ATOMIC_CONT266]] ], !dbg [[DBG143]]
// PPC64-NEXT:    store i64 [[TMP208]], i64* [[ATOMIC_TEMP267]], align 8, !dbg [[DBG143]]
// PPC64-NEXT:    store i64 [[TMP208]], i64* [[ATOMIC_TEMP268]], align 8, !dbg [[DBG143]]
// PPC64-NEXT:    [[BF_LOAD269:%.*]] = load i64, i64* [[ATOMIC_TEMP268]], align 8, !dbg [[DBG143]]
// PPC64-NEXT:    [[BF_SHL270:%.*]] = shl i64 [[BF_LOAD269]], 48, !dbg [[DBG143]]
// PPC64-NEXT:    [[BF_ASHR271:%.*]] = ashr i64 [[BF_SHL270]], 63, !dbg [[DBG143]]
// PPC64-NEXT:    [[BF_CAST272:%.*]] = trunc i64 [[BF_ASHR271]] to i32, !dbg [[DBG143]]
// PPC64-NEXT:    [[CONV273:%.*]] = sitofp i32 [[BF_CAST272]] to ppc_fp128, !dbg [[DBG144:![0-9]+]]
// PPC64-NEXT:    [[MUL274:%.*]] = fmul ppc_fp128 [[CONV273]], [[TMP207]], !dbg [[DBG145:![0-9]+]]
// PPC64-NEXT:    [[CONV275:%.*]] = fptosi ppc_fp128 [[MUL274]] to i32, !dbg [[DBG144]]
// PPC64-NEXT:    [[TMP209:%.*]] = zext i32 [[CONV275]] to i64, !dbg [[DBG143]]
// PPC64-NEXT:    [[BF_LOAD276:%.*]] = load i64, i64* [[ATOMIC_TEMP267]], align 8, !dbg [[DBG143]]
// PPC64-NEXT:    [[BF_VALUE277:%.*]] = and i64 [[TMP209]], 1, !dbg [[DBG143]]
// PPC64-NEXT:    [[BF_SHL278:%.*]] = shl i64 [[BF_VALUE277]], 15, !dbg [[DBG143]]
// PPC64-NEXT:    [[BF_CLEAR279:%.*]] = and i64 [[BF_LOAD276]], -32769, !dbg [[DBG143]]
// PPC64-NEXT:    [[BF_SET280:%.*]] = or i64 [[BF_CLEAR279]], [[BF_SHL278]], !dbg [[DBG143]]
// PPC64-NEXT:    store i64 [[BF_SET280]], i64* [[ATOMIC_TEMP267]], align 8, !dbg [[DBG143]]
// PPC64-NEXT:    [[TMP210:%.*]] = load i64, i64* [[ATOMIC_TEMP267]], align 8, !dbg [[DBG143]]
// PPC64-NEXT:    [[TMP211:%.*]] = cmpxchg i64* bitcast (%struct.BitFields4* @bfx4 to i64*), i64 [[TMP208]], i64 [[TMP210]] monotonic monotonic, align 8, !dbg [[DBG143]]
// PPC64-NEXT:    [[TMP212]] = extractvalue { i64, i1 } [[TMP211]], 0, !dbg [[DBG143]]
// PPC64-NEXT:    [[TMP213:%.*]] = extractvalue { i64, i1 } [[TMP211]], 1, !dbg [[DBG143]]
// PPC64-NEXT:    br i1 [[TMP213]], label [[ATOMIC_EXIT281:%.*]], label [[ATOMIC_CONT266]], !dbg [[DBG143]]
// PPC64:       atomic_exit281:
// PPC64-NEXT:    store i32 [[CONV275]], i32* @iv, align 4, !dbg [[DBG143]]
// PPC64-NEXT:    [[TMP214:%.*]] = load ppc_fp128, ppc_fp128* @ldv, align 16, !dbg [[DBG146:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD282:%.*]] = load atomic i8, i8* getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED:%.*]], %struct.BitFields4_packed* @bfx4_packed, i32 0, i32 0, i32 0) monotonic, align 1, !dbg [[DBG147:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT283:%.*]], !dbg [[DBG147]]
// PPC64:       atomic_cont283:
// PPC64-NEXT:    [[TMP215:%.*]] = phi i8 [ [[ATOMIC_LOAD282]], [[ATOMIC_EXIT281]] ], [ [[TMP221:%.*]], [[ATOMIC_CONT283]] ], !dbg [[DBG147]]
// PPC64-NEXT:    [[TMP216:%.*]] = bitcast i32* [[ATOMIC_TEMP284]] to i8*, !dbg [[DBG147]]
// PPC64-NEXT:    store i8 [[TMP215]], i8* [[TMP216]], align 1, !dbg [[DBG147]]
// PPC64-NEXT:    [[TMP217:%.*]] = bitcast i32* [[ATOMIC_TEMP285]] to i8*, !dbg [[DBG147]]
// PPC64-NEXT:    store i8 [[TMP215]], i8* [[TMP217]], align 1, !dbg [[DBG147]]
// PPC64-NEXT:    [[BF_LOAD286:%.*]] = load i8, i8* [[TMP217]], align 1, !dbg [[DBG147]]
// PPC64-NEXT:    [[BF_ASHR287:%.*]] = ashr i8 [[BF_LOAD286]], 7, !dbg [[DBG147]]
// PPC64-NEXT:    [[BF_CAST288:%.*]] = sext i8 [[BF_ASHR287]] to i32, !dbg [[DBG147]]
// PPC64-NEXT:    [[CONV289:%.*]] = sitofp i32 [[BF_CAST288]] to ppc_fp128, !dbg [[DBG148:![0-9]+]]
// PPC64-NEXT:    [[SUB290:%.*]] = fsub ppc_fp128 [[CONV289]], [[TMP214]], !dbg [[DBG149:![0-9]+]]
// PPC64-NEXT:    [[CONV291:%.*]] = fptosi ppc_fp128 [[SUB290]] to i32, !dbg [[DBG148]]
// PPC64-NEXT:    [[TMP218:%.*]] = trunc i32 [[CONV291]] to i8, !dbg [[DBG147]]
// PPC64-NEXT:    [[BF_LOAD292:%.*]] = load i8, i8* [[TMP216]], align 1, !dbg [[DBG147]]
// PPC64-NEXT:    [[BF_VALUE293:%.*]] = and i8 [[TMP218]], 1, !dbg [[DBG147]]
// PPC64-NEXT:    [[BF_SHL294:%.*]] = shl i8 [[BF_VALUE293]], 7, !dbg [[DBG147]]
// PPC64-NEXT:    [[BF_CLEAR295:%.*]] = and i8 [[BF_LOAD292]], 127, !dbg [[DBG147]]
// PPC64-NEXT:    [[BF_SET296:%.*]] = or i8 [[BF_CLEAR295]], [[BF_SHL294]], !dbg [[DBG147]]
// PPC64-NEXT:    store i8 [[BF_SET296]], i8* [[TMP216]], align 1, !dbg [[DBG147]]
// PPC64-NEXT:    [[TMP219:%.*]] = load i8, i8* [[TMP216]], align 1, !dbg [[DBG147]]
// PPC64-NEXT:    [[TMP220:%.*]] = cmpxchg i8* getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED]], %struct.BitFields4_packed* @bfx4_packed, i32 0, i32 0, i32 0), i8 [[TMP215]], i8 [[TMP219]] monotonic monotonic, align 1, !dbg [[DBG147]]
// PPC64-NEXT:    [[TMP221]] = extractvalue { i8, i1 } [[TMP220]], 0, !dbg [[DBG147]]
// PPC64-NEXT:    [[TMP222:%.*]] = extractvalue { i8, i1 } [[TMP220]], 1, !dbg [[DBG147]]
// PPC64-NEXT:    br i1 [[TMP222]], label [[ATOMIC_EXIT297:%.*]], label [[ATOMIC_CONT283]], !dbg [[DBG147]]
// PPC64:       atomic_exit297:
// PPC64-NEXT:    store i32 [[BF_CAST288]], i32* @iv, align 4, !dbg [[DBG147]]
// PPC64-NEXT:    [[TMP223:%.*]] = load ppc_fp128, ppc_fp128* @ldv, align 16, !dbg [[DBG150:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD298:%.*]] = load atomic i64, i64* bitcast (%struct.BitFields4* @bfx4 to i64*) monotonic, align 8, !dbg [[DBG151:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT299:%.*]], !dbg [[DBG151]]
// PPC64:       atomic_cont299:
// PPC64-NEXT:    [[TMP224:%.*]] = phi i64 [ [[ATOMIC_LOAD298]], [[ATOMIC_EXIT297]] ], [ [[TMP227:%.*]], [[ATOMIC_CONT299]] ], !dbg [[DBG151]]
// PPC64-NEXT:    store i64 [[TMP224]], i64* [[ATOMIC_TEMP300]], align 8, !dbg [[DBG151]]
// PPC64-NEXT:    store i64 [[TMP224]], i64* [[ATOMIC_TEMP301]], align 8, !dbg [[DBG151]]
// PPC64-NEXT:    [[BF_LOAD302:%.*]] = load i64, i64* [[ATOMIC_TEMP301]], align 8, !dbg [[DBG151]]
// PPC64-NEXT:    [[BF_SHL303:%.*]] = shl i64 [[BF_LOAD302]], 49, !dbg [[DBG151]]
// PPC64-NEXT:    [[BF_ASHR304:%.*]] = ashr i64 [[BF_SHL303]], 57, !dbg [[DBG151]]
// PPC64-NEXT:    [[CONV305:%.*]] = sitofp i64 [[BF_ASHR304]] to ppc_fp128, !dbg [[DBG152:![0-9]+]]
// PPC64-NEXT:    [[DIV306:%.*]] = fdiv ppc_fp128 [[CONV305]], [[TMP223]], !dbg [[DBG153:![0-9]+]]
// PPC64-NEXT:    [[CONV307:%.*]] = fptosi ppc_fp128 [[DIV306]] to i64, !dbg [[DBG152]]
// PPC64-NEXT:    [[BF_LOAD308:%.*]] = load i64, i64* [[ATOMIC_TEMP300]], align 8, !dbg [[DBG151]]
// PPC64-NEXT:    [[BF_VALUE309:%.*]] = and i64 [[CONV307]], 127, !dbg [[DBG151]]
// PPC64-NEXT:    [[BF_SHL310:%.*]] = shl i64 [[BF_VALUE309]], 8, !dbg [[DBG151]]
// PPC64-NEXT:    [[BF_CLEAR311:%.*]] = and i64 [[BF_LOAD308]], -32513, !dbg [[DBG151]]
// PPC64-NEXT:    [[BF_SET312:%.*]] = or i64 [[BF_CLEAR311]], [[BF_SHL310]], !dbg [[DBG151]]
// PPC64-NEXT:    store i64 [[BF_SET312]], i64* [[ATOMIC_TEMP300]], align 8, !dbg [[DBG151]]
// PPC64-NEXT:    [[TMP225:%.*]] = load i64, i64* [[ATOMIC_TEMP300]], align 8, !dbg [[DBG151]]
// PPC64-NEXT:    [[TMP226:%.*]] = cmpxchg i64* bitcast (%struct.BitFields4* @bfx4 to i64*), i64 [[TMP224]], i64 [[TMP225]] release monotonic, align 8, !dbg [[DBG151]]
// PPC64-NEXT:    [[TMP227]] = extractvalue { i64, i1 } [[TMP226]], 0, !dbg [[DBG151]]
// PPC64-NEXT:    [[TMP228:%.*]] = extractvalue { i64, i1 } [[TMP226]], 1, !dbg [[DBG151]]
// PPC64-NEXT:    br i1 [[TMP228]], label [[ATOMIC_EXIT313:%.*]], label [[ATOMIC_CONT299]], !dbg [[DBG151]]
// PPC64:       atomic_exit313:
// PPC64-NEXT:    [[CONV314:%.*]] = trunc i64 [[CONV307]] to i32, !dbg [[DBG151]]
// PPC64-NEXT:    store i32 [[CONV314]], i32* @iv, align 4, !dbg [[DBG151]]
// PPC64-NEXT:    [[TMP229:%.*]] = load ppc_fp128, ppc_fp128* @ldv, align 16, !dbg [[DBG154:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD315:%.*]] = load atomic i8, i8* getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED]], %struct.BitFields4_packed* @bfx4_packed, i32 0, i32 0, i32 0) acquire, align 1, !dbg [[DBG155:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT316:%.*]], !dbg [[DBG155]]
// PPC64:       atomic_cont316:
// PPC64-NEXT:    [[TMP230:%.*]] = phi i8 [ [[ATOMIC_LOAD315]], [[ATOMIC_EXIT313]] ], [ [[TMP236:%.*]], [[ATOMIC_CONT316]] ], !dbg [[DBG155]]
// PPC64-NEXT:    [[TMP231:%.*]] = bitcast i64* [[ATOMIC_TEMP317]] to i8*, !dbg [[DBG155]]
// PPC64-NEXT:    store i8 [[TMP230]], i8* [[TMP231]], align 1, !dbg [[DBG155]]
// PPC64-NEXT:    [[TMP232:%.*]] = bitcast i64* [[ATOMIC_TEMP318]] to i8*, !dbg [[DBG155]]
// PPC64-NEXT:    store i8 [[TMP230]], i8* [[TMP232]], align 1, !dbg [[DBG155]]
// PPC64-NEXT:    [[BF_LOAD319:%.*]] = load i8, i8* [[TMP232]], align 1, !dbg [[DBG155]]
// PPC64-NEXT:    [[BF_SHL320:%.*]] = shl i8 [[BF_LOAD319]], 1, !dbg [[DBG155]]
// PPC64-NEXT:    [[BF_ASHR321:%.*]] = ashr i8 [[BF_SHL320]], 1, !dbg [[DBG155]]
// PPC64-NEXT:    [[BF_CAST322:%.*]] = sext i8 [[BF_ASHR321]] to i64, !dbg [[DBG155]]
// PPC64-NEXT:    [[CONV323:%.*]] = sitofp i64 [[BF_CAST322]] to ppc_fp128, !dbg [[DBG156:![0-9]+]]
// PPC64-NEXT:    [[ADD324:%.*]] = fadd ppc_fp128 [[CONV323]], [[TMP229]], !dbg [[DBG157:![0-9]+]]
// PPC64-NEXT:    [[CONV325:%.*]] = fptosi ppc_fp128 [[ADD324]] to i64, !dbg [[DBG156]]
// PPC64-NEXT:    [[TMP233:%.*]] = trunc i64 [[CONV325]] to i8, !dbg [[DBG155]]
// PPC64-NEXT:    [[BF_LOAD326:%.*]] = load i8, i8* [[TMP231]], align 1, !dbg [[DBG155]]
// PPC64-NEXT:    [[BF_VALUE327:%.*]] = and i8 [[TMP233]], 127, !dbg [[DBG155]]
// PPC64-NEXT:    [[BF_CLEAR328:%.*]] = and i8 [[BF_LOAD326]], -128, !dbg [[DBG155]]
// PPC64-NEXT:    [[BF_SET329:%.*]] = or i8 [[BF_CLEAR328]], [[BF_VALUE327]], !dbg [[DBG155]]
// PPC64-NEXT:    store i8 [[BF_SET329]], i8* [[TMP231]], align 1, !dbg [[DBG155]]
// PPC64-NEXT:    [[TMP234:%.*]] = load i8, i8* [[TMP231]], align 1, !dbg [[DBG155]]
// PPC64-NEXT:    [[TMP235:%.*]] = cmpxchg i8* getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED]], %struct.BitFields4_packed* @bfx4_packed, i32 0, i32 0, i32 0), i8 [[TMP230]], i8 [[TMP234]] acquire acquire, align 1, !dbg [[DBG155]]
// PPC64-NEXT:    [[TMP236]] = extractvalue { i8, i1 } [[TMP235]], 0, !dbg [[DBG155]]
// PPC64-NEXT:    [[TMP237:%.*]] = extractvalue { i8, i1 } [[TMP235]], 1, !dbg [[DBG155]]
// PPC64-NEXT:    br i1 [[TMP237]], label [[ATOMIC_EXIT330:%.*]], label [[ATOMIC_CONT316]], !dbg [[DBG155]]
// PPC64:       atomic_exit330:
// PPC64-NEXT:    [[CONV331:%.*]] = trunc i64 [[CONV325]] to i32, !dbg [[DBG155]]
// PPC64-NEXT:    store i32 [[CONV331]], i32* @iv, align 4, !dbg [[DBG155]]
// PPC64-NEXT:    [[TMP238:%.*]] = load i64, i64* @ulv, align 8, !dbg [[DBG158:![0-9]+]]
// PPC64-NEXT:    [[CONV332:%.*]] = uitofp i64 [[TMP238]] to float, !dbg [[DBG158]]
// PPC64-NEXT:    [[ATOMIC_LOAD333:%.*]] = load atomic i64, i64* bitcast (<2 x float>* @float2x to i64*) acquire, align 8, !dbg [[DBG159:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT334:%.*]], !dbg [[DBG159]]
// PPC64:       atomic_cont334:
// PPC64-NEXT:    [[TMP239:%.*]] = phi i64 [ [[ATOMIC_LOAD333]], [[ATOMIC_EXIT330]] ], [ [[TMP248:%.*]], [[ATOMIC_CONT334]] ], !dbg [[DBG159]]
// PPC64-NEXT:    [[TMP240:%.*]] = bitcast <2 x float>* [[ATOMIC_TEMP335]] to i64*, !dbg [[DBG159]]
// PPC64-NEXT:    store i64 [[TMP239]], i64* [[TMP240]], align 8, !dbg [[DBG159]]
// PPC64-NEXT:    [[TMP241:%.*]] = bitcast i64 [[TMP239]] to <2 x float>, !dbg [[DBG159]]
// PPC64-NEXT:    store <2 x float> [[TMP241]], <2 x float>* [[ATOMIC_TEMP336]], align 8, !dbg [[DBG159]]
// PPC64-NEXT:    [[TMP242:%.*]] = load <2 x float>, <2 x float>* [[ATOMIC_TEMP336]], align 8, !dbg [[DBG159]]
// PPC64-NEXT:    [[TMP243:%.*]] = extractelement <2 x float> [[TMP242]], i64 0, !dbg [[DBG159]]
// PPC64-NEXT:    [[SUB337:%.*]] = fsub float [[CONV332]], [[TMP243]], !dbg [[DBG160:![0-9]+]]
// PPC64-NEXT:    [[TMP244:%.*]] = load <2 x float>, <2 x float>* [[ATOMIC_TEMP335]], align 8, !dbg [[DBG159]]
// PPC64-NEXT:    [[TMP245:%.*]] = insertelement <2 x float> [[TMP244]], float [[SUB337]], i64 0, !dbg [[DBG159]]
// PPC64-NEXT:    store <2 x float> [[TMP245]], <2 x float>* [[ATOMIC_TEMP335]], align 8, !dbg [[DBG159]]
// PPC64-NEXT:    [[TMP246:%.*]] = load i64, i64* [[TMP240]], align 8, !dbg [[DBG159]]
// PPC64-NEXT:    [[TMP247:%.*]] = cmpxchg i64* bitcast (<2 x float>* @float2x to i64*), i64 [[TMP239]], i64 [[TMP246]] acq_rel acquire, align 8, !dbg [[DBG159]]
// PPC64-NEXT:    [[TMP248]] = extractvalue { i64, i1 } [[TMP247]], 0, !dbg [[DBG159]]
// PPC64-NEXT:    [[TMP249:%.*]] = extractvalue { i64, i1 } [[TMP247]], 1, !dbg [[DBG159]]
// PPC64-NEXT:    br i1 [[TMP249]], label [[ATOMIC_EXIT338:%.*]], label [[ATOMIC_CONT334]], !dbg [[DBG159]]
// PPC64:       atomic_exit338:
// PPC64-NEXT:    store float [[TMP243]], float* @fv, align 4, !dbg [[DBG159]]
// PPC64-NEXT:    ret i32 0, !dbg [[DBG161:![0-9]+]]
//
//
// AARCH64-LABEL: define {{[^@]+}}@main
// AARCH64-SAME: () #[[ATTR0:[0-9]+]] !dbg [[DBG5:![0-9]+]] {
// AARCH64-NEXT:  entry:
// AARCH64-NEXT:    [[RETVAL:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca i16, align 2
// AARCH64-NEXT:    [[ATOMIC_TEMP10:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP14:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP18:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP22:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP28:%.*]] = alloca double, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP34:%.*]] = alloca fp128, align 16
// AARCH64-NEXT:    [[ATOMIC_TEMP38:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP40:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP44:%.*]] = alloca { float, float }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP46:%.*]] = alloca { float, float }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP51:%.*]] = alloca { double, double }, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP53:%.*]] = alloca { double, double }, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP63:%.*]] = alloca i8, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP73:%.*]] = alloca i8, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP81:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP88:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP92:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP94:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP106:%.*]] = alloca float, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP112:%.*]] = alloca double, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP116:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP118:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP128:%.*]] = alloca i16, align 2
// AARCH64-NEXT:    [[ATOMIC_TEMP136:%.*]] = alloca i8, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP149:%.*]] = alloca i8, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP164:%.*]] = alloca <4 x i32>, align 16
// AARCH64-NEXT:    [[ATOMIC_TEMP165:%.*]] = alloca <4 x i32>, align 16
// AARCH64-NEXT:    [[ATOMIC_TEMP170:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP171:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP177:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP179:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP180:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP195:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP196:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP210:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP211:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP225:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP226:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP239:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP241:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP242:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP259:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP260:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP276:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP277:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP292:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP293:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP309:%.*]] = alloca i64, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP310:%.*]] = alloca i64, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP327:%.*]] = alloca <2 x float>, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP328:%.*]] = alloca <2 x float>, align 8
// AARCH64-NEXT:    store i32 0, i32* [[RETVAL]], align 4
// AARCH64-NEXT:    [[TMP0:%.*]] = atomicrmw add i8* @bx, i8 1 monotonic, align 1, !dbg [[DBG9:![0-9]+]]
// AARCH64-NEXT:    store i8 [[TMP0]], i8* @bv, align 1, !dbg [[DBG9]]
// AARCH64-NEXT:    [[TMP1:%.*]] = atomicrmw add i8* @cx, i8 1 monotonic, align 1, !dbg [[DBG10:![0-9]+]]
// AARCH64-NEXT:    [[CONV:%.*]] = sext i8 [[TMP1]] to i32, !dbg [[DBG11:![0-9]+]]
// AARCH64-NEXT:    [[ADD:%.*]] = add nsw i32 [[CONV]], 1, !dbg [[DBG12:![0-9]+]]
// AARCH64-NEXT:    [[CONV1:%.*]] = trunc i32 [[ADD]] to i8, !dbg [[DBG11]]
// AARCH64-NEXT:    store i8 [[CONV1]], i8* @cv, align 1, !dbg [[DBG10]]
// AARCH64-NEXT:    [[TMP2:%.*]] = atomicrmw sub i8* @ucx, i8 1 monotonic, align 1, !dbg [[DBG13:![0-9]+]]
// AARCH64-NEXT:    store i8 [[TMP2]], i8* @ucv, align 1, !dbg [[DBG13]]
// AARCH64-NEXT:    [[TMP3:%.*]] = atomicrmw sub i16* @sx, i16 1 monotonic, align 2, !dbg [[DBG14:![0-9]+]]
// AARCH64-NEXT:    [[CONV2:%.*]] = sext i16 [[TMP3]] to i32, !dbg [[DBG15:![0-9]+]]
// AARCH64-NEXT:    [[SUB:%.*]] = sub nsw i32 [[CONV2]], 1, !dbg [[DBG16:![0-9]+]]
// AARCH64-NEXT:    [[CONV3:%.*]] = trunc i32 [[SUB]] to i16, !dbg [[DBG15]]
// AARCH64-NEXT:    store i16 [[CONV3]], i16* @sv, align 2, !dbg [[DBG14]]
// AARCH64-NEXT:    [[TMP4:%.*]] = load i16, i16* @usv, align 2, !dbg [[DBG17:![0-9]+]]
// AARCH64-NEXT:    [[CONV4:%.*]] = zext i16 [[TMP4]] to i32, !dbg [[DBG17]]
// AARCH64-NEXT:    [[ATOMIC_LOAD:%.*]] = load atomic i16, i16* @usx monotonic, align 2, !dbg [[DBG18:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT:%.*]], !dbg [[DBG18]]
// AARCH64:       atomic_cont:
// AARCH64-NEXT:    [[TMP5:%.*]] = phi i16 [ [[ATOMIC_LOAD]], [[ENTRY:%.*]] ], [ [[TMP8:%.*]], [[ATOMIC_CONT]] ], !dbg [[DBG18]]
// AARCH64-NEXT:    [[CONV5:%.*]] = zext i16 [[TMP5]] to i32, !dbg [[DBG19:![0-9]+]]
// AARCH64-NEXT:    [[ADD6:%.*]] = add nsw i32 [[CONV5]], [[CONV4]], !dbg [[DBG20:![0-9]+]]
// AARCH64-NEXT:    [[CONV7:%.*]] = trunc i32 [[ADD6]] to i16, !dbg [[DBG19]]
// AARCH64-NEXT:    store i16 [[CONV7]], i16* [[ATOMIC_TEMP]], align 2, !dbg [[DBG18]]
// AARCH64-NEXT:    [[TMP6:%.*]] = load i16, i16* [[ATOMIC_TEMP]], align 2, !dbg [[DBG18]]
// AARCH64-NEXT:    [[TMP7:%.*]] = cmpxchg i16* @usx, i16 [[TMP5]], i16 [[TMP6]] monotonic monotonic, align 2, !dbg [[DBG18]]
// AARCH64-NEXT:    [[TMP8]] = extractvalue { i16, i1 } [[TMP7]], 0, !dbg [[DBG18]]
// AARCH64-NEXT:    [[TMP9:%.*]] = extractvalue { i16, i1 } [[TMP7]], 1, !dbg [[DBG18]]
// AARCH64-NEXT:    br i1 [[TMP9]], label [[ATOMIC_EXIT:%.*]], label [[ATOMIC_CONT]], !dbg [[DBG18]]
// AARCH64:       atomic_exit:
// AARCH64-NEXT:    store i16 [[CONV7]], i16* @sv, align 2, !dbg [[DBG18]]
// AARCH64-NEXT:    [[TMP10:%.*]] = load i32, i32* @iv, align 4, !dbg [[DBG21:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD8:%.*]] = load atomic i32, i32* @ix monotonic, align 4, !dbg [[DBG22:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT9:%.*]], !dbg [[DBG22]]
// AARCH64:       atomic_cont9:
// AARCH64-NEXT:    [[TMP11:%.*]] = phi i32 [ [[ATOMIC_LOAD8]], [[ATOMIC_EXIT]] ], [ [[TMP14:%.*]], [[ATOMIC_CONT9]] ], !dbg [[DBG22]]
// AARCH64-NEXT:    [[MUL:%.*]] = mul nsw i32 [[TMP11]], [[TMP10]], !dbg [[DBG23:![0-9]+]]
// AARCH64-NEXT:    store i32 [[MUL]], i32* [[ATOMIC_TEMP10]], align 4, !dbg [[DBG22]]
// AARCH64-NEXT:    [[TMP12:%.*]] = load i32, i32* [[ATOMIC_TEMP10]], align 4, !dbg [[DBG22]]
// AARCH64-NEXT:    [[TMP13:%.*]] = cmpxchg i32* @ix, i32 [[TMP11]], i32 [[TMP12]] monotonic monotonic, align 4, !dbg [[DBG22]]
// AARCH64-NEXT:    [[TMP14]] = extractvalue { i32, i1 } [[TMP13]], 0, !dbg [[DBG22]]
// AARCH64-NEXT:    [[TMP15:%.*]] = extractvalue { i32, i1 } [[TMP13]], 1, !dbg [[DBG22]]
// AARCH64-NEXT:    br i1 [[TMP15]], label [[ATOMIC_EXIT11:%.*]], label [[ATOMIC_CONT9]], !dbg [[DBG22]]
// AARCH64:       atomic_exit11:
// AARCH64-NEXT:    store i32 [[MUL]], i32* @uiv, align 4, !dbg [[DBG22]]
// AARCH64-NEXT:    [[TMP16:%.*]] = load i32, i32* @uiv, align 4, !dbg [[DBG24:![0-9]+]]
// AARCH64-NEXT:    [[TMP17:%.*]] = atomicrmw sub i32* @uix, i32 [[TMP16]] monotonic, align 4, !dbg [[DBG25:![0-9]+]]
// AARCH64-NEXT:    store i32 [[TMP17]], i32* @iv, align 4, !dbg [[DBG25]]
// AARCH64-NEXT:    [[TMP18:%.*]] = load i32, i32* @iv, align 4, !dbg [[DBG26:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD12:%.*]] = load atomic i32, i32* @ix monotonic, align 4, !dbg [[DBG27:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT13:%.*]], !dbg [[DBG27]]
// AARCH64:       atomic_cont13:
// AARCH64-NEXT:    [[TMP19:%.*]] = phi i32 [ [[ATOMIC_LOAD12]], [[ATOMIC_EXIT11]] ], [ [[TMP22:%.*]], [[ATOMIC_CONT13]] ], !dbg [[DBG27]]
// AARCH64-NEXT:    [[SHL:%.*]] = shl i32 [[TMP19]], [[TMP18]], !dbg [[DBG28:![0-9]+]]
// AARCH64-NEXT:    store i32 [[SHL]], i32* [[ATOMIC_TEMP14]], align 4, !dbg [[DBG27]]
// AARCH64-NEXT:    [[TMP20:%.*]] = load i32, i32* [[ATOMIC_TEMP14]], align 4, !dbg [[DBG27]]
// AARCH64-NEXT:    [[TMP21:%.*]] = cmpxchg i32* @ix, i32 [[TMP19]], i32 [[TMP20]] monotonic monotonic, align 4, !dbg [[DBG27]]
// AARCH64-NEXT:    [[TMP22]] = extractvalue { i32, i1 } [[TMP21]], 0, !dbg [[DBG27]]
// AARCH64-NEXT:    [[TMP23:%.*]] = extractvalue { i32, i1 } [[TMP21]], 1, !dbg [[DBG27]]
// AARCH64-NEXT:    br i1 [[TMP23]], label [[ATOMIC_EXIT15:%.*]], label [[ATOMIC_CONT13]], !dbg [[DBG27]]
// AARCH64:       atomic_exit15:
// AARCH64-NEXT:    store i32 [[SHL]], i32* @uiv, align 4, !dbg [[DBG27]]
// AARCH64-NEXT:    [[TMP24:%.*]] = load i32, i32* @uiv, align 4, !dbg [[DBG29:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD16:%.*]] = load atomic i32, i32* @uix monotonic, align 4, !dbg [[DBG30:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT17:%.*]], !dbg [[DBG30]]
// AARCH64:       atomic_cont17:
// AARCH64-NEXT:    [[TMP25:%.*]] = phi i32 [ [[ATOMIC_LOAD16]], [[ATOMIC_EXIT15]] ], [ [[TMP28:%.*]], [[ATOMIC_CONT17]] ], !dbg [[DBG30]]
// AARCH64-NEXT:    [[SHR:%.*]] = lshr i32 [[TMP25]], [[TMP24]], !dbg [[DBG31:![0-9]+]]
// AARCH64-NEXT:    store i32 [[SHR]], i32* [[ATOMIC_TEMP18]], align 4, !dbg [[DBG30]]
// AARCH64-NEXT:    [[TMP26:%.*]] = load i32, i32* [[ATOMIC_TEMP18]], align 4, !dbg [[DBG30]]
// AARCH64-NEXT:    [[TMP27:%.*]] = cmpxchg i32* @uix, i32 [[TMP25]], i32 [[TMP26]] monotonic monotonic, align 4, !dbg [[DBG30]]
// AARCH64-NEXT:    [[TMP28]] = extractvalue { i32, i1 } [[TMP27]], 0, !dbg [[DBG30]]
// AARCH64-NEXT:    [[TMP29:%.*]] = extractvalue { i32, i1 } [[TMP27]], 1, !dbg [[DBG30]]
// AARCH64-NEXT:    br i1 [[TMP29]], label [[ATOMIC_EXIT19:%.*]], label [[ATOMIC_CONT17]], !dbg [[DBG30]]
// AARCH64:       atomic_exit19:
// AARCH64-NEXT:    store i32 [[SHR]], i32* @iv, align 4, !dbg [[DBG30]]
// AARCH64-NEXT:    [[TMP30:%.*]] = load i64, i64* @lv, align 8, !dbg [[DBG32:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD20:%.*]] = load atomic i64, i64* @lx monotonic, align 8, !dbg [[DBG33:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT21:%.*]], !dbg [[DBG33]]
// AARCH64:       atomic_cont21:
// AARCH64-NEXT:    [[TMP31:%.*]] = phi i64 [ [[ATOMIC_LOAD20]], [[ATOMIC_EXIT19]] ], [ [[TMP34:%.*]], [[ATOMIC_CONT21]] ], !dbg [[DBG33]]
// AARCH64-NEXT:    [[DIV:%.*]] = sdiv i64 [[TMP31]], [[TMP30]], !dbg [[DBG34:![0-9]+]]
// AARCH64-NEXT:    store i64 [[DIV]], i64* [[ATOMIC_TEMP22]], align 8, !dbg [[DBG33]]
// AARCH64-NEXT:    [[TMP32:%.*]] = load i64, i64* [[ATOMIC_TEMP22]], align 8, !dbg [[DBG33]]
// AARCH64-NEXT:    [[TMP33:%.*]] = cmpxchg i64* @lx, i64 [[TMP31]], i64 [[TMP32]] monotonic monotonic, align 8, !dbg [[DBG33]]
// AARCH64-NEXT:    [[TMP34]] = extractvalue { i64, i1 } [[TMP33]], 0, !dbg [[DBG33]]
// AARCH64-NEXT:    [[TMP35:%.*]] = extractvalue { i64, i1 } [[TMP33]], 1, !dbg [[DBG33]]
// AARCH64-NEXT:    br i1 [[TMP35]], label [[ATOMIC_EXIT23:%.*]], label [[ATOMIC_CONT21]], !dbg [[DBG33]]
// AARCH64:       atomic_exit23:
// AARCH64-NEXT:    store i64 [[TMP31]], i64* @ulv, align 8, !dbg [[DBG33]]
// AARCH64-NEXT:    [[TMP36:%.*]] = load i64, i64* @ulv, align 8, !dbg [[DBG35:![0-9]+]]
// AARCH64-NEXT:    [[TMP37:%.*]] = atomicrmw and i64* @ulx, i64 [[TMP36]] monotonic, align 8, !dbg [[DBG36:![0-9]+]]
// AARCH64-NEXT:    [[AND:%.*]] = and i64 [[TMP37]], [[TMP36]], !dbg [[DBG37:![0-9]+]]
// AARCH64-NEXT:    store i64 [[AND]], i64* @lv, align 8, !dbg [[DBG36]]
// AARCH64-NEXT:    [[TMP38:%.*]] = load i64, i64* @llv, align 8, !dbg [[DBG38:![0-9]+]]
// AARCH64-NEXT:    [[TMP39:%.*]] = atomicrmw xor i64* @llx, i64 [[TMP38]] monotonic, align 8, !dbg [[DBG39:![0-9]+]]
// AARCH64-NEXT:    [[XOR:%.*]] = xor i64 [[TMP39]], [[TMP38]], !dbg [[DBG40:![0-9]+]]
// AARCH64-NEXT:    store i64 [[XOR]], i64* @ullv, align 8, !dbg [[DBG39]]
// AARCH64-NEXT:    [[TMP40:%.*]] = load i64, i64* @ullv, align 8, !dbg [[DBG41:![0-9]+]]
// AARCH64-NEXT:    [[TMP41:%.*]] = atomicrmw or i64* @ullx, i64 [[TMP40]] monotonic, align 8, !dbg [[DBG42:![0-9]+]]
// AARCH64-NEXT:    [[OR:%.*]] = or i64 [[TMP41]], [[TMP40]], !dbg [[DBG43:![0-9]+]]
// AARCH64-NEXT:    store i64 [[OR]], i64* @llv, align 8, !dbg [[DBG42]]
// AARCH64-NEXT:    [[TMP42:%.*]] = load float, float* @fv, align 4, !dbg [[DBG44:![0-9]+]]
// AARCH64-NEXT:    [[TMP43:%.*]] = atomicrmw fadd float* @fx, float [[TMP42]] monotonic, align 4, !dbg [[DBG45:![0-9]+]]
// AARCH64-NEXT:    [[ADD24:%.*]] = fadd float [[TMP43]], [[TMP42]], !dbg [[DBG46:![0-9]+]]
// AARCH64-NEXT:    [[CONV25:%.*]] = fpext float [[ADD24]] to double, !dbg [[DBG45]]
// AARCH64-NEXT:    store double [[CONV25]], double* @dv, align 8, !dbg [[DBG45]]
// AARCH64-NEXT:    [[TMP44:%.*]] = load double, double* @dv, align 8, !dbg [[DBG47:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD26:%.*]] = load atomic i64, i64* bitcast (double* @dx to i64*) monotonic, align 8, !dbg [[DBG48:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT27:%.*]], !dbg [[DBG48]]
// AARCH64:       atomic_cont27:
// AARCH64-NEXT:    [[TMP45:%.*]] = phi i64 [ [[ATOMIC_LOAD26]], [[ATOMIC_EXIT23]] ], [ [[TMP50:%.*]], [[ATOMIC_CONT27]] ], !dbg [[DBG48]]
// AARCH64-NEXT:    [[TMP46:%.*]] = bitcast double* [[ATOMIC_TEMP28]] to i64*, !dbg [[DBG48]]
// AARCH64-NEXT:    [[TMP47:%.*]] = bitcast i64 [[TMP45]] to double, !dbg [[DBG48]]
// AARCH64-NEXT:    [[SUB29:%.*]] = fsub double [[TMP44]], [[TMP47]], !dbg [[DBG49:![0-9]+]]
// AARCH64-NEXT:    store double [[SUB29]], double* [[ATOMIC_TEMP28]], align 8, !dbg [[DBG48]]
// AARCH64-NEXT:    [[TMP48:%.*]] = load i64, i64* [[TMP46]], align 8, !dbg [[DBG48]]
// AARCH64-NEXT:    [[TMP49:%.*]] = cmpxchg i64* bitcast (double* @dx to i64*), i64 [[TMP45]], i64 [[TMP48]] monotonic monotonic, align 8, !dbg [[DBG48]]
// AARCH64-NEXT:    [[TMP50]] = extractvalue { i64, i1 } [[TMP49]], 0, !dbg [[DBG48]]
// AARCH64-NEXT:    [[TMP51:%.*]] = extractvalue { i64, i1 } [[TMP49]], 1, !dbg [[DBG48]]
// AARCH64-NEXT:    br i1 [[TMP51]], label [[ATOMIC_EXIT30:%.*]], label [[ATOMIC_CONT27]], !dbg [[DBG48]]
// AARCH64:       atomic_exit30:
// AARCH64-NEXT:    [[CONV31:%.*]] = fptrunc double [[TMP47]] to float, !dbg [[DBG48]]
// AARCH64-NEXT:    store float [[CONV31]], float* @fv, align 4, !dbg [[DBG48]]
// AARCH64-NEXT:    [[TMP52:%.*]] = load fp128, fp128* @ldv, align 16, !dbg [[DBG50:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD32:%.*]] = load atomic i128, i128* bitcast (fp128* @ldx to i128*) monotonic, align 16, !dbg [[DBG51:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT33:%.*]], !dbg [[DBG51]]
// AARCH64:       atomic_cont33:
// AARCH64-NEXT:    [[TMP53:%.*]] = phi i128 [ [[ATOMIC_LOAD32]], [[ATOMIC_EXIT30]] ], [ [[TMP58:%.*]], [[ATOMIC_CONT33]] ], !dbg [[DBG51]]
// AARCH64-NEXT:    [[TMP54:%.*]] = bitcast fp128* [[ATOMIC_TEMP34]] to i128*, !dbg [[DBG51]]
// AARCH64-NEXT:    [[TMP55:%.*]] = bitcast i128 [[TMP53]] to fp128, !dbg [[DBG51]]
// AARCH64-NEXT:    [[MUL35:%.*]] = fmul fp128 [[TMP55]], [[TMP52]], !dbg [[DBG52:![0-9]+]]
// AARCH64-NEXT:    store fp128 [[MUL35]], fp128* [[ATOMIC_TEMP34]], align 16, !dbg [[DBG51]]
// AARCH64-NEXT:    [[TMP56:%.*]] = load i128, i128* [[TMP54]], align 16, !dbg [[DBG51]]
// AARCH64-NEXT:    [[TMP57:%.*]] = cmpxchg i128* bitcast (fp128* @ldx to i128*), i128 [[TMP53]], i128 [[TMP56]] monotonic monotonic, align 16, !dbg [[DBG51]]
// AARCH64-NEXT:    [[TMP58]] = extractvalue { i128, i1 } [[TMP57]], 0, !dbg [[DBG51]]
// AARCH64-NEXT:    [[TMP59:%.*]] = extractvalue { i128, i1 } [[TMP57]], 1, !dbg [[DBG51]]
// AARCH64-NEXT:    br i1 [[TMP59]], label [[ATOMIC_EXIT36:%.*]], label [[ATOMIC_CONT33]], !dbg [[DBG51]]
// AARCH64:       atomic_exit36:
// AARCH64-NEXT:    [[CONV37:%.*]] = fptrunc fp128 [[MUL35]] to double, !dbg [[DBG51]]
// AARCH64-NEXT:    store double [[CONV37]], double* @dv, align 8, !dbg [[DBG51]]
// AARCH64-NEXT:    [[CIV_REAL:%.*]] = load i32, i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 0), align 4, !dbg [[DBG53:![0-9]+]]
// AARCH64-NEXT:    [[CIV_IMAG:%.*]] = load i32, i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 1), align 4, !dbg [[DBG53]]
// AARCH64-NEXT:    [[TMP60:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP38]] to i8*, !dbg [[DBG54:![0-9]+]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP60]], i32 noundef 0), !dbg [[DBG54]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT39:%.*]], !dbg [[DBG54]]
// AARCH64:       atomic_cont39:
// AARCH64-NEXT:    [[ATOMIC_TEMP38_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP38]], i32 0, i32 0, !dbg [[DBG54]]
// AARCH64-NEXT:    [[ATOMIC_TEMP38_REAL:%.*]] = load i32, i32* [[ATOMIC_TEMP38_REALP]], align 4, !dbg [[DBG54]]
// AARCH64-NEXT:    [[ATOMIC_TEMP38_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP38]], i32 0, i32 1, !dbg [[DBG54]]
// AARCH64-NEXT:    [[ATOMIC_TEMP38_IMAG:%.*]] = load i32, i32* [[ATOMIC_TEMP38_IMAGP]], align 4, !dbg [[DBG54]]
// AARCH64-NEXT:    [[TMP61:%.*]] = mul i32 [[CIV_REAL]], [[ATOMIC_TEMP38_REAL]], !dbg [[DBG55:![0-9]+]]
// AARCH64-NEXT:    [[TMP62:%.*]] = mul i32 [[CIV_IMAG]], [[ATOMIC_TEMP38_IMAG]], !dbg [[DBG55]]
// AARCH64-NEXT:    [[TMP63:%.*]] = add i32 [[TMP61]], [[TMP62]], !dbg [[DBG55]]
// AARCH64-NEXT:    [[TMP64:%.*]] = mul i32 [[ATOMIC_TEMP38_REAL]], [[ATOMIC_TEMP38_REAL]], !dbg [[DBG55]]
// AARCH64-NEXT:    [[TMP65:%.*]] = mul i32 [[ATOMIC_TEMP38_IMAG]], [[ATOMIC_TEMP38_IMAG]], !dbg [[DBG55]]
// AARCH64-NEXT:    [[TMP66:%.*]] = add i32 [[TMP64]], [[TMP65]], !dbg [[DBG55]]
// AARCH64-NEXT:    [[TMP67:%.*]] = mul i32 [[CIV_IMAG]], [[ATOMIC_TEMP38_REAL]], !dbg [[DBG55]]
// AARCH64-NEXT:    [[TMP68:%.*]] = mul i32 [[CIV_REAL]], [[ATOMIC_TEMP38_IMAG]], !dbg [[DBG55]]
// AARCH64-NEXT:    [[TMP69:%.*]] = sub i32 [[TMP67]], [[TMP68]], !dbg [[DBG55]]
// AARCH64-NEXT:    [[TMP70:%.*]] = sdiv i32 [[TMP63]], [[TMP66]], !dbg [[DBG55]]
// AARCH64-NEXT:    [[TMP71:%.*]] = sdiv i32 [[TMP69]], [[TMP66]], !dbg [[DBG55]]
// AARCH64-NEXT:    [[ATOMIC_TEMP40_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP40]], i32 0, i32 0, !dbg [[DBG54]]
// AARCH64-NEXT:    [[ATOMIC_TEMP40_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP40]], i32 0, i32 1, !dbg [[DBG54]]
// AARCH64-NEXT:    store i32 [[TMP70]], i32* [[ATOMIC_TEMP40_REALP]], align 4, !dbg [[DBG54]]
// AARCH64-NEXT:    store i32 [[TMP71]], i32* [[ATOMIC_TEMP40_IMAGP]], align 4, !dbg [[DBG54]]
// AARCH64-NEXT:    [[TMP72:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP38]] to i8*, !dbg [[DBG54]]
// AARCH64-NEXT:    [[TMP73:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP40]] to i8*, !dbg [[DBG54]]
// AARCH64-NEXT:    [[CALL:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP72]], i8* noundef [[TMP73]], i32 noundef 0, i32 noundef 0), !dbg [[DBG54]]
// AARCH64-NEXT:    br i1 [[CALL]], label [[ATOMIC_EXIT41:%.*]], label [[ATOMIC_CONT39]], !dbg [[DBG54]]
// AARCH64:       atomic_exit41:
// AARCH64-NEXT:    [[CONV42:%.*]] = sitofp i32 [[TMP70]] to float, !dbg [[DBG54]]
// AARCH64-NEXT:    [[CONV43:%.*]] = sitofp i32 [[TMP71]] to float, !dbg [[DBG54]]
// AARCH64-NEXT:    store float [[CONV42]], float* getelementptr inbounds ({ float, float }, { float, float }* @cfv, i32 0, i32 0), align 4, !dbg [[DBG54]]
// AARCH64-NEXT:    store float [[CONV43]], float* getelementptr inbounds ({ float, float }, { float, float }* @cfv, i32 0, i32 1), align 4, !dbg [[DBG54]]
// AARCH64-NEXT:    [[CFV_REAL:%.*]] = load float, float* getelementptr inbounds ({ float, float }, { float, float }* @cfv, i32 0, i32 0), align 4, !dbg [[DBG56:![0-9]+]]
// AARCH64-NEXT:    [[CFV_IMAG:%.*]] = load float, float* getelementptr inbounds ({ float, float }, { float, float }* @cfv, i32 0, i32 1), align 4, !dbg [[DBG56]]
// AARCH64-NEXT:    [[TMP74:%.*]] = bitcast { float, float }* [[ATOMIC_TEMP44]] to i8*, !dbg [[DBG57:![0-9]+]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 8, i8* noundef bitcast ({ float, float }* @cfx to i8*), i8* noundef [[TMP74]], i32 noundef 0), !dbg [[DBG57]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT45:%.*]], !dbg [[DBG57]]
// AARCH64:       atomic_cont45:
// AARCH64-NEXT:    [[ATOMIC_TEMP44_REALP:%.*]] = getelementptr inbounds { float, float }, { float, float }* [[ATOMIC_TEMP44]], i32 0, i32 0, !dbg [[DBG57]]
// AARCH64-NEXT:    [[ATOMIC_TEMP44_REAL:%.*]] = load float, float* [[ATOMIC_TEMP44_REALP]], align 4, !dbg [[DBG57]]
// AARCH64-NEXT:    [[ATOMIC_TEMP44_IMAGP:%.*]] = getelementptr inbounds { float, float }, { float, float }* [[ATOMIC_TEMP44]], i32 0, i32 1, !dbg [[DBG57]]
// AARCH64-NEXT:    [[ATOMIC_TEMP44_IMAG:%.*]] = load float, float* [[ATOMIC_TEMP44_IMAGP]], align 4, !dbg [[DBG57]]
// AARCH64-NEXT:    [[ADD_R:%.*]] = fadd float [[CFV_REAL]], [[ATOMIC_TEMP44_REAL]], !dbg [[DBG58:![0-9]+]]
// AARCH64-NEXT:    [[ADD_I:%.*]] = fadd float [[CFV_IMAG]], [[ATOMIC_TEMP44_IMAG]], !dbg [[DBG58]]
// AARCH64-NEXT:    [[ATOMIC_TEMP46_REALP:%.*]] = getelementptr inbounds { float, float }, { float, float }* [[ATOMIC_TEMP46]], i32 0, i32 0, !dbg [[DBG57]]
// AARCH64-NEXT:    [[ATOMIC_TEMP46_IMAGP:%.*]] = getelementptr inbounds { float, float }, { float, float }* [[ATOMIC_TEMP46]], i32 0, i32 1, !dbg [[DBG57]]
// AARCH64-NEXT:    store float [[ADD_R]], float* [[ATOMIC_TEMP46_REALP]], align 4, !dbg [[DBG57]]
// AARCH64-NEXT:    store float [[ADD_I]], float* [[ATOMIC_TEMP46_IMAGP]], align 4, !dbg [[DBG57]]
// AARCH64-NEXT:    [[TMP75:%.*]] = bitcast { float, float }* [[ATOMIC_TEMP44]] to i8*, !dbg [[DBG57]]
// AARCH64-NEXT:    [[TMP76:%.*]] = bitcast { float, float }* [[ATOMIC_TEMP46]] to i8*, !dbg [[DBG57]]
// AARCH64-NEXT:    [[CALL47:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 8, i8* noundef bitcast ({ float, float }* @cfx to i8*), i8* noundef [[TMP75]], i8* noundef [[TMP76]], i32 noundef 0, i32 noundef 0), !dbg [[DBG57]]
// AARCH64-NEXT:    br i1 [[CALL47]], label [[ATOMIC_EXIT48:%.*]], label [[ATOMIC_CONT45]], !dbg [[DBG57]]
// AARCH64:       atomic_exit48:
// AARCH64-NEXT:    [[CONV49:%.*]] = fptosi float [[ATOMIC_TEMP44_REAL]] to i32, !dbg [[DBG57]]
// AARCH64-NEXT:    [[CONV50:%.*]] = fptosi float [[ATOMIC_TEMP44_IMAG]] to i32, !dbg [[DBG57]]
// AARCH64-NEXT:    store i32 [[CONV49]], i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 0), align 4, !dbg [[DBG57]]
// AARCH64-NEXT:    store i32 [[CONV50]], i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 1), align 4, !dbg [[DBG57]]
// AARCH64-NEXT:    [[CDV_REAL:%.*]] = load double, double* getelementptr inbounds ({ double, double }, { double, double }* @cdv, i32 0, i32 0), align 8, !dbg [[DBG59:![0-9]+]]
// AARCH64-NEXT:    [[CDV_IMAG:%.*]] = load double, double* getelementptr inbounds ({ double, double }, { double, double }* @cdv, i32 0, i32 1), align 8, !dbg [[DBG59]]
// AARCH64-NEXT:    [[TMP77:%.*]] = bitcast { double, double }* [[ATOMIC_TEMP51]] to i8*, !dbg [[DBG60:![0-9]+]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 16, i8* noundef bitcast ({ double, double }* @cdx to i8*), i8* noundef [[TMP77]], i32 noundef 5), !dbg [[DBG60]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT52:%.*]], !dbg [[DBG60]]
// AARCH64:       atomic_cont52:
// AARCH64-NEXT:    [[ATOMIC_TEMP51_REALP:%.*]] = getelementptr inbounds { double, double }, { double, double }* [[ATOMIC_TEMP51]], i32 0, i32 0, !dbg [[DBG60]]
// AARCH64-NEXT:    [[ATOMIC_TEMP51_REAL:%.*]] = load double, double* [[ATOMIC_TEMP51_REALP]], align 8, !dbg [[DBG60]]
// AARCH64-NEXT:    [[ATOMIC_TEMP51_IMAGP:%.*]] = getelementptr inbounds { double, double }, { double, double }* [[ATOMIC_TEMP51]], i32 0, i32 1, !dbg [[DBG60]]
// AARCH64-NEXT:    [[ATOMIC_TEMP51_IMAG:%.*]] = load double, double* [[ATOMIC_TEMP51_IMAGP]], align 8, !dbg [[DBG60]]
// AARCH64-NEXT:    [[SUB_R:%.*]] = fsub double [[ATOMIC_TEMP51_REAL]], [[CDV_REAL]], !dbg [[DBG61:![0-9]+]]
// AARCH64-NEXT:    [[SUB_I:%.*]] = fsub double [[ATOMIC_TEMP51_IMAG]], [[CDV_IMAG]], !dbg [[DBG61]]
// AARCH64-NEXT:    [[ATOMIC_TEMP53_REALP:%.*]] = getelementptr inbounds { double, double }, { double, double }* [[ATOMIC_TEMP53]], i32 0, i32 0, !dbg [[DBG60]]
// AARCH64-NEXT:    [[ATOMIC_TEMP53_IMAGP:%.*]] = getelementptr inbounds { double, double }, { double, double }* [[ATOMIC_TEMP53]], i32 0, i32 1, !dbg [[DBG60]]
// AARCH64-NEXT:    store double [[SUB_R]], double* [[ATOMIC_TEMP53_REALP]], align 8, !dbg [[DBG60]]
// AARCH64-NEXT:    store double [[SUB_I]], double* [[ATOMIC_TEMP53_IMAGP]], align 8, !dbg [[DBG60]]
// AARCH64-NEXT:    [[TMP78:%.*]] = bitcast { double, double }* [[ATOMIC_TEMP51]] to i8*, !dbg [[DBG60]]
// AARCH64-NEXT:    [[TMP79:%.*]] = bitcast { double, double }* [[ATOMIC_TEMP53]] to i8*, !dbg [[DBG60]]
// AARCH64-NEXT:    [[CALL54:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 16, i8* noundef bitcast ({ double, double }* @cdx to i8*), i8* noundef [[TMP78]], i8* noundef [[TMP79]], i32 noundef 5, i32 noundef 5), !dbg [[DBG60]]
// AARCH64-NEXT:    br i1 [[CALL54]], label [[ATOMIC_EXIT55:%.*]], label [[ATOMIC_CONT52]], !dbg [[DBG60]]
// AARCH64:       atomic_exit55:
// AARCH64-NEXT:    [[CONV56:%.*]] = fptrunc double [[SUB_R]] to float, !dbg [[DBG60]]
// AARCH64-NEXT:    [[CONV57:%.*]] = fptrunc double [[SUB_I]] to float, !dbg [[DBG60]]
// AARCH64-NEXT:    store float [[CONV56]], float* getelementptr inbounds ({ float, float }, { float, float }* @cfv, i32 0, i32 0), align 4, !dbg [[DBG60]]
// AARCH64-NEXT:    store float [[CONV57]], float* getelementptr inbounds ({ float, float }, { float, float }* @cfv, i32 0, i32 1), align 4, !dbg [[DBG60]]
// AARCH64-NEXT:    [[TMP80:%.*]] = load i8, i8* @bv, align 1, !dbg [[DBG62:![0-9]+]]
// AARCH64-NEXT:    [[TOBOOL:%.*]] = trunc i8 [[TMP80]] to i1, !dbg [[DBG62]]
// AARCH64-NEXT:    [[CONV58:%.*]] = zext i1 [[TOBOOL]] to i64, !dbg [[DBG62]]
// AARCH64-NEXT:    [[TMP81:%.*]] = atomicrmw and i64* @ulx, i64 [[CONV58]] monotonic, align 8, !dbg [[DBG63:![0-9]+]]
// AARCH64-NEXT:    [[AND59:%.*]] = and i64 [[TMP81]], [[CONV58]], !dbg [[DBG64:![0-9]+]]
// AARCH64-NEXT:    store i64 [[AND59]], i64* @ulv, align 8, !dbg [[DBG63]]
// AARCH64-NEXT:    [[TMP82:%.*]] = load i8, i8* @cv, align 1, !dbg [[DBG65:![0-9]+]]
// AARCH64-NEXT:    [[CONV60:%.*]] = sext i8 [[TMP82]] to i32, !dbg [[DBG65]]
// AARCH64-NEXT:    [[ATOMIC_LOAD61:%.*]] = load atomic i8, i8* @bx monotonic, align 1, !dbg [[DBG66:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT62:%.*]], !dbg [[DBG66]]
// AARCH64:       atomic_cont62:
// AARCH64-NEXT:    [[TMP83:%.*]] = phi i8 [ [[ATOMIC_LOAD61]], [[ATOMIC_EXIT55]] ], [ [[TMP86:%.*]], [[ATOMIC_CONT62]] ], !dbg [[DBG66]]
// AARCH64-NEXT:    [[TOBOOL64:%.*]] = trunc i8 [[TMP83]] to i1, !dbg [[DBG66]]
// AARCH64-NEXT:    [[CONV65:%.*]] = zext i1 [[TOBOOL64]] to i32, !dbg [[DBG67:![0-9]+]]
// AARCH64-NEXT:    [[AND66:%.*]] = and i32 [[CONV60]], [[CONV65]], !dbg [[DBG68:![0-9]+]]
// AARCH64-NEXT:    [[TOBOOL67:%.*]] = icmp ne i32 [[AND66]], 0, !dbg [[DBG65]]
// AARCH64-NEXT:    [[FROMBOOL:%.*]] = zext i1 [[TOBOOL67]] to i8, !dbg [[DBG66]]
// AARCH64-NEXT:    store i8 [[FROMBOOL]], i8* [[ATOMIC_TEMP63]], align 1, !dbg [[DBG66]]
// AARCH64-NEXT:    [[TMP84:%.*]] = load i8, i8* [[ATOMIC_TEMP63]], align 1, !dbg [[DBG66]]
// AARCH64-NEXT:    [[TMP85:%.*]] = cmpxchg i8* @bx, i8 [[TMP83]], i8 [[TMP84]] monotonic monotonic, align 1, !dbg [[DBG66]]
// AARCH64-NEXT:    [[TMP86]] = extractvalue { i8, i1 } [[TMP85]], 0, !dbg [[DBG66]]
// AARCH64-NEXT:    [[TMP87:%.*]] = extractvalue { i8, i1 } [[TMP85]], 1, !dbg [[DBG66]]
// AARCH64-NEXT:    br i1 [[TMP87]], label [[ATOMIC_EXIT68:%.*]], label [[ATOMIC_CONT62]], !dbg [[DBG66]]
// AARCH64:       atomic_exit68:
// AARCH64-NEXT:    [[FROMBOOL69:%.*]] = zext i1 [[TOBOOL64]] to i8, !dbg [[DBG66]]
// AARCH64-NEXT:    store i8 [[FROMBOOL69]], i8* @bv, align 1, !dbg [[DBG66]]
// AARCH64-NEXT:    [[TMP88:%.*]] = load i8, i8* @ucv, align 1, !dbg [[DBG69:![0-9]+]]
// AARCH64-NEXT:    [[CONV70:%.*]] = zext i8 [[TMP88]] to i32, !dbg [[DBG69]]
// AARCH64-NEXT:    [[ATOMIC_LOAD71:%.*]] = load atomic i8, i8* @cx seq_cst, align 1, !dbg [[DBG70:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT72:%.*]], !dbg [[DBG70]]
// AARCH64:       atomic_cont72:
// AARCH64-NEXT:    [[TMP89:%.*]] = phi i8 [ [[ATOMIC_LOAD71]], [[ATOMIC_EXIT68]] ], [ [[TMP92:%.*]], [[ATOMIC_CONT72]] ], !dbg [[DBG70]]
// AARCH64-NEXT:    [[CONV74:%.*]] = sext i8 [[TMP89]] to i32, !dbg [[DBG71:![0-9]+]]
// AARCH64-NEXT:    [[SHR75:%.*]] = ashr i32 [[CONV74]], [[CONV70]], !dbg [[DBG72:![0-9]+]]
// AARCH64-NEXT:    [[CONV76:%.*]] = trunc i32 [[SHR75]] to i8, !dbg [[DBG71]]
// AARCH64-NEXT:    store i8 [[CONV76]], i8* [[ATOMIC_TEMP73]], align 1, !dbg [[DBG70]]
// AARCH64-NEXT:    [[TMP90:%.*]] = load i8, i8* [[ATOMIC_TEMP73]], align 1, !dbg [[DBG70]]
// AARCH64-NEXT:    [[TMP91:%.*]] = cmpxchg i8* @cx, i8 [[TMP89]], i8 [[TMP90]] seq_cst seq_cst, align 1, !dbg [[DBG70]]
// AARCH64-NEXT:    [[TMP92]] = extractvalue { i8, i1 } [[TMP91]], 0, !dbg [[DBG70]]
// AARCH64-NEXT:    [[TMP93:%.*]] = extractvalue { i8, i1 } [[TMP91]], 1, !dbg [[DBG70]]
// AARCH64-NEXT:    br i1 [[TMP93]], label [[ATOMIC_EXIT77:%.*]], label [[ATOMIC_CONT72]], !dbg [[DBG70]]
// AARCH64:       atomic_exit77:
// AARCH64-NEXT:    store i8 [[CONV76]], i8* @cv, align 1, !dbg [[DBG70]]
// AARCH64-NEXT:    [[TMP94:%.*]] = load i16, i16* @sv, align 2, !dbg [[DBG73:![0-9]+]]
// AARCH64-NEXT:    [[CONV78:%.*]] = sext i16 [[TMP94]] to i32, !dbg [[DBG73]]
// AARCH64-NEXT:    [[ATOMIC_LOAD79:%.*]] = load atomic i64, i64* @ulx monotonic, align 8, !dbg [[DBG74:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT80:%.*]], !dbg [[DBG74]]
// AARCH64:       atomic_cont80:
// AARCH64-NEXT:    [[TMP95:%.*]] = phi i64 [ [[ATOMIC_LOAD79]], [[ATOMIC_EXIT77]] ], [ [[TMP98:%.*]], [[ATOMIC_CONT80]] ], !dbg [[DBG74]]
// AARCH64-NEXT:    [[SH_PROM:%.*]] = trunc i64 [[TMP95]] to i32, !dbg [[DBG75:![0-9]+]]
// AARCH64-NEXT:    [[SHL82:%.*]] = shl i32 [[CONV78]], [[SH_PROM]], !dbg [[DBG75]]
// AARCH64-NEXT:    [[CONV83:%.*]] = sext i32 [[SHL82]] to i64, !dbg [[DBG73]]
// AARCH64-NEXT:    store i64 [[CONV83]], i64* [[ATOMIC_TEMP81]], align 8, !dbg [[DBG74]]
// AARCH64-NEXT:    [[TMP96:%.*]] = load i64, i64* [[ATOMIC_TEMP81]], align 8, !dbg [[DBG74]]
// AARCH64-NEXT:    [[TMP97:%.*]] = cmpxchg i64* @ulx, i64 [[TMP95]], i64 [[TMP96]] monotonic monotonic, align 8, !dbg [[DBG74]]
// AARCH64-NEXT:    [[TMP98]] = extractvalue { i64, i1 } [[TMP97]], 0, !dbg [[DBG74]]
// AARCH64-NEXT:    [[TMP99:%.*]] = extractvalue { i64, i1 } [[TMP97]], 1, !dbg [[DBG74]]
// AARCH64-NEXT:    br i1 [[TMP99]], label [[ATOMIC_EXIT84:%.*]], label [[ATOMIC_CONT80]], !dbg [[DBG74]]
// AARCH64:       atomic_exit84:
// AARCH64-NEXT:    store i64 [[CONV83]], i64* @ulv, align 8, !dbg [[DBG74]]
// AARCH64-NEXT:    [[TMP100:%.*]] = load i16, i16* @usv, align 2, !dbg [[DBG76:![0-9]+]]
// AARCH64-NEXT:    [[CONV85:%.*]] = zext i16 [[TMP100]] to i64, !dbg [[DBG76]]
// AARCH64-NEXT:    [[ATOMIC_LOAD86:%.*]] = load atomic i64, i64* @lx monotonic, align 8, !dbg [[DBG77:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT87:%.*]], !dbg [[DBG77]]
// AARCH64:       atomic_cont87:
// AARCH64-NEXT:    [[TMP101:%.*]] = phi i64 [ [[ATOMIC_LOAD86]], [[ATOMIC_EXIT84]] ], [ [[TMP104:%.*]], [[ATOMIC_CONT87]] ], !dbg [[DBG77]]
// AARCH64-NEXT:    [[REM:%.*]] = srem i64 [[TMP101]], [[CONV85]], !dbg [[DBG78:![0-9]+]]
// AARCH64-NEXT:    store i64 [[REM]], i64* [[ATOMIC_TEMP88]], align 8, !dbg [[DBG77]]
// AARCH64-NEXT:    [[TMP102:%.*]] = load i64, i64* [[ATOMIC_TEMP88]], align 8, !dbg [[DBG77]]
// AARCH64-NEXT:    [[TMP103:%.*]] = cmpxchg i64* @lx, i64 [[TMP101]], i64 [[TMP102]] monotonic monotonic, align 8, !dbg [[DBG77]]
// AARCH64-NEXT:    [[TMP104]] = extractvalue { i64, i1 } [[TMP103]], 0, !dbg [[DBG77]]
// AARCH64-NEXT:    [[TMP105:%.*]] = extractvalue { i64, i1 } [[TMP103]], 1, !dbg [[DBG77]]
// AARCH64-NEXT:    br i1 [[TMP105]], label [[ATOMIC_EXIT89:%.*]], label [[ATOMIC_CONT87]], !dbg [[DBG77]]
// AARCH64:       atomic_exit89:
// AARCH64-NEXT:    store i64 [[TMP101]], i64* @lv, align 8, !dbg [[DBG77]]
// AARCH64-NEXT:    [[TMP106:%.*]] = load i32, i32* @iv, align 4, !dbg [[DBG79:![0-9]+]]
// AARCH64-NEXT:    [[TMP107:%.*]] = atomicrmw or i32* @uix, i32 [[TMP106]] seq_cst, align 4, !dbg [[DBG80:![0-9]+]]
// AARCH64-NEXT:    [[OR90:%.*]] = or i32 [[TMP106]], [[TMP107]], !dbg [[DBG81:![0-9]+]]
// AARCH64-NEXT:    store i32 [[OR90]], i32* @uiv, align 4, !dbg [[DBG80]]
// AARCH64-NEXT:    [[TMP108:%.*]] = load i32, i32* @uiv, align 4, !dbg [[DBG82:![0-9]+]]
// AARCH64-NEXT:    [[TMP109:%.*]] = atomicrmw and i32* @ix, i32 [[TMP108]] monotonic, align 4, !dbg [[DBG83:![0-9]+]]
// AARCH64-NEXT:    [[AND91:%.*]] = and i32 [[TMP109]], [[TMP108]], !dbg [[DBG84:![0-9]+]]
// AARCH64-NEXT:    store i32 [[AND91]], i32* @iv, align 4, !dbg [[DBG83]]
// AARCH64-NEXT:    [[TMP110:%.*]] = load i64, i64* @lv, align 8, !dbg [[DBG85:![0-9]+]]
// AARCH64-NEXT:    [[TMP111:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP92]] to i8*, !dbg [[DBG86:![0-9]+]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP111]], i32 noundef 0), !dbg [[DBG86]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT93:%.*]], !dbg [[DBG86]]
// AARCH64:       atomic_cont93:
// AARCH64-NEXT:    [[ATOMIC_TEMP92_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP92]], i32 0, i32 0, !dbg [[DBG86]]
// AARCH64-NEXT:    [[ATOMIC_TEMP92_REAL:%.*]] = load i32, i32* [[ATOMIC_TEMP92_REALP]], align 4, !dbg [[DBG86]]
// AARCH64-NEXT:    [[ATOMIC_TEMP92_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP92]], i32 0, i32 1, !dbg [[DBG86]]
// AARCH64-NEXT:    [[ATOMIC_TEMP92_IMAG:%.*]] = load i32, i32* [[ATOMIC_TEMP92_IMAGP]], align 4, !dbg [[DBG86]]
// AARCH64-NEXT:    [[CONV95:%.*]] = sext i32 [[ATOMIC_TEMP92_REAL]] to i64, !dbg [[DBG87:![0-9]+]]
// AARCH64-NEXT:    [[CONV96:%.*]] = sext i32 [[ATOMIC_TEMP92_IMAG]] to i64, !dbg [[DBG87]]
// AARCH64-NEXT:    [[ADD_R97:%.*]] = add i64 [[TMP110]], [[CONV95]], !dbg [[DBG88:![0-9]+]]
// AARCH64-NEXT:    [[ADD_I98:%.*]] = add i64 0, [[CONV96]], !dbg [[DBG88]]
// AARCH64-NEXT:    [[CONV99:%.*]] = trunc i64 [[ADD_R97]] to i32, !dbg [[DBG85]]
// AARCH64-NEXT:    [[CONV100:%.*]] = trunc i64 [[ADD_I98]] to i32, !dbg [[DBG85]]
// AARCH64-NEXT:    [[ATOMIC_TEMP94_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP94]], i32 0, i32 0, !dbg [[DBG86]]
// AARCH64-NEXT:    [[ATOMIC_TEMP94_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP94]], i32 0, i32 1, !dbg [[DBG86]]
// AARCH64-NEXT:    store i32 [[CONV99]], i32* [[ATOMIC_TEMP94_REALP]], align 4, !dbg [[DBG86]]
// AARCH64-NEXT:    store i32 [[CONV100]], i32* [[ATOMIC_TEMP94_IMAGP]], align 4, !dbg [[DBG86]]
// AARCH64-NEXT:    [[TMP112:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP92]] to i8*, !dbg [[DBG86]]
// AARCH64-NEXT:    [[TMP113:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP94]] to i8*, !dbg [[DBG86]]
// AARCH64-NEXT:    [[CALL101:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP112]], i8* noundef [[TMP113]], i32 noundef 0, i32 noundef 0), !dbg [[DBG86]]
// AARCH64-NEXT:    br i1 [[CALL101]], label [[ATOMIC_EXIT102:%.*]], label [[ATOMIC_CONT93]], !dbg [[DBG86]]
// AARCH64:       atomic_exit102:
// AARCH64-NEXT:    store i32 [[ATOMIC_TEMP92_REAL]], i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 0), align 4, !dbg [[DBG86]]
// AARCH64-NEXT:    store i32 [[ATOMIC_TEMP92_IMAG]], i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 1), align 4, !dbg [[DBG86]]
// AARCH64-NEXT:    [[TMP114:%.*]] = load i64, i64* @ulv, align 8, !dbg [[DBG89:![0-9]+]]
// AARCH64-NEXT:    [[CONV103:%.*]] = uitofp i64 [[TMP114]] to float, !dbg [[DBG89]]
// AARCH64-NEXT:    [[ATOMIC_LOAD104:%.*]] = load atomic i32, i32* bitcast (float* @fx to i32*) monotonic, align 4, !dbg [[DBG90:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT105:%.*]], !dbg [[DBG90]]
// AARCH64:       atomic_cont105:
// AARCH64-NEXT:    [[TMP115:%.*]] = phi i32 [ [[ATOMIC_LOAD104]], [[ATOMIC_EXIT102]] ], [ [[TMP120:%.*]], [[ATOMIC_CONT105]] ], !dbg [[DBG90]]
// AARCH64-NEXT:    [[TMP116:%.*]] = bitcast float* [[ATOMIC_TEMP106]] to i32*, !dbg [[DBG90]]
// AARCH64-NEXT:    [[TMP117:%.*]] = bitcast i32 [[TMP115]] to float, !dbg [[DBG90]]
// AARCH64-NEXT:    [[MUL107:%.*]] = fmul float [[TMP117]], [[CONV103]], !dbg [[DBG91:![0-9]+]]
// AARCH64-NEXT:    store float [[MUL107]], float* [[ATOMIC_TEMP106]], align 4, !dbg [[DBG90]]
// AARCH64-NEXT:    [[TMP118:%.*]] = load i32, i32* [[TMP116]], align 4, !dbg [[DBG90]]
// AARCH64-NEXT:    [[TMP119:%.*]] = cmpxchg i32* bitcast (float* @fx to i32*), i32 [[TMP115]], i32 [[TMP118]] monotonic monotonic, align 4, !dbg [[DBG90]]
// AARCH64-NEXT:    [[TMP120]] = extractvalue { i32, i1 } [[TMP119]], 0, !dbg [[DBG90]]
// AARCH64-NEXT:    [[TMP121:%.*]] = extractvalue { i32, i1 } [[TMP119]], 1, !dbg [[DBG90]]
// AARCH64-NEXT:    br i1 [[TMP121]], label [[ATOMIC_EXIT108:%.*]], label [[ATOMIC_CONT105]], !dbg [[DBG90]]
// AARCH64:       atomic_exit108:
// AARCH64-NEXT:    store float [[MUL107]], float* @fv, align 4, !dbg [[DBG90]]
// AARCH64-NEXT:    [[TMP122:%.*]] = load i64, i64* @llv, align 8, !dbg [[DBG92:![0-9]+]]
// AARCH64-NEXT:    [[CONV109:%.*]] = sitofp i64 [[TMP122]] to double, !dbg [[DBG92]]
// AARCH64-NEXT:    [[ATOMIC_LOAD110:%.*]] = load atomic i64, i64* bitcast (double* @dx to i64*) monotonic, align 8, !dbg [[DBG93:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT111:%.*]], !dbg [[DBG93]]
// AARCH64:       atomic_cont111:
// AARCH64-NEXT:    [[TMP123:%.*]] = phi i64 [ [[ATOMIC_LOAD110]], [[ATOMIC_EXIT108]] ], [ [[TMP128:%.*]], [[ATOMIC_CONT111]] ], !dbg [[DBG93]]
// AARCH64-NEXT:    [[TMP124:%.*]] = bitcast double* [[ATOMIC_TEMP112]] to i64*, !dbg [[DBG93]]
// AARCH64-NEXT:    [[TMP125:%.*]] = bitcast i64 [[TMP123]] to double, !dbg [[DBG93]]
// AARCH64-NEXT:    [[DIV113:%.*]] = fdiv double [[TMP125]], [[CONV109]], !dbg [[DBG94:![0-9]+]]
// AARCH64-NEXT:    store double [[DIV113]], double* [[ATOMIC_TEMP112]], align 8, !dbg [[DBG93]]
// AARCH64-NEXT:    [[TMP126:%.*]] = load i64, i64* [[TMP124]], align 8, !dbg [[DBG93]]
// AARCH64-NEXT:    [[TMP127:%.*]] = cmpxchg i64* bitcast (double* @dx to i64*), i64 [[TMP123]], i64 [[TMP126]] monotonic monotonic, align 8, !dbg [[DBG93]]
// AARCH64-NEXT:    [[TMP128]] = extractvalue { i64, i1 } [[TMP127]], 0, !dbg [[DBG93]]
// AARCH64-NEXT:    [[TMP129:%.*]] = extractvalue { i64, i1 } [[TMP127]], 1, !dbg [[DBG93]]
// AARCH64-NEXT:    br i1 [[TMP129]], label [[ATOMIC_EXIT114:%.*]], label [[ATOMIC_CONT111]], !dbg [[DBG93]]
// AARCH64:       atomic_exit114:
// AARCH64-NEXT:    store double [[DIV113]], double* @dv, align 8, !dbg [[DBG93]]
// AARCH64-NEXT:    [[TMP130:%.*]] = load i64, i64* @ullv, align 8, !dbg [[DBG95:![0-9]+]]
// AARCH64-NEXT:    [[CONV115:%.*]] = uitofp i64 [[TMP130]] to fp128, !dbg [[DBG95]]
// AARCH64-NEXT:    [[TMP131:%.*]] = atomicrmw fsub fp128* @ldx, fp128 [[CONV115]] monotonic, align 16, !dbg [[DBG96:![0-9]+]]
// AARCH64-NEXT:    store fp128 [[TMP131]], fp128* @ldv, align 16, !dbg [[DBG96]]
// AARCH64-NEXT:    [[TMP132:%.*]] = load float, float* @fv, align 4, !dbg [[DBG97:![0-9]+]]
// AARCH64-NEXT:    [[TMP133:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP116]] to i8*, !dbg [[DBG98:![0-9]+]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP133]], i32 noundef 0), !dbg [[DBG98]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT117:%.*]], !dbg [[DBG98]]
// AARCH64:       atomic_cont117:
// AARCH64-NEXT:    [[ATOMIC_TEMP116_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP116]], i32 0, i32 0, !dbg [[DBG98]]
// AARCH64-NEXT:    [[ATOMIC_TEMP116_REAL:%.*]] = load i32, i32* [[ATOMIC_TEMP116_REALP]], align 4, !dbg [[DBG98]]
// AARCH64-NEXT:    [[ATOMIC_TEMP116_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP116]], i32 0, i32 1, !dbg [[DBG98]]
// AARCH64-NEXT:    [[ATOMIC_TEMP116_IMAG:%.*]] = load i32, i32* [[ATOMIC_TEMP116_IMAGP]], align 4, !dbg [[DBG98]]
// AARCH64-NEXT:    [[CONV119:%.*]] = sitofp i32 [[ATOMIC_TEMP116_REAL]] to float, !dbg [[DBG99:![0-9]+]]
// AARCH64-NEXT:    [[CONV120:%.*]] = sitofp i32 [[ATOMIC_TEMP116_IMAG]] to float, !dbg [[DBG99]]
// AARCH64-NEXT:    [[CALL121:%.*]] = call { float, float } @__divsc3(float noundef [[TMP132]], float noundef 0.000000e+00, float noundef [[CONV119]], float noundef [[CONV120]]) #[[ATTR2:[0-9]+]], !dbg [[DBG100:![0-9]+]]
// AARCH64-NEXT:    [[TMP134:%.*]] = extractvalue { float, float } [[CALL121]], 0, !dbg [[DBG100]]
// AARCH64-NEXT:    [[TMP135:%.*]] = extractvalue { float, float } [[CALL121]], 1, !dbg [[DBG100]]
// AARCH64-NEXT:    [[CONV122:%.*]] = fptosi float [[TMP134]] to i32, !dbg [[DBG97]]
// AARCH64-NEXT:    [[CONV123:%.*]] = fptosi float [[TMP135]] to i32, !dbg [[DBG97]]
// AARCH64-NEXT:    [[ATOMIC_TEMP118_REALP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP118]], i32 0, i32 0, !dbg [[DBG98]]
// AARCH64-NEXT:    [[ATOMIC_TEMP118_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, { i32, i32 }* [[ATOMIC_TEMP118]], i32 0, i32 1, !dbg [[DBG98]]
// AARCH64-NEXT:    store i32 [[CONV122]], i32* [[ATOMIC_TEMP118_REALP]], align 4, !dbg [[DBG98]]
// AARCH64-NEXT:    store i32 [[CONV123]], i32* [[ATOMIC_TEMP118_IMAGP]], align 4, !dbg [[DBG98]]
// AARCH64-NEXT:    [[TMP136:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP116]] to i8*, !dbg [[DBG98]]
// AARCH64-NEXT:    [[TMP137:%.*]] = bitcast { i32, i32 }* [[ATOMIC_TEMP118]] to i8*, !dbg [[DBG98]]
// AARCH64-NEXT:    [[CALL124:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 8, i8* noundef bitcast ({ i32, i32 }* @cix to i8*), i8* noundef [[TMP136]], i8* noundef [[TMP137]], i32 noundef 0, i32 noundef 0), !dbg [[DBG98]]
// AARCH64-NEXT:    br i1 [[CALL124]], label [[ATOMIC_EXIT125:%.*]], label [[ATOMIC_CONT117]], !dbg [[DBG98]]
// AARCH64:       atomic_exit125:
// AARCH64-NEXT:    store i32 [[CONV122]], i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 0), align 4, !dbg [[DBG98]]
// AARCH64-NEXT:    store i32 [[CONV123]], i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 1), align 4, !dbg [[DBG98]]
// AARCH64-NEXT:    [[TMP138:%.*]] = load double, double* @dv, align 8, !dbg [[DBG101:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD126:%.*]] = load atomic i16, i16* @sx monotonic, align 2, !dbg [[DBG102:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT127:%.*]], !dbg [[DBG102]]
// AARCH64:       atomic_cont127:
// AARCH64-NEXT:    [[TMP139:%.*]] = phi i16 [ [[ATOMIC_LOAD126]], [[ATOMIC_EXIT125]] ], [ [[TMP142:%.*]], [[ATOMIC_CONT127]] ], !dbg [[DBG102]]
// AARCH64-NEXT:    [[CONV129:%.*]] = sext i16 [[TMP139]] to i32, !dbg [[DBG103:![0-9]+]]
// AARCH64-NEXT:    [[CONV130:%.*]] = sitofp i32 [[CONV129]] to double, !dbg [[DBG103]]
// AARCH64-NEXT:    [[ADD131:%.*]] = fadd double [[CONV130]], [[TMP138]], !dbg [[DBG104:![0-9]+]]
// AARCH64-NEXT:    [[CONV132:%.*]] = fptosi double [[ADD131]] to i16, !dbg [[DBG103]]
// AARCH64-NEXT:    store i16 [[CONV132]], i16* [[ATOMIC_TEMP128]], align 2, !dbg [[DBG102]]
// AARCH64-NEXT:    [[TMP140:%.*]] = load i16, i16* [[ATOMIC_TEMP128]], align 2, !dbg [[DBG102]]
// AARCH64-NEXT:    [[TMP141:%.*]] = cmpxchg i16* @sx, i16 [[TMP139]], i16 [[TMP140]] monotonic monotonic, align 2, !dbg [[DBG102]]
// AARCH64-NEXT:    [[TMP142]] = extractvalue { i16, i1 } [[TMP141]], 0, !dbg [[DBG102]]
// AARCH64-NEXT:    [[TMP143:%.*]] = extractvalue { i16, i1 } [[TMP141]], 1, !dbg [[DBG102]]
// AARCH64-NEXT:    br i1 [[TMP143]], label [[ATOMIC_EXIT133:%.*]], label [[ATOMIC_CONT127]], !dbg [[DBG102]]
// AARCH64:       atomic_exit133:
// AARCH64-NEXT:    store i16 [[CONV132]], i16* @sv, align 2, !dbg [[DBG102]]
// AARCH64-NEXT:    [[TMP144:%.*]] = load fp128, fp128* @ldv, align 16, !dbg [[DBG105:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD134:%.*]] = load atomic i8, i8* @bx monotonic, align 1, !dbg [[DBG106:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT135:%.*]], !dbg [[DBG106]]
// AARCH64:       atomic_cont135:
// AARCH64-NEXT:    [[TMP145:%.*]] = phi i8 [ [[ATOMIC_LOAD134]], [[ATOMIC_EXIT133]] ], [ [[TMP148:%.*]], [[ATOMIC_CONT135]] ], !dbg [[DBG106]]
// AARCH64-NEXT:    [[TOBOOL137:%.*]] = trunc i8 [[TMP145]] to i1, !dbg [[DBG106]]
// AARCH64-NEXT:    [[CONV138:%.*]] = zext i1 [[TOBOOL137]] to i32, !dbg [[DBG107:![0-9]+]]
// AARCH64-NEXT:    [[CONV139:%.*]] = sitofp i32 [[CONV138]] to fp128, !dbg [[DBG107]]
// AARCH64-NEXT:    [[MUL140:%.*]] = fmul fp128 [[TMP144]], [[CONV139]], !dbg [[DBG108:![0-9]+]]
// AARCH64-NEXT:    [[TOBOOL141:%.*]] = fcmp une fp128 [[MUL140]], 0xL00000000000000000000000000000000, !dbg [[DBG105]]
// AARCH64-NEXT:    [[FROMBOOL142:%.*]] = zext i1 [[TOBOOL141]] to i8, !dbg [[DBG106]]
// AARCH64-NEXT:    store i8 [[FROMBOOL142]], i8* [[ATOMIC_TEMP136]], align 1, !dbg [[DBG106]]
// AARCH64-NEXT:    [[TMP146:%.*]] = load i8, i8* [[ATOMIC_TEMP136]], align 1, !dbg [[DBG106]]
// AARCH64-NEXT:    [[TMP147:%.*]] = cmpxchg i8* @bx, i8 [[TMP145]], i8 [[TMP146]] monotonic monotonic, align 1, !dbg [[DBG106]]
// AARCH64-NEXT:    [[TMP148]] = extractvalue { i8, i1 } [[TMP147]], 0, !dbg [[DBG106]]
// AARCH64-NEXT:    [[TMP149:%.*]] = extractvalue { i8, i1 } [[TMP147]], 1, !dbg [[DBG106]]
// AARCH64-NEXT:    br i1 [[TMP149]], label [[ATOMIC_EXIT143:%.*]], label [[ATOMIC_CONT135]], !dbg [[DBG106]]
// AARCH64:       atomic_exit143:
// AARCH64-NEXT:    [[FROMBOOL144:%.*]] = zext i1 [[TOBOOL137]] to i8, !dbg [[DBG106]]
// AARCH64-NEXT:    store i8 [[FROMBOOL144]], i8* @bv, align 1, !dbg [[DBG106]]
// AARCH64-NEXT:    [[CIV_REAL145:%.*]] = load i32, i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 0), align 4, !dbg [[DBG109:![0-9]+]]
// AARCH64-NEXT:    [[CIV_IMAG146:%.*]] = load i32, i32* getelementptr inbounds ({ i32, i32 }, { i32, i32 }* @civ, i32 0, i32 1), align 4, !dbg [[DBG109]]
// AARCH64-NEXT:    [[ATOMIC_LOAD147:%.*]] = load atomic i8, i8* @bx monotonic, align 1, !dbg [[DBG110:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT148:%.*]], !dbg [[DBG110]]
// AARCH64:       atomic_cont148:
// AARCH64-NEXT:    [[TMP150:%.*]] = phi i8 [ [[ATOMIC_LOAD147]], [[ATOMIC_EXIT143]] ], [ [[TMP153:%.*]], [[ATOMIC_CONT148]] ], !dbg [[DBG110]]
// AARCH64-NEXT:    [[TOBOOL150:%.*]] = trunc i8 [[TMP150]] to i1, !dbg [[DBG110]]
// AARCH64-NEXT:    [[CONV151:%.*]] = zext i1 [[TOBOOL150]] to i32, !dbg [[DBG111:![0-9]+]]
// AARCH64-NEXT:    [[SUB_R152:%.*]] = sub i32 [[CIV_REAL145]], [[CONV151]], !dbg [[DBG112:![0-9]+]]
// AARCH64-NEXT:    [[SUB_I153:%.*]] = sub i32 [[CIV_IMAG146]], 0, !dbg [[DBG112]]
// AARCH64-NEXT:    [[TOBOOL154:%.*]] = icmp ne i32 [[SUB_R152]], 0, !dbg [[DBG109]]
// AARCH64-NEXT:    [[TOBOOL155:%.*]] = icmp ne i32 [[SUB_I153]], 0, !dbg [[DBG109]]
// AARCH64-NEXT:    [[TOBOOL156:%.*]] = or i1 [[TOBOOL154]], [[TOBOOL155]], !dbg [[DBG109]]
// AARCH64-NEXT:    [[FROMBOOL157:%.*]] = zext i1 [[TOBOOL156]] to i8, !dbg [[DBG110]]
// AARCH64-NEXT:    store i8 [[FROMBOOL157]], i8* [[ATOMIC_TEMP149]], align 1, !dbg [[DBG110]]
// AARCH64-NEXT:    [[TMP151:%.*]] = load i8, i8* [[ATOMIC_TEMP149]], align 1, !dbg [[DBG110]]
// AARCH64-NEXT:    [[TMP152:%.*]] = cmpxchg i8* @bx, i8 [[TMP150]], i8 [[TMP151]] monotonic monotonic, align 1, !dbg [[DBG110]]
// AARCH64-NEXT:    [[TMP153]] = extractvalue { i8, i1 } [[TMP152]], 0, !dbg [[DBG110]]
// AARCH64-NEXT:    [[TMP154:%.*]] = extractvalue { i8, i1 } [[TMP152]], 1, !dbg [[DBG110]]
// AARCH64-NEXT:    br i1 [[TMP154]], label [[ATOMIC_EXIT158:%.*]], label [[ATOMIC_CONT148]], !dbg [[DBG110]]
// AARCH64:       atomic_exit158:
// AARCH64-NEXT:    [[FROMBOOL159:%.*]] = zext i1 [[TOBOOL156]] to i8, !dbg [[DBG110]]
// AARCH64-NEXT:    store i8 [[FROMBOOL159]], i8* @bv, align 1, !dbg [[DBG110]]
// AARCH64-NEXT:    [[TMP155:%.*]] = load i16, i16* @sv, align 2, !dbg [[DBG113:![0-9]+]]
// AARCH64-NEXT:    [[TMP156:%.*]] = load i8, i8* @bv, align 1, !dbg [[DBG114:![0-9]+]]
// AARCH64-NEXT:    [[TOBOOL160:%.*]] = trunc i8 [[TMP156]] to i1, !dbg [[DBG114]]
// AARCH64-NEXT:    [[CONV161:%.*]] = zext i1 [[TOBOOL160]] to i32, !dbg [[DBG114]]
// AARCH64-NEXT:    [[ATOMIC_LOAD162:%.*]] = load atomic i128, i128* bitcast (<4 x i32>* @int4x to i128*) monotonic, align 16, !dbg [[DBG115:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT163:%.*]], !dbg [[DBG115]]
// AARCH64:       atomic_cont163:
// AARCH64-NEXT:    [[TMP157:%.*]] = phi i128 [ [[ATOMIC_LOAD162]], [[ATOMIC_EXIT158]] ], [ [[TMP164:%.*]], [[ATOMIC_CONT163]] ], !dbg [[DBG115]]
// AARCH64-NEXT:    [[TMP158:%.*]] = bitcast <4 x i32>* [[ATOMIC_TEMP164]] to i128*, !dbg [[DBG115]]
// AARCH64-NEXT:    store i128 [[TMP157]], i128* [[TMP158]], align 16, !dbg [[DBG115]]
// AARCH64-NEXT:    [[TMP159:%.*]] = bitcast i128 [[TMP157]] to <4 x i32>, !dbg [[DBG115]]
// AARCH64-NEXT:    store <4 x i32> [[TMP159]], <4 x i32>* [[ATOMIC_TEMP165]], align 16, !dbg [[DBG115]]
// AARCH64-NEXT:    [[TMP160:%.*]] = load <4 x i32>, <4 x i32>* [[ATOMIC_TEMP165]], align 16, !dbg [[DBG115]]
// AARCH64-NEXT:    [[VECEXT:%.*]] = extractelement <4 x i32> [[TMP160]], i16 [[TMP155]], !dbg [[DBG115]]
// AARCH64-NEXT:    [[OR166:%.*]] = or i32 [[VECEXT]], [[CONV161]], !dbg [[DBG116:![0-9]+]]
// AARCH64-NEXT:    [[TMP161:%.*]] = load <4 x i32>, <4 x i32>* [[ATOMIC_TEMP164]], align 16, !dbg [[DBG115]]
// AARCH64-NEXT:    [[VECINS:%.*]] = insertelement <4 x i32> [[TMP161]], i32 [[OR166]], i16 [[TMP155]], !dbg [[DBG115]]
// AARCH64-NEXT:    store <4 x i32> [[VECINS]], <4 x i32>* [[ATOMIC_TEMP164]], align 16, !dbg [[DBG115]]
// AARCH64-NEXT:    [[TMP162:%.*]] = load i128, i128* [[TMP158]], align 16, !dbg [[DBG115]]
// AARCH64-NEXT:    [[TMP163:%.*]] = cmpxchg i128* bitcast (<4 x i32>* @int4x to i128*), i128 [[TMP157]], i128 [[TMP162]] monotonic monotonic, align 16, !dbg [[DBG115]]
// AARCH64-NEXT:    [[TMP164]] = extractvalue { i128, i1 } [[TMP163]], 0, !dbg [[DBG115]]
// AARCH64-NEXT:    [[TMP165:%.*]] = extractvalue { i128, i1 } [[TMP163]], 1, !dbg [[DBG115]]
// AARCH64-NEXT:    br i1 [[TMP165]], label [[ATOMIC_EXIT167:%.*]], label [[ATOMIC_CONT163]], !dbg [[DBG115]]
// AARCH64:       atomic_exit167:
// AARCH64-NEXT:    store i32 [[OR166]], i32* @iv, align 4, !dbg [[DBG115]]
// AARCH64-NEXT:    [[TMP166:%.*]] = load fp128, fp128* @ldv, align 16, !dbg [[DBG117:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD168:%.*]] = load atomic i32, i32* bitcast (i8* getelementptr (i8, i8* bitcast (%struct.BitFields* @bfx to i8*), i64 4) to i32*) monotonic, align 4, !dbg [[DBG118:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT169:%.*]], !dbg [[DBG118]]
// AARCH64:       atomic_cont169:
// AARCH64-NEXT:    [[TMP167:%.*]] = phi i32 [ [[ATOMIC_LOAD168]], [[ATOMIC_EXIT167]] ], [ [[TMP170:%.*]], [[ATOMIC_CONT169]] ], !dbg [[DBG118]]
// AARCH64-NEXT:    store i32 [[TMP167]], i32* [[ATOMIC_TEMP170]], align 4, !dbg [[DBG118]]
// AARCH64-NEXT:    store i32 [[TMP167]], i32* [[ATOMIC_TEMP171]], align 4, !dbg [[DBG118]]
// AARCH64-NEXT:    [[BF_LOAD:%.*]] = load i32, i32* [[ATOMIC_TEMP171]], align 4, !dbg [[DBG118]]
// AARCH64-NEXT:    [[BF_SHL:%.*]] = shl i32 [[BF_LOAD]], 1, !dbg [[DBG118]]
// AARCH64-NEXT:    [[BF_ASHR:%.*]] = ashr i32 [[BF_SHL]], 1, !dbg [[DBG118]]
// AARCH64-NEXT:    [[CONV172:%.*]] = sitofp i32 [[BF_ASHR]] to fp128, !dbg [[DBG119:![0-9]+]]
// AARCH64-NEXT:    [[SUB173:%.*]] = fsub fp128 [[CONV172]], [[TMP166]], !dbg [[DBG120:![0-9]+]]
// AARCH64-NEXT:    [[CONV174:%.*]] = fptosi fp128 [[SUB173]] to i32, !dbg [[DBG119]]
// AARCH64-NEXT:    [[BF_LOAD175:%.*]] = load i32, i32* [[ATOMIC_TEMP170]], align 4, !dbg [[DBG118]]
// AARCH64-NEXT:    [[BF_VALUE:%.*]] = and i32 [[CONV174]], 2147483647, !dbg [[DBG118]]
// AARCH64-NEXT:    [[BF_CLEAR:%.*]] = and i32 [[BF_LOAD175]], -2147483648, !dbg [[DBG118]]
// AARCH64-NEXT:    [[BF_SET:%.*]] = or i32 [[BF_CLEAR]], [[BF_VALUE]], !dbg [[DBG118]]
// AARCH64-NEXT:    store i32 [[BF_SET]], i32* [[ATOMIC_TEMP170]], align 4, !dbg [[DBG118]]
// AARCH64-NEXT:    [[TMP168:%.*]] = load i32, i32* [[ATOMIC_TEMP170]], align 4, !dbg [[DBG118]]
// AARCH64-NEXT:    [[TMP169:%.*]] = cmpxchg i32* bitcast (i8* getelementptr (i8, i8* bitcast (%struct.BitFields* @bfx to i8*), i64 4) to i32*), i32 [[TMP167]], i32 [[TMP168]] monotonic monotonic, align 4, !dbg [[DBG118]]
// AARCH64-NEXT:    [[TMP170]] = extractvalue { i32, i1 } [[TMP169]], 0, !dbg [[DBG118]]
// AARCH64-NEXT:    [[TMP171:%.*]] = extractvalue { i32, i1 } [[TMP169]], 1, !dbg [[DBG118]]
// AARCH64-NEXT:    br i1 [[TMP171]], label [[ATOMIC_EXIT176:%.*]], label [[ATOMIC_CONT169]], !dbg [[DBG118]]
// AARCH64:       atomic_exit176:
// AARCH64-NEXT:    store i32 [[CONV174]], i32* @iv, align 4, !dbg [[DBG118]]
// AARCH64-NEXT:    [[TMP172:%.*]] = load fp128, fp128* @ldv, align 16, !dbg [[DBG121:![0-9]+]]
// AARCH64-NEXT:    [[TMP173:%.*]] = bitcast i32* [[ATOMIC_TEMP177]] to i8*, !dbg [[DBG122:![0-9]+]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 4, i8* noundef getelementptr (i8, i8* bitcast (%struct.BitFields_packed* @bfx_packed to i8*), i64 4), i8* noundef [[TMP173]], i32 noundef 0), !dbg [[DBG122]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT178:%.*]], !dbg [[DBG122]]
// AARCH64:       atomic_cont178:
// AARCH64-NEXT:    [[TMP174:%.*]] = load i32, i32* [[ATOMIC_TEMP177]], align 1, !dbg [[DBG122]]
// AARCH64-NEXT:    store i32 [[TMP174]], i32* [[ATOMIC_TEMP179]], align 1, !dbg [[DBG122]]
// AARCH64-NEXT:    [[TMP175:%.*]] = load i32, i32* [[ATOMIC_TEMP177]], align 1, !dbg [[DBG122]]
// AARCH64-NEXT:    store i32 [[TMP175]], i32* [[ATOMIC_TEMP180]], align 4, !dbg [[DBG122]]
// AARCH64-NEXT:    [[BF_LOAD181:%.*]] = load i32, i32* [[ATOMIC_TEMP180]], align 1, !dbg [[DBG122]]
// AARCH64-NEXT:    [[BF_SHL182:%.*]] = shl i32 [[BF_LOAD181]], 1, !dbg [[DBG122]]
// AARCH64-NEXT:    [[BF_ASHR183:%.*]] = ashr i32 [[BF_SHL182]], 1, !dbg [[DBG122]]
// AARCH64-NEXT:    [[CONV184:%.*]] = sitofp i32 [[BF_ASHR183]] to fp128, !dbg [[DBG123:![0-9]+]]
// AARCH64-NEXT:    [[MUL185:%.*]] = fmul fp128 [[CONV184]], [[TMP172]], !dbg [[DBG124:![0-9]+]]
// AARCH64-NEXT:    [[CONV186:%.*]] = fptosi fp128 [[MUL185]] to i32, !dbg [[DBG123]]
// AARCH64-NEXT:    [[BF_LOAD187:%.*]] = load i32, i32* [[ATOMIC_TEMP179]], align 1, !dbg [[DBG122]]
// AARCH64-NEXT:    [[BF_VALUE188:%.*]] = and i32 [[CONV186]], 2147483647, !dbg [[DBG122]]
// AARCH64-NEXT:    [[BF_CLEAR189:%.*]] = and i32 [[BF_LOAD187]], -2147483648, !dbg [[DBG122]]
// AARCH64-NEXT:    [[BF_SET190:%.*]] = or i32 [[BF_CLEAR189]], [[BF_VALUE188]], !dbg [[DBG122]]
// AARCH64-NEXT:    store i32 [[BF_SET190]], i32* [[ATOMIC_TEMP179]], align 1, !dbg [[DBG122]]
// AARCH64-NEXT:    [[TMP176:%.*]] = bitcast i32* [[ATOMIC_TEMP177]] to i8*, !dbg [[DBG122]]
// AARCH64-NEXT:    [[TMP177:%.*]] = bitcast i32* [[ATOMIC_TEMP179]] to i8*, !dbg [[DBG122]]
// AARCH64-NEXT:    [[CALL191:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 4, i8* noundef getelementptr (i8, i8* bitcast (%struct.BitFields_packed* @bfx_packed to i8*), i64 4), i8* noundef [[TMP176]], i8* noundef [[TMP177]], i32 noundef 0, i32 noundef 0), !dbg [[DBG122]]
// AARCH64-NEXT:    br i1 [[CALL191]], label [[ATOMIC_EXIT192:%.*]], label [[ATOMIC_CONT178]], !dbg [[DBG122]]
// AARCH64:       atomic_exit192:
// AARCH64-NEXT:    store i32 [[BF_ASHR183]], i32* @iv, align 4, !dbg [[DBG122]]
// AARCH64-NEXT:    [[TMP178:%.*]] = load fp128, fp128* @ldv, align 16, !dbg [[DBG125:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD193:%.*]] = load atomic i32, i32* getelementptr inbounds ([[STRUCT_BITFIELDS2:%.*]], %struct.BitFields2* @bfx2, i32 0, i32 0) monotonic, align 4, !dbg [[DBG126:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT194:%.*]], !dbg [[DBG126]]
// AARCH64:       atomic_cont194:
// AARCH64-NEXT:    [[TMP179:%.*]] = phi i32 [ [[ATOMIC_LOAD193]], [[ATOMIC_EXIT192]] ], [ [[TMP182:%.*]], [[ATOMIC_CONT194]] ], !dbg [[DBG126]]
// AARCH64-NEXT:    store i32 [[TMP179]], i32* [[ATOMIC_TEMP195]], align 4, !dbg [[DBG126]]
// AARCH64-NEXT:    store i32 [[TMP179]], i32* [[ATOMIC_TEMP196]], align 4, !dbg [[DBG126]]
// AARCH64-NEXT:    [[BF_LOAD197:%.*]] = load i32, i32* [[ATOMIC_TEMP196]], align 4, !dbg [[DBG126]]
// AARCH64-NEXT:    [[BF_ASHR198:%.*]] = ashr i32 [[BF_LOAD197]], 31, !dbg [[DBG126]]
// AARCH64-NEXT:    [[CONV199:%.*]] = sitofp i32 [[BF_ASHR198]] to fp128, !dbg [[DBG127:![0-9]+]]
// AARCH64-NEXT:    [[SUB200:%.*]] = fsub fp128 [[CONV199]], [[TMP178]], !dbg [[DBG128:![0-9]+]]
// AARCH64-NEXT:    [[CONV201:%.*]] = fptosi fp128 [[SUB200]] to i32, !dbg [[DBG127]]
// AARCH64-NEXT:    [[BF_LOAD202:%.*]] = load i32, i32* [[ATOMIC_TEMP195]], align 4, !dbg [[DBG126]]
// AARCH64-NEXT:    [[BF_VALUE203:%.*]] = and i32 [[CONV201]], 1, !dbg [[DBG126]]
// AARCH64-NEXT:    [[BF_SHL204:%.*]] = shl i32 [[BF_VALUE203]], 31, !dbg [[DBG126]]
// AARCH64-NEXT:    [[BF_CLEAR205:%.*]] = and i32 [[BF_LOAD202]], 2147483647, !dbg [[DBG126]]
// AARCH64-NEXT:    [[BF_SET206:%.*]] = or i32 [[BF_CLEAR205]], [[BF_SHL204]], !dbg [[DBG126]]
// AARCH64-NEXT:    store i32 [[BF_SET206]], i32* [[ATOMIC_TEMP195]], align 4, !dbg [[DBG126]]
// AARCH64-NEXT:    [[TMP180:%.*]] = load i32, i32* [[ATOMIC_TEMP195]], align 4, !dbg [[DBG126]]
// AARCH64-NEXT:    [[TMP181:%.*]] = cmpxchg i32* getelementptr inbounds ([[STRUCT_BITFIELDS2]], %struct.BitFields2* @bfx2, i32 0, i32 0), i32 [[TMP179]], i32 [[TMP180]] monotonic monotonic, align 4, !dbg [[DBG126]]
// AARCH64-NEXT:    [[TMP182]] = extractvalue { i32, i1 } [[TMP181]], 0, !dbg [[DBG126]]
// AARCH64-NEXT:    [[TMP183:%.*]] = extractvalue { i32, i1 } [[TMP181]], 1, !dbg [[DBG126]]
// AARCH64-NEXT:    br i1 [[TMP183]], label [[ATOMIC_EXIT207:%.*]], label [[ATOMIC_CONT194]], !dbg [[DBG126]]
// AARCH64:       atomic_exit207:
// AARCH64-NEXT:    store i32 [[CONV201]], i32* @iv, align 4, !dbg [[DBG126]]
// AARCH64-NEXT:    [[TMP184:%.*]] = load fp128, fp128* @ldv, align 16, !dbg [[DBG129:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD208:%.*]] = load atomic i8, i8* getelementptr (i8, i8* bitcast (%struct.BitFields2_packed* @bfx2_packed to i8*), i64 3) monotonic, align 1, !dbg [[DBG130:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT209:%.*]], !dbg [[DBG130]]
// AARCH64:       atomic_cont209:
// AARCH64-NEXT:    [[TMP185:%.*]] = phi i8 [ [[ATOMIC_LOAD208]], [[ATOMIC_EXIT207]] ], [ [[TMP191:%.*]], [[ATOMIC_CONT209]] ], !dbg [[DBG130]]
// AARCH64-NEXT:    [[TMP186:%.*]] = bitcast i32* [[ATOMIC_TEMP210]] to i8*, !dbg [[DBG130]]
// AARCH64-NEXT:    store i8 [[TMP185]], i8* [[TMP186]], align 1, !dbg [[DBG130]]
// AARCH64-NEXT:    [[TMP187:%.*]] = bitcast i32* [[ATOMIC_TEMP211]] to i8*, !dbg [[DBG130]]
// AARCH64-NEXT:    store i8 [[TMP185]], i8* [[TMP187]], align 1, !dbg [[DBG130]]
// AARCH64-NEXT:    [[BF_LOAD212:%.*]] = load i8, i8* [[TMP187]], align 1, !dbg [[DBG130]]
// AARCH64-NEXT:    [[BF_ASHR213:%.*]] = ashr i8 [[BF_LOAD212]], 7, !dbg [[DBG130]]
// AARCH64-NEXT:    [[BF_CAST:%.*]] = sext i8 [[BF_ASHR213]] to i32, !dbg [[DBG130]]
// AARCH64-NEXT:    [[CONV214:%.*]] = sitofp i32 [[BF_CAST]] to fp128, !dbg [[DBG131:![0-9]+]]
// AARCH64-NEXT:    [[DIV215:%.*]] = fdiv fp128 [[TMP184]], [[CONV214]], !dbg [[DBG132:![0-9]+]]
// AARCH64-NEXT:    [[CONV216:%.*]] = fptosi fp128 [[DIV215]] to i32, !dbg [[DBG129]]
// AARCH64-NEXT:    [[TMP188:%.*]] = trunc i32 [[CONV216]] to i8, !dbg [[DBG130]]
// AARCH64-NEXT:    [[BF_LOAD217:%.*]] = load i8, i8* [[TMP186]], align 1, !dbg [[DBG130]]
// AARCH64-NEXT:    [[BF_VALUE218:%.*]] = and i8 [[TMP188]], 1, !dbg [[DBG130]]
// AARCH64-NEXT:    [[BF_SHL219:%.*]] = shl i8 [[BF_VALUE218]], 7, !dbg [[DBG130]]
// AARCH64-NEXT:    [[BF_CLEAR220:%.*]] = and i8 [[BF_LOAD217]], 127, !dbg [[DBG130]]
// AARCH64-NEXT:    [[BF_SET221:%.*]] = or i8 [[BF_CLEAR220]], [[BF_SHL219]], !dbg [[DBG130]]
// AARCH64-NEXT:    store i8 [[BF_SET221]], i8* [[TMP186]], align 1, !dbg [[DBG130]]
// AARCH64-NEXT:    [[TMP189:%.*]] = load i8, i8* [[TMP186]], align 1, !dbg [[DBG130]]
// AARCH64-NEXT:    [[TMP190:%.*]] = cmpxchg i8* getelementptr (i8, i8* bitcast (%struct.BitFields2_packed* @bfx2_packed to i8*), i64 3), i8 [[TMP185]], i8 [[TMP189]] monotonic monotonic, align 1, !dbg [[DBG130]]
// AARCH64-NEXT:    [[TMP191]] = extractvalue { i8, i1 } [[TMP190]], 0, !dbg [[DBG130]]
// AARCH64-NEXT:    [[TMP192:%.*]] = extractvalue { i8, i1 } [[TMP190]], 1, !dbg [[DBG130]]
// AARCH64-NEXT:    br i1 [[TMP192]], label [[ATOMIC_EXIT222:%.*]], label [[ATOMIC_CONT209]], !dbg [[DBG130]]
// AARCH64:       atomic_exit222:
// AARCH64-NEXT:    store i32 [[CONV216]], i32* @iv, align 4, !dbg [[DBG130]]
// AARCH64-NEXT:    [[TMP193:%.*]] = load fp128, fp128* @ldv, align 16, !dbg [[DBG133:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD223:%.*]] = load atomic i32, i32* getelementptr inbounds ([[STRUCT_BITFIELDS3:%.*]], %struct.BitFields3* @bfx3, i32 0, i32 0) monotonic, align 4, !dbg [[DBG134:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT224:%.*]], !dbg [[DBG134]]
// AARCH64:       atomic_cont224:
// AARCH64-NEXT:    [[TMP194:%.*]] = phi i32 [ [[ATOMIC_LOAD223]], [[ATOMIC_EXIT222]] ], [ [[TMP197:%.*]], [[ATOMIC_CONT224]] ], !dbg [[DBG134]]
// AARCH64-NEXT:    store i32 [[TMP194]], i32* [[ATOMIC_TEMP225]], align 4, !dbg [[DBG134]]
// AARCH64-NEXT:    store i32 [[TMP194]], i32* [[ATOMIC_TEMP226]], align 4, !dbg [[DBG134]]
// AARCH64-NEXT:    [[BF_LOAD227:%.*]] = load i32, i32* [[ATOMIC_TEMP226]], align 4, !dbg [[DBG134]]
// AARCH64-NEXT:    [[BF_SHL228:%.*]] = shl i32 [[BF_LOAD227]], 7, !dbg [[DBG134]]
// AARCH64-NEXT:    [[BF_ASHR229:%.*]] = ashr i32 [[BF_SHL228]], 18, !dbg [[DBG134]]
// AARCH64-NEXT:    [[CONV230:%.*]] = sitofp i32 [[BF_ASHR229]] to fp128, !dbg [[DBG135:![0-9]+]]
// AARCH64-NEXT:    [[DIV231:%.*]] = fdiv fp128 [[CONV230]], [[TMP193]], !dbg [[DBG136:![0-9]+]]
// AARCH64-NEXT:    [[CONV232:%.*]] = fptosi fp128 [[DIV231]] to i32, !dbg [[DBG135]]
// AARCH64-NEXT:    [[BF_LOAD233:%.*]] = load i32, i32* [[ATOMIC_TEMP225]], align 4, !dbg [[DBG134]]
// AARCH64-NEXT:    [[BF_VALUE234:%.*]] = and i32 [[CONV232]], 16383, !dbg [[DBG134]]
// AARCH64-NEXT:    [[BF_SHL235:%.*]] = shl i32 [[BF_VALUE234]], 11, !dbg [[DBG134]]
// AARCH64-NEXT:    [[BF_CLEAR236:%.*]] = and i32 [[BF_LOAD233]], -33552385, !dbg [[DBG134]]
// AARCH64-NEXT:    [[BF_SET237:%.*]] = or i32 [[BF_CLEAR236]], [[BF_SHL235]], !dbg [[DBG134]]
// AARCH64-NEXT:    store i32 [[BF_SET237]], i32* [[ATOMIC_TEMP225]], align 4, !dbg [[DBG134]]
// AARCH64-NEXT:    [[TMP195:%.*]] = load i32, i32* [[ATOMIC_TEMP225]], align 4, !dbg [[DBG134]]
// AARCH64-NEXT:    [[TMP196:%.*]] = cmpxchg i32* getelementptr inbounds ([[STRUCT_BITFIELDS3]], %struct.BitFields3* @bfx3, i32 0, i32 0), i32 [[TMP194]], i32 [[TMP195]] monotonic monotonic, align 4, !dbg [[DBG134]]
// AARCH64-NEXT:    [[TMP197]] = extractvalue { i32, i1 } [[TMP196]], 0, !dbg [[DBG134]]
// AARCH64-NEXT:    [[TMP198:%.*]] = extractvalue { i32, i1 } [[TMP196]], 1, !dbg [[DBG134]]
// AARCH64-NEXT:    br i1 [[TMP198]], label [[ATOMIC_EXIT238:%.*]], label [[ATOMIC_CONT224]], !dbg [[DBG134]]
// AARCH64:       atomic_exit238:
// AARCH64-NEXT:    store i32 [[BF_ASHR229]], i32* @iv, align 4, !dbg [[DBG134]]
// AARCH64-NEXT:    [[TMP199:%.*]] = load fp128, fp128* @ldv, align 16, !dbg [[DBG137:![0-9]+]]
// AARCH64-NEXT:    [[TMP200:%.*]] = bitcast i32* [[ATOMIC_TEMP239]] to i24*, !dbg [[DBG138:![0-9]+]]
// AARCH64-NEXT:    [[TMP201:%.*]] = bitcast i24* [[TMP200]] to i8*, !dbg [[DBG138]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 3, i8* noundef getelementptr (i8, i8* bitcast (%struct.BitFields3_packed* @bfx3_packed to i8*), i64 1), i8* noundef [[TMP201]], i32 noundef 0), !dbg [[DBG138]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT240:%.*]], !dbg [[DBG138]]
// AARCH64:       atomic_cont240:
// AARCH64-NEXT:    [[TMP202:%.*]] = bitcast i32* [[ATOMIC_TEMP241]] to i24*, !dbg [[DBG138]]
// AARCH64-NEXT:    [[TMP203:%.*]] = load i24, i24* [[TMP200]], align 1, !dbg [[DBG138]]
// AARCH64-NEXT:    store i24 [[TMP203]], i24* [[TMP202]], align 1, !dbg [[DBG138]]
// AARCH64-NEXT:    [[TMP204:%.*]] = load i24, i24* [[TMP200]], align 1, !dbg [[DBG138]]
// AARCH64-NEXT:    [[TMP205:%.*]] = bitcast i32* [[ATOMIC_TEMP242]] to i24*, !dbg [[DBG138]]
// AARCH64-NEXT:    store i24 [[TMP204]], i24* [[TMP205]], align 1, !dbg [[DBG138]]
// AARCH64-NEXT:    [[BF_LOAD243:%.*]] = load i24, i24* [[TMP205]], align 1, !dbg [[DBG138]]
// AARCH64-NEXT:    [[BF_SHL244:%.*]] = shl i24 [[BF_LOAD243]], 7, !dbg [[DBG138]]
// AARCH64-NEXT:    [[BF_ASHR245:%.*]] = ashr i24 [[BF_SHL244]], 10, !dbg [[DBG138]]
// AARCH64-NEXT:    [[BF_CAST246:%.*]] = sext i24 [[BF_ASHR245]] to i32, !dbg [[DBG138]]
// AARCH64-NEXT:    [[CONV247:%.*]] = sitofp i32 [[BF_CAST246]] to fp128, !dbg [[DBG139:![0-9]+]]
// AARCH64-NEXT:    [[ADD248:%.*]] = fadd fp128 [[CONV247]], [[TMP199]], !dbg [[DBG140:![0-9]+]]
// AARCH64-NEXT:    [[CONV249:%.*]] = fptosi fp128 [[ADD248]] to i32, !dbg [[DBG139]]
// AARCH64-NEXT:    [[TMP206:%.*]] = trunc i32 [[CONV249]] to i24, !dbg [[DBG138]]
// AARCH64-NEXT:    [[BF_LOAD250:%.*]] = load i24, i24* [[TMP202]], align 1, !dbg [[DBG138]]
// AARCH64-NEXT:    [[BF_VALUE251:%.*]] = and i24 [[TMP206]], 16383, !dbg [[DBG138]]
// AARCH64-NEXT:    [[BF_SHL252:%.*]] = shl i24 [[BF_VALUE251]], 3, !dbg [[DBG138]]
// AARCH64-NEXT:    [[BF_CLEAR253:%.*]] = and i24 [[BF_LOAD250]], -131065, !dbg [[DBG138]]
// AARCH64-NEXT:    [[BF_SET254:%.*]] = or i24 [[BF_CLEAR253]], [[BF_SHL252]], !dbg [[DBG138]]
// AARCH64-NEXT:    store i24 [[BF_SET254]], i24* [[TMP202]], align 1, !dbg [[DBG138]]
// AARCH64-NEXT:    [[TMP207:%.*]] = bitcast i24* [[TMP200]] to i8*, !dbg [[DBG138]]
// AARCH64-NEXT:    [[TMP208:%.*]] = bitcast i24* [[TMP202]] to i8*, !dbg [[DBG138]]
// AARCH64-NEXT:    [[CALL255:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 3, i8* noundef getelementptr (i8, i8* bitcast (%struct.BitFields3_packed* @bfx3_packed to i8*), i64 1), i8* noundef [[TMP207]], i8* noundef [[TMP208]], i32 noundef 0, i32 noundef 0), !dbg [[DBG138]]
// AARCH64-NEXT:    br i1 [[CALL255]], label [[ATOMIC_EXIT256:%.*]], label [[ATOMIC_CONT240]], !dbg [[DBG138]]
// AARCH64:       atomic_exit256:
// AARCH64-NEXT:    store i32 [[CONV249]], i32* @iv, align 4, !dbg [[DBG138]]
// AARCH64-NEXT:    [[TMP209:%.*]] = load fp128, fp128* @ldv, align 16, !dbg [[DBG141:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD257:%.*]] = load atomic i64, i64* bitcast (%struct.BitFields4* @bfx4 to i64*) monotonic, align 8, !dbg [[DBG142:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT258:%.*]], !dbg [[DBG142]]
// AARCH64:       atomic_cont258:
// AARCH64-NEXT:    [[TMP210:%.*]] = phi i64 [ [[ATOMIC_LOAD257]], [[ATOMIC_EXIT256]] ], [ [[TMP214:%.*]], [[ATOMIC_CONT258]] ], !dbg [[DBG142]]
// AARCH64-NEXT:    store i64 [[TMP210]], i64* [[ATOMIC_TEMP259]], align 8, !dbg [[DBG142]]
// AARCH64-NEXT:    store i64 [[TMP210]], i64* [[ATOMIC_TEMP260]], align 8, !dbg [[DBG142]]
// AARCH64-NEXT:    [[BF_LOAD261:%.*]] = load i64, i64* [[ATOMIC_TEMP260]], align 8, !dbg [[DBG142]]
// AARCH64-NEXT:    [[BF_SHL262:%.*]] = shl i64 [[BF_LOAD261]], 47, !dbg [[DBG142]]
// AARCH64-NEXT:    [[BF_ASHR263:%.*]] = ashr i64 [[BF_SHL262]], 63, !dbg [[DBG142]]
// AARCH64-NEXT:    [[BF_CAST264:%.*]] = trunc i64 [[BF_ASHR263]] to i32, !dbg [[DBG142]]
// AARCH64-NEXT:    [[CONV265:%.*]] = sitofp i32 [[BF_CAST264]] to fp128, !dbg [[DBG143:![0-9]+]]
// AARCH64-NEXT:    [[MUL266:%.*]] = fmul fp128 [[CONV265]], [[TMP209]], !dbg [[DBG144:![0-9]+]]
// AARCH64-NEXT:    [[CONV267:%.*]] = fptosi fp128 [[MUL266]] to i32, !dbg [[DBG143]]
// AARCH64-NEXT:    [[TMP211:%.*]] = zext i32 [[CONV267]] to i64, !dbg [[DBG142]]
// AARCH64-NEXT:    [[BF_LOAD268:%.*]] = load i64, i64* [[ATOMIC_TEMP259]], align 8, !dbg [[DBG142]]
// AARCH64-NEXT:    [[BF_VALUE269:%.*]] = and i64 [[TMP211]], 1, !dbg [[DBG142]]
// AARCH64-NEXT:    [[BF_SHL270:%.*]] = shl i64 [[BF_VALUE269]], 16, !dbg [[DBG142]]
// AARCH64-NEXT:    [[BF_CLEAR271:%.*]] = and i64 [[BF_LOAD268]], -65537, !dbg [[DBG142]]
// AARCH64-NEXT:    [[BF_SET272:%.*]] = or i64 [[BF_CLEAR271]], [[BF_SHL270]], !dbg [[DBG142]]
// AARCH64-NEXT:    store i64 [[BF_SET272]], i64* [[ATOMIC_TEMP259]], align 8, !dbg [[DBG142]]
// AARCH64-NEXT:    [[TMP212:%.*]] = load i64, i64* [[ATOMIC_TEMP259]], align 8, !dbg [[DBG142]]
// AARCH64-NEXT:    [[TMP213:%.*]] = cmpxchg i64* bitcast (%struct.BitFields4* @bfx4 to i64*), i64 [[TMP210]], i64 [[TMP212]] monotonic monotonic, align 8, !dbg [[DBG142]]
// AARCH64-NEXT:    [[TMP214]] = extractvalue { i64, i1 } [[TMP213]], 0, !dbg [[DBG142]]
// AARCH64-NEXT:    [[TMP215:%.*]] = extractvalue { i64, i1 } [[TMP213]], 1, !dbg [[DBG142]]
// AARCH64-NEXT:    br i1 [[TMP215]], label [[ATOMIC_EXIT273:%.*]], label [[ATOMIC_CONT258]], !dbg [[DBG142]]
// AARCH64:       atomic_exit273:
// AARCH64-NEXT:    store i32 [[CONV267]], i32* @iv, align 4, !dbg [[DBG142]]
// AARCH64-NEXT:    [[TMP216:%.*]] = load fp128, fp128* @ldv, align 16, !dbg [[DBG145:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD274:%.*]] = load atomic i8, i8* getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED:%.*]], %struct.BitFields4_packed* @bfx4_packed, i32 0, i32 0, i64 2) monotonic, align 1, !dbg [[DBG146:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT275:%.*]], !dbg [[DBG146]]
// AARCH64:       atomic_cont275:
// AARCH64-NEXT:    [[TMP217:%.*]] = phi i8 [ [[ATOMIC_LOAD274]], [[ATOMIC_EXIT273]] ], [ [[TMP223:%.*]], [[ATOMIC_CONT275]] ], !dbg [[DBG146]]
// AARCH64-NEXT:    [[TMP218:%.*]] = bitcast i32* [[ATOMIC_TEMP276]] to i8*, !dbg [[DBG146]]
// AARCH64-NEXT:    store i8 [[TMP217]], i8* [[TMP218]], align 1, !dbg [[DBG146]]
// AARCH64-NEXT:    [[TMP219:%.*]] = bitcast i32* [[ATOMIC_TEMP277]] to i8*, !dbg [[DBG146]]
// AARCH64-NEXT:    store i8 [[TMP217]], i8* [[TMP219]], align 1, !dbg [[DBG146]]
// AARCH64-NEXT:    [[BF_LOAD278:%.*]] = load i8, i8* [[TMP219]], align 1, !dbg [[DBG146]]
// AARCH64-NEXT:    [[BF_SHL279:%.*]] = shl i8 [[BF_LOAD278]], 7, !dbg [[DBG146]]
// AARCH64-NEXT:    [[BF_ASHR280:%.*]] = ashr i8 [[BF_SHL279]], 7, !dbg [[DBG146]]
// AARCH64-NEXT:    [[BF_CAST281:%.*]] = sext i8 [[BF_ASHR280]] to i32, !dbg [[DBG146]]
// AARCH64-NEXT:    [[CONV282:%.*]] = sitofp i32 [[BF_CAST281]] to fp128, !dbg [[DBG147:![0-9]+]]
// AARCH64-NEXT:    [[SUB283:%.*]] = fsub fp128 [[CONV282]], [[TMP216]], !dbg [[DBG148:![0-9]+]]
// AARCH64-NEXT:    [[CONV284:%.*]] = fptosi fp128 [[SUB283]] to i32, !dbg [[DBG147]]
// AARCH64-NEXT:    [[TMP220:%.*]] = trunc i32 [[CONV284]] to i8, !dbg [[DBG146]]
// AARCH64-NEXT:    [[BF_LOAD285:%.*]] = load i8, i8* [[TMP218]], align 1, !dbg [[DBG146]]
// AARCH64-NEXT:    [[BF_VALUE286:%.*]] = and i8 [[TMP220]], 1, !dbg [[DBG146]]
// AARCH64-NEXT:    [[BF_CLEAR287:%.*]] = and i8 [[BF_LOAD285]], -2, !dbg [[DBG146]]
// AARCH64-NEXT:    [[BF_SET288:%.*]] = or i8 [[BF_CLEAR287]], [[BF_VALUE286]], !dbg [[DBG146]]
// AARCH64-NEXT:    store i8 [[BF_SET288]], i8* [[TMP218]], align 1, !dbg [[DBG146]]
// AARCH64-NEXT:    [[TMP221:%.*]] = load i8, i8* [[TMP218]], align 1, !dbg [[DBG146]]
// AARCH64-NEXT:    [[TMP222:%.*]] = cmpxchg i8* getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED]], %struct.BitFields4_packed* @bfx4_packed, i32 0, i32 0, i64 2), i8 [[TMP217]], i8 [[TMP221]] monotonic monotonic, align 1, !dbg [[DBG146]]
// AARCH64-NEXT:    [[TMP223]] = extractvalue { i8, i1 } [[TMP222]], 0, !dbg [[DBG146]]
// AARCH64-NEXT:    [[TMP224:%.*]] = extractvalue { i8, i1 } [[TMP222]], 1, !dbg [[DBG146]]
// AARCH64-NEXT:    br i1 [[TMP224]], label [[ATOMIC_EXIT289:%.*]], label [[ATOMIC_CONT275]], !dbg [[DBG146]]
// AARCH64:       atomic_exit289:
// AARCH64-NEXT:    store i32 [[BF_CAST281]], i32* @iv, align 4, !dbg [[DBG146]]
// AARCH64-NEXT:    [[TMP225:%.*]] = load fp128, fp128* @ldv, align 16, !dbg [[DBG149:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD290:%.*]] = load atomic i64, i64* bitcast (%struct.BitFields4* @bfx4 to i64*) monotonic, align 8, !dbg [[DBG150:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT291:%.*]], !dbg [[DBG150]]
// AARCH64:       atomic_cont291:
// AARCH64-NEXT:    [[TMP226:%.*]] = phi i64 [ [[ATOMIC_LOAD290]], [[ATOMIC_EXIT289]] ], [ [[TMP229:%.*]], [[ATOMIC_CONT291]] ], !dbg [[DBG150]]
// AARCH64-NEXT:    store i64 [[TMP226]], i64* [[ATOMIC_TEMP292]], align 8, !dbg [[DBG150]]
// AARCH64-NEXT:    store i64 [[TMP226]], i64* [[ATOMIC_TEMP293]], align 8, !dbg [[DBG150]]
// AARCH64-NEXT:    [[BF_LOAD294:%.*]] = load i64, i64* [[ATOMIC_TEMP293]], align 8, !dbg [[DBG150]]
// AARCH64-NEXT:    [[BF_SHL295:%.*]] = shl i64 [[BF_LOAD294]], 40, !dbg [[DBG150]]
// AARCH64-NEXT:    [[BF_ASHR296:%.*]] = ashr i64 [[BF_SHL295]], 57, !dbg [[DBG150]]
// AARCH64-NEXT:    [[CONV297:%.*]] = sitofp i64 [[BF_ASHR296]] to fp128, !dbg [[DBG151:![0-9]+]]
// AARCH64-NEXT:    [[DIV298:%.*]] = fdiv fp128 [[CONV297]], [[TMP225]], !dbg [[DBG152:![0-9]+]]
// AARCH64-NEXT:    [[CONV299:%.*]] = fptosi fp128 [[DIV298]] to i64, !dbg [[DBG151]]
// AARCH64-NEXT:    [[BF_LOAD300:%.*]] = load i64, i64* [[ATOMIC_TEMP292]], align 8, !dbg [[DBG150]]
// AARCH64-NEXT:    [[BF_VALUE301:%.*]] = and i64 [[CONV299]], 127, !dbg [[DBG150]]
// AARCH64-NEXT:    [[BF_SHL302:%.*]] = shl i64 [[BF_VALUE301]], 17, !dbg [[DBG150]]
// AARCH64-NEXT:    [[BF_CLEAR303:%.*]] = and i64 [[BF_LOAD300]], -16646145, !dbg [[DBG150]]
// AARCH64-NEXT:    [[BF_SET304:%.*]] = or i64 [[BF_CLEAR303]], [[BF_SHL302]], !dbg [[DBG150]]
// AARCH64-NEXT:    store i64 [[BF_SET304]], i64* [[ATOMIC_TEMP292]], align 8, !dbg [[DBG150]]
// AARCH64-NEXT:    [[TMP227:%.*]] = load i64, i64* [[ATOMIC_TEMP292]], align 8, !dbg [[DBG150]]
// AARCH64-NEXT:    [[TMP228:%.*]] = cmpxchg i64* bitcast (%struct.BitFields4* @bfx4 to i64*), i64 [[TMP226]], i64 [[TMP227]] release monotonic, align 8, !dbg [[DBG150]]
// AARCH64-NEXT:    [[TMP229]] = extractvalue { i64, i1 } [[TMP228]], 0, !dbg [[DBG150]]
// AARCH64-NEXT:    [[TMP230:%.*]] = extractvalue { i64, i1 } [[TMP228]], 1, !dbg [[DBG150]]
// AARCH64-NEXT:    br i1 [[TMP230]], label [[ATOMIC_EXIT305:%.*]], label [[ATOMIC_CONT291]], !dbg [[DBG150]]
// AARCH64:       atomic_exit305:
// AARCH64-NEXT:    [[CONV306:%.*]] = trunc i64 [[CONV299]] to i32, !dbg [[DBG150]]
// AARCH64-NEXT:    store i32 [[CONV306]], i32* @iv, align 4, !dbg [[DBG150]]
// AARCH64-NEXT:    [[TMP231:%.*]] = load fp128, fp128* @ldv, align 16, !dbg [[DBG153:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD307:%.*]] = load atomic i8, i8* getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED]], %struct.BitFields4_packed* @bfx4_packed, i32 0, i32 0, i64 2) acquire, align 1, !dbg [[DBG154:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT308:%.*]], !dbg [[DBG154]]
// AARCH64:       atomic_cont308:
// AARCH64-NEXT:    [[TMP232:%.*]] = phi i8 [ [[ATOMIC_LOAD307]], [[ATOMIC_EXIT305]] ], [ [[TMP238:%.*]], [[ATOMIC_CONT308]] ], !dbg [[DBG154]]
// AARCH64-NEXT:    [[TMP233:%.*]] = bitcast i64* [[ATOMIC_TEMP309]] to i8*, !dbg [[DBG154]]
// AARCH64-NEXT:    store i8 [[TMP232]], i8* [[TMP233]], align 1, !dbg [[DBG154]]
// AARCH64-NEXT:    [[TMP234:%.*]] = bitcast i64* [[ATOMIC_TEMP310]] to i8*, !dbg [[DBG154]]
// AARCH64-NEXT:    store i8 [[TMP232]], i8* [[TMP234]], align 1, !dbg [[DBG154]]
// AARCH64-NEXT:    [[BF_LOAD311:%.*]] = load i8, i8* [[TMP234]], align 1, !dbg [[DBG154]]
// AARCH64-NEXT:    [[BF_ASHR312:%.*]] = ashr i8 [[BF_LOAD311]], 1, !dbg [[DBG154]]
// AARCH64-NEXT:    [[BF_CAST313:%.*]] = sext i8 [[BF_ASHR312]] to i64, !dbg [[DBG154]]
// AARCH64-NEXT:    [[CONV314:%.*]] = sitofp i64 [[BF_CAST313]] to fp128, !dbg [[DBG155:![0-9]+]]
// AARCH64-NEXT:    [[ADD315:%.*]] = fadd fp128 [[CONV314]], [[TMP231]], !dbg [[DBG156:![0-9]+]]
// AARCH64-NEXT:    [[CONV316:%.*]] = fptosi fp128 [[ADD315]] to i64, !dbg [[DBG155]]
// AARCH64-NEXT:    [[TMP235:%.*]] = trunc i64 [[CONV316]] to i8, !dbg [[DBG154]]
// AARCH64-NEXT:    [[BF_LOAD317:%.*]] = load i8, i8* [[TMP233]], align 1, !dbg [[DBG154]]
// AARCH64-NEXT:    [[BF_VALUE318:%.*]] = and i8 [[TMP235]], 127, !dbg [[DBG154]]
// AARCH64-NEXT:    [[BF_SHL319:%.*]] = shl i8 [[BF_VALUE318]], 1, !dbg [[DBG154]]
// AARCH64-NEXT:    [[BF_CLEAR320:%.*]] = and i8 [[BF_LOAD317]], 1, !dbg [[DBG154]]
// AARCH64-NEXT:    [[BF_SET321:%.*]] = or i8 [[BF_CLEAR320]], [[BF_SHL319]], !dbg [[DBG154]]
// AARCH64-NEXT:    store i8 [[BF_SET321]], i8* [[TMP233]], align 1, !dbg [[DBG154]]
// AARCH64-NEXT:    [[TMP236:%.*]] = load i8, i8* [[TMP233]], align 1, !dbg [[DBG154]]
// AARCH64-NEXT:    [[TMP237:%.*]] = cmpxchg i8* getelementptr inbounds ([[STRUCT_BITFIELDS4_PACKED]], %struct.BitFields4_packed* @bfx4_packed, i32 0, i32 0, i64 2), i8 [[TMP232]], i8 [[TMP236]] acquire acquire, align 1, !dbg [[DBG154]]
// AARCH64-NEXT:    [[TMP238]] = extractvalue { i8, i1 } [[TMP237]], 0, !dbg [[DBG154]]
// AARCH64-NEXT:    [[TMP239:%.*]] = extractvalue { i8, i1 } [[TMP237]], 1, !dbg [[DBG154]]
// AARCH64-NEXT:    br i1 [[TMP239]], label [[ATOMIC_EXIT322:%.*]], label [[ATOMIC_CONT308]], !dbg [[DBG154]]
// AARCH64:       atomic_exit322:
// AARCH64-NEXT:    [[CONV323:%.*]] = trunc i64 [[CONV316]] to i32, !dbg [[DBG154]]
// AARCH64-NEXT:    store i32 [[CONV323]], i32* @iv, align 4, !dbg [[DBG154]]
// AARCH64-NEXT:    [[TMP240:%.*]] = load i64, i64* @ulv, align 8, !dbg [[DBG157:![0-9]+]]
// AARCH64-NEXT:    [[CONV324:%.*]] = uitofp i64 [[TMP240]] to float, !dbg [[DBG157]]
// AARCH64-NEXT:    [[ATOMIC_LOAD325:%.*]] = load atomic i64, i64* bitcast (<2 x float>* @float2x to i64*) acquire, align 8, !dbg [[DBG158:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT326:%.*]], !dbg [[DBG158]]
// AARCH64:       atomic_cont326:
// AARCH64-NEXT:    [[TMP241:%.*]] = phi i64 [ [[ATOMIC_LOAD325]], [[ATOMIC_EXIT322]] ], [ [[TMP250:%.*]], [[ATOMIC_CONT326]] ], !dbg [[DBG158]]
// AARCH64-NEXT:    [[TMP242:%.*]] = bitcast <2 x float>* [[ATOMIC_TEMP327]] to i64*, !dbg [[DBG158]]
// AARCH64-NEXT:    store i64 [[TMP241]], i64* [[TMP242]], align 8, !dbg [[DBG158]]
// AARCH64-NEXT:    [[TMP243:%.*]] = bitcast i64 [[TMP241]] to <2 x float>, !dbg [[DBG158]]
// AARCH64-NEXT:    store <2 x float> [[TMP243]], <2 x float>* [[ATOMIC_TEMP328]], align 8, !dbg [[DBG158]]
// AARCH64-NEXT:    [[TMP244:%.*]] = load <2 x float>, <2 x float>* [[ATOMIC_TEMP328]], align 8, !dbg [[DBG158]]
// AARCH64-NEXT:    [[TMP245:%.*]] = extractelement <2 x float> [[TMP244]], i64 0, !dbg [[DBG158]]
// AARCH64-NEXT:    [[SUB329:%.*]] = fsub float [[CONV324]], [[TMP245]], !dbg [[DBG159:![0-9]+]]
// AARCH64-NEXT:    [[TMP246:%.*]] = load <2 x float>, <2 x float>* [[ATOMIC_TEMP327]], align 8, !dbg [[DBG158]]
// AARCH64-NEXT:    [[TMP247:%.*]] = insertelement <2 x float> [[TMP246]], float [[SUB329]], i64 0, !dbg [[DBG158]]
// AARCH64-NEXT:    store <2 x float> [[TMP247]], <2 x float>* [[ATOMIC_TEMP327]], align 8, !dbg [[DBG158]]
// AARCH64-NEXT:    [[TMP248:%.*]] = load i64, i64* [[TMP242]], align 8, !dbg [[DBG158]]
// AARCH64-NEXT:    [[TMP249:%.*]] = cmpxchg i64* bitcast (<2 x float>* @float2x to i64*), i64 [[TMP241]], i64 [[TMP248]] acq_rel acquire, align 8, !dbg [[DBG158]]
// AARCH64-NEXT:    [[TMP250]] = extractvalue { i64, i1 } [[TMP249]], 0, !dbg [[DBG158]]
// AARCH64-NEXT:    [[TMP251:%.*]] = extractvalue { i64, i1 } [[TMP249]], 1, !dbg [[DBG158]]
// AARCH64-NEXT:    br i1 [[TMP251]], label [[ATOMIC_EXIT330:%.*]], label [[ATOMIC_CONT326]], !dbg [[DBG158]]
// AARCH64:       atomic_exit330:
// AARCH64-NEXT:    store float [[TMP245]], float* @fv, align 4, !dbg [[DBG158]]
// AARCH64-NEXT:    ret i32 0, !dbg [[DBG160:![0-9]+]]
//
