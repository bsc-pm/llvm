// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --function-signature --include-generated-funcs
// RUN: %clang_cc1 -x c -triple x86_64-gnu-linux -verify -fompss-2 -disable-llvm-passes -ferror-limit 100 %s -emit-llvm -o - | FileCheck %s --check-prefixes=LIN64
// RUN: %clang_cc1 -x c -triple ppc64 -verify -fompss-2 -disable-llvm-passes -ferror-limit 100 %s -emit-llvm -o - | FileCheck %s --check-prefixes=PPC64
// RUN: %clang_cc1 -x c -triple aarch64 -verify -fompss-2 -disable-llvm-passes -ferror-limit 100 %s -emit-llvm -o - | FileCheck %s --check-prefixes=AARCH64
// expected-no-diagnostics
#ifndef HEADER
#define HEADER

_Bool bv, bx;
char cv, cx;
unsigned char ucv, ucx;
short sv, sx;
unsigned short usv, usx;
int iv, ix;
unsigned int uiv, uix;
long lv, lx;
unsigned long ulv, ulx;
long long llv, llx;
unsigned long long ullv, ullx;
float fv, fx;
double dv, dx;
long double ldv, ldx;
_Complex int civ, cix;
_Complex float cfv, cfx;
_Complex double cdv, cdx;

typedef int int4 __attribute__((__vector_size__(16)));
int4 int4x;

struct BitFields {
  int : 32;
  int a : 31;
} bfx;

struct BitFields_packed {
  int : 32;
  int a : 31;
} __attribute__ ((__packed__)) bfx_packed;

struct BitFields2 {
  int : 31;
  int a : 1;
} bfx2;

struct BitFields2_packed {
  int : 31;
  int a : 1;
} __attribute__ ((__packed__)) bfx2_packed;

struct BitFields3 {
  int : 11;
  int a : 14;
} bfx3;

struct BitFields3_packed {
  int : 11;
  int a : 14;
} __attribute__ ((__packed__)) bfx3_packed;

struct BitFields4 {
  short : 16;
  int a: 1;
  long b : 7;
} bfx4;

struct BitFields4_packed {
  short : 16;
  int a: 1;
  long b : 7;
} __attribute__ ((__packed__)) bfx4_packed;

typedef float float2 __attribute__((ext_vector_type(2)));
float2 float2x;

#if defined(__x86_64__)
// Register "0" is currently an invalid register for global register variables.
// Use "esp" instead of "0".
// register int rix __asm__("0");
register int rix __asm__("esp");
#endif

int main(void) {
#pragma oss atomic capture
  bv = bx++;
#pragma oss atomic capture
  cv = ++cx;
#pragma oss atomic capture
  ucv = ucx--;
#pragma oss atomic capture
  sv = --sx;
#pragma oss atomic capture
  sv = usx += usv;
#pragma oss atomic capture
  uiv = ix *= iv;
#pragma oss atomic capture
  {iv = uix; uix -= uiv;}
#pragma oss atomic capture
  {ix <<= iv; uiv = ix;}
#pragma oss atomic capture
  iv = uix >>= uiv;
#pragma oss atomic capture
  {ulv = lx; lx /= lv;}
#pragma oss atomic capture
  {ulx &= ulv; lv = ulx;}
#pragma oss atomic capture
  ullv = llx ^= llv;
#pragma oss atomic capture
  llv = ullx |= ullv;
#pragma oss atomic capture
  dv = fx = fx + fv;
#pragma oss atomic capture
  {fv = dx; dx = dv - dx;}
#pragma oss atomic capture
  {ldx = ldx * ldv; dv = ldx;}
// <Skip checks for complex calculations>
#pragma oss atomic capture
  cfv = cix = civ / cix;
// <Skip checks for complex calculations>
#pragma oss atomic capture
  {civ = cfx; cfx = cfv + cfx;}
// <Skip checks for complex calculations>
#pragma oss atomic capture seq_cst
  {cdx = cdx - cdv; cfv = cdx;}
#pragma oss atomic capture
  ulv = ulx = ulx & bv;
#pragma oss atomic capture
  {bv = bx; bx = cv & bx;}
#pragma oss atomic capture, seq_cst
  {cx = cx >> ucv; cv = cx;}
#pragma oss atomic capture
  ulv = ulx = sv << ulx;
#pragma oss atomic capture
  {lv = lx; lx = lx % usv;}
#pragma oss atomic seq_cst, capture
  {uix = iv | uix; uiv = uix;}
#pragma oss atomic capture
  iv = ix = ix & uiv;
// <Skip checks for complex calculations>
#pragma oss atomic capture
  {civ = cix; cix = lv + cix;}
#pragma oss atomic capture
  {fx = fx * ulv; fv = fx;}
#pragma oss atomic capture
  dv = dx /= llv;
#pragma oss atomic capture
  {ldv = ldx; ldx -= ullv;}
// <Skip checks for complex calculations>
#pragma oss atomic capture
  {cix = fv / cix; civ = cix;}
#pragma oss atomic capture
  sv = sx = sx + dv;
#pragma oss atomic capture
  {bv = bx; bx = ldv * bx;}
#pragma oss atomic capture
  {bx = civ - bx; bv = bx;}
#pragma oss atomic capture
  {int4x[sv] |= bv; iv = int4x[sv];}
#pragma oss atomic capture
  iv = bfx.a = bfx.a - ldv;
#pragma oss atomic capture
  {iv = bfx_packed.a; bfx_packed.a *= ldv;}
#pragma oss atomic capture
  {bfx2.a -= ldv; iv = bfx2.a;}
#pragma oss atomic capture
  iv = bfx2_packed.a = ldv / bfx2_packed.a;
#pragma oss atomic capture
  {iv = bfx3.a; bfx3.a /= ldv;}
#pragma oss atomic capture
  {bfx3_packed.a += ldv; iv = bfx3_packed.a;}
#pragma oss atomic relaxed capture
  iv = bfx4.a = bfx4.a * ldv;
#pragma oss atomic capture relaxed
  {iv = bfx4_packed.a; bfx4_packed.a -= ldv;}
#pragma oss atomic capture release
  {bfx4.b /= ldv; iv = bfx4.b;}
#pragma oss atomic capture acquire
  iv = bfx4_packed.b += ldv;
#pragma oss atomic capture acq_rel
  {fv = float2x.x; float2x.x = ulv - float2x.x;}
#if defined(__x86_64__)
#pragma oss atomic capture seq_cst
  {rix = dv / rix; iv = rix;}
#pragma oss atomic capture
  {rix = ix; ix = 5;}
#endif
  return 0;
}
#endif
// LIN64-LABEL: define {{[^@]+}}@main
// LIN64-SAME: () #[[ATTR0:[0-9]+]] !dbg [[DBG6:![0-9]+]] {
// LIN64-NEXT:  entry:
// LIN64-NEXT:    [[RETVAL:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca i16, align 2
// LIN64-NEXT:    [[ATOMIC_TEMP10:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP14:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP18:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP22:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP28:%.*]] = alloca double, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP32:%.*]] = alloca x86_fp80, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP34:%.*]] = alloca x86_fp80, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP38:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP40:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP45:%.*]] = alloca { float, float }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP47:%.*]] = alloca { float, float }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP52:%.*]] = alloca { double, double }, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP54:%.*]] = alloca { double, double }, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP64:%.*]] = alloca i8, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP73:%.*]] = alloca i8, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP81:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP88:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP92:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP94:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP106:%.*]] = alloca float, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP112:%.*]] = alloca double, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP116:%.*]] = alloca x86_fp80, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP118:%.*]] = alloca x86_fp80, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP122:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP124:%.*]] = alloca { i32, i32 }, align 4
// LIN64-NEXT:    [[COERCE:%.*]] = alloca { float, float }, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP134:%.*]] = alloca i16, align 2
// LIN64-NEXT:    [[ATOMIC_TEMP142:%.*]] = alloca i8, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP155:%.*]] = alloca i8, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP168:%.*]] = alloca <4 x i32>, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP170:%.*]] = alloca <4 x i32>, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP171:%.*]] = alloca <4 x i32>, align 16
// LIN64-NEXT:    [[ATOMIC_TEMP177:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP178:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP184:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP186:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP187:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP202:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP203:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP217:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP218:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP232:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP233:%.*]] = alloca i32, align 4
// LIN64-NEXT:    [[ATOMIC_TEMP246:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP248:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP249:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP266:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP267:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP283:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP284:%.*]] = alloca i32, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP299:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP300:%.*]] = alloca i64, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP316:%.*]] = alloca i64, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP317:%.*]] = alloca i64, align 1
// LIN64-NEXT:    [[ATOMIC_TEMP334:%.*]] = alloca <2 x float>, align 8
// LIN64-NEXT:    [[ATOMIC_TEMP335:%.*]] = alloca <2 x float>, align 8
// LIN64-NEXT:    store i32 0, ptr [[RETVAL]], align 4
// LIN64-NEXT:    [[TMP0:%.*]] = atomicrmw add ptr @bx, i8 1 monotonic, align 1, !dbg [[DBG10:![0-9]+]]
// LIN64-NEXT:    store i8 [[TMP0]], ptr @bv, align 1, !dbg [[DBG10]]
// LIN64-NEXT:    [[TMP1:%.*]] = atomicrmw add ptr @cx, i8 1 monotonic, align 1, !dbg [[DBG11:![0-9]+]]
// LIN64-NEXT:    [[CONV:%.*]] = sext i8 [[TMP1]] to i32, !dbg [[DBG12:![0-9]+]]
// LIN64-NEXT:    [[ADD:%.*]] = add nsw i32 [[CONV]], 1, !dbg [[DBG13:![0-9]+]]
// LIN64-NEXT:    [[CONV1:%.*]] = trunc i32 [[ADD]] to i8, !dbg [[DBG12]]
// LIN64-NEXT:    store i8 [[CONV1]], ptr @cv, align 1, !dbg [[DBG11]]
// LIN64-NEXT:    [[TMP2:%.*]] = atomicrmw sub ptr @ucx, i8 1 monotonic, align 1, !dbg [[DBG14:![0-9]+]]
// LIN64-NEXT:    store i8 [[TMP2]], ptr @ucv, align 1, !dbg [[DBG14]]
// LIN64-NEXT:    [[TMP3:%.*]] = atomicrmw sub ptr @sx, i16 1 monotonic, align 2, !dbg [[DBG15:![0-9]+]]
// LIN64-NEXT:    [[CONV2:%.*]] = sext i16 [[TMP3]] to i32, !dbg [[DBG16:![0-9]+]]
// LIN64-NEXT:    [[SUB:%.*]] = sub nsw i32 [[CONV2]], 1, !dbg [[DBG17:![0-9]+]]
// LIN64-NEXT:    [[CONV3:%.*]] = trunc i32 [[SUB]] to i16, !dbg [[DBG16]]
// LIN64-NEXT:    store i16 [[CONV3]], ptr @sv, align 2, !dbg [[DBG15]]
// LIN64-NEXT:    [[TMP4:%.*]] = load i16, ptr @usv, align 2, !dbg [[DBG18:![0-9]+]]
// LIN64-NEXT:    [[CONV4:%.*]] = zext i16 [[TMP4]] to i32, !dbg [[DBG18]]
// LIN64-NEXT:    [[ATOMIC_LOAD:%.*]] = load atomic i16, ptr @usx monotonic, align 2, !dbg [[DBG19:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT:%.*]], !dbg [[DBG19]]
// LIN64:       atomic_cont:
// LIN64-NEXT:    [[TMP5:%.*]] = phi i16 [ [[ATOMIC_LOAD]], [[ENTRY:%.*]] ], [ [[TMP8:%.*]], [[ATOMIC_CONT]] ], !dbg [[DBG19]]
// LIN64-NEXT:    [[CONV5:%.*]] = zext i16 [[TMP5]] to i32, !dbg [[DBG20:![0-9]+]]
// LIN64-NEXT:    [[ADD6:%.*]] = add nsw i32 [[CONV5]], [[CONV4]], !dbg [[DBG21:![0-9]+]]
// LIN64-NEXT:    [[CONV7:%.*]] = trunc i32 [[ADD6]] to i16, !dbg [[DBG20]]
// LIN64-NEXT:    store i16 [[CONV7]], ptr [[ATOMIC_TEMP]], align 2, !dbg [[DBG19]]
// LIN64-NEXT:    [[TMP6:%.*]] = load i16, ptr [[ATOMIC_TEMP]], align 2, !dbg [[DBG19]]
// LIN64-NEXT:    [[TMP7:%.*]] = cmpxchg ptr @usx, i16 [[TMP5]], i16 [[TMP6]] monotonic monotonic, align 2, !dbg [[DBG19]]
// LIN64-NEXT:    [[TMP8]] = extractvalue { i16, i1 } [[TMP7]], 0, !dbg [[DBG19]]
// LIN64-NEXT:    [[TMP9:%.*]] = extractvalue { i16, i1 } [[TMP7]], 1, !dbg [[DBG19]]
// LIN64-NEXT:    br i1 [[TMP9]], label [[ATOMIC_EXIT:%.*]], label [[ATOMIC_CONT]], !dbg [[DBG19]]
// LIN64:       atomic_exit:
// LIN64-NEXT:    store i16 [[CONV7]], ptr @sv, align 2, !dbg [[DBG19]]
// LIN64-NEXT:    [[TMP10:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG22:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD8:%.*]] = load atomic i32, ptr @ix monotonic, align 4, !dbg [[DBG23:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT9:%.*]], !dbg [[DBG23]]
// LIN64:       atomic_cont9:
// LIN64-NEXT:    [[TMP11:%.*]] = phi i32 [ [[ATOMIC_LOAD8]], [[ATOMIC_EXIT]] ], [ [[TMP14:%.*]], [[ATOMIC_CONT9]] ], !dbg [[DBG23]]
// LIN64-NEXT:    [[MUL:%.*]] = mul nsw i32 [[TMP11]], [[TMP10]], !dbg [[DBG24:![0-9]+]]
// LIN64-NEXT:    store i32 [[MUL]], ptr [[ATOMIC_TEMP10]], align 4, !dbg [[DBG23]]
// LIN64-NEXT:    [[TMP12:%.*]] = load i32, ptr [[ATOMIC_TEMP10]], align 4, !dbg [[DBG23]]
// LIN64-NEXT:    [[TMP13:%.*]] = cmpxchg ptr @ix, i32 [[TMP11]], i32 [[TMP12]] monotonic monotonic, align 4, !dbg [[DBG23]]
// LIN64-NEXT:    [[TMP14]] = extractvalue { i32, i1 } [[TMP13]], 0, !dbg [[DBG23]]
// LIN64-NEXT:    [[TMP15:%.*]] = extractvalue { i32, i1 } [[TMP13]], 1, !dbg [[DBG23]]
// LIN64-NEXT:    br i1 [[TMP15]], label [[ATOMIC_EXIT11:%.*]], label [[ATOMIC_CONT9]], !dbg [[DBG23]]
// LIN64:       atomic_exit11:
// LIN64-NEXT:    store i32 [[MUL]], ptr @uiv, align 4, !dbg [[DBG23]]
// LIN64-NEXT:    [[TMP16:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG25:![0-9]+]]
// LIN64-NEXT:    [[TMP17:%.*]] = atomicrmw sub ptr @uix, i32 [[TMP16]] monotonic, align 4, !dbg [[DBG26:![0-9]+]]
// LIN64-NEXT:    store i32 [[TMP17]], ptr @iv, align 4, !dbg [[DBG26]]
// LIN64-NEXT:    [[TMP18:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG27:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD12:%.*]] = load atomic i32, ptr @ix monotonic, align 4, !dbg [[DBG28:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT13:%.*]], !dbg [[DBG28]]
// LIN64:       atomic_cont13:
// LIN64-NEXT:    [[TMP19:%.*]] = phi i32 [ [[ATOMIC_LOAD12]], [[ATOMIC_EXIT11]] ], [ [[TMP22:%.*]], [[ATOMIC_CONT13]] ], !dbg [[DBG28]]
// LIN64-NEXT:    [[SHL:%.*]] = shl i32 [[TMP19]], [[TMP18]], !dbg [[DBG29:![0-9]+]]
// LIN64-NEXT:    store i32 [[SHL]], ptr [[ATOMIC_TEMP14]], align 4, !dbg [[DBG28]]
// LIN64-NEXT:    [[TMP20:%.*]] = load i32, ptr [[ATOMIC_TEMP14]], align 4, !dbg [[DBG28]]
// LIN64-NEXT:    [[TMP21:%.*]] = cmpxchg ptr @ix, i32 [[TMP19]], i32 [[TMP20]] monotonic monotonic, align 4, !dbg [[DBG28]]
// LIN64-NEXT:    [[TMP22]] = extractvalue { i32, i1 } [[TMP21]], 0, !dbg [[DBG28]]
// LIN64-NEXT:    [[TMP23:%.*]] = extractvalue { i32, i1 } [[TMP21]], 1, !dbg [[DBG28]]
// LIN64-NEXT:    br i1 [[TMP23]], label [[ATOMIC_EXIT15:%.*]], label [[ATOMIC_CONT13]], !dbg [[DBG28]]
// LIN64:       atomic_exit15:
// LIN64-NEXT:    store i32 [[SHL]], ptr @uiv, align 4, !dbg [[DBG28]]
// LIN64-NEXT:    [[TMP24:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG30:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD16:%.*]] = load atomic i32, ptr @uix monotonic, align 4, !dbg [[DBG31:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT17:%.*]], !dbg [[DBG31]]
// LIN64:       atomic_cont17:
// LIN64-NEXT:    [[TMP25:%.*]] = phi i32 [ [[ATOMIC_LOAD16]], [[ATOMIC_EXIT15]] ], [ [[TMP28:%.*]], [[ATOMIC_CONT17]] ], !dbg [[DBG31]]
// LIN64-NEXT:    [[SHR:%.*]] = lshr i32 [[TMP25]], [[TMP24]], !dbg [[DBG32:![0-9]+]]
// LIN64-NEXT:    store i32 [[SHR]], ptr [[ATOMIC_TEMP18]], align 4, !dbg [[DBG31]]
// LIN64-NEXT:    [[TMP26:%.*]] = load i32, ptr [[ATOMIC_TEMP18]], align 4, !dbg [[DBG31]]
// LIN64-NEXT:    [[TMP27:%.*]] = cmpxchg ptr @uix, i32 [[TMP25]], i32 [[TMP26]] monotonic monotonic, align 4, !dbg [[DBG31]]
// LIN64-NEXT:    [[TMP28]] = extractvalue { i32, i1 } [[TMP27]], 0, !dbg [[DBG31]]
// LIN64-NEXT:    [[TMP29:%.*]] = extractvalue { i32, i1 } [[TMP27]], 1, !dbg [[DBG31]]
// LIN64-NEXT:    br i1 [[TMP29]], label [[ATOMIC_EXIT19:%.*]], label [[ATOMIC_CONT17]], !dbg [[DBG31]]
// LIN64:       atomic_exit19:
// LIN64-NEXT:    store i32 [[SHR]], ptr @iv, align 4, !dbg [[DBG31]]
// LIN64-NEXT:    [[TMP30:%.*]] = load i64, ptr @lv, align 8, !dbg [[DBG33:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD20:%.*]] = load atomic i64, ptr @lx monotonic, align 8, !dbg [[DBG34:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT21:%.*]], !dbg [[DBG34]]
// LIN64:       atomic_cont21:
// LIN64-NEXT:    [[TMP31:%.*]] = phi i64 [ [[ATOMIC_LOAD20]], [[ATOMIC_EXIT19]] ], [ [[TMP34:%.*]], [[ATOMIC_CONT21]] ], !dbg [[DBG34]]
// LIN64-NEXT:    [[DIV:%.*]] = sdiv i64 [[TMP31]], [[TMP30]], !dbg [[DBG35:![0-9]+]]
// LIN64-NEXT:    store i64 [[DIV]], ptr [[ATOMIC_TEMP22]], align 8, !dbg [[DBG34]]
// LIN64-NEXT:    [[TMP32:%.*]] = load i64, ptr [[ATOMIC_TEMP22]], align 8, !dbg [[DBG34]]
// LIN64-NEXT:    [[TMP33:%.*]] = cmpxchg ptr @lx, i64 [[TMP31]], i64 [[TMP32]] monotonic monotonic, align 8, !dbg [[DBG34]]
// LIN64-NEXT:    [[TMP34]] = extractvalue { i64, i1 } [[TMP33]], 0, !dbg [[DBG34]]
// LIN64-NEXT:    [[TMP35:%.*]] = extractvalue { i64, i1 } [[TMP33]], 1, !dbg [[DBG34]]
// LIN64-NEXT:    br i1 [[TMP35]], label [[ATOMIC_EXIT23:%.*]], label [[ATOMIC_CONT21]], !dbg [[DBG34]]
// LIN64:       atomic_exit23:
// LIN64-NEXT:    store i64 [[TMP31]], ptr @ulv, align 8, !dbg [[DBG34]]
// LIN64-NEXT:    [[TMP36:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG36:![0-9]+]]
// LIN64-NEXT:    [[TMP37:%.*]] = atomicrmw and ptr @ulx, i64 [[TMP36]] monotonic, align 8, !dbg [[DBG37:![0-9]+]]
// LIN64-NEXT:    [[AND:%.*]] = and i64 [[TMP37]], [[TMP36]], !dbg [[DBG38:![0-9]+]]
// LIN64-NEXT:    store i64 [[AND]], ptr @lv, align 8, !dbg [[DBG37]]
// LIN64-NEXT:    [[TMP38:%.*]] = load i64, ptr @llv, align 8, !dbg [[DBG39:![0-9]+]]
// LIN64-NEXT:    [[TMP39:%.*]] = atomicrmw xor ptr @llx, i64 [[TMP38]] monotonic, align 8, !dbg [[DBG40:![0-9]+]]
// LIN64-NEXT:    [[XOR:%.*]] = xor i64 [[TMP39]], [[TMP38]], !dbg [[DBG41:![0-9]+]]
// LIN64-NEXT:    store i64 [[XOR]], ptr @ullv, align 8, !dbg [[DBG40]]
// LIN64-NEXT:    [[TMP40:%.*]] = load i64, ptr @ullv, align 8, !dbg [[DBG42:![0-9]+]]
// LIN64-NEXT:    [[TMP41:%.*]] = atomicrmw or ptr @ullx, i64 [[TMP40]] monotonic, align 8, !dbg [[DBG43:![0-9]+]]
// LIN64-NEXT:    [[OR:%.*]] = or i64 [[TMP41]], [[TMP40]], !dbg [[DBG44:![0-9]+]]
// LIN64-NEXT:    store i64 [[OR]], ptr @llv, align 8, !dbg [[DBG43]]
// LIN64-NEXT:    [[TMP42:%.*]] = load float, ptr @fv, align 4, !dbg [[DBG45:![0-9]+]]
// LIN64-NEXT:    [[TMP43:%.*]] = atomicrmw fadd ptr @fx, float [[TMP42]] monotonic, align 4, !dbg [[DBG46:![0-9]+]]
// LIN64-NEXT:    [[ADD24:%.*]] = fadd float [[TMP43]], [[TMP42]], !dbg [[DBG47:![0-9]+]]
// LIN64-NEXT:    [[CONV25:%.*]] = fpext float [[ADD24]] to double, !dbg [[DBG46]]
// LIN64-NEXT:    store double [[CONV25]], ptr @dv, align 8, !dbg [[DBG46]]
// LIN64-NEXT:    [[TMP44:%.*]] = load double, ptr @dv, align 8, !dbg [[DBG48:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD26:%.*]] = load atomic i64, ptr @dx monotonic, align 8, !dbg [[DBG49:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT27:%.*]], !dbg [[DBG49]]
// LIN64:       atomic_cont27:
// LIN64-NEXT:    [[TMP45:%.*]] = phi i64 [ [[ATOMIC_LOAD26]], [[ATOMIC_EXIT23]] ], [ [[TMP49:%.*]], [[ATOMIC_CONT27]] ], !dbg [[DBG49]]
// LIN64-NEXT:    [[TMP46:%.*]] = bitcast i64 [[TMP45]] to double, !dbg [[DBG49]]
// LIN64-NEXT:    [[SUB29:%.*]] = fsub double [[TMP44]], [[TMP46]], !dbg [[DBG50:![0-9]+]]
// LIN64-NEXT:    store double [[SUB29]], ptr [[ATOMIC_TEMP28]], align 8, !dbg [[DBG49]]
// LIN64-NEXT:    [[TMP47:%.*]] = load i64, ptr [[ATOMIC_TEMP28]], align 8, !dbg [[DBG49]]
// LIN64-NEXT:    [[TMP48:%.*]] = cmpxchg ptr @dx, i64 [[TMP45]], i64 [[TMP47]] monotonic monotonic, align 8, !dbg [[DBG49]]
// LIN64-NEXT:    [[TMP49]] = extractvalue { i64, i1 } [[TMP48]], 0, !dbg [[DBG49]]
// LIN64-NEXT:    [[TMP50:%.*]] = extractvalue { i64, i1 } [[TMP48]], 1, !dbg [[DBG49]]
// LIN64-NEXT:    br i1 [[TMP50]], label [[ATOMIC_EXIT30:%.*]], label [[ATOMIC_CONT27]], !dbg [[DBG49]]
// LIN64:       atomic_exit30:
// LIN64-NEXT:    [[CONV31:%.*]] = fptrunc double [[TMP46]] to float, !dbg [[DBG49]]
// LIN64-NEXT:    store float [[CONV31]], ptr @fv, align 4, !dbg [[DBG49]]
// LIN64-NEXT:    [[TMP51:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG51:![0-9]+]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 16, ptr noundef @ldx, ptr noundef [[ATOMIC_TEMP32]], i32 noundef 0), !dbg [[DBG52:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT33:%.*]], !dbg [[DBG52]]
// LIN64:       atomic_cont33:
// LIN64-NEXT:    [[TMP52:%.*]] = load x86_fp80, ptr [[ATOMIC_TEMP32]], align 16, !dbg [[DBG52]]
// LIN64-NEXT:    store x86_fp80 [[TMP52]], ptr [[ATOMIC_TEMP34]], align 16, !dbg [[DBG52]]
// LIN64-NEXT:    [[TMP53:%.*]] = load x86_fp80, ptr [[ATOMIC_TEMP32]], align 16, !dbg [[DBG52]]
// LIN64-NEXT:    [[MUL35:%.*]] = fmul x86_fp80 [[TMP53]], [[TMP51]], !dbg [[DBG53:![0-9]+]]
// LIN64-NEXT:    store x86_fp80 [[MUL35]], ptr [[ATOMIC_TEMP34]], align 16, !dbg [[DBG52]]
// LIN64-NEXT:    [[CALL:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, ptr noundef @ldx, ptr noundef [[ATOMIC_TEMP32]], ptr noundef [[ATOMIC_TEMP34]], i32 noundef 0, i32 noundef 0), !dbg [[DBG52]]
// LIN64-NEXT:    br i1 [[CALL]], label [[ATOMIC_EXIT36:%.*]], label [[ATOMIC_CONT33]], !dbg [[DBG52]]
// LIN64:       atomic_exit36:
// LIN64-NEXT:    [[CONV37:%.*]] = fptrunc x86_fp80 [[MUL35]] to double, !dbg [[DBG52]]
// LIN64-NEXT:    store double [[CONV37]], ptr @dv, align 8, !dbg [[DBG52]]
// LIN64-NEXT:    [[CIV_REAL:%.*]] = load i32, ptr @civ, align 4, !dbg [[DBG54:![0-9]+]]
// LIN64-NEXT:    [[CIV_IMAG:%.*]] = load i32, ptr getelementptr inbounds nuw ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG54]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP38]], i32 noundef 0), !dbg [[DBG55:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT39:%.*]], !dbg [[DBG55]]
// LIN64:       atomic_cont39:
// LIN64-NEXT:    [[ATOMIC_TEMP38_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP38]], i32 0, i32 0, !dbg [[DBG55]]
// LIN64-NEXT:    [[ATOMIC_TEMP38_REAL:%.*]] = load i32, ptr [[ATOMIC_TEMP38_REALP]], align 4, !dbg [[DBG55]]
// LIN64-NEXT:    [[ATOMIC_TEMP38_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP38]], i32 0, i32 1, !dbg [[DBG55]]
// LIN64-NEXT:    [[ATOMIC_TEMP38_IMAG:%.*]] = load i32, ptr [[ATOMIC_TEMP38_IMAGP]], align 4, !dbg [[DBG55]]
// LIN64-NEXT:    [[TMP54:%.*]] = mul i32 [[CIV_REAL]], [[ATOMIC_TEMP38_REAL]], !dbg [[DBG56:![0-9]+]]
// LIN64-NEXT:    [[TMP55:%.*]] = mul i32 [[CIV_IMAG]], [[ATOMIC_TEMP38_IMAG]], !dbg [[DBG56]]
// LIN64-NEXT:    [[TMP56:%.*]] = add i32 [[TMP54]], [[TMP55]], !dbg [[DBG56]]
// LIN64-NEXT:    [[TMP57:%.*]] = mul i32 [[ATOMIC_TEMP38_REAL]], [[ATOMIC_TEMP38_REAL]], !dbg [[DBG56]]
// LIN64-NEXT:    [[TMP58:%.*]] = mul i32 [[ATOMIC_TEMP38_IMAG]], [[ATOMIC_TEMP38_IMAG]], !dbg [[DBG56]]
// LIN64-NEXT:    [[TMP59:%.*]] = add i32 [[TMP57]], [[TMP58]], !dbg [[DBG56]]
// LIN64-NEXT:    [[TMP60:%.*]] = mul i32 [[CIV_IMAG]], [[ATOMIC_TEMP38_REAL]], !dbg [[DBG56]]
// LIN64-NEXT:    [[TMP61:%.*]] = mul i32 [[CIV_REAL]], [[ATOMIC_TEMP38_IMAG]], !dbg [[DBG56]]
// LIN64-NEXT:    [[TMP62:%.*]] = sub i32 [[TMP60]], [[TMP61]], !dbg [[DBG56]]
// LIN64-NEXT:    [[TMP63:%.*]] = sdiv i32 [[TMP56]], [[TMP59]], !dbg [[DBG56]]
// LIN64-NEXT:    [[TMP64:%.*]] = sdiv i32 [[TMP62]], [[TMP59]], !dbg [[DBG56]]
// LIN64-NEXT:    [[ATOMIC_TEMP40_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP40]], i32 0, i32 0, !dbg [[DBG55]]
// LIN64-NEXT:    [[ATOMIC_TEMP40_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP40]], i32 0, i32 1, !dbg [[DBG55]]
// LIN64-NEXT:    store i32 [[TMP63]], ptr [[ATOMIC_TEMP40_REALP]], align 4, !dbg [[DBG55]]
// LIN64-NEXT:    store i32 [[TMP64]], ptr [[ATOMIC_TEMP40_IMAGP]], align 4, !dbg [[DBG55]]
// LIN64-NEXT:    [[CALL41:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP38]], ptr noundef [[ATOMIC_TEMP40]], i32 noundef 0, i32 noundef 0), !dbg [[DBG55]]
// LIN64-NEXT:    br i1 [[CALL41]], label [[ATOMIC_EXIT42:%.*]], label [[ATOMIC_CONT39]], !dbg [[DBG55]]
// LIN64:       atomic_exit42:
// LIN64-NEXT:    [[CONV43:%.*]] = sitofp i32 [[TMP63]] to float, !dbg [[DBG55]]
// LIN64-NEXT:    [[CONV44:%.*]] = sitofp i32 [[TMP64]] to float, !dbg [[DBG55]]
// LIN64-NEXT:    store float [[CONV43]], ptr @cfv, align 4, !dbg [[DBG55]]
// LIN64-NEXT:    store float [[CONV44]], ptr getelementptr inbounds nuw ({ float, float }, ptr @cfv, i32 0, i32 1), align 4, !dbg [[DBG55]]
// LIN64-NEXT:    [[CFV_REAL:%.*]] = load float, ptr @cfv, align 4, !dbg [[DBG57:![0-9]+]]
// LIN64-NEXT:    [[CFV_IMAG:%.*]] = load float, ptr getelementptr inbounds nuw ({ float, float }, ptr @cfv, i32 0, i32 1), align 4, !dbg [[DBG57]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cfx, ptr noundef [[ATOMIC_TEMP45]], i32 noundef 0), !dbg [[DBG58:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT46:%.*]], !dbg [[DBG58]]
// LIN64:       atomic_cont46:
// LIN64-NEXT:    [[ATOMIC_TEMP45_REALP:%.*]] = getelementptr inbounds nuw { float, float }, ptr [[ATOMIC_TEMP45]], i32 0, i32 0, !dbg [[DBG58]]
// LIN64-NEXT:    [[ATOMIC_TEMP45_REAL:%.*]] = load float, ptr [[ATOMIC_TEMP45_REALP]], align 4, !dbg [[DBG58]]
// LIN64-NEXT:    [[ATOMIC_TEMP45_IMAGP:%.*]] = getelementptr inbounds nuw { float, float }, ptr [[ATOMIC_TEMP45]], i32 0, i32 1, !dbg [[DBG58]]
// LIN64-NEXT:    [[ATOMIC_TEMP45_IMAG:%.*]] = load float, ptr [[ATOMIC_TEMP45_IMAGP]], align 4, !dbg [[DBG58]]
// LIN64-NEXT:    [[ADD_R:%.*]] = fadd float [[CFV_REAL]], [[ATOMIC_TEMP45_REAL]], !dbg [[DBG59:![0-9]+]]
// LIN64-NEXT:    [[ADD_I:%.*]] = fadd float [[CFV_IMAG]], [[ATOMIC_TEMP45_IMAG]], !dbg [[DBG59]]
// LIN64-NEXT:    [[ATOMIC_TEMP47_REALP:%.*]] = getelementptr inbounds nuw { float, float }, ptr [[ATOMIC_TEMP47]], i32 0, i32 0, !dbg [[DBG58]]
// LIN64-NEXT:    [[ATOMIC_TEMP47_IMAGP:%.*]] = getelementptr inbounds nuw { float, float }, ptr [[ATOMIC_TEMP47]], i32 0, i32 1, !dbg [[DBG58]]
// LIN64-NEXT:    store float [[ADD_R]], ptr [[ATOMIC_TEMP47_REALP]], align 4, !dbg [[DBG58]]
// LIN64-NEXT:    store float [[ADD_I]], ptr [[ATOMIC_TEMP47_IMAGP]], align 4, !dbg [[DBG58]]
// LIN64-NEXT:    [[CALL48:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cfx, ptr noundef [[ATOMIC_TEMP45]], ptr noundef [[ATOMIC_TEMP47]], i32 noundef 0, i32 noundef 0), !dbg [[DBG58]]
// LIN64-NEXT:    br i1 [[CALL48]], label [[ATOMIC_EXIT49:%.*]], label [[ATOMIC_CONT46]], !dbg [[DBG58]]
// LIN64:       atomic_exit49:
// LIN64-NEXT:    [[CONV50:%.*]] = fptosi float [[ATOMIC_TEMP45_REAL]] to i32, !dbg [[DBG58]]
// LIN64-NEXT:    [[CONV51:%.*]] = fptosi float [[ATOMIC_TEMP45_IMAG]] to i32, !dbg [[DBG58]]
// LIN64-NEXT:    store i32 [[CONV50]], ptr @civ, align 4, !dbg [[DBG58]]
// LIN64-NEXT:    store i32 [[CONV51]], ptr getelementptr inbounds nuw ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG58]]
// LIN64-NEXT:    [[CDV_REAL:%.*]] = load double, ptr @cdv, align 8, !dbg [[DBG60:![0-9]+]]
// LIN64-NEXT:    [[CDV_IMAG:%.*]] = load double, ptr getelementptr inbounds nuw ({ double, double }, ptr @cdv, i32 0, i32 1), align 8, !dbg [[DBG60]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 16, ptr noundef @cdx, ptr noundef [[ATOMIC_TEMP52]], i32 noundef 5), !dbg [[DBG61:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT53:%.*]], !dbg [[DBG61]]
// LIN64:       atomic_cont53:
// LIN64-NEXT:    [[ATOMIC_TEMP52_REALP:%.*]] = getelementptr inbounds nuw { double, double }, ptr [[ATOMIC_TEMP52]], i32 0, i32 0, !dbg [[DBG61]]
// LIN64-NEXT:    [[ATOMIC_TEMP52_REAL:%.*]] = load double, ptr [[ATOMIC_TEMP52_REALP]], align 8, !dbg [[DBG61]]
// LIN64-NEXT:    [[ATOMIC_TEMP52_IMAGP:%.*]] = getelementptr inbounds nuw { double, double }, ptr [[ATOMIC_TEMP52]], i32 0, i32 1, !dbg [[DBG61]]
// LIN64-NEXT:    [[ATOMIC_TEMP52_IMAG:%.*]] = load double, ptr [[ATOMIC_TEMP52_IMAGP]], align 8, !dbg [[DBG61]]
// LIN64-NEXT:    [[SUB_R:%.*]] = fsub double [[ATOMIC_TEMP52_REAL]], [[CDV_REAL]], !dbg [[DBG62:![0-9]+]]
// LIN64-NEXT:    [[SUB_I:%.*]] = fsub double [[ATOMIC_TEMP52_IMAG]], [[CDV_IMAG]], !dbg [[DBG62]]
// LIN64-NEXT:    [[ATOMIC_TEMP54_REALP:%.*]] = getelementptr inbounds nuw { double, double }, ptr [[ATOMIC_TEMP54]], i32 0, i32 0, !dbg [[DBG61]]
// LIN64-NEXT:    [[ATOMIC_TEMP54_IMAGP:%.*]] = getelementptr inbounds nuw { double, double }, ptr [[ATOMIC_TEMP54]], i32 0, i32 1, !dbg [[DBG61]]
// LIN64-NEXT:    store double [[SUB_R]], ptr [[ATOMIC_TEMP54_REALP]], align 8, !dbg [[DBG61]]
// LIN64-NEXT:    store double [[SUB_I]], ptr [[ATOMIC_TEMP54_IMAGP]], align 8, !dbg [[DBG61]]
// LIN64-NEXT:    [[CALL55:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, ptr noundef @cdx, ptr noundef [[ATOMIC_TEMP52]], ptr noundef [[ATOMIC_TEMP54]], i32 noundef 5, i32 noundef 5), !dbg [[DBG61]]
// LIN64-NEXT:    br i1 [[CALL55]], label [[ATOMIC_EXIT56:%.*]], label [[ATOMIC_CONT53]], !dbg [[DBG61]]
// LIN64:       atomic_exit56:
// LIN64-NEXT:    [[CONV57:%.*]] = fptrunc double [[SUB_R]] to float, !dbg [[DBG61]]
// LIN64-NEXT:    [[CONV58:%.*]] = fptrunc double [[SUB_I]] to float, !dbg [[DBG61]]
// LIN64-NEXT:    store float [[CONV57]], ptr @cfv, align 4, !dbg [[DBG61]]
// LIN64-NEXT:    store float [[CONV58]], ptr getelementptr inbounds nuw ({ float, float }, ptr @cfv, i32 0, i32 1), align 4, !dbg [[DBG61]]
// LIN64-NEXT:    [[TMP65:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG63:![0-9]+]]
// LIN64-NEXT:    [[LOADEDV:%.*]] = trunc i8 [[TMP65]] to i1, !dbg [[DBG63]]
// LIN64-NEXT:    [[CONV59:%.*]] = zext i1 [[LOADEDV]] to i64, !dbg [[DBG63]]
// LIN64-NEXT:    [[TMP66:%.*]] = atomicrmw and ptr @ulx, i64 [[CONV59]] monotonic, align 8, !dbg [[DBG64:![0-9]+]]
// LIN64-NEXT:    [[AND60:%.*]] = and i64 [[TMP66]], [[CONV59]], !dbg [[DBG65:![0-9]+]]
// LIN64-NEXT:    store i64 [[AND60]], ptr @ulv, align 8, !dbg [[DBG64]]
// LIN64-NEXT:    [[TMP67:%.*]] = load i8, ptr @cv, align 1, !dbg [[DBG66:![0-9]+]]
// LIN64-NEXT:    [[CONV61:%.*]] = sext i8 [[TMP67]] to i32, !dbg [[DBG66]]
// LIN64-NEXT:    [[ATOMIC_LOAD62:%.*]] = load atomic i8, ptr @bx monotonic, align 1, !dbg [[DBG67:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT63:%.*]], !dbg [[DBG67]]
// LIN64:       atomic_cont63:
// LIN64-NEXT:    [[TMP68:%.*]] = phi i8 [ [[ATOMIC_LOAD62]], [[ATOMIC_EXIT56]] ], [ [[TMP71:%.*]], [[ATOMIC_CONT63]] ], !dbg [[DBG67]]
// LIN64-NEXT:    [[LOADEDV65:%.*]] = trunc i8 [[TMP68]] to i1, !dbg [[DBG67]]
// LIN64-NEXT:    [[CONV66:%.*]] = zext i1 [[LOADEDV65]] to i32, !dbg [[DBG68:![0-9]+]]
// LIN64-NEXT:    [[AND67:%.*]] = and i32 [[CONV61]], [[CONV66]], !dbg [[DBG69:![0-9]+]]
// LIN64-NEXT:    [[TOBOOL:%.*]] = icmp ne i32 [[AND67]], 0, !dbg [[DBG66]]
// LIN64-NEXT:    [[STOREDV:%.*]] = zext i1 [[TOBOOL]] to i8, !dbg [[DBG67]]
// LIN64-NEXT:    store i8 [[STOREDV]], ptr [[ATOMIC_TEMP64]], align 1, !dbg [[DBG67]]
// LIN64-NEXT:    [[TMP69:%.*]] = load i8, ptr [[ATOMIC_TEMP64]], align 1, !dbg [[DBG67]]
// LIN64-NEXT:    [[TMP70:%.*]] = cmpxchg ptr @bx, i8 [[TMP68]], i8 [[TMP69]] monotonic monotonic, align 1, !dbg [[DBG67]]
// LIN64-NEXT:    [[TMP71]] = extractvalue { i8, i1 } [[TMP70]], 0, !dbg [[DBG67]]
// LIN64-NEXT:    [[TMP72:%.*]] = extractvalue { i8, i1 } [[TMP70]], 1, !dbg [[DBG67]]
// LIN64-NEXT:    br i1 [[TMP72]], label [[ATOMIC_EXIT68:%.*]], label [[ATOMIC_CONT63]], !dbg [[DBG67]]
// LIN64:       atomic_exit68:
// LIN64-NEXT:    [[STOREDV69:%.*]] = zext i1 [[LOADEDV65]] to i8, !dbg [[DBG67]]
// LIN64-NEXT:    store i8 [[STOREDV69]], ptr @bv, align 1, !dbg [[DBG67]]
// LIN64-NEXT:    [[TMP73:%.*]] = load i8, ptr @ucv, align 1, !dbg [[DBG70:![0-9]+]]
// LIN64-NEXT:    [[CONV70:%.*]] = zext i8 [[TMP73]] to i32, !dbg [[DBG70]]
// LIN64-NEXT:    [[ATOMIC_LOAD71:%.*]] = load atomic i8, ptr @cx seq_cst, align 1, !dbg [[DBG71:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT72:%.*]], !dbg [[DBG71]]
// LIN64:       atomic_cont72:
// LIN64-NEXT:    [[TMP74:%.*]] = phi i8 [ [[ATOMIC_LOAD71]], [[ATOMIC_EXIT68]] ], [ [[TMP77:%.*]], [[ATOMIC_CONT72]] ], !dbg [[DBG71]]
// LIN64-NEXT:    [[CONV74:%.*]] = sext i8 [[TMP74]] to i32, !dbg [[DBG72:![0-9]+]]
// LIN64-NEXT:    [[SHR75:%.*]] = ashr i32 [[CONV74]], [[CONV70]], !dbg [[DBG73:![0-9]+]]
// LIN64-NEXT:    [[CONV76:%.*]] = trunc i32 [[SHR75]] to i8, !dbg [[DBG72]]
// LIN64-NEXT:    store i8 [[CONV76]], ptr [[ATOMIC_TEMP73]], align 1, !dbg [[DBG71]]
// LIN64-NEXT:    [[TMP75:%.*]] = load i8, ptr [[ATOMIC_TEMP73]], align 1, !dbg [[DBG71]]
// LIN64-NEXT:    [[TMP76:%.*]] = cmpxchg ptr @cx, i8 [[TMP74]], i8 [[TMP75]] seq_cst seq_cst, align 1, !dbg [[DBG71]]
// LIN64-NEXT:    [[TMP77]] = extractvalue { i8, i1 } [[TMP76]], 0, !dbg [[DBG71]]
// LIN64-NEXT:    [[TMP78:%.*]] = extractvalue { i8, i1 } [[TMP76]], 1, !dbg [[DBG71]]
// LIN64-NEXT:    br i1 [[TMP78]], label [[ATOMIC_EXIT77:%.*]], label [[ATOMIC_CONT72]], !dbg [[DBG71]]
// LIN64:       atomic_exit77:
// LIN64-NEXT:    store i8 [[CONV76]], ptr @cv, align 1, !dbg [[DBG71]]
// LIN64-NEXT:    [[TMP79:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG74:![0-9]+]]
// LIN64-NEXT:    [[CONV78:%.*]] = sext i16 [[TMP79]] to i32, !dbg [[DBG74]]
// LIN64-NEXT:    [[ATOMIC_LOAD79:%.*]] = load atomic i64, ptr @ulx monotonic, align 8, !dbg [[DBG75:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT80:%.*]], !dbg [[DBG75]]
// LIN64:       atomic_cont80:
// LIN64-NEXT:    [[TMP80:%.*]] = phi i64 [ [[ATOMIC_LOAD79]], [[ATOMIC_EXIT77]] ], [ [[TMP83:%.*]], [[ATOMIC_CONT80]] ], !dbg [[DBG75]]
// LIN64-NEXT:    [[SH_PROM:%.*]] = trunc i64 [[TMP80]] to i32, !dbg [[DBG76:![0-9]+]]
// LIN64-NEXT:    [[SHL82:%.*]] = shl i32 [[CONV78]], [[SH_PROM]], !dbg [[DBG76]]
// LIN64-NEXT:    [[CONV83:%.*]] = sext i32 [[SHL82]] to i64, !dbg [[DBG74]]
// LIN64-NEXT:    store i64 [[CONV83]], ptr [[ATOMIC_TEMP81]], align 8, !dbg [[DBG75]]
// LIN64-NEXT:    [[TMP81:%.*]] = load i64, ptr [[ATOMIC_TEMP81]], align 8, !dbg [[DBG75]]
// LIN64-NEXT:    [[TMP82:%.*]] = cmpxchg ptr @ulx, i64 [[TMP80]], i64 [[TMP81]] monotonic monotonic, align 8, !dbg [[DBG75]]
// LIN64-NEXT:    [[TMP83]] = extractvalue { i64, i1 } [[TMP82]], 0, !dbg [[DBG75]]
// LIN64-NEXT:    [[TMP84:%.*]] = extractvalue { i64, i1 } [[TMP82]], 1, !dbg [[DBG75]]
// LIN64-NEXT:    br i1 [[TMP84]], label [[ATOMIC_EXIT84:%.*]], label [[ATOMIC_CONT80]], !dbg [[DBG75]]
// LIN64:       atomic_exit84:
// LIN64-NEXT:    store i64 [[CONV83]], ptr @ulv, align 8, !dbg [[DBG75]]
// LIN64-NEXT:    [[TMP85:%.*]] = load i16, ptr @usv, align 2, !dbg [[DBG77:![0-9]+]]
// LIN64-NEXT:    [[CONV85:%.*]] = zext i16 [[TMP85]] to i64, !dbg [[DBG77]]
// LIN64-NEXT:    [[ATOMIC_LOAD86:%.*]] = load atomic i64, ptr @lx monotonic, align 8, !dbg [[DBG78:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT87:%.*]], !dbg [[DBG78]]
// LIN64:       atomic_cont87:
// LIN64-NEXT:    [[TMP86:%.*]] = phi i64 [ [[ATOMIC_LOAD86]], [[ATOMIC_EXIT84]] ], [ [[TMP89:%.*]], [[ATOMIC_CONT87]] ], !dbg [[DBG78]]
// LIN64-NEXT:    [[REM:%.*]] = srem i64 [[TMP86]], [[CONV85]], !dbg [[DBG79:![0-9]+]]
// LIN64-NEXT:    store i64 [[REM]], ptr [[ATOMIC_TEMP88]], align 8, !dbg [[DBG78]]
// LIN64-NEXT:    [[TMP87:%.*]] = load i64, ptr [[ATOMIC_TEMP88]], align 8, !dbg [[DBG78]]
// LIN64-NEXT:    [[TMP88:%.*]] = cmpxchg ptr @lx, i64 [[TMP86]], i64 [[TMP87]] monotonic monotonic, align 8, !dbg [[DBG78]]
// LIN64-NEXT:    [[TMP89]] = extractvalue { i64, i1 } [[TMP88]], 0, !dbg [[DBG78]]
// LIN64-NEXT:    [[TMP90:%.*]] = extractvalue { i64, i1 } [[TMP88]], 1, !dbg [[DBG78]]
// LIN64-NEXT:    br i1 [[TMP90]], label [[ATOMIC_EXIT89:%.*]], label [[ATOMIC_CONT87]], !dbg [[DBG78]]
// LIN64:       atomic_exit89:
// LIN64-NEXT:    store i64 [[TMP86]], ptr @lv, align 8, !dbg [[DBG78]]
// LIN64-NEXT:    [[TMP91:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG80:![0-9]+]]
// LIN64-NEXT:    [[TMP92:%.*]] = atomicrmw or ptr @uix, i32 [[TMP91]] seq_cst, align 4, !dbg [[DBG81:![0-9]+]]
// LIN64-NEXT:    [[OR90:%.*]] = or i32 [[TMP91]], [[TMP92]], !dbg [[DBG82:![0-9]+]]
// LIN64-NEXT:    store i32 [[OR90]], ptr @uiv, align 4, !dbg [[DBG81]]
// LIN64-NEXT:    [[TMP93:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG83:![0-9]+]]
// LIN64-NEXT:    [[TMP94:%.*]] = atomicrmw and ptr @ix, i32 [[TMP93]] monotonic, align 4, !dbg [[DBG84:![0-9]+]]
// LIN64-NEXT:    [[AND91:%.*]] = and i32 [[TMP94]], [[TMP93]], !dbg [[DBG85:![0-9]+]]
// LIN64-NEXT:    store i32 [[AND91]], ptr @iv, align 4, !dbg [[DBG84]]
// LIN64-NEXT:    [[TMP95:%.*]] = load i64, ptr @lv, align 8, !dbg [[DBG86:![0-9]+]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP92]], i32 noundef 0), !dbg [[DBG87:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT93:%.*]], !dbg [[DBG87]]
// LIN64:       atomic_cont93:
// LIN64-NEXT:    [[ATOMIC_TEMP92_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP92]], i32 0, i32 0, !dbg [[DBG87]]
// LIN64-NEXT:    [[ATOMIC_TEMP92_REAL:%.*]] = load i32, ptr [[ATOMIC_TEMP92_REALP]], align 4, !dbg [[DBG87]]
// LIN64-NEXT:    [[ATOMIC_TEMP92_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP92]], i32 0, i32 1, !dbg [[DBG87]]
// LIN64-NEXT:    [[ATOMIC_TEMP92_IMAG:%.*]] = load i32, ptr [[ATOMIC_TEMP92_IMAGP]], align 4, !dbg [[DBG87]]
// LIN64-NEXT:    [[CONV95:%.*]] = sext i32 [[ATOMIC_TEMP92_REAL]] to i64, !dbg [[DBG88:![0-9]+]]
// LIN64-NEXT:    [[CONV96:%.*]] = sext i32 [[ATOMIC_TEMP92_IMAG]] to i64, !dbg [[DBG88]]
// LIN64-NEXT:    [[ADD_R97:%.*]] = add i64 [[TMP95]], [[CONV95]], !dbg [[DBG89:![0-9]+]]
// LIN64-NEXT:    [[ADD_I98:%.*]] = add i64 0, [[CONV96]], !dbg [[DBG89]]
// LIN64-NEXT:    [[CONV99:%.*]] = trunc i64 [[ADD_R97]] to i32, !dbg [[DBG86]]
// LIN64-NEXT:    [[CONV100:%.*]] = trunc i64 [[ADD_I98]] to i32, !dbg [[DBG86]]
// LIN64-NEXT:    [[ATOMIC_TEMP94_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP94]], i32 0, i32 0, !dbg [[DBG87]]
// LIN64-NEXT:    [[ATOMIC_TEMP94_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP94]], i32 0, i32 1, !dbg [[DBG87]]
// LIN64-NEXT:    store i32 [[CONV99]], ptr [[ATOMIC_TEMP94_REALP]], align 4, !dbg [[DBG87]]
// LIN64-NEXT:    store i32 [[CONV100]], ptr [[ATOMIC_TEMP94_IMAGP]], align 4, !dbg [[DBG87]]
// LIN64-NEXT:    [[CALL101:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP92]], ptr noundef [[ATOMIC_TEMP94]], i32 noundef 0, i32 noundef 0), !dbg [[DBG87]]
// LIN64-NEXT:    br i1 [[CALL101]], label [[ATOMIC_EXIT102:%.*]], label [[ATOMIC_CONT93]], !dbg [[DBG87]]
// LIN64:       atomic_exit102:
// LIN64-NEXT:    store i32 [[ATOMIC_TEMP92_REAL]], ptr @civ, align 4, !dbg [[DBG87]]
// LIN64-NEXT:    store i32 [[ATOMIC_TEMP92_IMAG]], ptr getelementptr inbounds nuw ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG87]]
// LIN64-NEXT:    [[TMP96:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG90:![0-9]+]]
// LIN64-NEXT:    [[CONV103:%.*]] = uitofp i64 [[TMP96]] to float, !dbg [[DBG90]]
// LIN64-NEXT:    [[ATOMIC_LOAD104:%.*]] = load atomic i32, ptr @fx monotonic, align 4, !dbg [[DBG91:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT105:%.*]], !dbg [[DBG91]]
// LIN64:       atomic_cont105:
// LIN64-NEXT:    [[TMP97:%.*]] = phi i32 [ [[ATOMIC_LOAD104]], [[ATOMIC_EXIT102]] ], [ [[TMP101:%.*]], [[ATOMIC_CONT105]] ], !dbg [[DBG91]]
// LIN64-NEXT:    [[TMP98:%.*]] = bitcast i32 [[TMP97]] to float, !dbg [[DBG91]]
// LIN64-NEXT:    [[MUL107:%.*]] = fmul float [[TMP98]], [[CONV103]], !dbg [[DBG92:![0-9]+]]
// LIN64-NEXT:    store float [[MUL107]], ptr [[ATOMIC_TEMP106]], align 4, !dbg [[DBG91]]
// LIN64-NEXT:    [[TMP99:%.*]] = load i32, ptr [[ATOMIC_TEMP106]], align 4, !dbg [[DBG91]]
// LIN64-NEXT:    [[TMP100:%.*]] = cmpxchg ptr @fx, i32 [[TMP97]], i32 [[TMP99]] monotonic monotonic, align 4, !dbg [[DBG91]]
// LIN64-NEXT:    [[TMP101]] = extractvalue { i32, i1 } [[TMP100]], 0, !dbg [[DBG91]]
// LIN64-NEXT:    [[TMP102:%.*]] = extractvalue { i32, i1 } [[TMP100]], 1, !dbg [[DBG91]]
// LIN64-NEXT:    br i1 [[TMP102]], label [[ATOMIC_EXIT108:%.*]], label [[ATOMIC_CONT105]], !dbg [[DBG91]]
// LIN64:       atomic_exit108:
// LIN64-NEXT:    store float [[MUL107]], ptr @fv, align 4, !dbg [[DBG91]]
// LIN64-NEXT:    [[TMP103:%.*]] = load i64, ptr @llv, align 8, !dbg [[DBG93:![0-9]+]]
// LIN64-NEXT:    [[CONV109:%.*]] = sitofp i64 [[TMP103]] to double, !dbg [[DBG93]]
// LIN64-NEXT:    [[ATOMIC_LOAD110:%.*]] = load atomic i64, ptr @dx monotonic, align 8, !dbg [[DBG94:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT111:%.*]], !dbg [[DBG94]]
// LIN64:       atomic_cont111:
// LIN64-NEXT:    [[TMP104:%.*]] = phi i64 [ [[ATOMIC_LOAD110]], [[ATOMIC_EXIT108]] ], [ [[TMP108:%.*]], [[ATOMIC_CONT111]] ], !dbg [[DBG94]]
// LIN64-NEXT:    [[TMP105:%.*]] = bitcast i64 [[TMP104]] to double, !dbg [[DBG94]]
// LIN64-NEXT:    [[DIV113:%.*]] = fdiv double [[TMP105]], [[CONV109]], !dbg [[DBG95:![0-9]+]]
// LIN64-NEXT:    store double [[DIV113]], ptr [[ATOMIC_TEMP112]], align 8, !dbg [[DBG94]]
// LIN64-NEXT:    [[TMP106:%.*]] = load i64, ptr [[ATOMIC_TEMP112]], align 8, !dbg [[DBG94]]
// LIN64-NEXT:    [[TMP107:%.*]] = cmpxchg ptr @dx, i64 [[TMP104]], i64 [[TMP106]] monotonic monotonic, align 8, !dbg [[DBG94]]
// LIN64-NEXT:    [[TMP108]] = extractvalue { i64, i1 } [[TMP107]], 0, !dbg [[DBG94]]
// LIN64-NEXT:    [[TMP109:%.*]] = extractvalue { i64, i1 } [[TMP107]], 1, !dbg [[DBG94]]
// LIN64-NEXT:    br i1 [[TMP109]], label [[ATOMIC_EXIT114:%.*]], label [[ATOMIC_CONT111]], !dbg [[DBG94]]
// LIN64:       atomic_exit114:
// LIN64-NEXT:    store double [[DIV113]], ptr @dv, align 8, !dbg [[DBG94]]
// LIN64-NEXT:    [[TMP110:%.*]] = load i64, ptr @ullv, align 8, !dbg [[DBG96:![0-9]+]]
// LIN64-NEXT:    [[CONV115:%.*]] = uitofp i64 [[TMP110]] to x86_fp80, !dbg [[DBG96]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 16, ptr noundef @ldx, ptr noundef [[ATOMIC_TEMP116]], i32 noundef 0), !dbg [[DBG97:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT117:%.*]], !dbg [[DBG97]]
// LIN64:       atomic_cont117:
// LIN64-NEXT:    [[TMP111:%.*]] = load x86_fp80, ptr [[ATOMIC_TEMP116]], align 16, !dbg [[DBG97]]
// LIN64-NEXT:    store x86_fp80 [[TMP111]], ptr [[ATOMIC_TEMP118]], align 16, !dbg [[DBG97]]
// LIN64-NEXT:    [[TMP112:%.*]] = load x86_fp80, ptr [[ATOMIC_TEMP116]], align 16, !dbg [[DBG97]]
// LIN64-NEXT:    [[SUB119:%.*]] = fsub x86_fp80 [[TMP112]], [[CONV115]], !dbg [[DBG98:![0-9]+]]
// LIN64-NEXT:    store x86_fp80 [[SUB119]], ptr [[ATOMIC_TEMP118]], align 16, !dbg [[DBG97]]
// LIN64-NEXT:    [[CALL120:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, ptr noundef @ldx, ptr noundef [[ATOMIC_TEMP116]], ptr noundef [[ATOMIC_TEMP118]], i32 noundef 0, i32 noundef 0), !dbg [[DBG97]]
// LIN64-NEXT:    br i1 [[CALL120]], label [[ATOMIC_EXIT121:%.*]], label [[ATOMIC_CONT117]], !dbg [[DBG97]]
// LIN64:       atomic_exit121:
// LIN64-NEXT:    store x86_fp80 [[TMP112]], ptr @ldv, align 16, !dbg [[DBG97]]
// LIN64-NEXT:    [[TMP113:%.*]] = load float, ptr @fv, align 4, !dbg [[DBG99:![0-9]+]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP122]], i32 noundef 0), !dbg [[DBG100:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT123:%.*]], !dbg [[DBG100]]
// LIN64:       atomic_cont123:
// LIN64-NEXT:    [[ATOMIC_TEMP122_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP122]], i32 0, i32 0, !dbg [[DBG100]]
// LIN64-NEXT:    [[ATOMIC_TEMP122_REAL:%.*]] = load i32, ptr [[ATOMIC_TEMP122_REALP]], align 4, !dbg [[DBG100]]
// LIN64-NEXT:    [[ATOMIC_TEMP122_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP122]], i32 0, i32 1, !dbg [[DBG100]]
// LIN64-NEXT:    [[ATOMIC_TEMP122_IMAG:%.*]] = load i32, ptr [[ATOMIC_TEMP122_IMAGP]], align 4, !dbg [[DBG100]]
// LIN64-NEXT:    [[CONV125:%.*]] = sitofp i32 [[ATOMIC_TEMP122_REAL]] to float, !dbg [[DBG101:![0-9]+]]
// LIN64-NEXT:    [[CONV126:%.*]] = sitofp i32 [[ATOMIC_TEMP122_IMAG]] to float, !dbg [[DBG101]]
// LIN64-NEXT:    [[CALL127:%.*]] = call <2 x float> @__divsc3(float noundef [[TMP113]], float noundef 0.000000e+00, float noundef [[CONV125]], float noundef [[CONV126]]) #[[ATTR4:[0-9]+]], !dbg [[DBG102:![0-9]+]]
// LIN64-NEXT:    store <2 x float> [[CALL127]], ptr [[COERCE]], align 4, !dbg [[DBG102]]
// LIN64-NEXT:    [[COERCE_REALP:%.*]] = getelementptr inbounds nuw { float, float }, ptr [[COERCE]], i32 0, i32 0, !dbg [[DBG102]]
// LIN64-NEXT:    [[COERCE_REAL:%.*]] = load float, ptr [[COERCE_REALP]], align 4, !dbg [[DBG102]]
// LIN64-NEXT:    [[COERCE_IMAGP:%.*]] = getelementptr inbounds nuw { float, float }, ptr [[COERCE]], i32 0, i32 1, !dbg [[DBG102]]
// LIN64-NEXT:    [[COERCE_IMAG:%.*]] = load float, ptr [[COERCE_IMAGP]], align 4, !dbg [[DBG102]]
// LIN64-NEXT:    [[CONV128:%.*]] = fptosi float [[COERCE_REAL]] to i32, !dbg [[DBG99]]
// LIN64-NEXT:    [[CONV129:%.*]] = fptosi float [[COERCE_IMAG]] to i32, !dbg [[DBG99]]
// LIN64-NEXT:    [[ATOMIC_TEMP124_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP124]], i32 0, i32 0, !dbg [[DBG100]]
// LIN64-NEXT:    [[ATOMIC_TEMP124_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP124]], i32 0, i32 1, !dbg [[DBG100]]
// LIN64-NEXT:    store i32 [[CONV128]], ptr [[ATOMIC_TEMP124_REALP]], align 4, !dbg [[DBG100]]
// LIN64-NEXT:    store i32 [[CONV129]], ptr [[ATOMIC_TEMP124_IMAGP]], align 4, !dbg [[DBG100]]
// LIN64-NEXT:    [[CALL130:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP122]], ptr noundef [[ATOMIC_TEMP124]], i32 noundef 0, i32 noundef 0), !dbg [[DBG100]]
// LIN64-NEXT:    br i1 [[CALL130]], label [[ATOMIC_EXIT131:%.*]], label [[ATOMIC_CONT123]], !dbg [[DBG100]]
// LIN64:       atomic_exit131:
// LIN64-NEXT:    store i32 [[CONV128]], ptr @civ, align 4, !dbg [[DBG100]]
// LIN64-NEXT:    store i32 [[CONV129]], ptr getelementptr inbounds nuw ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG100]]
// LIN64-NEXT:    [[TMP114:%.*]] = load double, ptr @dv, align 8, !dbg [[DBG103:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD132:%.*]] = load atomic i16, ptr @sx monotonic, align 2, !dbg [[DBG104:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT133:%.*]], !dbg [[DBG104]]
// LIN64:       atomic_cont133:
// LIN64-NEXT:    [[TMP115:%.*]] = phi i16 [ [[ATOMIC_LOAD132]], [[ATOMIC_EXIT131]] ], [ [[TMP118:%.*]], [[ATOMIC_CONT133]] ], !dbg [[DBG104]]
// LIN64-NEXT:    [[CONV135:%.*]] = sext i16 [[TMP115]] to i32, !dbg [[DBG105:![0-9]+]]
// LIN64-NEXT:    [[CONV136:%.*]] = sitofp i32 [[CONV135]] to double, !dbg [[DBG105]]
// LIN64-NEXT:    [[ADD137:%.*]] = fadd double [[CONV136]], [[TMP114]], !dbg [[DBG106:![0-9]+]]
// LIN64-NEXT:    [[CONV138:%.*]] = fptosi double [[ADD137]] to i16, !dbg [[DBG105]]
// LIN64-NEXT:    store i16 [[CONV138]], ptr [[ATOMIC_TEMP134]], align 2, !dbg [[DBG104]]
// LIN64-NEXT:    [[TMP116:%.*]] = load i16, ptr [[ATOMIC_TEMP134]], align 2, !dbg [[DBG104]]
// LIN64-NEXT:    [[TMP117:%.*]] = cmpxchg ptr @sx, i16 [[TMP115]], i16 [[TMP116]] monotonic monotonic, align 2, !dbg [[DBG104]]
// LIN64-NEXT:    [[TMP118]] = extractvalue { i16, i1 } [[TMP117]], 0, !dbg [[DBG104]]
// LIN64-NEXT:    [[TMP119:%.*]] = extractvalue { i16, i1 } [[TMP117]], 1, !dbg [[DBG104]]
// LIN64-NEXT:    br i1 [[TMP119]], label [[ATOMIC_EXIT139:%.*]], label [[ATOMIC_CONT133]], !dbg [[DBG104]]
// LIN64:       atomic_exit139:
// LIN64-NEXT:    store i16 [[CONV138]], ptr @sv, align 2, !dbg [[DBG104]]
// LIN64-NEXT:    [[TMP120:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG107:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD140:%.*]] = load atomic i8, ptr @bx monotonic, align 1, !dbg [[DBG108:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT141:%.*]], !dbg [[DBG108]]
// LIN64:       atomic_cont141:
// LIN64-NEXT:    [[TMP121:%.*]] = phi i8 [ [[ATOMIC_LOAD140]], [[ATOMIC_EXIT139]] ], [ [[TMP124:%.*]], [[ATOMIC_CONT141]] ], !dbg [[DBG108]]
// LIN64-NEXT:    [[LOADEDV143:%.*]] = trunc i8 [[TMP121]] to i1, !dbg [[DBG108]]
// LIN64-NEXT:    [[CONV144:%.*]] = zext i1 [[LOADEDV143]] to i32, !dbg [[DBG109:![0-9]+]]
// LIN64-NEXT:    [[CONV145:%.*]] = sitofp i32 [[CONV144]] to x86_fp80, !dbg [[DBG109]]
// LIN64-NEXT:    [[MUL146:%.*]] = fmul x86_fp80 [[TMP120]], [[CONV145]], !dbg [[DBG110:![0-9]+]]
// LIN64-NEXT:    [[TOBOOL147:%.*]] = fcmp une x86_fp80 [[MUL146]], 0xK00000000000000000000, !dbg [[DBG107]]
// LIN64-NEXT:    [[STOREDV148:%.*]] = zext i1 [[TOBOOL147]] to i8, !dbg [[DBG108]]
// LIN64-NEXT:    store i8 [[STOREDV148]], ptr [[ATOMIC_TEMP142]], align 1, !dbg [[DBG108]]
// LIN64-NEXT:    [[TMP122:%.*]] = load i8, ptr [[ATOMIC_TEMP142]], align 1, !dbg [[DBG108]]
// LIN64-NEXT:    [[TMP123:%.*]] = cmpxchg ptr @bx, i8 [[TMP121]], i8 [[TMP122]] monotonic monotonic, align 1, !dbg [[DBG108]]
// LIN64-NEXT:    [[TMP124]] = extractvalue { i8, i1 } [[TMP123]], 0, !dbg [[DBG108]]
// LIN64-NEXT:    [[TMP125:%.*]] = extractvalue { i8, i1 } [[TMP123]], 1, !dbg [[DBG108]]
// LIN64-NEXT:    br i1 [[TMP125]], label [[ATOMIC_EXIT149:%.*]], label [[ATOMIC_CONT141]], !dbg [[DBG108]]
// LIN64:       atomic_exit149:
// LIN64-NEXT:    [[STOREDV150:%.*]] = zext i1 [[LOADEDV143]] to i8, !dbg [[DBG108]]
// LIN64-NEXT:    store i8 [[STOREDV150]], ptr @bv, align 1, !dbg [[DBG108]]
// LIN64-NEXT:    [[CIV_REAL151:%.*]] = load i32, ptr @civ, align 4, !dbg [[DBG111:![0-9]+]]
// LIN64-NEXT:    [[CIV_IMAG152:%.*]] = load i32, ptr getelementptr inbounds nuw ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG111]]
// LIN64-NEXT:    [[ATOMIC_LOAD153:%.*]] = load atomic i8, ptr @bx monotonic, align 1, !dbg [[DBG112:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT154:%.*]], !dbg [[DBG112]]
// LIN64:       atomic_cont154:
// LIN64-NEXT:    [[TMP126:%.*]] = phi i8 [ [[ATOMIC_LOAD153]], [[ATOMIC_EXIT149]] ], [ [[TMP129:%.*]], [[ATOMIC_CONT154]] ], !dbg [[DBG112]]
// LIN64-NEXT:    [[LOADEDV156:%.*]] = trunc i8 [[TMP126]] to i1, !dbg [[DBG112]]
// LIN64-NEXT:    [[CONV157:%.*]] = zext i1 [[LOADEDV156]] to i32, !dbg [[DBG113:![0-9]+]]
// LIN64-NEXT:    [[SUB_R158:%.*]] = sub i32 [[CIV_REAL151]], [[CONV157]], !dbg [[DBG114:![0-9]+]]
// LIN64-NEXT:    [[SUB_I159:%.*]] = sub i32 [[CIV_IMAG152]], 0, !dbg [[DBG114]]
// LIN64-NEXT:    [[TOBOOL160:%.*]] = icmp ne i32 [[SUB_R158]], 0, !dbg [[DBG111]]
// LIN64-NEXT:    [[TOBOOL161:%.*]] = icmp ne i32 [[SUB_I159]], 0, !dbg [[DBG111]]
// LIN64-NEXT:    [[TOBOOL162:%.*]] = or i1 [[TOBOOL160]], [[TOBOOL161]], !dbg [[DBG111]]
// LIN64-NEXT:    [[STOREDV163:%.*]] = zext i1 [[TOBOOL162]] to i8, !dbg [[DBG112]]
// LIN64-NEXT:    store i8 [[STOREDV163]], ptr [[ATOMIC_TEMP155]], align 1, !dbg [[DBG112]]
// LIN64-NEXT:    [[TMP127:%.*]] = load i8, ptr [[ATOMIC_TEMP155]], align 1, !dbg [[DBG112]]
// LIN64-NEXT:    [[TMP128:%.*]] = cmpxchg ptr @bx, i8 [[TMP126]], i8 [[TMP127]] monotonic monotonic, align 1, !dbg [[DBG112]]
// LIN64-NEXT:    [[TMP129]] = extractvalue { i8, i1 } [[TMP128]], 0, !dbg [[DBG112]]
// LIN64-NEXT:    [[TMP130:%.*]] = extractvalue { i8, i1 } [[TMP128]], 1, !dbg [[DBG112]]
// LIN64-NEXT:    br i1 [[TMP130]], label [[ATOMIC_EXIT164:%.*]], label [[ATOMIC_CONT154]], !dbg [[DBG112]]
// LIN64:       atomic_exit164:
// LIN64-NEXT:    [[STOREDV165:%.*]] = zext i1 [[TOBOOL162]] to i8, !dbg [[DBG112]]
// LIN64-NEXT:    store i8 [[STOREDV165]], ptr @bv, align 1, !dbg [[DBG112]]
// LIN64-NEXT:    [[TMP131:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG115:![0-9]+]]
// LIN64-NEXT:    [[TMP132:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG116:![0-9]+]]
// LIN64-NEXT:    [[LOADEDV166:%.*]] = trunc i8 [[TMP132]] to i1, !dbg [[DBG116]]
// LIN64-NEXT:    [[CONV167:%.*]] = zext i1 [[LOADEDV166]] to i32, !dbg [[DBG116]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 16, ptr noundef @int4x, ptr noundef [[ATOMIC_TEMP168]], i32 noundef 0), !dbg [[DBG117:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT169:%.*]], !dbg [[DBG117]]
// LIN64:       atomic_cont169:
// LIN64-NEXT:    [[TMP133:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP168]], align 16, !dbg [[DBG117]]
// LIN64-NEXT:    store <4 x i32> [[TMP133]], ptr [[ATOMIC_TEMP170]], align 16, !dbg [[DBG117]]
// LIN64-NEXT:    [[TMP134:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP168]], align 16, !dbg [[DBG117]]
// LIN64-NEXT:    store <4 x i32> [[TMP134]], ptr [[ATOMIC_TEMP171]], align 16, !dbg [[DBG117]]
// LIN64-NEXT:    [[TMP135:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP171]], align 16, !dbg [[DBG117]]
// LIN64-NEXT:    [[VECEXT:%.*]] = extractelement <4 x i32> [[TMP135]], i16 [[TMP131]], !dbg [[DBG117]]
// LIN64-NEXT:    [[OR172:%.*]] = or i32 [[VECEXT]], [[CONV167]], !dbg [[DBG118:![0-9]+]]
// LIN64-NEXT:    [[TMP136:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP170]], align 16, !dbg [[DBG117]]
// LIN64-NEXT:    [[VECINS:%.*]] = insertelement <4 x i32> [[TMP136]], i32 [[OR172]], i16 [[TMP131]], !dbg [[DBG117]]
// LIN64-NEXT:    store <4 x i32> [[VECINS]], ptr [[ATOMIC_TEMP170]], align 16, !dbg [[DBG117]]
// LIN64-NEXT:    [[CALL173:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, ptr noundef @int4x, ptr noundef [[ATOMIC_TEMP168]], ptr noundef [[ATOMIC_TEMP170]], i32 noundef 0, i32 noundef 0), !dbg [[DBG117]]
// LIN64-NEXT:    br i1 [[CALL173]], label [[ATOMIC_EXIT174:%.*]], label [[ATOMIC_CONT169]], !dbg [[DBG117]]
// LIN64:       atomic_exit174:
// LIN64-NEXT:    store i32 [[OR172]], ptr @iv, align 4, !dbg [[DBG117]]
// LIN64-NEXT:    [[TMP137:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG119:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD175:%.*]] = load atomic i32, ptr getelementptr (i8, ptr @bfx, i64 4) monotonic, align 4, !dbg [[DBG120:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT176:%.*]], !dbg [[DBG120]]
// LIN64:       atomic_cont176:
// LIN64-NEXT:    [[TMP138:%.*]] = phi i32 [ [[ATOMIC_LOAD175]], [[ATOMIC_EXIT174]] ], [ [[TMP141:%.*]], [[ATOMIC_CONT176]] ], !dbg [[DBG120]]
// LIN64-NEXT:    store i32 [[TMP138]], ptr [[ATOMIC_TEMP177]], align 4, !dbg [[DBG120]]
// LIN64-NEXT:    store i32 [[TMP138]], ptr [[ATOMIC_TEMP178]], align 4, !dbg [[DBG120]]
// LIN64-NEXT:    [[BF_LOAD:%.*]] = load i32, ptr [[ATOMIC_TEMP178]], align 4, !dbg [[DBG120]]
// LIN64-NEXT:    [[BF_SHL:%.*]] = shl i32 [[BF_LOAD]], 1, !dbg [[DBG120]]
// LIN64-NEXT:    [[BF_ASHR:%.*]] = ashr i32 [[BF_SHL]], 1, !dbg [[DBG120]]
// LIN64-NEXT:    [[CONV179:%.*]] = sitofp i32 [[BF_ASHR]] to x86_fp80, !dbg [[DBG121:![0-9]+]]
// LIN64-NEXT:    [[SUB180:%.*]] = fsub x86_fp80 [[CONV179]], [[TMP137]], !dbg [[DBG122:![0-9]+]]
// LIN64-NEXT:    [[CONV181:%.*]] = fptosi x86_fp80 [[SUB180]] to i32, !dbg [[DBG121]]
// LIN64-NEXT:    [[BF_LOAD182:%.*]] = load i32, ptr [[ATOMIC_TEMP177]], align 4, !dbg [[DBG120]]
// LIN64-NEXT:    [[BF_VALUE:%.*]] = and i32 [[CONV181]], 2147483647, !dbg [[DBG120]]
// LIN64-NEXT:    [[BF_CLEAR:%.*]] = and i32 [[BF_LOAD182]], -2147483648, !dbg [[DBG120]]
// LIN64-NEXT:    [[BF_SET:%.*]] = or i32 [[BF_CLEAR]], [[BF_VALUE]], !dbg [[DBG120]]
// LIN64-NEXT:    store i32 [[BF_SET]], ptr [[ATOMIC_TEMP177]], align 4, !dbg [[DBG120]]
// LIN64-NEXT:    [[TMP139:%.*]] = load i32, ptr [[ATOMIC_TEMP177]], align 4, !dbg [[DBG120]]
// LIN64-NEXT:    [[TMP140:%.*]] = cmpxchg ptr getelementptr (i8, ptr @bfx, i64 4), i32 [[TMP138]], i32 [[TMP139]] monotonic monotonic, align 4, !dbg [[DBG120]]
// LIN64-NEXT:    [[TMP141]] = extractvalue { i32, i1 } [[TMP140]], 0, !dbg [[DBG120]]
// LIN64-NEXT:    [[TMP142:%.*]] = extractvalue { i32, i1 } [[TMP140]], 1, !dbg [[DBG120]]
// LIN64-NEXT:    br i1 [[TMP142]], label [[ATOMIC_EXIT183:%.*]], label [[ATOMIC_CONT176]], !dbg [[DBG120]]
// LIN64:       atomic_exit183:
// LIN64-NEXT:    store i32 [[CONV181]], ptr @iv, align 4, !dbg [[DBG120]]
// LIN64-NEXT:    [[TMP143:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG123:![0-9]+]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 4, ptr noundef getelementptr (i8, ptr @bfx_packed, i64 4), ptr noundef [[ATOMIC_TEMP184]], i32 noundef 0), !dbg [[DBG124:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT185:%.*]], !dbg [[DBG124]]
// LIN64:       atomic_cont185:
// LIN64-NEXT:    [[TMP144:%.*]] = load i32, ptr [[ATOMIC_TEMP184]], align 1, !dbg [[DBG124]]
// LIN64-NEXT:    store i32 [[TMP144]], ptr [[ATOMIC_TEMP186]], align 1, !dbg [[DBG124]]
// LIN64-NEXT:    [[TMP145:%.*]] = load i32, ptr [[ATOMIC_TEMP184]], align 1, !dbg [[DBG124]]
// LIN64-NEXT:    store i32 [[TMP145]], ptr [[ATOMIC_TEMP187]], align 4, !dbg [[DBG124]]
// LIN64-NEXT:    [[BF_LOAD188:%.*]] = load i32, ptr [[ATOMIC_TEMP187]], align 1, !dbg [[DBG124]]
// LIN64-NEXT:    [[BF_SHL189:%.*]] = shl i32 [[BF_LOAD188]], 1, !dbg [[DBG124]]
// LIN64-NEXT:    [[BF_ASHR190:%.*]] = ashr i32 [[BF_SHL189]], 1, !dbg [[DBG124]]
// LIN64-NEXT:    [[CONV191:%.*]] = sitofp i32 [[BF_ASHR190]] to x86_fp80, !dbg [[DBG125:![0-9]+]]
// LIN64-NEXT:    [[MUL192:%.*]] = fmul x86_fp80 [[CONV191]], [[TMP143]], !dbg [[DBG126:![0-9]+]]
// LIN64-NEXT:    [[CONV193:%.*]] = fptosi x86_fp80 [[MUL192]] to i32, !dbg [[DBG125]]
// LIN64-NEXT:    [[BF_LOAD194:%.*]] = load i32, ptr [[ATOMIC_TEMP186]], align 1, !dbg [[DBG124]]
// LIN64-NEXT:    [[BF_VALUE195:%.*]] = and i32 [[CONV193]], 2147483647, !dbg [[DBG124]]
// LIN64-NEXT:    [[BF_CLEAR196:%.*]] = and i32 [[BF_LOAD194]], -2147483648, !dbg [[DBG124]]
// LIN64-NEXT:    [[BF_SET197:%.*]] = or i32 [[BF_CLEAR196]], [[BF_VALUE195]], !dbg [[DBG124]]
// LIN64-NEXT:    store i32 [[BF_SET197]], ptr [[ATOMIC_TEMP186]], align 1, !dbg [[DBG124]]
// LIN64-NEXT:    [[CALL198:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 4, ptr noundef getelementptr (i8, ptr @bfx_packed, i64 4), ptr noundef [[ATOMIC_TEMP184]], ptr noundef [[ATOMIC_TEMP186]], i32 noundef 0, i32 noundef 0), !dbg [[DBG124]]
// LIN64-NEXT:    br i1 [[CALL198]], label [[ATOMIC_EXIT199:%.*]], label [[ATOMIC_CONT185]], !dbg [[DBG124]]
// LIN64:       atomic_exit199:
// LIN64-NEXT:    store i32 [[BF_ASHR190]], ptr @iv, align 4, !dbg [[DBG124]]
// LIN64-NEXT:    [[TMP146:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG127:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD200:%.*]] = load atomic i32, ptr @bfx2 monotonic, align 4, !dbg [[DBG128:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT201:%.*]], !dbg [[DBG128]]
// LIN64:       atomic_cont201:
// LIN64-NEXT:    [[TMP147:%.*]] = phi i32 [ [[ATOMIC_LOAD200]], [[ATOMIC_EXIT199]] ], [ [[TMP150:%.*]], [[ATOMIC_CONT201]] ], !dbg [[DBG128]]
// LIN64-NEXT:    store i32 [[TMP147]], ptr [[ATOMIC_TEMP202]], align 4, !dbg [[DBG128]]
// LIN64-NEXT:    store i32 [[TMP147]], ptr [[ATOMIC_TEMP203]], align 4, !dbg [[DBG128]]
// LIN64-NEXT:    [[BF_LOAD204:%.*]] = load i32, ptr [[ATOMIC_TEMP203]], align 4, !dbg [[DBG128]]
// LIN64-NEXT:    [[BF_ASHR205:%.*]] = ashr i32 [[BF_LOAD204]], 31, !dbg [[DBG128]]
// LIN64-NEXT:    [[CONV206:%.*]] = sitofp i32 [[BF_ASHR205]] to x86_fp80, !dbg [[DBG129:![0-9]+]]
// LIN64-NEXT:    [[SUB207:%.*]] = fsub x86_fp80 [[CONV206]], [[TMP146]], !dbg [[DBG130:![0-9]+]]
// LIN64-NEXT:    [[CONV208:%.*]] = fptosi x86_fp80 [[SUB207]] to i32, !dbg [[DBG129]]
// LIN64-NEXT:    [[BF_LOAD209:%.*]] = load i32, ptr [[ATOMIC_TEMP202]], align 4, !dbg [[DBG128]]
// LIN64-NEXT:    [[BF_VALUE210:%.*]] = and i32 [[CONV208]], 1, !dbg [[DBG128]]
// LIN64-NEXT:    [[BF_SHL211:%.*]] = shl i32 [[BF_VALUE210]], 31, !dbg [[DBG128]]
// LIN64-NEXT:    [[BF_CLEAR212:%.*]] = and i32 [[BF_LOAD209]], 2147483647, !dbg [[DBG128]]
// LIN64-NEXT:    [[BF_SET213:%.*]] = or i32 [[BF_CLEAR212]], [[BF_SHL211]], !dbg [[DBG128]]
// LIN64-NEXT:    store i32 [[BF_SET213]], ptr [[ATOMIC_TEMP202]], align 4, !dbg [[DBG128]]
// LIN64-NEXT:    [[TMP148:%.*]] = load i32, ptr [[ATOMIC_TEMP202]], align 4, !dbg [[DBG128]]
// LIN64-NEXT:    [[TMP149:%.*]] = cmpxchg ptr @bfx2, i32 [[TMP147]], i32 [[TMP148]] monotonic monotonic, align 4, !dbg [[DBG128]]
// LIN64-NEXT:    [[TMP150]] = extractvalue { i32, i1 } [[TMP149]], 0, !dbg [[DBG128]]
// LIN64-NEXT:    [[TMP151:%.*]] = extractvalue { i32, i1 } [[TMP149]], 1, !dbg [[DBG128]]
// LIN64-NEXT:    br i1 [[TMP151]], label [[ATOMIC_EXIT214:%.*]], label [[ATOMIC_CONT201]], !dbg [[DBG128]]
// LIN64:       atomic_exit214:
// LIN64-NEXT:    store i32 [[CONV208]], ptr @iv, align 4, !dbg [[DBG128]]
// LIN64-NEXT:    [[TMP152:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG131:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD215:%.*]] = load atomic i8, ptr getelementptr (i8, ptr @bfx2_packed, i64 3) monotonic, align 1, !dbg [[DBG132:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT216:%.*]], !dbg [[DBG132]]
// LIN64:       atomic_cont216:
// LIN64-NEXT:    [[TMP153:%.*]] = phi i8 [ [[ATOMIC_LOAD215]], [[ATOMIC_EXIT214]] ], [ [[TMP157:%.*]], [[ATOMIC_CONT216]] ], !dbg [[DBG132]]
// LIN64-NEXT:    store i8 [[TMP153]], ptr [[ATOMIC_TEMP217]], align 1, !dbg [[DBG132]]
// LIN64-NEXT:    store i8 [[TMP153]], ptr [[ATOMIC_TEMP218]], align 1, !dbg [[DBG132]]
// LIN64-NEXT:    [[BF_LOAD219:%.*]] = load i8, ptr [[ATOMIC_TEMP218]], align 1, !dbg [[DBG132]]
// LIN64-NEXT:    [[BF_ASHR220:%.*]] = ashr i8 [[BF_LOAD219]], 7, !dbg [[DBG132]]
// LIN64-NEXT:    [[BF_CAST:%.*]] = sext i8 [[BF_ASHR220]] to i32, !dbg [[DBG132]]
// LIN64-NEXT:    [[CONV221:%.*]] = sitofp i32 [[BF_CAST]] to x86_fp80, !dbg [[DBG133:![0-9]+]]
// LIN64-NEXT:    [[DIV222:%.*]] = fdiv x86_fp80 [[TMP152]], [[CONV221]], !dbg [[DBG134:![0-9]+]]
// LIN64-NEXT:    [[CONV223:%.*]] = fptosi x86_fp80 [[DIV222]] to i32, !dbg [[DBG131]]
// LIN64-NEXT:    [[TMP154:%.*]] = trunc i32 [[CONV223]] to i8, !dbg [[DBG132]]
// LIN64-NEXT:    [[BF_LOAD224:%.*]] = load i8, ptr [[ATOMIC_TEMP217]], align 1, !dbg [[DBG132]]
// LIN64-NEXT:    [[BF_VALUE225:%.*]] = and i8 [[TMP154]], 1, !dbg [[DBG132]]
// LIN64-NEXT:    [[BF_SHL226:%.*]] = shl i8 [[BF_VALUE225]], 7, !dbg [[DBG132]]
// LIN64-NEXT:    [[BF_CLEAR227:%.*]] = and i8 [[BF_LOAD224]], 127, !dbg [[DBG132]]
// LIN64-NEXT:    [[BF_SET228:%.*]] = or i8 [[BF_CLEAR227]], [[BF_SHL226]], !dbg [[DBG132]]
// LIN64-NEXT:    store i8 [[BF_SET228]], ptr [[ATOMIC_TEMP217]], align 1, !dbg [[DBG132]]
// LIN64-NEXT:    [[TMP155:%.*]] = load i8, ptr [[ATOMIC_TEMP217]], align 1, !dbg [[DBG132]]
// LIN64-NEXT:    [[TMP156:%.*]] = cmpxchg ptr getelementptr (i8, ptr @bfx2_packed, i64 3), i8 [[TMP153]], i8 [[TMP155]] monotonic monotonic, align 1, !dbg [[DBG132]]
// LIN64-NEXT:    [[TMP157]] = extractvalue { i8, i1 } [[TMP156]], 0, !dbg [[DBG132]]
// LIN64-NEXT:    [[TMP158:%.*]] = extractvalue { i8, i1 } [[TMP156]], 1, !dbg [[DBG132]]
// LIN64-NEXT:    br i1 [[TMP158]], label [[ATOMIC_EXIT229:%.*]], label [[ATOMIC_CONT216]], !dbg [[DBG132]]
// LIN64:       atomic_exit229:
// LIN64-NEXT:    store i32 [[CONV223]], ptr @iv, align 4, !dbg [[DBG132]]
// LIN64-NEXT:    [[TMP159:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG135:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD230:%.*]] = load atomic i32, ptr @bfx3 monotonic, align 4, !dbg [[DBG136:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT231:%.*]], !dbg [[DBG136]]
// LIN64:       atomic_cont231:
// LIN64-NEXT:    [[TMP160:%.*]] = phi i32 [ [[ATOMIC_LOAD230]], [[ATOMIC_EXIT229]] ], [ [[TMP163:%.*]], [[ATOMIC_CONT231]] ], !dbg [[DBG136]]
// LIN64-NEXT:    store i32 [[TMP160]], ptr [[ATOMIC_TEMP232]], align 4, !dbg [[DBG136]]
// LIN64-NEXT:    store i32 [[TMP160]], ptr [[ATOMIC_TEMP233]], align 4, !dbg [[DBG136]]
// LIN64-NEXT:    [[BF_LOAD234:%.*]] = load i32, ptr [[ATOMIC_TEMP233]], align 4, !dbg [[DBG136]]
// LIN64-NEXT:    [[BF_SHL235:%.*]] = shl i32 [[BF_LOAD234]], 7, !dbg [[DBG136]]
// LIN64-NEXT:    [[BF_ASHR236:%.*]] = ashr i32 [[BF_SHL235]], 18, !dbg [[DBG136]]
// LIN64-NEXT:    [[CONV237:%.*]] = sitofp i32 [[BF_ASHR236]] to x86_fp80, !dbg [[DBG137:![0-9]+]]
// LIN64-NEXT:    [[DIV238:%.*]] = fdiv x86_fp80 [[CONV237]], [[TMP159]], !dbg [[DBG138:![0-9]+]]
// LIN64-NEXT:    [[CONV239:%.*]] = fptosi x86_fp80 [[DIV238]] to i32, !dbg [[DBG137]]
// LIN64-NEXT:    [[BF_LOAD240:%.*]] = load i32, ptr [[ATOMIC_TEMP232]], align 4, !dbg [[DBG136]]
// LIN64-NEXT:    [[BF_VALUE241:%.*]] = and i32 [[CONV239]], 16383, !dbg [[DBG136]]
// LIN64-NEXT:    [[BF_SHL242:%.*]] = shl i32 [[BF_VALUE241]], 11, !dbg [[DBG136]]
// LIN64-NEXT:    [[BF_CLEAR243:%.*]] = and i32 [[BF_LOAD240]], -33552385, !dbg [[DBG136]]
// LIN64-NEXT:    [[BF_SET244:%.*]] = or i32 [[BF_CLEAR243]], [[BF_SHL242]], !dbg [[DBG136]]
// LIN64-NEXT:    store i32 [[BF_SET244]], ptr [[ATOMIC_TEMP232]], align 4, !dbg [[DBG136]]
// LIN64-NEXT:    [[TMP161:%.*]] = load i32, ptr [[ATOMIC_TEMP232]], align 4, !dbg [[DBG136]]
// LIN64-NEXT:    [[TMP162:%.*]] = cmpxchg ptr @bfx3, i32 [[TMP160]], i32 [[TMP161]] monotonic monotonic, align 4, !dbg [[DBG136]]
// LIN64-NEXT:    [[TMP163]] = extractvalue { i32, i1 } [[TMP162]], 0, !dbg [[DBG136]]
// LIN64-NEXT:    [[TMP164:%.*]] = extractvalue { i32, i1 } [[TMP162]], 1, !dbg [[DBG136]]
// LIN64-NEXT:    br i1 [[TMP164]], label [[ATOMIC_EXIT245:%.*]], label [[ATOMIC_CONT231]], !dbg [[DBG136]]
// LIN64:       atomic_exit245:
// LIN64-NEXT:    store i32 [[BF_ASHR236]], ptr @iv, align 4, !dbg [[DBG136]]
// LIN64-NEXT:    [[TMP165:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG139:![0-9]+]]
// LIN64-NEXT:    call void @__atomic_load(i64 noundef 3, ptr noundef getelementptr (i8, ptr @bfx3_packed, i64 1), ptr noundef [[ATOMIC_TEMP246]], i32 noundef 0), !dbg [[DBG140:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT247:%.*]], !dbg [[DBG140]]
// LIN64:       atomic_cont247:
// LIN64-NEXT:    [[TMP166:%.*]] = load i24, ptr [[ATOMIC_TEMP246]], align 1, !dbg [[DBG140]]
// LIN64-NEXT:    store i24 [[TMP166]], ptr [[ATOMIC_TEMP248]], align 1, !dbg [[DBG140]]
// LIN64-NEXT:    [[TMP167:%.*]] = load i24, ptr [[ATOMIC_TEMP246]], align 1, !dbg [[DBG140]]
// LIN64-NEXT:    store i24 [[TMP167]], ptr [[ATOMIC_TEMP249]], align 1, !dbg [[DBG140]]
// LIN64-NEXT:    [[BF_LOAD250:%.*]] = load i24, ptr [[ATOMIC_TEMP249]], align 1, !dbg [[DBG140]]
// LIN64-NEXT:    [[BF_SHL251:%.*]] = shl i24 [[BF_LOAD250]], 7, !dbg [[DBG140]]
// LIN64-NEXT:    [[BF_ASHR252:%.*]] = ashr i24 [[BF_SHL251]], 10, !dbg [[DBG140]]
// LIN64-NEXT:    [[BF_CAST253:%.*]] = sext i24 [[BF_ASHR252]] to i32, !dbg [[DBG140]]
// LIN64-NEXT:    [[CONV254:%.*]] = sitofp i32 [[BF_CAST253]] to x86_fp80, !dbg [[DBG141:![0-9]+]]
// LIN64-NEXT:    [[ADD255:%.*]] = fadd x86_fp80 [[CONV254]], [[TMP165]], !dbg [[DBG142:![0-9]+]]
// LIN64-NEXT:    [[CONV256:%.*]] = fptosi x86_fp80 [[ADD255]] to i32, !dbg [[DBG141]]
// LIN64-NEXT:    [[TMP168:%.*]] = trunc i32 [[CONV256]] to i24, !dbg [[DBG140]]
// LIN64-NEXT:    [[BF_LOAD257:%.*]] = load i24, ptr [[ATOMIC_TEMP248]], align 1, !dbg [[DBG140]]
// LIN64-NEXT:    [[BF_VALUE258:%.*]] = and i24 [[TMP168]], 16383, !dbg [[DBG140]]
// LIN64-NEXT:    [[BF_SHL259:%.*]] = shl i24 [[BF_VALUE258]], 3, !dbg [[DBG140]]
// LIN64-NEXT:    [[BF_CLEAR260:%.*]] = and i24 [[BF_LOAD257]], -131065, !dbg [[DBG140]]
// LIN64-NEXT:    [[BF_SET261:%.*]] = or i24 [[BF_CLEAR260]], [[BF_SHL259]], !dbg [[DBG140]]
// LIN64-NEXT:    store i24 [[BF_SET261]], ptr [[ATOMIC_TEMP248]], align 1, !dbg [[DBG140]]
// LIN64-NEXT:    [[CALL262:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 3, ptr noundef getelementptr (i8, ptr @bfx3_packed, i64 1), ptr noundef [[ATOMIC_TEMP246]], ptr noundef [[ATOMIC_TEMP248]], i32 noundef 0, i32 noundef 0), !dbg [[DBG140]]
// LIN64-NEXT:    br i1 [[CALL262]], label [[ATOMIC_EXIT263:%.*]], label [[ATOMIC_CONT247]], !dbg [[DBG140]]
// LIN64:       atomic_exit263:
// LIN64-NEXT:    store i32 [[CONV256]], ptr @iv, align 4, !dbg [[DBG140]]
// LIN64-NEXT:    [[TMP169:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG143:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD264:%.*]] = load atomic i64, ptr @bfx4 monotonic, align 8, !dbg [[DBG144:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT265:%.*]], !dbg [[DBG144]]
// LIN64:       atomic_cont265:
// LIN64-NEXT:    [[TMP170:%.*]] = phi i64 [ [[ATOMIC_LOAD264]], [[ATOMIC_EXIT263]] ], [ [[TMP174:%.*]], [[ATOMIC_CONT265]] ], !dbg [[DBG144]]
// LIN64-NEXT:    store i64 [[TMP170]], ptr [[ATOMIC_TEMP266]], align 8, !dbg [[DBG144]]
// LIN64-NEXT:    store i64 [[TMP170]], ptr [[ATOMIC_TEMP267]], align 8, !dbg [[DBG144]]
// LIN64-NEXT:    [[BF_LOAD268:%.*]] = load i64, ptr [[ATOMIC_TEMP267]], align 8, !dbg [[DBG144]]
// LIN64-NEXT:    [[BF_SHL269:%.*]] = shl i64 [[BF_LOAD268]], 47, !dbg [[DBG144]]
// LIN64-NEXT:    [[BF_ASHR270:%.*]] = ashr i64 [[BF_SHL269]], 63, !dbg [[DBG144]]
// LIN64-NEXT:    [[BF_CAST271:%.*]] = trunc i64 [[BF_ASHR270]] to i32, !dbg [[DBG144]]
// LIN64-NEXT:    [[CONV272:%.*]] = sitofp i32 [[BF_CAST271]] to x86_fp80, !dbg [[DBG145:![0-9]+]]
// LIN64-NEXT:    [[MUL273:%.*]] = fmul x86_fp80 [[CONV272]], [[TMP169]], !dbg [[DBG146:![0-9]+]]
// LIN64-NEXT:    [[CONV274:%.*]] = fptosi x86_fp80 [[MUL273]] to i32, !dbg [[DBG145]]
// LIN64-NEXT:    [[TMP171:%.*]] = zext i32 [[CONV274]] to i64, !dbg [[DBG144]]
// LIN64-NEXT:    [[BF_LOAD275:%.*]] = load i64, ptr [[ATOMIC_TEMP266]], align 8, !dbg [[DBG144]]
// LIN64-NEXT:    [[BF_VALUE276:%.*]] = and i64 [[TMP171]], 1, !dbg [[DBG144]]
// LIN64-NEXT:    [[BF_SHL277:%.*]] = shl i64 [[BF_VALUE276]], 16, !dbg [[DBG144]]
// LIN64-NEXT:    [[BF_CLEAR278:%.*]] = and i64 [[BF_LOAD275]], -65537, !dbg [[DBG144]]
// LIN64-NEXT:    [[BF_SET279:%.*]] = or i64 [[BF_CLEAR278]], [[BF_SHL277]], !dbg [[DBG144]]
// LIN64-NEXT:    store i64 [[BF_SET279]], ptr [[ATOMIC_TEMP266]], align 8, !dbg [[DBG144]]
// LIN64-NEXT:    [[TMP172:%.*]] = load i64, ptr [[ATOMIC_TEMP266]], align 8, !dbg [[DBG144]]
// LIN64-NEXT:    [[TMP173:%.*]] = cmpxchg ptr @bfx4, i64 [[TMP170]], i64 [[TMP172]] monotonic monotonic, align 8, !dbg [[DBG144]]
// LIN64-NEXT:    [[TMP174]] = extractvalue { i64, i1 } [[TMP173]], 0, !dbg [[DBG144]]
// LIN64-NEXT:    [[TMP175:%.*]] = extractvalue { i64, i1 } [[TMP173]], 1, !dbg [[DBG144]]
// LIN64-NEXT:    br i1 [[TMP175]], label [[ATOMIC_EXIT280:%.*]], label [[ATOMIC_CONT265]], !dbg [[DBG144]]
// LIN64:       atomic_exit280:
// LIN64-NEXT:    store i32 [[CONV274]], ptr @iv, align 4, !dbg [[DBG144]]
// LIN64-NEXT:    [[TMP176:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG147:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD281:%.*]] = load atomic i8, ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED:%.*]], ptr @bfx4_packed, i32 0, i32 1) monotonic, align 1, !dbg [[DBG148:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT282:%.*]], !dbg [[DBG148]]
// LIN64:       atomic_cont282:
// LIN64-NEXT:    [[TMP177:%.*]] = phi i8 [ [[ATOMIC_LOAD281]], [[ATOMIC_EXIT280]] ], [ [[TMP181:%.*]], [[ATOMIC_CONT282]] ], !dbg [[DBG148]]
// LIN64-NEXT:    store i8 [[TMP177]], ptr [[ATOMIC_TEMP283]], align 1, !dbg [[DBG148]]
// LIN64-NEXT:    store i8 [[TMP177]], ptr [[ATOMIC_TEMP284]], align 1, !dbg [[DBG148]]
// LIN64-NEXT:    [[BF_LOAD285:%.*]] = load i8, ptr [[ATOMIC_TEMP284]], align 1, !dbg [[DBG148]]
// LIN64-NEXT:    [[BF_SHL286:%.*]] = shl i8 [[BF_LOAD285]], 7, !dbg [[DBG148]]
// LIN64-NEXT:    [[BF_ASHR287:%.*]] = ashr i8 [[BF_SHL286]], 7, !dbg [[DBG148]]
// LIN64-NEXT:    [[BF_CAST288:%.*]] = sext i8 [[BF_ASHR287]] to i32, !dbg [[DBG148]]
// LIN64-NEXT:    [[CONV289:%.*]] = sitofp i32 [[BF_CAST288]] to x86_fp80, !dbg [[DBG149:![0-9]+]]
// LIN64-NEXT:    [[SUB290:%.*]] = fsub x86_fp80 [[CONV289]], [[TMP176]], !dbg [[DBG150:![0-9]+]]
// LIN64-NEXT:    [[CONV291:%.*]] = fptosi x86_fp80 [[SUB290]] to i32, !dbg [[DBG149]]
// LIN64-NEXT:    [[TMP178:%.*]] = trunc i32 [[CONV291]] to i8, !dbg [[DBG148]]
// LIN64-NEXT:    [[BF_LOAD292:%.*]] = load i8, ptr [[ATOMIC_TEMP283]], align 1, !dbg [[DBG148]]
// LIN64-NEXT:    [[BF_VALUE293:%.*]] = and i8 [[TMP178]], 1, !dbg [[DBG148]]
// LIN64-NEXT:    [[BF_CLEAR294:%.*]] = and i8 [[BF_LOAD292]], -2, !dbg [[DBG148]]
// LIN64-NEXT:    [[BF_SET295:%.*]] = or i8 [[BF_CLEAR294]], [[BF_VALUE293]], !dbg [[DBG148]]
// LIN64-NEXT:    store i8 [[BF_SET295]], ptr [[ATOMIC_TEMP283]], align 1, !dbg [[DBG148]]
// LIN64-NEXT:    [[TMP179:%.*]] = load i8, ptr [[ATOMIC_TEMP283]], align 1, !dbg [[DBG148]]
// LIN64-NEXT:    [[TMP180:%.*]] = cmpxchg ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1), i8 [[TMP177]], i8 [[TMP179]] monotonic monotonic, align 1, !dbg [[DBG148]]
// LIN64-NEXT:    [[TMP181]] = extractvalue { i8, i1 } [[TMP180]], 0, !dbg [[DBG148]]
// LIN64-NEXT:    [[TMP182:%.*]] = extractvalue { i8, i1 } [[TMP180]], 1, !dbg [[DBG148]]
// LIN64-NEXT:    br i1 [[TMP182]], label [[ATOMIC_EXIT296:%.*]], label [[ATOMIC_CONT282]], !dbg [[DBG148]]
// LIN64:       atomic_exit296:
// LIN64-NEXT:    store i32 [[BF_CAST288]], ptr @iv, align 4, !dbg [[DBG148]]
// LIN64-NEXT:    [[TMP183:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG151:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD297:%.*]] = load atomic i64, ptr @bfx4 monotonic, align 8, !dbg [[DBG152:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT298:%.*]], !dbg [[DBG152]]
// LIN64:       atomic_cont298:
// LIN64-NEXT:    [[TMP184:%.*]] = phi i64 [ [[ATOMIC_LOAD297]], [[ATOMIC_EXIT296]] ], [ [[TMP187:%.*]], [[ATOMIC_CONT298]] ], !dbg [[DBG152]]
// LIN64-NEXT:    store i64 [[TMP184]], ptr [[ATOMIC_TEMP299]], align 8, !dbg [[DBG152]]
// LIN64-NEXT:    store i64 [[TMP184]], ptr [[ATOMIC_TEMP300]], align 8, !dbg [[DBG152]]
// LIN64-NEXT:    [[BF_LOAD301:%.*]] = load i64, ptr [[ATOMIC_TEMP300]], align 8, !dbg [[DBG152]]
// LIN64-NEXT:    [[BF_SHL302:%.*]] = shl i64 [[BF_LOAD301]], 40, !dbg [[DBG152]]
// LIN64-NEXT:    [[BF_ASHR303:%.*]] = ashr i64 [[BF_SHL302]], 57, !dbg [[DBG152]]
// LIN64-NEXT:    [[CONV304:%.*]] = sitofp i64 [[BF_ASHR303]] to x86_fp80, !dbg [[DBG153:![0-9]+]]
// LIN64-NEXT:    [[DIV305:%.*]] = fdiv x86_fp80 [[CONV304]], [[TMP183]], !dbg [[DBG154:![0-9]+]]
// LIN64-NEXT:    [[CONV306:%.*]] = fptosi x86_fp80 [[DIV305]] to i64, !dbg [[DBG153]]
// LIN64-NEXT:    [[BF_LOAD307:%.*]] = load i64, ptr [[ATOMIC_TEMP299]], align 8, !dbg [[DBG152]]
// LIN64-NEXT:    [[BF_VALUE308:%.*]] = and i64 [[CONV306]], 127, !dbg [[DBG152]]
// LIN64-NEXT:    [[BF_SHL309:%.*]] = shl i64 [[BF_VALUE308]], 17, !dbg [[DBG152]]
// LIN64-NEXT:    [[BF_CLEAR310:%.*]] = and i64 [[BF_LOAD307]], -16646145, !dbg [[DBG152]]
// LIN64-NEXT:    [[BF_SET311:%.*]] = or i64 [[BF_CLEAR310]], [[BF_SHL309]], !dbg [[DBG152]]
// LIN64-NEXT:    store i64 [[BF_SET311]], ptr [[ATOMIC_TEMP299]], align 8, !dbg [[DBG152]]
// LIN64-NEXT:    [[TMP185:%.*]] = load i64, ptr [[ATOMIC_TEMP299]], align 8, !dbg [[DBG152]]
// LIN64-NEXT:    [[TMP186:%.*]] = cmpxchg ptr @bfx4, i64 [[TMP184]], i64 [[TMP185]] release monotonic, align 8, !dbg [[DBG152]]
// LIN64-NEXT:    [[TMP187]] = extractvalue { i64, i1 } [[TMP186]], 0, !dbg [[DBG152]]
// LIN64-NEXT:    [[TMP188:%.*]] = extractvalue { i64, i1 } [[TMP186]], 1, !dbg [[DBG152]]
// LIN64-NEXT:    br i1 [[TMP188]], label [[ATOMIC_EXIT312:%.*]], label [[ATOMIC_CONT298]], !dbg [[DBG152]]
// LIN64:       atomic_exit312:
// LIN64-NEXT:    [[CONV313:%.*]] = trunc i64 [[CONV306]] to i32, !dbg [[DBG152]]
// LIN64-NEXT:    store i32 [[CONV313]], ptr @iv, align 4, !dbg [[DBG152]]
// LIN64-NEXT:    [[TMP189:%.*]] = load x86_fp80, ptr @ldv, align 16, !dbg [[DBG155:![0-9]+]]
// LIN64-NEXT:    [[ATOMIC_LOAD314:%.*]] = load atomic i8, ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1) acquire, align 1, !dbg [[DBG156:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT315:%.*]], !dbg [[DBG156]]
// LIN64:       atomic_cont315:
// LIN64-NEXT:    [[TMP190:%.*]] = phi i8 [ [[ATOMIC_LOAD314]], [[ATOMIC_EXIT312]] ], [ [[TMP194:%.*]], [[ATOMIC_CONT315]] ], !dbg [[DBG156]]
// LIN64-NEXT:    store i8 [[TMP190]], ptr [[ATOMIC_TEMP316]], align 1, !dbg [[DBG156]]
// LIN64-NEXT:    store i8 [[TMP190]], ptr [[ATOMIC_TEMP317]], align 1, !dbg [[DBG156]]
// LIN64-NEXT:    [[BF_LOAD318:%.*]] = load i8, ptr [[ATOMIC_TEMP317]], align 1, !dbg [[DBG156]]
// LIN64-NEXT:    [[BF_ASHR319:%.*]] = ashr i8 [[BF_LOAD318]], 1, !dbg [[DBG156]]
// LIN64-NEXT:    [[BF_CAST320:%.*]] = sext i8 [[BF_ASHR319]] to i64, !dbg [[DBG156]]
// LIN64-NEXT:    [[CONV321:%.*]] = sitofp i64 [[BF_CAST320]] to x86_fp80, !dbg [[DBG157:![0-9]+]]
// LIN64-NEXT:    [[ADD322:%.*]] = fadd x86_fp80 [[CONV321]], [[TMP189]], !dbg [[DBG158:![0-9]+]]
// LIN64-NEXT:    [[CONV323:%.*]] = fptosi x86_fp80 [[ADD322]] to i64, !dbg [[DBG157]]
// LIN64-NEXT:    [[TMP191:%.*]] = trunc i64 [[CONV323]] to i8, !dbg [[DBG156]]
// LIN64-NEXT:    [[BF_LOAD324:%.*]] = load i8, ptr [[ATOMIC_TEMP316]], align 1, !dbg [[DBG156]]
// LIN64-NEXT:    [[BF_VALUE325:%.*]] = and i8 [[TMP191]], 127, !dbg [[DBG156]]
// LIN64-NEXT:    [[BF_SHL326:%.*]] = shl i8 [[BF_VALUE325]], 1, !dbg [[DBG156]]
// LIN64-NEXT:    [[BF_CLEAR327:%.*]] = and i8 [[BF_LOAD324]], 1, !dbg [[DBG156]]
// LIN64-NEXT:    [[BF_SET328:%.*]] = or i8 [[BF_CLEAR327]], [[BF_SHL326]], !dbg [[DBG156]]
// LIN64-NEXT:    store i8 [[BF_SET328]], ptr [[ATOMIC_TEMP316]], align 1, !dbg [[DBG156]]
// LIN64-NEXT:    [[TMP192:%.*]] = load i8, ptr [[ATOMIC_TEMP316]], align 1, !dbg [[DBG156]]
// LIN64-NEXT:    [[TMP193:%.*]] = cmpxchg ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1), i8 [[TMP190]], i8 [[TMP192]] acquire acquire, align 1, !dbg [[DBG156]]
// LIN64-NEXT:    [[TMP194]] = extractvalue { i8, i1 } [[TMP193]], 0, !dbg [[DBG156]]
// LIN64-NEXT:    [[TMP195:%.*]] = extractvalue { i8, i1 } [[TMP193]], 1, !dbg [[DBG156]]
// LIN64-NEXT:    br i1 [[TMP195]], label [[ATOMIC_EXIT329:%.*]], label [[ATOMIC_CONT315]], !dbg [[DBG156]]
// LIN64:       atomic_exit329:
// LIN64-NEXT:    [[CONV330:%.*]] = trunc i64 [[CONV323]] to i32, !dbg [[DBG156]]
// LIN64-NEXT:    store i32 [[CONV330]], ptr @iv, align 4, !dbg [[DBG156]]
// LIN64-NEXT:    [[TMP196:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG159:![0-9]+]]
// LIN64-NEXT:    [[CONV331:%.*]] = uitofp i64 [[TMP196]] to float, !dbg [[DBG159]]
// LIN64-NEXT:    [[ATOMIC_LOAD332:%.*]] = load atomic i64, ptr @float2x acquire, align 8, !dbg [[DBG160:![0-9]+]]
// LIN64-NEXT:    br label [[ATOMIC_CONT333:%.*]], !dbg [[DBG160]]
// LIN64:       atomic_cont333:
// LIN64-NEXT:    [[TMP197:%.*]] = phi i64 [ [[ATOMIC_LOAD332]], [[ATOMIC_EXIT329]] ], [ [[TMP205:%.*]], [[ATOMIC_CONT333]] ], !dbg [[DBG160]]
// LIN64-NEXT:    store i64 [[TMP197]], ptr [[ATOMIC_TEMP334]], align 8, !dbg [[DBG160]]
// LIN64-NEXT:    [[TMP198:%.*]] = bitcast i64 [[TMP197]] to <2 x float>, !dbg [[DBG160]]
// LIN64-NEXT:    store <2 x float> [[TMP198]], ptr [[ATOMIC_TEMP335]], align 8, !dbg [[DBG160]]
// LIN64-NEXT:    [[TMP199:%.*]] = load <2 x float>, ptr [[ATOMIC_TEMP335]], align 8, !dbg [[DBG160]]
// LIN64-NEXT:    [[TMP200:%.*]] = extractelement <2 x float> [[TMP199]], i64 0, !dbg [[DBG160]]
// LIN64-NEXT:    [[SUB336:%.*]] = fsub float [[CONV331]], [[TMP200]], !dbg [[DBG161:![0-9]+]]
// LIN64-NEXT:    [[TMP201:%.*]] = load <2 x float>, ptr [[ATOMIC_TEMP334]], align 8, !dbg [[DBG160]]
// LIN64-NEXT:    [[TMP202:%.*]] = insertelement <2 x float> [[TMP201]], float [[SUB336]], i64 0, !dbg [[DBG160]]
// LIN64-NEXT:    store <2 x float> [[TMP202]], ptr [[ATOMIC_TEMP334]], align 8, !dbg [[DBG160]]
// LIN64-NEXT:    [[TMP203:%.*]] = load i64, ptr [[ATOMIC_TEMP334]], align 8, !dbg [[DBG160]]
// LIN64-NEXT:    [[TMP204:%.*]] = cmpxchg ptr @float2x, i64 [[TMP197]], i64 [[TMP203]] acq_rel acquire, align 8, !dbg [[DBG160]]
// LIN64-NEXT:    [[TMP205]] = extractvalue { i64, i1 } [[TMP204]], 0, !dbg [[DBG160]]
// LIN64-NEXT:    [[TMP206:%.*]] = extractvalue { i64, i1 } [[TMP204]], 1, !dbg [[DBG160]]
// LIN64-NEXT:    br i1 [[TMP206]], label [[ATOMIC_EXIT337:%.*]], label [[ATOMIC_CONT333]], !dbg [[DBG160]]
// LIN64:       atomic_exit337:
// LIN64-NEXT:    store float [[TMP200]], ptr @fv, align 4, !dbg [[DBG160]]
// LIN64-NEXT:    [[TMP207:%.*]] = load double, ptr @dv, align 8, !dbg [[DBG162:![0-9]+]]
// LIN64-NEXT:    [[TMP208:%.*]] = call i32 @llvm.read_register.i32(metadata [[META2:![0-9]+]]), !dbg [[DBG163:![0-9]+]]
// LIN64-NEXT:    [[CONV338:%.*]] = sitofp i32 [[TMP208]] to double, !dbg [[DBG164:![0-9]+]]
// LIN64-NEXT:    [[DIV339:%.*]] = fdiv double [[TMP207]], [[CONV338]], !dbg [[DBG165:![0-9]+]]
// LIN64-NEXT:    [[CONV340:%.*]] = fptosi double [[DIV339]] to i32, !dbg [[DBG162]]
// LIN64-NEXT:    call void @llvm.write_register.i32(metadata [[META2]], i32 [[CONV340]]), !dbg [[DBG163]]
// LIN64-NEXT:    store i32 [[CONV340]], ptr @iv, align 4, !dbg [[DBG163]]
// LIN64-NEXT:    [[TMP209:%.*]] = atomicrmw xchg ptr @ix, i32 5 monotonic, align 4, !dbg [[DBG166:![0-9]+]]
// LIN64-NEXT:    call void @llvm.write_register.i32(metadata [[META2]], i32 [[TMP209]]), !dbg [[DBG166]]
// LIN64-NEXT:    ret i32 0, !dbg [[DBG167:![0-9]+]]
//
//
// PPC64-LABEL: define {{[^@]+}}@main
// PPC64-SAME: () #[[ATTR0:[0-9]+]] !dbg [[DBG6:![0-9]+]] {
// PPC64-NEXT:  entry:
// PPC64-NEXT:    [[RETVAL:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca i16, align 2
// PPC64-NEXT:    [[ATOMIC_TEMP10:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP14:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP18:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP22:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP28:%.*]] = alloca double, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP32:%.*]] = alloca ppc_fp128, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP34:%.*]] = alloca ppc_fp128, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP38:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP40:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP45:%.*]] = alloca { float, float }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP47:%.*]] = alloca { float, float }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP52:%.*]] = alloca { double, double }, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP54:%.*]] = alloca { double, double }, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP64:%.*]] = alloca i8, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP73:%.*]] = alloca i8, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP81:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP88:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP92:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP94:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP106:%.*]] = alloca float, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP112:%.*]] = alloca double, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP116:%.*]] = alloca ppc_fp128, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP118:%.*]] = alloca ppc_fp128, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP122:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP124:%.*]] = alloca { i32, i32 }, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP134:%.*]] = alloca i16, align 2
// PPC64-NEXT:    [[ATOMIC_TEMP142:%.*]] = alloca i8, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP155:%.*]] = alloca i8, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP168:%.*]] = alloca <4 x i32>, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP170:%.*]] = alloca <4 x i32>, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP171:%.*]] = alloca <4 x i32>, align 16
// PPC64-NEXT:    [[ATOMIC_TEMP177:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP178:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP184:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP186:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP187:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP202:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP203:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP217:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP218:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP232:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP233:%.*]] = alloca i32, align 4
// PPC64-NEXT:    [[ATOMIC_TEMP246:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP248:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP249:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP266:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP267:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP283:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP284:%.*]] = alloca i32, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP299:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP300:%.*]] = alloca i64, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP316:%.*]] = alloca i64, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP317:%.*]] = alloca i64, align 1
// PPC64-NEXT:    [[ATOMIC_TEMP334:%.*]] = alloca <2 x float>, align 8
// PPC64-NEXT:    [[ATOMIC_TEMP335:%.*]] = alloca <2 x float>, align 8
// PPC64-NEXT:    store i32 0, ptr [[RETVAL]], align 4
// PPC64-NEXT:    [[TMP0:%.*]] = atomicrmw add ptr @bx, i8 1 monotonic, align 1, !dbg [[DBG10:![0-9]+]]
// PPC64-NEXT:    store i8 [[TMP0]], ptr @bv, align 1, !dbg [[DBG10]]
// PPC64-NEXT:    [[TMP1:%.*]] = atomicrmw add ptr @cx, i8 1 monotonic, align 1, !dbg [[DBG11:![0-9]+]]
// PPC64-NEXT:    [[CONV:%.*]] = sext i8 [[TMP1]] to i32, !dbg [[DBG12:![0-9]+]]
// PPC64-NEXT:    [[ADD:%.*]] = add nsw i32 [[CONV]], 1, !dbg [[DBG13:![0-9]+]]
// PPC64-NEXT:    [[CONV1:%.*]] = trunc i32 [[ADD]] to i8, !dbg [[DBG12]]
// PPC64-NEXT:    store i8 [[CONV1]], ptr @cv, align 1, !dbg [[DBG11]]
// PPC64-NEXT:    [[TMP2:%.*]] = atomicrmw sub ptr @ucx, i8 1 monotonic, align 1, !dbg [[DBG14:![0-9]+]]
// PPC64-NEXT:    store i8 [[TMP2]], ptr @ucv, align 1, !dbg [[DBG14]]
// PPC64-NEXT:    [[TMP3:%.*]] = atomicrmw sub ptr @sx, i16 1 monotonic, align 2, !dbg [[DBG15:![0-9]+]]
// PPC64-NEXT:    [[CONV2:%.*]] = sext i16 [[TMP3]] to i32, !dbg [[DBG16:![0-9]+]]
// PPC64-NEXT:    [[SUB:%.*]] = sub nsw i32 [[CONV2]], 1, !dbg [[DBG17:![0-9]+]]
// PPC64-NEXT:    [[CONV3:%.*]] = trunc i32 [[SUB]] to i16, !dbg [[DBG16]]
// PPC64-NEXT:    store i16 [[CONV3]], ptr @sv, align 2, !dbg [[DBG15]]
// PPC64-NEXT:    [[TMP4:%.*]] = load i16, ptr @usv, align 2, !dbg [[DBG18:![0-9]+]]
// PPC64-NEXT:    [[CONV4:%.*]] = zext i16 [[TMP4]] to i32, !dbg [[DBG18]]
// PPC64-NEXT:    [[ATOMIC_LOAD:%.*]] = load atomic i16, ptr @usx monotonic, align 2, !dbg [[DBG19:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT:%.*]], !dbg [[DBG19]]
// PPC64:       atomic_cont:
// PPC64-NEXT:    [[TMP5:%.*]] = phi i16 [ [[ATOMIC_LOAD]], [[ENTRY:%.*]] ], [ [[TMP8:%.*]], [[ATOMIC_CONT]] ], !dbg [[DBG19]]
// PPC64-NEXT:    [[CONV5:%.*]] = zext i16 [[TMP5]] to i32, !dbg [[DBG20:![0-9]+]]
// PPC64-NEXT:    [[ADD6:%.*]] = add nsw i32 [[CONV5]], [[CONV4]], !dbg [[DBG21:![0-9]+]]
// PPC64-NEXT:    [[CONV7:%.*]] = trunc i32 [[ADD6]] to i16, !dbg [[DBG20]]
// PPC64-NEXT:    store i16 [[CONV7]], ptr [[ATOMIC_TEMP]], align 2, !dbg [[DBG19]]
// PPC64-NEXT:    [[TMP6:%.*]] = load i16, ptr [[ATOMIC_TEMP]], align 2, !dbg [[DBG19]]
// PPC64-NEXT:    [[TMP7:%.*]] = cmpxchg ptr @usx, i16 [[TMP5]], i16 [[TMP6]] monotonic monotonic, align 2, !dbg [[DBG19]]
// PPC64-NEXT:    [[TMP8]] = extractvalue { i16, i1 } [[TMP7]], 0, !dbg [[DBG19]]
// PPC64-NEXT:    [[TMP9:%.*]] = extractvalue { i16, i1 } [[TMP7]], 1, !dbg [[DBG19]]
// PPC64-NEXT:    br i1 [[TMP9]], label [[ATOMIC_EXIT:%.*]], label [[ATOMIC_CONT]], !dbg [[DBG19]]
// PPC64:       atomic_exit:
// PPC64-NEXT:    store i16 [[CONV7]], ptr @sv, align 2, !dbg [[DBG19]]
// PPC64-NEXT:    [[TMP10:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG22:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD8:%.*]] = load atomic i32, ptr @ix monotonic, align 4, !dbg [[DBG23:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT9:%.*]], !dbg [[DBG23]]
// PPC64:       atomic_cont9:
// PPC64-NEXT:    [[TMP11:%.*]] = phi i32 [ [[ATOMIC_LOAD8]], [[ATOMIC_EXIT]] ], [ [[TMP14:%.*]], [[ATOMIC_CONT9]] ], !dbg [[DBG23]]
// PPC64-NEXT:    [[MUL:%.*]] = mul nsw i32 [[TMP11]], [[TMP10]], !dbg [[DBG24:![0-9]+]]
// PPC64-NEXT:    store i32 [[MUL]], ptr [[ATOMIC_TEMP10]], align 4, !dbg [[DBG23]]
// PPC64-NEXT:    [[TMP12:%.*]] = load i32, ptr [[ATOMIC_TEMP10]], align 4, !dbg [[DBG23]]
// PPC64-NEXT:    [[TMP13:%.*]] = cmpxchg ptr @ix, i32 [[TMP11]], i32 [[TMP12]] monotonic monotonic, align 4, !dbg [[DBG23]]
// PPC64-NEXT:    [[TMP14]] = extractvalue { i32, i1 } [[TMP13]], 0, !dbg [[DBG23]]
// PPC64-NEXT:    [[TMP15:%.*]] = extractvalue { i32, i1 } [[TMP13]], 1, !dbg [[DBG23]]
// PPC64-NEXT:    br i1 [[TMP15]], label [[ATOMIC_EXIT11:%.*]], label [[ATOMIC_CONT9]], !dbg [[DBG23]]
// PPC64:       atomic_exit11:
// PPC64-NEXT:    store i32 [[MUL]], ptr @uiv, align 4, !dbg [[DBG23]]
// PPC64-NEXT:    [[TMP16:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG25:![0-9]+]]
// PPC64-NEXT:    [[TMP17:%.*]] = atomicrmw sub ptr @uix, i32 [[TMP16]] monotonic, align 4, !dbg [[DBG26:![0-9]+]]
// PPC64-NEXT:    store i32 [[TMP17]], ptr @iv, align 4, !dbg [[DBG26]]
// PPC64-NEXT:    [[TMP18:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG27:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD12:%.*]] = load atomic i32, ptr @ix monotonic, align 4, !dbg [[DBG28:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT13:%.*]], !dbg [[DBG28]]
// PPC64:       atomic_cont13:
// PPC64-NEXT:    [[TMP19:%.*]] = phi i32 [ [[ATOMIC_LOAD12]], [[ATOMIC_EXIT11]] ], [ [[TMP22:%.*]], [[ATOMIC_CONT13]] ], !dbg [[DBG28]]
// PPC64-NEXT:    [[SHL:%.*]] = shl i32 [[TMP19]], [[TMP18]], !dbg [[DBG29:![0-9]+]]
// PPC64-NEXT:    store i32 [[SHL]], ptr [[ATOMIC_TEMP14]], align 4, !dbg [[DBG28]]
// PPC64-NEXT:    [[TMP20:%.*]] = load i32, ptr [[ATOMIC_TEMP14]], align 4, !dbg [[DBG28]]
// PPC64-NEXT:    [[TMP21:%.*]] = cmpxchg ptr @ix, i32 [[TMP19]], i32 [[TMP20]] monotonic monotonic, align 4, !dbg [[DBG28]]
// PPC64-NEXT:    [[TMP22]] = extractvalue { i32, i1 } [[TMP21]], 0, !dbg [[DBG28]]
// PPC64-NEXT:    [[TMP23:%.*]] = extractvalue { i32, i1 } [[TMP21]], 1, !dbg [[DBG28]]
// PPC64-NEXT:    br i1 [[TMP23]], label [[ATOMIC_EXIT15:%.*]], label [[ATOMIC_CONT13]], !dbg [[DBG28]]
// PPC64:       atomic_exit15:
// PPC64-NEXT:    store i32 [[SHL]], ptr @uiv, align 4, !dbg [[DBG28]]
// PPC64-NEXT:    [[TMP24:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG30:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD16:%.*]] = load atomic i32, ptr @uix monotonic, align 4, !dbg [[DBG31:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT17:%.*]], !dbg [[DBG31]]
// PPC64:       atomic_cont17:
// PPC64-NEXT:    [[TMP25:%.*]] = phi i32 [ [[ATOMIC_LOAD16]], [[ATOMIC_EXIT15]] ], [ [[TMP28:%.*]], [[ATOMIC_CONT17]] ], !dbg [[DBG31]]
// PPC64-NEXT:    [[SHR:%.*]] = lshr i32 [[TMP25]], [[TMP24]], !dbg [[DBG32:![0-9]+]]
// PPC64-NEXT:    store i32 [[SHR]], ptr [[ATOMIC_TEMP18]], align 4, !dbg [[DBG31]]
// PPC64-NEXT:    [[TMP26:%.*]] = load i32, ptr [[ATOMIC_TEMP18]], align 4, !dbg [[DBG31]]
// PPC64-NEXT:    [[TMP27:%.*]] = cmpxchg ptr @uix, i32 [[TMP25]], i32 [[TMP26]] monotonic monotonic, align 4, !dbg [[DBG31]]
// PPC64-NEXT:    [[TMP28]] = extractvalue { i32, i1 } [[TMP27]], 0, !dbg [[DBG31]]
// PPC64-NEXT:    [[TMP29:%.*]] = extractvalue { i32, i1 } [[TMP27]], 1, !dbg [[DBG31]]
// PPC64-NEXT:    br i1 [[TMP29]], label [[ATOMIC_EXIT19:%.*]], label [[ATOMIC_CONT17]], !dbg [[DBG31]]
// PPC64:       atomic_exit19:
// PPC64-NEXT:    store i32 [[SHR]], ptr @iv, align 4, !dbg [[DBG31]]
// PPC64-NEXT:    [[TMP30:%.*]] = load i64, ptr @lv, align 8, !dbg [[DBG33:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD20:%.*]] = load atomic i64, ptr @lx monotonic, align 8, !dbg [[DBG34:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT21:%.*]], !dbg [[DBG34]]
// PPC64:       atomic_cont21:
// PPC64-NEXT:    [[TMP31:%.*]] = phi i64 [ [[ATOMIC_LOAD20]], [[ATOMIC_EXIT19]] ], [ [[TMP34:%.*]], [[ATOMIC_CONT21]] ], !dbg [[DBG34]]
// PPC64-NEXT:    [[DIV:%.*]] = sdiv i64 [[TMP31]], [[TMP30]], !dbg [[DBG35:![0-9]+]]
// PPC64-NEXT:    store i64 [[DIV]], ptr [[ATOMIC_TEMP22]], align 8, !dbg [[DBG34]]
// PPC64-NEXT:    [[TMP32:%.*]] = load i64, ptr [[ATOMIC_TEMP22]], align 8, !dbg [[DBG34]]
// PPC64-NEXT:    [[TMP33:%.*]] = cmpxchg ptr @lx, i64 [[TMP31]], i64 [[TMP32]] monotonic monotonic, align 8, !dbg [[DBG34]]
// PPC64-NEXT:    [[TMP34]] = extractvalue { i64, i1 } [[TMP33]], 0, !dbg [[DBG34]]
// PPC64-NEXT:    [[TMP35:%.*]] = extractvalue { i64, i1 } [[TMP33]], 1, !dbg [[DBG34]]
// PPC64-NEXT:    br i1 [[TMP35]], label [[ATOMIC_EXIT23:%.*]], label [[ATOMIC_CONT21]], !dbg [[DBG34]]
// PPC64:       atomic_exit23:
// PPC64-NEXT:    store i64 [[TMP31]], ptr @ulv, align 8, !dbg [[DBG34]]
// PPC64-NEXT:    [[TMP36:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG36:![0-9]+]]
// PPC64-NEXT:    [[TMP37:%.*]] = atomicrmw and ptr @ulx, i64 [[TMP36]] monotonic, align 8, !dbg [[DBG37:![0-9]+]]
// PPC64-NEXT:    [[AND:%.*]] = and i64 [[TMP37]], [[TMP36]], !dbg [[DBG38:![0-9]+]]
// PPC64-NEXT:    store i64 [[AND]], ptr @lv, align 8, !dbg [[DBG37]]
// PPC64-NEXT:    [[TMP38:%.*]] = load i64, ptr @llv, align 8, !dbg [[DBG39:![0-9]+]]
// PPC64-NEXT:    [[TMP39:%.*]] = atomicrmw xor ptr @llx, i64 [[TMP38]] monotonic, align 8, !dbg [[DBG40:![0-9]+]]
// PPC64-NEXT:    [[XOR:%.*]] = xor i64 [[TMP39]], [[TMP38]], !dbg [[DBG41:![0-9]+]]
// PPC64-NEXT:    store i64 [[XOR]], ptr @ullv, align 8, !dbg [[DBG40]]
// PPC64-NEXT:    [[TMP40:%.*]] = load i64, ptr @ullv, align 8, !dbg [[DBG42:![0-9]+]]
// PPC64-NEXT:    [[TMP41:%.*]] = atomicrmw or ptr @ullx, i64 [[TMP40]] monotonic, align 8, !dbg [[DBG43:![0-9]+]]
// PPC64-NEXT:    [[OR:%.*]] = or i64 [[TMP41]], [[TMP40]], !dbg [[DBG44:![0-9]+]]
// PPC64-NEXT:    store i64 [[OR]], ptr @llv, align 8, !dbg [[DBG43]]
// PPC64-NEXT:    [[TMP42:%.*]] = load float, ptr @fv, align 4, !dbg [[DBG45:![0-9]+]]
// PPC64-NEXT:    [[TMP43:%.*]] = atomicrmw fadd ptr @fx, float [[TMP42]] monotonic, align 4, !dbg [[DBG46:![0-9]+]]
// PPC64-NEXT:    [[ADD24:%.*]] = fadd float [[TMP43]], [[TMP42]], !dbg [[DBG47:![0-9]+]]
// PPC64-NEXT:    [[CONV25:%.*]] = fpext float [[ADD24]] to double, !dbg [[DBG46]]
// PPC64-NEXT:    store double [[CONV25]], ptr @dv, align 8, !dbg [[DBG46]]
// PPC64-NEXT:    [[TMP44:%.*]] = load double, ptr @dv, align 8, !dbg [[DBG48:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD26:%.*]] = load atomic i64, ptr @dx monotonic, align 8, !dbg [[DBG49:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT27:%.*]], !dbg [[DBG49]]
// PPC64:       atomic_cont27:
// PPC64-NEXT:    [[TMP45:%.*]] = phi i64 [ [[ATOMIC_LOAD26]], [[ATOMIC_EXIT23]] ], [ [[TMP49:%.*]], [[ATOMIC_CONT27]] ], !dbg [[DBG49]]
// PPC64-NEXT:    [[TMP46:%.*]] = bitcast i64 [[TMP45]] to double, !dbg [[DBG49]]
// PPC64-NEXT:    [[SUB29:%.*]] = fsub double [[TMP44]], [[TMP46]], !dbg [[DBG50:![0-9]+]]
// PPC64-NEXT:    store double [[SUB29]], ptr [[ATOMIC_TEMP28]], align 8, !dbg [[DBG49]]
// PPC64-NEXT:    [[TMP47:%.*]] = load i64, ptr [[ATOMIC_TEMP28]], align 8, !dbg [[DBG49]]
// PPC64-NEXT:    [[TMP48:%.*]] = cmpxchg ptr @dx, i64 [[TMP45]], i64 [[TMP47]] monotonic monotonic, align 8, !dbg [[DBG49]]
// PPC64-NEXT:    [[TMP49]] = extractvalue { i64, i1 } [[TMP48]], 0, !dbg [[DBG49]]
// PPC64-NEXT:    [[TMP50:%.*]] = extractvalue { i64, i1 } [[TMP48]], 1, !dbg [[DBG49]]
// PPC64-NEXT:    br i1 [[TMP50]], label [[ATOMIC_EXIT30:%.*]], label [[ATOMIC_CONT27]], !dbg [[DBG49]]
// PPC64:       atomic_exit30:
// PPC64-NEXT:    [[CONV31:%.*]] = fptrunc double [[TMP46]] to float, !dbg [[DBG49]]
// PPC64-NEXT:    store float [[CONV31]], ptr @fv, align 4, !dbg [[DBG49]]
// PPC64-NEXT:    [[TMP51:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG51:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 16, ptr noundef @ldx, ptr noundef [[ATOMIC_TEMP32]], i32 noundef signext 0), !dbg [[DBG52:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT33:%.*]], !dbg [[DBG52]]
// PPC64:       atomic_cont33:
// PPC64-NEXT:    [[TMP52:%.*]] = load ppc_fp128, ptr [[ATOMIC_TEMP32]], align 16, !dbg [[DBG52]]
// PPC64-NEXT:    [[MUL35:%.*]] = fmul ppc_fp128 [[TMP52]], [[TMP51]], !dbg [[DBG53:![0-9]+]]
// PPC64-NEXT:    store ppc_fp128 [[MUL35]], ptr [[ATOMIC_TEMP34]], align 16, !dbg [[DBG52]]
// PPC64-NEXT:    [[CALL:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, ptr noundef @ldx, ptr noundef [[ATOMIC_TEMP32]], ptr noundef [[ATOMIC_TEMP34]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG52]]
// PPC64-NEXT:    br i1 [[CALL]], label [[ATOMIC_EXIT36:%.*]], label [[ATOMIC_CONT33]], !dbg [[DBG52]]
// PPC64:       atomic_exit36:
// PPC64-NEXT:    [[CONV37:%.*]] = fptrunc ppc_fp128 [[MUL35]] to double, !dbg [[DBG52]]
// PPC64-NEXT:    store double [[CONV37]], ptr @dv, align 8, !dbg [[DBG52]]
// PPC64-NEXT:    [[CIV_REAL:%.*]] = load i32, ptr @civ, align 4, !dbg [[DBG54:![0-9]+]]
// PPC64-NEXT:    [[CIV_IMAG:%.*]] = load i32, ptr getelementptr inbounds nuw ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG54]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP38]], i32 noundef signext 0), !dbg [[DBG55:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT39:%.*]], !dbg [[DBG55]]
// PPC64:       atomic_cont39:
// PPC64-NEXT:    [[ATOMIC_TEMP38_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP38]], i32 0, i32 0, !dbg [[DBG55]]
// PPC64-NEXT:    [[ATOMIC_TEMP38_REAL:%.*]] = load i32, ptr [[ATOMIC_TEMP38_REALP]], align 4, !dbg [[DBG55]]
// PPC64-NEXT:    [[ATOMIC_TEMP38_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP38]], i32 0, i32 1, !dbg [[DBG55]]
// PPC64-NEXT:    [[ATOMIC_TEMP38_IMAG:%.*]] = load i32, ptr [[ATOMIC_TEMP38_IMAGP]], align 4, !dbg [[DBG55]]
// PPC64-NEXT:    [[TMP53:%.*]] = mul i32 [[CIV_REAL]], [[ATOMIC_TEMP38_REAL]], !dbg [[DBG56:![0-9]+]]
// PPC64-NEXT:    [[TMP54:%.*]] = mul i32 [[CIV_IMAG]], [[ATOMIC_TEMP38_IMAG]], !dbg [[DBG56]]
// PPC64-NEXT:    [[TMP55:%.*]] = add i32 [[TMP53]], [[TMP54]], !dbg [[DBG56]]
// PPC64-NEXT:    [[TMP56:%.*]] = mul i32 [[ATOMIC_TEMP38_REAL]], [[ATOMIC_TEMP38_REAL]], !dbg [[DBG56]]
// PPC64-NEXT:    [[TMP57:%.*]] = mul i32 [[ATOMIC_TEMP38_IMAG]], [[ATOMIC_TEMP38_IMAG]], !dbg [[DBG56]]
// PPC64-NEXT:    [[TMP58:%.*]] = add i32 [[TMP56]], [[TMP57]], !dbg [[DBG56]]
// PPC64-NEXT:    [[TMP59:%.*]] = mul i32 [[CIV_IMAG]], [[ATOMIC_TEMP38_REAL]], !dbg [[DBG56]]
// PPC64-NEXT:    [[TMP60:%.*]] = mul i32 [[CIV_REAL]], [[ATOMIC_TEMP38_IMAG]], !dbg [[DBG56]]
// PPC64-NEXT:    [[TMP61:%.*]] = sub i32 [[TMP59]], [[TMP60]], !dbg [[DBG56]]
// PPC64-NEXT:    [[TMP62:%.*]] = sdiv i32 [[TMP55]], [[TMP58]], !dbg [[DBG56]]
// PPC64-NEXT:    [[TMP63:%.*]] = sdiv i32 [[TMP61]], [[TMP58]], !dbg [[DBG56]]
// PPC64-NEXT:    [[ATOMIC_TEMP40_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP40]], i32 0, i32 0, !dbg [[DBG55]]
// PPC64-NEXT:    [[ATOMIC_TEMP40_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP40]], i32 0, i32 1, !dbg [[DBG55]]
// PPC64-NEXT:    store i32 [[TMP62]], ptr [[ATOMIC_TEMP40_REALP]], align 4, !dbg [[DBG55]]
// PPC64-NEXT:    store i32 [[TMP63]], ptr [[ATOMIC_TEMP40_IMAGP]], align 4, !dbg [[DBG55]]
// PPC64-NEXT:    [[CALL41:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP38]], ptr noundef [[ATOMIC_TEMP40]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG55]]
// PPC64-NEXT:    br i1 [[CALL41]], label [[ATOMIC_EXIT42:%.*]], label [[ATOMIC_CONT39]], !dbg [[DBG55]]
// PPC64:       atomic_exit42:
// PPC64-NEXT:    [[CONV43:%.*]] = sitofp i32 [[TMP62]] to float, !dbg [[DBG55]]
// PPC64-NEXT:    [[CONV44:%.*]] = sitofp i32 [[TMP63]] to float, !dbg [[DBG55]]
// PPC64-NEXT:    store float [[CONV43]], ptr @cfv, align 4, !dbg [[DBG55]]
// PPC64-NEXT:    store float [[CONV44]], ptr getelementptr inbounds nuw ({ float, float }, ptr @cfv, i32 0, i32 1), align 4, !dbg [[DBG55]]
// PPC64-NEXT:    [[CFV_REAL:%.*]] = load float, ptr @cfv, align 4, !dbg [[DBG57:![0-9]+]]
// PPC64-NEXT:    [[CFV_IMAG:%.*]] = load float, ptr getelementptr inbounds nuw ({ float, float }, ptr @cfv, i32 0, i32 1), align 4, !dbg [[DBG57]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cfx, ptr noundef [[ATOMIC_TEMP45]], i32 noundef signext 0), !dbg [[DBG58:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT46:%.*]], !dbg [[DBG58]]
// PPC64:       atomic_cont46:
// PPC64-NEXT:    [[ATOMIC_TEMP45_REALP:%.*]] = getelementptr inbounds nuw { float, float }, ptr [[ATOMIC_TEMP45]], i32 0, i32 0, !dbg [[DBG58]]
// PPC64-NEXT:    [[ATOMIC_TEMP45_REAL:%.*]] = load float, ptr [[ATOMIC_TEMP45_REALP]], align 4, !dbg [[DBG58]]
// PPC64-NEXT:    [[ATOMIC_TEMP45_IMAGP:%.*]] = getelementptr inbounds nuw { float, float }, ptr [[ATOMIC_TEMP45]], i32 0, i32 1, !dbg [[DBG58]]
// PPC64-NEXT:    [[ATOMIC_TEMP45_IMAG:%.*]] = load float, ptr [[ATOMIC_TEMP45_IMAGP]], align 4, !dbg [[DBG58]]
// PPC64-NEXT:    [[ADD_R:%.*]] = fadd float [[CFV_REAL]], [[ATOMIC_TEMP45_REAL]], !dbg [[DBG59:![0-9]+]]
// PPC64-NEXT:    [[ADD_I:%.*]] = fadd float [[CFV_IMAG]], [[ATOMIC_TEMP45_IMAG]], !dbg [[DBG59]]
// PPC64-NEXT:    [[ATOMIC_TEMP47_REALP:%.*]] = getelementptr inbounds nuw { float, float }, ptr [[ATOMIC_TEMP47]], i32 0, i32 0, !dbg [[DBG58]]
// PPC64-NEXT:    [[ATOMIC_TEMP47_IMAGP:%.*]] = getelementptr inbounds nuw { float, float }, ptr [[ATOMIC_TEMP47]], i32 0, i32 1, !dbg [[DBG58]]
// PPC64-NEXT:    store float [[ADD_R]], ptr [[ATOMIC_TEMP47_REALP]], align 4, !dbg [[DBG58]]
// PPC64-NEXT:    store float [[ADD_I]], ptr [[ATOMIC_TEMP47_IMAGP]], align 4, !dbg [[DBG58]]
// PPC64-NEXT:    [[CALL48:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cfx, ptr noundef [[ATOMIC_TEMP45]], ptr noundef [[ATOMIC_TEMP47]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG58]]
// PPC64-NEXT:    br i1 [[CALL48]], label [[ATOMIC_EXIT49:%.*]], label [[ATOMIC_CONT46]], !dbg [[DBG58]]
// PPC64:       atomic_exit49:
// PPC64-NEXT:    [[CONV50:%.*]] = fptosi float [[ATOMIC_TEMP45_REAL]] to i32, !dbg [[DBG58]]
// PPC64-NEXT:    [[CONV51:%.*]] = fptosi float [[ATOMIC_TEMP45_IMAG]] to i32, !dbg [[DBG58]]
// PPC64-NEXT:    store i32 [[CONV50]], ptr @civ, align 4, !dbg [[DBG58]]
// PPC64-NEXT:    store i32 [[CONV51]], ptr getelementptr inbounds nuw ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG58]]
// PPC64-NEXT:    [[CDV_REAL:%.*]] = load double, ptr @cdv, align 8, !dbg [[DBG60:![0-9]+]]
// PPC64-NEXT:    [[CDV_IMAG:%.*]] = load double, ptr getelementptr inbounds nuw ({ double, double }, ptr @cdv, i32 0, i32 1), align 8, !dbg [[DBG60]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 16, ptr noundef @cdx, ptr noundef [[ATOMIC_TEMP52]], i32 noundef signext 5), !dbg [[DBG61:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT53:%.*]], !dbg [[DBG61]]
// PPC64:       atomic_cont53:
// PPC64-NEXT:    [[ATOMIC_TEMP52_REALP:%.*]] = getelementptr inbounds nuw { double, double }, ptr [[ATOMIC_TEMP52]], i32 0, i32 0, !dbg [[DBG61]]
// PPC64-NEXT:    [[ATOMIC_TEMP52_REAL:%.*]] = load double, ptr [[ATOMIC_TEMP52_REALP]], align 8, !dbg [[DBG61]]
// PPC64-NEXT:    [[ATOMIC_TEMP52_IMAGP:%.*]] = getelementptr inbounds nuw { double, double }, ptr [[ATOMIC_TEMP52]], i32 0, i32 1, !dbg [[DBG61]]
// PPC64-NEXT:    [[ATOMIC_TEMP52_IMAG:%.*]] = load double, ptr [[ATOMIC_TEMP52_IMAGP]], align 8, !dbg [[DBG61]]
// PPC64-NEXT:    [[SUB_R:%.*]] = fsub double [[ATOMIC_TEMP52_REAL]], [[CDV_REAL]], !dbg [[DBG62:![0-9]+]]
// PPC64-NEXT:    [[SUB_I:%.*]] = fsub double [[ATOMIC_TEMP52_IMAG]], [[CDV_IMAG]], !dbg [[DBG62]]
// PPC64-NEXT:    [[ATOMIC_TEMP54_REALP:%.*]] = getelementptr inbounds nuw { double, double }, ptr [[ATOMIC_TEMP54]], i32 0, i32 0, !dbg [[DBG61]]
// PPC64-NEXT:    [[ATOMIC_TEMP54_IMAGP:%.*]] = getelementptr inbounds nuw { double, double }, ptr [[ATOMIC_TEMP54]], i32 0, i32 1, !dbg [[DBG61]]
// PPC64-NEXT:    store double [[SUB_R]], ptr [[ATOMIC_TEMP54_REALP]], align 8, !dbg [[DBG61]]
// PPC64-NEXT:    store double [[SUB_I]], ptr [[ATOMIC_TEMP54_IMAGP]], align 8, !dbg [[DBG61]]
// PPC64-NEXT:    [[CALL55:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, ptr noundef @cdx, ptr noundef [[ATOMIC_TEMP52]], ptr noundef [[ATOMIC_TEMP54]], i32 noundef signext 5, i32 noundef signext 5), !dbg [[DBG61]]
// PPC64-NEXT:    br i1 [[CALL55]], label [[ATOMIC_EXIT56:%.*]], label [[ATOMIC_CONT53]], !dbg [[DBG61]]
// PPC64:       atomic_exit56:
// PPC64-NEXT:    [[CONV57:%.*]] = fptrunc double [[SUB_R]] to float, !dbg [[DBG61]]
// PPC64-NEXT:    [[CONV58:%.*]] = fptrunc double [[SUB_I]] to float, !dbg [[DBG61]]
// PPC64-NEXT:    store float [[CONV57]], ptr @cfv, align 4, !dbg [[DBG61]]
// PPC64-NEXT:    store float [[CONV58]], ptr getelementptr inbounds nuw ({ float, float }, ptr @cfv, i32 0, i32 1), align 4, !dbg [[DBG61]]
// PPC64-NEXT:    [[TMP64:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG63:![0-9]+]]
// PPC64-NEXT:    [[LOADEDV:%.*]] = trunc i8 [[TMP64]] to i1, !dbg [[DBG63]]
// PPC64-NEXT:    [[CONV59:%.*]] = zext i1 [[LOADEDV]] to i64, !dbg [[DBG63]]
// PPC64-NEXT:    [[TMP65:%.*]] = atomicrmw and ptr @ulx, i64 [[CONV59]] monotonic, align 8, !dbg [[DBG64:![0-9]+]]
// PPC64-NEXT:    [[AND60:%.*]] = and i64 [[TMP65]], [[CONV59]], !dbg [[DBG65:![0-9]+]]
// PPC64-NEXT:    store i64 [[AND60]], ptr @ulv, align 8, !dbg [[DBG64]]
// PPC64-NEXT:    [[TMP66:%.*]] = load i8, ptr @cv, align 1, !dbg [[DBG66:![0-9]+]]
// PPC64-NEXT:    [[CONV61:%.*]] = sext i8 [[TMP66]] to i32, !dbg [[DBG66]]
// PPC64-NEXT:    [[ATOMIC_LOAD62:%.*]] = load atomic i8, ptr @bx monotonic, align 1, !dbg [[DBG67:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT63:%.*]], !dbg [[DBG67]]
// PPC64:       atomic_cont63:
// PPC64-NEXT:    [[TMP67:%.*]] = phi i8 [ [[ATOMIC_LOAD62]], [[ATOMIC_EXIT56]] ], [ [[TMP70:%.*]], [[ATOMIC_CONT63]] ], !dbg [[DBG67]]
// PPC64-NEXT:    [[LOADEDV65:%.*]] = trunc i8 [[TMP67]] to i1, !dbg [[DBG67]]
// PPC64-NEXT:    [[CONV66:%.*]] = zext i1 [[LOADEDV65]] to i32, !dbg [[DBG68:![0-9]+]]
// PPC64-NEXT:    [[AND67:%.*]] = and i32 [[CONV61]], [[CONV66]], !dbg [[DBG69:![0-9]+]]
// PPC64-NEXT:    [[TOBOOL:%.*]] = icmp ne i32 [[AND67]], 0, !dbg [[DBG66]]
// PPC64-NEXT:    [[STOREDV:%.*]] = zext i1 [[TOBOOL]] to i8, !dbg [[DBG67]]
// PPC64-NEXT:    store i8 [[STOREDV]], ptr [[ATOMIC_TEMP64]], align 1, !dbg [[DBG67]]
// PPC64-NEXT:    [[TMP68:%.*]] = load i8, ptr [[ATOMIC_TEMP64]], align 1, !dbg [[DBG67]]
// PPC64-NEXT:    [[TMP69:%.*]] = cmpxchg ptr @bx, i8 [[TMP67]], i8 [[TMP68]] monotonic monotonic, align 1, !dbg [[DBG67]]
// PPC64-NEXT:    [[TMP70]] = extractvalue { i8, i1 } [[TMP69]], 0, !dbg [[DBG67]]
// PPC64-NEXT:    [[TMP71:%.*]] = extractvalue { i8, i1 } [[TMP69]], 1, !dbg [[DBG67]]
// PPC64-NEXT:    br i1 [[TMP71]], label [[ATOMIC_EXIT68:%.*]], label [[ATOMIC_CONT63]], !dbg [[DBG67]]
// PPC64:       atomic_exit68:
// PPC64-NEXT:    [[STOREDV69:%.*]] = zext i1 [[LOADEDV65]] to i8, !dbg [[DBG67]]
// PPC64-NEXT:    store i8 [[STOREDV69]], ptr @bv, align 1, !dbg [[DBG67]]
// PPC64-NEXT:    [[TMP72:%.*]] = load i8, ptr @ucv, align 1, !dbg [[DBG70:![0-9]+]]
// PPC64-NEXT:    [[CONV70:%.*]] = zext i8 [[TMP72]] to i32, !dbg [[DBG70]]
// PPC64-NEXT:    [[ATOMIC_LOAD71:%.*]] = load atomic i8, ptr @cx seq_cst, align 1, !dbg [[DBG71:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT72:%.*]], !dbg [[DBG71]]
// PPC64:       atomic_cont72:
// PPC64-NEXT:    [[TMP73:%.*]] = phi i8 [ [[ATOMIC_LOAD71]], [[ATOMIC_EXIT68]] ], [ [[TMP76:%.*]], [[ATOMIC_CONT72]] ], !dbg [[DBG71]]
// PPC64-NEXT:    [[CONV74:%.*]] = sext i8 [[TMP73]] to i32, !dbg [[DBG72:![0-9]+]]
// PPC64-NEXT:    [[SHR75:%.*]] = ashr i32 [[CONV74]], [[CONV70]], !dbg [[DBG73:![0-9]+]]
// PPC64-NEXT:    [[CONV76:%.*]] = trunc i32 [[SHR75]] to i8, !dbg [[DBG72]]
// PPC64-NEXT:    store i8 [[CONV76]], ptr [[ATOMIC_TEMP73]], align 1, !dbg [[DBG71]]
// PPC64-NEXT:    [[TMP74:%.*]] = load i8, ptr [[ATOMIC_TEMP73]], align 1, !dbg [[DBG71]]
// PPC64-NEXT:    [[TMP75:%.*]] = cmpxchg ptr @cx, i8 [[TMP73]], i8 [[TMP74]] seq_cst seq_cst, align 1, !dbg [[DBG71]]
// PPC64-NEXT:    [[TMP76]] = extractvalue { i8, i1 } [[TMP75]], 0, !dbg [[DBG71]]
// PPC64-NEXT:    [[TMP77:%.*]] = extractvalue { i8, i1 } [[TMP75]], 1, !dbg [[DBG71]]
// PPC64-NEXT:    br i1 [[TMP77]], label [[ATOMIC_EXIT77:%.*]], label [[ATOMIC_CONT72]], !dbg [[DBG71]]
// PPC64:       atomic_exit77:
// PPC64-NEXT:    store i8 [[CONV76]], ptr @cv, align 1, !dbg [[DBG71]]
// PPC64-NEXT:    [[TMP78:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG74:![0-9]+]]
// PPC64-NEXT:    [[CONV78:%.*]] = sext i16 [[TMP78]] to i32, !dbg [[DBG74]]
// PPC64-NEXT:    [[ATOMIC_LOAD79:%.*]] = load atomic i64, ptr @ulx monotonic, align 8, !dbg [[DBG75:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT80:%.*]], !dbg [[DBG75]]
// PPC64:       atomic_cont80:
// PPC64-NEXT:    [[TMP79:%.*]] = phi i64 [ [[ATOMIC_LOAD79]], [[ATOMIC_EXIT77]] ], [ [[TMP82:%.*]], [[ATOMIC_CONT80]] ], !dbg [[DBG75]]
// PPC64-NEXT:    [[SH_PROM:%.*]] = trunc i64 [[TMP79]] to i32, !dbg [[DBG76:![0-9]+]]
// PPC64-NEXT:    [[SHL82:%.*]] = shl i32 [[CONV78]], [[SH_PROM]], !dbg [[DBG76]]
// PPC64-NEXT:    [[CONV83:%.*]] = sext i32 [[SHL82]] to i64, !dbg [[DBG74]]
// PPC64-NEXT:    store i64 [[CONV83]], ptr [[ATOMIC_TEMP81]], align 8, !dbg [[DBG75]]
// PPC64-NEXT:    [[TMP80:%.*]] = load i64, ptr [[ATOMIC_TEMP81]], align 8, !dbg [[DBG75]]
// PPC64-NEXT:    [[TMP81:%.*]] = cmpxchg ptr @ulx, i64 [[TMP79]], i64 [[TMP80]] monotonic monotonic, align 8, !dbg [[DBG75]]
// PPC64-NEXT:    [[TMP82]] = extractvalue { i64, i1 } [[TMP81]], 0, !dbg [[DBG75]]
// PPC64-NEXT:    [[TMP83:%.*]] = extractvalue { i64, i1 } [[TMP81]], 1, !dbg [[DBG75]]
// PPC64-NEXT:    br i1 [[TMP83]], label [[ATOMIC_EXIT84:%.*]], label [[ATOMIC_CONT80]], !dbg [[DBG75]]
// PPC64:       atomic_exit84:
// PPC64-NEXT:    store i64 [[CONV83]], ptr @ulv, align 8, !dbg [[DBG75]]
// PPC64-NEXT:    [[TMP84:%.*]] = load i16, ptr @usv, align 2, !dbg [[DBG77:![0-9]+]]
// PPC64-NEXT:    [[CONV85:%.*]] = zext i16 [[TMP84]] to i64, !dbg [[DBG77]]
// PPC64-NEXT:    [[ATOMIC_LOAD86:%.*]] = load atomic i64, ptr @lx monotonic, align 8, !dbg [[DBG78:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT87:%.*]], !dbg [[DBG78]]
// PPC64:       atomic_cont87:
// PPC64-NEXT:    [[TMP85:%.*]] = phi i64 [ [[ATOMIC_LOAD86]], [[ATOMIC_EXIT84]] ], [ [[TMP88:%.*]], [[ATOMIC_CONT87]] ], !dbg [[DBG78]]
// PPC64-NEXT:    [[REM:%.*]] = srem i64 [[TMP85]], [[CONV85]], !dbg [[DBG79:![0-9]+]]
// PPC64-NEXT:    store i64 [[REM]], ptr [[ATOMIC_TEMP88]], align 8, !dbg [[DBG78]]
// PPC64-NEXT:    [[TMP86:%.*]] = load i64, ptr [[ATOMIC_TEMP88]], align 8, !dbg [[DBG78]]
// PPC64-NEXT:    [[TMP87:%.*]] = cmpxchg ptr @lx, i64 [[TMP85]], i64 [[TMP86]] monotonic monotonic, align 8, !dbg [[DBG78]]
// PPC64-NEXT:    [[TMP88]] = extractvalue { i64, i1 } [[TMP87]], 0, !dbg [[DBG78]]
// PPC64-NEXT:    [[TMP89:%.*]] = extractvalue { i64, i1 } [[TMP87]], 1, !dbg [[DBG78]]
// PPC64-NEXT:    br i1 [[TMP89]], label [[ATOMIC_EXIT89:%.*]], label [[ATOMIC_CONT87]], !dbg [[DBG78]]
// PPC64:       atomic_exit89:
// PPC64-NEXT:    store i64 [[TMP85]], ptr @lv, align 8, !dbg [[DBG78]]
// PPC64-NEXT:    [[TMP90:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG80:![0-9]+]]
// PPC64-NEXT:    [[TMP91:%.*]] = atomicrmw or ptr @uix, i32 [[TMP90]] seq_cst, align 4, !dbg [[DBG81:![0-9]+]]
// PPC64-NEXT:    [[OR90:%.*]] = or i32 [[TMP90]], [[TMP91]], !dbg [[DBG82:![0-9]+]]
// PPC64-NEXT:    store i32 [[OR90]], ptr @uiv, align 4, !dbg [[DBG81]]
// PPC64-NEXT:    [[TMP92:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG83:![0-9]+]]
// PPC64-NEXT:    [[TMP93:%.*]] = atomicrmw and ptr @ix, i32 [[TMP92]] monotonic, align 4, !dbg [[DBG84:![0-9]+]]
// PPC64-NEXT:    [[AND91:%.*]] = and i32 [[TMP93]], [[TMP92]], !dbg [[DBG85:![0-9]+]]
// PPC64-NEXT:    store i32 [[AND91]], ptr @iv, align 4, !dbg [[DBG84]]
// PPC64-NEXT:    [[TMP94:%.*]] = load i64, ptr @lv, align 8, !dbg [[DBG86:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP92]], i32 noundef signext 0), !dbg [[DBG87:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT93:%.*]], !dbg [[DBG87]]
// PPC64:       atomic_cont93:
// PPC64-NEXT:    [[ATOMIC_TEMP92_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP92]], i32 0, i32 0, !dbg [[DBG87]]
// PPC64-NEXT:    [[ATOMIC_TEMP92_REAL:%.*]] = load i32, ptr [[ATOMIC_TEMP92_REALP]], align 4, !dbg [[DBG87]]
// PPC64-NEXT:    [[ATOMIC_TEMP92_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP92]], i32 0, i32 1, !dbg [[DBG87]]
// PPC64-NEXT:    [[ATOMIC_TEMP92_IMAG:%.*]] = load i32, ptr [[ATOMIC_TEMP92_IMAGP]], align 4, !dbg [[DBG87]]
// PPC64-NEXT:    [[CONV95:%.*]] = sext i32 [[ATOMIC_TEMP92_REAL]] to i64, !dbg [[DBG88:![0-9]+]]
// PPC64-NEXT:    [[CONV96:%.*]] = sext i32 [[ATOMIC_TEMP92_IMAG]] to i64, !dbg [[DBG88]]
// PPC64-NEXT:    [[ADD_R97:%.*]] = add i64 [[TMP94]], [[CONV95]], !dbg [[DBG89:![0-9]+]]
// PPC64-NEXT:    [[ADD_I98:%.*]] = add i64 0, [[CONV96]], !dbg [[DBG89]]
// PPC64-NEXT:    [[CONV99:%.*]] = trunc i64 [[ADD_R97]] to i32, !dbg [[DBG86]]
// PPC64-NEXT:    [[CONV100:%.*]] = trunc i64 [[ADD_I98]] to i32, !dbg [[DBG86]]
// PPC64-NEXT:    [[ATOMIC_TEMP94_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP94]], i32 0, i32 0, !dbg [[DBG87]]
// PPC64-NEXT:    [[ATOMIC_TEMP94_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP94]], i32 0, i32 1, !dbg [[DBG87]]
// PPC64-NEXT:    store i32 [[CONV99]], ptr [[ATOMIC_TEMP94_REALP]], align 4, !dbg [[DBG87]]
// PPC64-NEXT:    store i32 [[CONV100]], ptr [[ATOMIC_TEMP94_IMAGP]], align 4, !dbg [[DBG87]]
// PPC64-NEXT:    [[CALL101:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP92]], ptr noundef [[ATOMIC_TEMP94]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG87]]
// PPC64-NEXT:    br i1 [[CALL101]], label [[ATOMIC_EXIT102:%.*]], label [[ATOMIC_CONT93]], !dbg [[DBG87]]
// PPC64:       atomic_exit102:
// PPC64-NEXT:    store i32 [[ATOMIC_TEMP92_REAL]], ptr @civ, align 4, !dbg [[DBG87]]
// PPC64-NEXT:    store i32 [[ATOMIC_TEMP92_IMAG]], ptr getelementptr inbounds nuw ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG87]]
// PPC64-NEXT:    [[TMP95:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG90:![0-9]+]]
// PPC64-NEXT:    [[CONV103:%.*]] = uitofp i64 [[TMP95]] to float, !dbg [[DBG90]]
// PPC64-NEXT:    [[ATOMIC_LOAD104:%.*]] = load atomic i32, ptr @fx monotonic, align 4, !dbg [[DBG91:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT105:%.*]], !dbg [[DBG91]]
// PPC64:       atomic_cont105:
// PPC64-NEXT:    [[TMP96:%.*]] = phi i32 [ [[ATOMIC_LOAD104]], [[ATOMIC_EXIT102]] ], [ [[TMP100:%.*]], [[ATOMIC_CONT105]] ], !dbg [[DBG91]]
// PPC64-NEXT:    [[TMP97:%.*]] = bitcast i32 [[TMP96]] to float, !dbg [[DBG91]]
// PPC64-NEXT:    [[MUL107:%.*]] = fmul float [[TMP97]], [[CONV103]], !dbg [[DBG92:![0-9]+]]
// PPC64-NEXT:    store float [[MUL107]], ptr [[ATOMIC_TEMP106]], align 4, !dbg [[DBG91]]
// PPC64-NEXT:    [[TMP98:%.*]] = load i32, ptr [[ATOMIC_TEMP106]], align 4, !dbg [[DBG91]]
// PPC64-NEXT:    [[TMP99:%.*]] = cmpxchg ptr @fx, i32 [[TMP96]], i32 [[TMP98]] monotonic monotonic, align 4, !dbg [[DBG91]]
// PPC64-NEXT:    [[TMP100]] = extractvalue { i32, i1 } [[TMP99]], 0, !dbg [[DBG91]]
// PPC64-NEXT:    [[TMP101:%.*]] = extractvalue { i32, i1 } [[TMP99]], 1, !dbg [[DBG91]]
// PPC64-NEXT:    br i1 [[TMP101]], label [[ATOMIC_EXIT108:%.*]], label [[ATOMIC_CONT105]], !dbg [[DBG91]]
// PPC64:       atomic_exit108:
// PPC64-NEXT:    store float [[MUL107]], ptr @fv, align 4, !dbg [[DBG91]]
// PPC64-NEXT:    [[TMP102:%.*]] = load i64, ptr @llv, align 8, !dbg [[DBG93:![0-9]+]]
// PPC64-NEXT:    [[CONV109:%.*]] = sitofp i64 [[TMP102]] to double, !dbg [[DBG93]]
// PPC64-NEXT:    [[ATOMIC_LOAD110:%.*]] = load atomic i64, ptr @dx monotonic, align 8, !dbg [[DBG94:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT111:%.*]], !dbg [[DBG94]]
// PPC64:       atomic_cont111:
// PPC64-NEXT:    [[TMP103:%.*]] = phi i64 [ [[ATOMIC_LOAD110]], [[ATOMIC_EXIT108]] ], [ [[TMP107:%.*]], [[ATOMIC_CONT111]] ], !dbg [[DBG94]]
// PPC64-NEXT:    [[TMP104:%.*]] = bitcast i64 [[TMP103]] to double, !dbg [[DBG94]]
// PPC64-NEXT:    [[DIV113:%.*]] = fdiv double [[TMP104]], [[CONV109]], !dbg [[DBG95:![0-9]+]]
// PPC64-NEXT:    store double [[DIV113]], ptr [[ATOMIC_TEMP112]], align 8, !dbg [[DBG94]]
// PPC64-NEXT:    [[TMP105:%.*]] = load i64, ptr [[ATOMIC_TEMP112]], align 8, !dbg [[DBG94]]
// PPC64-NEXT:    [[TMP106:%.*]] = cmpxchg ptr @dx, i64 [[TMP103]], i64 [[TMP105]] monotonic monotonic, align 8, !dbg [[DBG94]]
// PPC64-NEXT:    [[TMP107]] = extractvalue { i64, i1 } [[TMP106]], 0, !dbg [[DBG94]]
// PPC64-NEXT:    [[TMP108:%.*]] = extractvalue { i64, i1 } [[TMP106]], 1, !dbg [[DBG94]]
// PPC64-NEXT:    br i1 [[TMP108]], label [[ATOMIC_EXIT114:%.*]], label [[ATOMIC_CONT111]], !dbg [[DBG94]]
// PPC64:       atomic_exit114:
// PPC64-NEXT:    store double [[DIV113]], ptr @dv, align 8, !dbg [[DBG94]]
// PPC64-NEXT:    [[TMP109:%.*]] = load i64, ptr @ullv, align 8, !dbg [[DBG96:![0-9]+]]
// PPC64-NEXT:    [[CONV115:%.*]] = uitofp i64 [[TMP109]] to ppc_fp128, !dbg [[DBG96]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 16, ptr noundef @ldx, ptr noundef [[ATOMIC_TEMP116]], i32 noundef signext 0), !dbg [[DBG97:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT117:%.*]], !dbg [[DBG97]]
// PPC64:       atomic_cont117:
// PPC64-NEXT:    [[TMP110:%.*]] = load ppc_fp128, ptr [[ATOMIC_TEMP116]], align 16, !dbg [[DBG97]]
// PPC64-NEXT:    [[SUB119:%.*]] = fsub ppc_fp128 [[TMP110]], [[CONV115]], !dbg [[DBG98:![0-9]+]]
// PPC64-NEXT:    store ppc_fp128 [[SUB119]], ptr [[ATOMIC_TEMP118]], align 16, !dbg [[DBG97]]
// PPC64-NEXT:    [[CALL120:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, ptr noundef @ldx, ptr noundef [[ATOMIC_TEMP116]], ptr noundef [[ATOMIC_TEMP118]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG97]]
// PPC64-NEXT:    br i1 [[CALL120]], label [[ATOMIC_EXIT121:%.*]], label [[ATOMIC_CONT117]], !dbg [[DBG97]]
// PPC64:       atomic_exit121:
// PPC64-NEXT:    store ppc_fp128 [[TMP110]], ptr @ldv, align 16, !dbg [[DBG97]]
// PPC64-NEXT:    [[TMP111:%.*]] = load float, ptr @fv, align 4, !dbg [[DBG99:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP122]], i32 noundef signext 0), !dbg [[DBG100:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT123:%.*]], !dbg [[DBG100]]
// PPC64:       atomic_cont123:
// PPC64-NEXT:    [[ATOMIC_TEMP122_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP122]], i32 0, i32 0, !dbg [[DBG100]]
// PPC64-NEXT:    [[ATOMIC_TEMP122_REAL:%.*]] = load i32, ptr [[ATOMIC_TEMP122_REALP]], align 4, !dbg [[DBG100]]
// PPC64-NEXT:    [[ATOMIC_TEMP122_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP122]], i32 0, i32 1, !dbg [[DBG100]]
// PPC64-NEXT:    [[ATOMIC_TEMP122_IMAG:%.*]] = load i32, ptr [[ATOMIC_TEMP122_IMAGP]], align 4, !dbg [[DBG100]]
// PPC64-NEXT:    [[CONV125:%.*]] = sitofp i32 [[ATOMIC_TEMP122_REAL]] to float, !dbg [[DBG101:![0-9]+]]
// PPC64-NEXT:    [[CONV126:%.*]] = sitofp i32 [[ATOMIC_TEMP122_IMAG]] to float, !dbg [[DBG101]]
// PPC64-NEXT:    [[CALL127:%.*]] = call { float, float } @__divsc3(float noundef [[TMP111]], float noundef 0.000000e+00, float noundef [[CONV125]], float noundef [[CONV126]]) #[[ATTR2:[0-9]+]], !dbg [[DBG102:![0-9]+]]
// PPC64-NEXT:    [[TMP112:%.*]] = extractvalue { float, float } [[CALL127]], 0, !dbg [[DBG102]]
// PPC64-NEXT:    [[TMP113:%.*]] = extractvalue { float, float } [[CALL127]], 1, !dbg [[DBG102]]
// PPC64-NEXT:    [[CONV128:%.*]] = fptosi float [[TMP112]] to i32, !dbg [[DBG99]]
// PPC64-NEXT:    [[CONV129:%.*]] = fptosi float [[TMP113]] to i32, !dbg [[DBG99]]
// PPC64-NEXT:    [[ATOMIC_TEMP124_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP124]], i32 0, i32 0, !dbg [[DBG100]]
// PPC64-NEXT:    [[ATOMIC_TEMP124_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP124]], i32 0, i32 1, !dbg [[DBG100]]
// PPC64-NEXT:    store i32 [[CONV128]], ptr [[ATOMIC_TEMP124_REALP]], align 4, !dbg [[DBG100]]
// PPC64-NEXT:    store i32 [[CONV129]], ptr [[ATOMIC_TEMP124_IMAGP]], align 4, !dbg [[DBG100]]
// PPC64-NEXT:    [[CALL130:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP122]], ptr noundef [[ATOMIC_TEMP124]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG100]]
// PPC64-NEXT:    br i1 [[CALL130]], label [[ATOMIC_EXIT131:%.*]], label [[ATOMIC_CONT123]], !dbg [[DBG100]]
// PPC64:       atomic_exit131:
// PPC64-NEXT:    store i32 [[CONV128]], ptr @civ, align 4, !dbg [[DBG100]]
// PPC64-NEXT:    store i32 [[CONV129]], ptr getelementptr inbounds nuw ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG100]]
// PPC64-NEXT:    [[TMP114:%.*]] = load double, ptr @dv, align 8, !dbg [[DBG103:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD132:%.*]] = load atomic i16, ptr @sx monotonic, align 2, !dbg [[DBG104:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT133:%.*]], !dbg [[DBG104]]
// PPC64:       atomic_cont133:
// PPC64-NEXT:    [[TMP115:%.*]] = phi i16 [ [[ATOMIC_LOAD132]], [[ATOMIC_EXIT131]] ], [ [[TMP118:%.*]], [[ATOMIC_CONT133]] ], !dbg [[DBG104]]
// PPC64-NEXT:    [[CONV135:%.*]] = sext i16 [[TMP115]] to i32, !dbg [[DBG105:![0-9]+]]
// PPC64-NEXT:    [[CONV136:%.*]] = sitofp i32 [[CONV135]] to double, !dbg [[DBG105]]
// PPC64-NEXT:    [[ADD137:%.*]] = fadd double [[CONV136]], [[TMP114]], !dbg [[DBG106:![0-9]+]]
// PPC64-NEXT:    [[CONV138:%.*]] = fptosi double [[ADD137]] to i16, !dbg [[DBG105]]
// PPC64-NEXT:    store i16 [[CONV138]], ptr [[ATOMIC_TEMP134]], align 2, !dbg [[DBG104]]
// PPC64-NEXT:    [[TMP116:%.*]] = load i16, ptr [[ATOMIC_TEMP134]], align 2, !dbg [[DBG104]]
// PPC64-NEXT:    [[TMP117:%.*]] = cmpxchg ptr @sx, i16 [[TMP115]], i16 [[TMP116]] monotonic monotonic, align 2, !dbg [[DBG104]]
// PPC64-NEXT:    [[TMP118]] = extractvalue { i16, i1 } [[TMP117]], 0, !dbg [[DBG104]]
// PPC64-NEXT:    [[TMP119:%.*]] = extractvalue { i16, i1 } [[TMP117]], 1, !dbg [[DBG104]]
// PPC64-NEXT:    br i1 [[TMP119]], label [[ATOMIC_EXIT139:%.*]], label [[ATOMIC_CONT133]], !dbg [[DBG104]]
// PPC64:       atomic_exit139:
// PPC64-NEXT:    store i16 [[CONV138]], ptr @sv, align 2, !dbg [[DBG104]]
// PPC64-NEXT:    [[TMP120:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG107:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD140:%.*]] = load atomic i8, ptr @bx monotonic, align 1, !dbg [[DBG108:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT141:%.*]], !dbg [[DBG108]]
// PPC64:       atomic_cont141:
// PPC64-NEXT:    [[TMP121:%.*]] = phi i8 [ [[ATOMIC_LOAD140]], [[ATOMIC_EXIT139]] ], [ [[TMP124:%.*]], [[ATOMIC_CONT141]] ], !dbg [[DBG108]]
// PPC64-NEXT:    [[LOADEDV143:%.*]] = trunc i8 [[TMP121]] to i1, !dbg [[DBG108]]
// PPC64-NEXT:    [[CONV144:%.*]] = zext i1 [[LOADEDV143]] to i32, !dbg [[DBG109:![0-9]+]]
// PPC64-NEXT:    [[CONV145:%.*]] = sitofp i32 [[CONV144]] to ppc_fp128, !dbg [[DBG109]]
// PPC64-NEXT:    [[MUL146:%.*]] = fmul ppc_fp128 [[TMP120]], [[CONV145]], !dbg [[DBG110:![0-9]+]]
// PPC64-NEXT:    [[TOBOOL147:%.*]] = fcmp une ppc_fp128 [[MUL146]], 0xM00000000000000000000000000000000, !dbg [[DBG107]]
// PPC64-NEXT:    [[STOREDV148:%.*]] = zext i1 [[TOBOOL147]] to i8, !dbg [[DBG108]]
// PPC64-NEXT:    store i8 [[STOREDV148]], ptr [[ATOMIC_TEMP142]], align 1, !dbg [[DBG108]]
// PPC64-NEXT:    [[TMP122:%.*]] = load i8, ptr [[ATOMIC_TEMP142]], align 1, !dbg [[DBG108]]
// PPC64-NEXT:    [[TMP123:%.*]] = cmpxchg ptr @bx, i8 [[TMP121]], i8 [[TMP122]] monotonic monotonic, align 1, !dbg [[DBG108]]
// PPC64-NEXT:    [[TMP124]] = extractvalue { i8, i1 } [[TMP123]], 0, !dbg [[DBG108]]
// PPC64-NEXT:    [[TMP125:%.*]] = extractvalue { i8, i1 } [[TMP123]], 1, !dbg [[DBG108]]
// PPC64-NEXT:    br i1 [[TMP125]], label [[ATOMIC_EXIT149:%.*]], label [[ATOMIC_CONT141]], !dbg [[DBG108]]
// PPC64:       atomic_exit149:
// PPC64-NEXT:    [[STOREDV150:%.*]] = zext i1 [[LOADEDV143]] to i8, !dbg [[DBG108]]
// PPC64-NEXT:    store i8 [[STOREDV150]], ptr @bv, align 1, !dbg [[DBG108]]
// PPC64-NEXT:    [[CIV_REAL151:%.*]] = load i32, ptr @civ, align 4, !dbg [[DBG111:![0-9]+]]
// PPC64-NEXT:    [[CIV_IMAG152:%.*]] = load i32, ptr getelementptr inbounds nuw ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG111]]
// PPC64-NEXT:    [[ATOMIC_LOAD153:%.*]] = load atomic i8, ptr @bx monotonic, align 1, !dbg [[DBG112:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT154:%.*]], !dbg [[DBG112]]
// PPC64:       atomic_cont154:
// PPC64-NEXT:    [[TMP126:%.*]] = phi i8 [ [[ATOMIC_LOAD153]], [[ATOMIC_EXIT149]] ], [ [[TMP129:%.*]], [[ATOMIC_CONT154]] ], !dbg [[DBG112]]
// PPC64-NEXT:    [[LOADEDV156:%.*]] = trunc i8 [[TMP126]] to i1, !dbg [[DBG112]]
// PPC64-NEXT:    [[CONV157:%.*]] = zext i1 [[LOADEDV156]] to i32, !dbg [[DBG113:![0-9]+]]
// PPC64-NEXT:    [[SUB_R158:%.*]] = sub i32 [[CIV_REAL151]], [[CONV157]], !dbg [[DBG114:![0-9]+]]
// PPC64-NEXT:    [[SUB_I159:%.*]] = sub i32 [[CIV_IMAG152]], 0, !dbg [[DBG114]]
// PPC64-NEXT:    [[TOBOOL160:%.*]] = icmp ne i32 [[SUB_R158]], 0, !dbg [[DBG111]]
// PPC64-NEXT:    [[TOBOOL161:%.*]] = icmp ne i32 [[SUB_I159]], 0, !dbg [[DBG111]]
// PPC64-NEXT:    [[TOBOOL162:%.*]] = or i1 [[TOBOOL160]], [[TOBOOL161]], !dbg [[DBG111]]
// PPC64-NEXT:    [[STOREDV163:%.*]] = zext i1 [[TOBOOL162]] to i8, !dbg [[DBG112]]
// PPC64-NEXT:    store i8 [[STOREDV163]], ptr [[ATOMIC_TEMP155]], align 1, !dbg [[DBG112]]
// PPC64-NEXT:    [[TMP127:%.*]] = load i8, ptr [[ATOMIC_TEMP155]], align 1, !dbg [[DBG112]]
// PPC64-NEXT:    [[TMP128:%.*]] = cmpxchg ptr @bx, i8 [[TMP126]], i8 [[TMP127]] monotonic monotonic, align 1, !dbg [[DBG112]]
// PPC64-NEXT:    [[TMP129]] = extractvalue { i8, i1 } [[TMP128]], 0, !dbg [[DBG112]]
// PPC64-NEXT:    [[TMP130:%.*]] = extractvalue { i8, i1 } [[TMP128]], 1, !dbg [[DBG112]]
// PPC64-NEXT:    br i1 [[TMP130]], label [[ATOMIC_EXIT164:%.*]], label [[ATOMIC_CONT154]], !dbg [[DBG112]]
// PPC64:       atomic_exit164:
// PPC64-NEXT:    [[STOREDV165:%.*]] = zext i1 [[TOBOOL162]] to i8, !dbg [[DBG112]]
// PPC64-NEXT:    store i8 [[STOREDV165]], ptr @bv, align 1, !dbg [[DBG112]]
// PPC64-NEXT:    [[TMP131:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG115:![0-9]+]]
// PPC64-NEXT:    [[TMP132:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG116:![0-9]+]]
// PPC64-NEXT:    [[LOADEDV166:%.*]] = trunc i8 [[TMP132]] to i1, !dbg [[DBG116]]
// PPC64-NEXT:    [[CONV167:%.*]] = zext i1 [[LOADEDV166]] to i32, !dbg [[DBG116]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 16, ptr noundef @int4x, ptr noundef [[ATOMIC_TEMP168]], i32 noundef signext 0), !dbg [[DBG117:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT169:%.*]], !dbg [[DBG117]]
// PPC64:       atomic_cont169:
// PPC64-NEXT:    [[TMP133:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP168]], align 16, !dbg [[DBG117]]
// PPC64-NEXT:    store <4 x i32> [[TMP133]], ptr [[ATOMIC_TEMP170]], align 16, !dbg [[DBG117]]
// PPC64-NEXT:    [[TMP134:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP168]], align 16, !dbg [[DBG117]]
// PPC64-NEXT:    store <4 x i32> [[TMP134]], ptr [[ATOMIC_TEMP171]], align 16, !dbg [[DBG117]]
// PPC64-NEXT:    [[TMP135:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP171]], align 16, !dbg [[DBG117]]
// PPC64-NEXT:    [[VECEXT:%.*]] = extractelement <4 x i32> [[TMP135]], i16 [[TMP131]], !dbg [[DBG117]]
// PPC64-NEXT:    [[OR172:%.*]] = or i32 [[VECEXT]], [[CONV167]], !dbg [[DBG118:![0-9]+]]
// PPC64-NEXT:    [[TMP136:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP170]], align 16, !dbg [[DBG117]]
// PPC64-NEXT:    [[VECINS:%.*]] = insertelement <4 x i32> [[TMP136]], i32 [[OR172]], i16 [[TMP131]], !dbg [[DBG117]]
// PPC64-NEXT:    store <4 x i32> [[VECINS]], ptr [[ATOMIC_TEMP170]], align 16, !dbg [[DBG117]]
// PPC64-NEXT:    [[CALL173:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 16, ptr noundef @int4x, ptr noundef [[ATOMIC_TEMP168]], ptr noundef [[ATOMIC_TEMP170]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG117]]
// PPC64-NEXT:    br i1 [[CALL173]], label [[ATOMIC_EXIT174:%.*]], label [[ATOMIC_CONT169]], !dbg [[DBG117]]
// PPC64:       atomic_exit174:
// PPC64-NEXT:    store i32 [[OR172]], ptr @iv, align 4, !dbg [[DBG117]]
// PPC64-NEXT:    [[TMP137:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG119:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD175:%.*]] = load atomic i32, ptr @bfx monotonic, align 4, !dbg [[DBG120:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT176:%.*]], !dbg [[DBG120]]
// PPC64:       atomic_cont176:
// PPC64-NEXT:    [[TMP138:%.*]] = phi i32 [ [[ATOMIC_LOAD175]], [[ATOMIC_EXIT174]] ], [ [[TMP141:%.*]], [[ATOMIC_CONT176]] ], !dbg [[DBG120]]
// PPC64-NEXT:    store i32 [[TMP138]], ptr [[ATOMIC_TEMP177]], align 4, !dbg [[DBG120]]
// PPC64-NEXT:    store i32 [[TMP138]], ptr [[ATOMIC_TEMP178]], align 4, !dbg [[DBG120]]
// PPC64-NEXT:    [[BF_LOAD:%.*]] = load i32, ptr [[ATOMIC_TEMP178]], align 4, !dbg [[DBG120]]
// PPC64-NEXT:    [[BF_ASHR:%.*]] = ashr i32 [[BF_LOAD]], 1, !dbg [[DBG120]]
// PPC64-NEXT:    [[CONV179:%.*]] = sitofp i32 [[BF_ASHR]] to ppc_fp128, !dbg [[DBG121:![0-9]+]]
// PPC64-NEXT:    [[SUB180:%.*]] = fsub ppc_fp128 [[CONV179]], [[TMP137]], !dbg [[DBG122:![0-9]+]]
// PPC64-NEXT:    [[CONV181:%.*]] = fptosi ppc_fp128 [[SUB180]] to i32, !dbg [[DBG121]]
// PPC64-NEXT:    [[BF_LOAD182:%.*]] = load i32, ptr [[ATOMIC_TEMP177]], align 4, !dbg [[DBG120]]
// PPC64-NEXT:    [[BF_VALUE:%.*]] = and i32 [[CONV181]], 2147483647, !dbg [[DBG120]]
// PPC64-NEXT:    [[BF_SHL:%.*]] = shl i32 [[BF_VALUE]], 1, !dbg [[DBG120]]
// PPC64-NEXT:    [[BF_CLEAR:%.*]] = and i32 [[BF_LOAD182]], 1, !dbg [[DBG120]]
// PPC64-NEXT:    [[BF_SET:%.*]] = or i32 [[BF_CLEAR]], [[BF_SHL]], !dbg [[DBG120]]
// PPC64-NEXT:    store i32 [[BF_SET]], ptr [[ATOMIC_TEMP177]], align 4, !dbg [[DBG120]]
// PPC64-NEXT:    [[TMP139:%.*]] = load i32, ptr [[ATOMIC_TEMP177]], align 4, !dbg [[DBG120]]
// PPC64-NEXT:    [[TMP140:%.*]] = cmpxchg ptr @bfx, i32 [[TMP138]], i32 [[TMP139]] monotonic monotonic, align 4, !dbg [[DBG120]]
// PPC64-NEXT:    [[TMP141]] = extractvalue { i32, i1 } [[TMP140]], 0, !dbg [[DBG120]]
// PPC64-NEXT:    [[TMP142:%.*]] = extractvalue { i32, i1 } [[TMP140]], 1, !dbg [[DBG120]]
// PPC64-NEXT:    br i1 [[TMP142]], label [[ATOMIC_EXIT183:%.*]], label [[ATOMIC_CONT176]], !dbg [[DBG120]]
// PPC64:       atomic_exit183:
// PPC64-NEXT:    store i32 [[CONV181]], ptr @iv, align 4, !dbg [[DBG120]]
// PPC64-NEXT:    [[TMP143:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG123:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 4, ptr noundef @bfx_packed, ptr noundef [[ATOMIC_TEMP184]], i32 noundef signext 0), !dbg [[DBG124:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT185:%.*]], !dbg [[DBG124]]
// PPC64:       atomic_cont185:
// PPC64-NEXT:    [[TMP144:%.*]] = load i32, ptr [[ATOMIC_TEMP184]], align 1, !dbg [[DBG124]]
// PPC64-NEXT:    store i32 [[TMP144]], ptr [[ATOMIC_TEMP186]], align 1, !dbg [[DBG124]]
// PPC64-NEXT:    [[TMP145:%.*]] = load i32, ptr [[ATOMIC_TEMP184]], align 1, !dbg [[DBG124]]
// PPC64-NEXT:    store i32 [[TMP145]], ptr [[ATOMIC_TEMP187]], align 4, !dbg [[DBG124]]
// PPC64-NEXT:    [[BF_LOAD188:%.*]] = load i32, ptr [[ATOMIC_TEMP187]], align 1, !dbg [[DBG124]]
// PPC64-NEXT:    [[BF_ASHR189:%.*]] = ashr i32 [[BF_LOAD188]], 1, !dbg [[DBG124]]
// PPC64-NEXT:    [[CONV190:%.*]] = sitofp i32 [[BF_ASHR189]] to ppc_fp128, !dbg [[DBG125:![0-9]+]]
// PPC64-NEXT:    [[MUL191:%.*]] = fmul ppc_fp128 [[CONV190]], [[TMP143]], !dbg [[DBG126:![0-9]+]]
// PPC64-NEXT:    [[CONV192:%.*]] = fptosi ppc_fp128 [[MUL191]] to i32, !dbg [[DBG125]]
// PPC64-NEXT:    [[BF_LOAD193:%.*]] = load i32, ptr [[ATOMIC_TEMP186]], align 1, !dbg [[DBG124]]
// PPC64-NEXT:    [[BF_VALUE194:%.*]] = and i32 [[CONV192]], 2147483647, !dbg [[DBG124]]
// PPC64-NEXT:    [[BF_SHL195:%.*]] = shl i32 [[BF_VALUE194]], 1, !dbg [[DBG124]]
// PPC64-NEXT:    [[BF_CLEAR196:%.*]] = and i32 [[BF_LOAD193]], 1, !dbg [[DBG124]]
// PPC64-NEXT:    [[BF_SET197:%.*]] = or i32 [[BF_CLEAR196]], [[BF_SHL195]], !dbg [[DBG124]]
// PPC64-NEXT:    store i32 [[BF_SET197]], ptr [[ATOMIC_TEMP186]], align 1, !dbg [[DBG124]]
// PPC64-NEXT:    [[CALL198:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 4, ptr noundef @bfx_packed, ptr noundef [[ATOMIC_TEMP184]], ptr noundef [[ATOMIC_TEMP186]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG124]]
// PPC64-NEXT:    br i1 [[CALL198]], label [[ATOMIC_EXIT199:%.*]], label [[ATOMIC_CONT185]], !dbg [[DBG124]]
// PPC64:       atomic_exit199:
// PPC64-NEXT:    store i32 [[BF_ASHR189]], ptr @iv, align 4, !dbg [[DBG124]]
// PPC64-NEXT:    [[TMP146:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG127:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD200:%.*]] = load atomic i32, ptr @bfx2 monotonic, align 4, !dbg [[DBG128:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT201:%.*]], !dbg [[DBG128]]
// PPC64:       atomic_cont201:
// PPC64-NEXT:    [[TMP147:%.*]] = phi i32 [ [[ATOMIC_LOAD200]], [[ATOMIC_EXIT199]] ], [ [[TMP150:%.*]], [[ATOMIC_CONT201]] ], !dbg [[DBG128]]
// PPC64-NEXT:    store i32 [[TMP147]], ptr [[ATOMIC_TEMP202]], align 4, !dbg [[DBG128]]
// PPC64-NEXT:    store i32 [[TMP147]], ptr [[ATOMIC_TEMP203]], align 4, !dbg [[DBG128]]
// PPC64-NEXT:    [[BF_LOAD204:%.*]] = load i32, ptr [[ATOMIC_TEMP203]], align 4, !dbg [[DBG128]]
// PPC64-NEXT:    [[BF_SHL205:%.*]] = shl i32 [[BF_LOAD204]], 31, !dbg [[DBG128]]
// PPC64-NEXT:    [[BF_ASHR206:%.*]] = ashr i32 [[BF_SHL205]], 31, !dbg [[DBG128]]
// PPC64-NEXT:    [[CONV207:%.*]] = sitofp i32 [[BF_ASHR206]] to ppc_fp128, !dbg [[DBG129:![0-9]+]]
// PPC64-NEXT:    [[SUB208:%.*]] = fsub ppc_fp128 [[CONV207]], [[TMP146]], !dbg [[DBG130:![0-9]+]]
// PPC64-NEXT:    [[CONV209:%.*]] = fptosi ppc_fp128 [[SUB208]] to i32, !dbg [[DBG129]]
// PPC64-NEXT:    [[BF_LOAD210:%.*]] = load i32, ptr [[ATOMIC_TEMP202]], align 4, !dbg [[DBG128]]
// PPC64-NEXT:    [[BF_VALUE211:%.*]] = and i32 [[CONV209]], 1, !dbg [[DBG128]]
// PPC64-NEXT:    [[BF_CLEAR212:%.*]] = and i32 [[BF_LOAD210]], -2, !dbg [[DBG128]]
// PPC64-NEXT:    [[BF_SET213:%.*]] = or i32 [[BF_CLEAR212]], [[BF_VALUE211]], !dbg [[DBG128]]
// PPC64-NEXT:    store i32 [[BF_SET213]], ptr [[ATOMIC_TEMP202]], align 4, !dbg [[DBG128]]
// PPC64-NEXT:    [[TMP148:%.*]] = load i32, ptr [[ATOMIC_TEMP202]], align 4, !dbg [[DBG128]]
// PPC64-NEXT:    [[TMP149:%.*]] = cmpxchg ptr @bfx2, i32 [[TMP147]], i32 [[TMP148]] monotonic monotonic, align 4, !dbg [[DBG128]]
// PPC64-NEXT:    [[TMP150]] = extractvalue { i32, i1 } [[TMP149]], 0, !dbg [[DBG128]]
// PPC64-NEXT:    [[TMP151:%.*]] = extractvalue { i32, i1 } [[TMP149]], 1, !dbg [[DBG128]]
// PPC64-NEXT:    br i1 [[TMP151]], label [[ATOMIC_EXIT214:%.*]], label [[ATOMIC_CONT201]], !dbg [[DBG128]]
// PPC64:       atomic_exit214:
// PPC64-NEXT:    store i32 [[CONV209]], ptr @iv, align 4, !dbg [[DBG128]]
// PPC64-NEXT:    [[TMP152:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG131:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD215:%.*]] = load atomic i8, ptr @bfx2_packed monotonic, align 1, !dbg [[DBG132:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT216:%.*]], !dbg [[DBG132]]
// PPC64:       atomic_cont216:
// PPC64-NEXT:    [[TMP153:%.*]] = phi i8 [ [[ATOMIC_LOAD215]], [[ATOMIC_EXIT214]] ], [ [[TMP157:%.*]], [[ATOMIC_CONT216]] ], !dbg [[DBG132]]
// PPC64-NEXT:    store i8 [[TMP153]], ptr [[ATOMIC_TEMP217]], align 1, !dbg [[DBG132]]
// PPC64-NEXT:    store i8 [[TMP153]], ptr [[ATOMIC_TEMP218]], align 1, !dbg [[DBG132]]
// PPC64-NEXT:    [[BF_LOAD219:%.*]] = load i8, ptr [[ATOMIC_TEMP218]], align 1, !dbg [[DBG132]]
// PPC64-NEXT:    [[BF_SHL220:%.*]] = shl i8 [[BF_LOAD219]], 7, !dbg [[DBG132]]
// PPC64-NEXT:    [[BF_ASHR221:%.*]] = ashr i8 [[BF_SHL220]], 7, !dbg [[DBG132]]
// PPC64-NEXT:    [[BF_CAST:%.*]] = sext i8 [[BF_ASHR221]] to i32, !dbg [[DBG132]]
// PPC64-NEXT:    [[CONV222:%.*]] = sitofp i32 [[BF_CAST]] to ppc_fp128, !dbg [[DBG133:![0-9]+]]
// PPC64-NEXT:    [[DIV223:%.*]] = fdiv ppc_fp128 [[TMP152]], [[CONV222]], !dbg [[DBG134:![0-9]+]]
// PPC64-NEXT:    [[CONV224:%.*]] = fptosi ppc_fp128 [[DIV223]] to i32, !dbg [[DBG131]]
// PPC64-NEXT:    [[TMP154:%.*]] = trunc i32 [[CONV224]] to i8, !dbg [[DBG132]]
// PPC64-NEXT:    [[BF_LOAD225:%.*]] = load i8, ptr [[ATOMIC_TEMP217]], align 1, !dbg [[DBG132]]
// PPC64-NEXT:    [[BF_VALUE226:%.*]] = and i8 [[TMP154]], 1, !dbg [[DBG132]]
// PPC64-NEXT:    [[BF_CLEAR227:%.*]] = and i8 [[BF_LOAD225]], -2, !dbg [[DBG132]]
// PPC64-NEXT:    [[BF_SET228:%.*]] = or i8 [[BF_CLEAR227]], [[BF_VALUE226]], !dbg [[DBG132]]
// PPC64-NEXT:    store i8 [[BF_SET228]], ptr [[ATOMIC_TEMP217]], align 1, !dbg [[DBG132]]
// PPC64-NEXT:    [[TMP155:%.*]] = load i8, ptr [[ATOMIC_TEMP217]], align 1, !dbg [[DBG132]]
// PPC64-NEXT:    [[TMP156:%.*]] = cmpxchg ptr @bfx2_packed, i8 [[TMP153]], i8 [[TMP155]] monotonic monotonic, align 1, !dbg [[DBG132]]
// PPC64-NEXT:    [[TMP157]] = extractvalue { i8, i1 } [[TMP156]], 0, !dbg [[DBG132]]
// PPC64-NEXT:    [[TMP158:%.*]] = extractvalue { i8, i1 } [[TMP156]], 1, !dbg [[DBG132]]
// PPC64-NEXT:    br i1 [[TMP158]], label [[ATOMIC_EXIT229:%.*]], label [[ATOMIC_CONT216]], !dbg [[DBG132]]
// PPC64:       atomic_exit229:
// PPC64-NEXT:    store i32 [[CONV224]], ptr @iv, align 4, !dbg [[DBG132]]
// PPC64-NEXT:    [[TMP159:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG135:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD230:%.*]] = load atomic i32, ptr @bfx3 monotonic, align 4, !dbg [[DBG136:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT231:%.*]], !dbg [[DBG136]]
// PPC64:       atomic_cont231:
// PPC64-NEXT:    [[TMP160:%.*]] = phi i32 [ [[ATOMIC_LOAD230]], [[ATOMIC_EXIT229]] ], [ [[TMP163:%.*]], [[ATOMIC_CONT231]] ], !dbg [[DBG136]]
// PPC64-NEXT:    store i32 [[TMP160]], ptr [[ATOMIC_TEMP232]], align 4, !dbg [[DBG136]]
// PPC64-NEXT:    store i32 [[TMP160]], ptr [[ATOMIC_TEMP233]], align 4, !dbg [[DBG136]]
// PPC64-NEXT:    [[BF_LOAD234:%.*]] = load i32, ptr [[ATOMIC_TEMP233]], align 4, !dbg [[DBG136]]
// PPC64-NEXT:    [[BF_SHL235:%.*]] = shl i32 [[BF_LOAD234]], 11, !dbg [[DBG136]]
// PPC64-NEXT:    [[BF_ASHR236:%.*]] = ashr i32 [[BF_SHL235]], 18, !dbg [[DBG136]]
// PPC64-NEXT:    [[CONV237:%.*]] = sitofp i32 [[BF_ASHR236]] to ppc_fp128, !dbg [[DBG137:![0-9]+]]
// PPC64-NEXT:    [[DIV238:%.*]] = fdiv ppc_fp128 [[CONV237]], [[TMP159]], !dbg [[DBG138:![0-9]+]]
// PPC64-NEXT:    [[CONV239:%.*]] = fptosi ppc_fp128 [[DIV238]] to i32, !dbg [[DBG137]]
// PPC64-NEXT:    [[BF_LOAD240:%.*]] = load i32, ptr [[ATOMIC_TEMP232]], align 4, !dbg [[DBG136]]
// PPC64-NEXT:    [[BF_VALUE241:%.*]] = and i32 [[CONV239]], 16383, !dbg [[DBG136]]
// PPC64-NEXT:    [[BF_SHL242:%.*]] = shl i32 [[BF_VALUE241]], 7, !dbg [[DBG136]]
// PPC64-NEXT:    [[BF_CLEAR243:%.*]] = and i32 [[BF_LOAD240]], -2097025, !dbg [[DBG136]]
// PPC64-NEXT:    [[BF_SET244:%.*]] = or i32 [[BF_CLEAR243]], [[BF_SHL242]], !dbg [[DBG136]]
// PPC64-NEXT:    store i32 [[BF_SET244]], ptr [[ATOMIC_TEMP232]], align 4, !dbg [[DBG136]]
// PPC64-NEXT:    [[TMP161:%.*]] = load i32, ptr [[ATOMIC_TEMP232]], align 4, !dbg [[DBG136]]
// PPC64-NEXT:    [[TMP162:%.*]] = cmpxchg ptr @bfx3, i32 [[TMP160]], i32 [[TMP161]] monotonic monotonic, align 4, !dbg [[DBG136]]
// PPC64-NEXT:    [[TMP163]] = extractvalue { i32, i1 } [[TMP162]], 0, !dbg [[DBG136]]
// PPC64-NEXT:    [[TMP164:%.*]] = extractvalue { i32, i1 } [[TMP162]], 1, !dbg [[DBG136]]
// PPC64-NEXT:    br i1 [[TMP164]], label [[ATOMIC_EXIT245:%.*]], label [[ATOMIC_CONT231]], !dbg [[DBG136]]
// PPC64:       atomic_exit245:
// PPC64-NEXT:    store i32 [[BF_ASHR236]], ptr @iv, align 4, !dbg [[DBG136]]
// PPC64-NEXT:    [[TMP165:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG139:![0-9]+]]
// PPC64-NEXT:    call void @__atomic_load(i64 noundef 3, ptr noundef @bfx3_packed, ptr noundef [[ATOMIC_TEMP246]], i32 noundef signext 0), !dbg [[DBG140:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT247:%.*]], !dbg [[DBG140]]
// PPC64:       atomic_cont247:
// PPC64-NEXT:    [[TMP166:%.*]] = load i24, ptr [[ATOMIC_TEMP246]], align 1, !dbg [[DBG140]]
// PPC64-NEXT:    store i24 [[TMP166]], ptr [[ATOMIC_TEMP248]], align 1, !dbg [[DBG140]]
// PPC64-NEXT:    [[TMP167:%.*]] = load i24, ptr [[ATOMIC_TEMP246]], align 1, !dbg [[DBG140]]
// PPC64-NEXT:    store i24 [[TMP167]], ptr [[ATOMIC_TEMP249]], align 1, !dbg [[DBG140]]
// PPC64-NEXT:    [[BF_LOAD250:%.*]] = load i24, ptr [[ATOMIC_TEMP249]], align 1, !dbg [[DBG140]]
// PPC64-NEXT:    [[BF_SHL251:%.*]] = shl i24 [[BF_LOAD250]], 3, !dbg [[DBG140]]
// PPC64-NEXT:    [[BF_ASHR252:%.*]] = ashr i24 [[BF_SHL251]], 10, !dbg [[DBG140]]
// PPC64-NEXT:    [[BF_CAST253:%.*]] = sext i24 [[BF_ASHR252]] to i32, !dbg [[DBG140]]
// PPC64-NEXT:    [[CONV254:%.*]] = sitofp i32 [[BF_CAST253]] to ppc_fp128, !dbg [[DBG141:![0-9]+]]
// PPC64-NEXT:    [[ADD255:%.*]] = fadd ppc_fp128 [[CONV254]], [[TMP165]], !dbg [[DBG142:![0-9]+]]
// PPC64-NEXT:    [[CONV256:%.*]] = fptosi ppc_fp128 [[ADD255]] to i32, !dbg [[DBG141]]
// PPC64-NEXT:    [[TMP168:%.*]] = trunc i32 [[CONV256]] to i24, !dbg [[DBG140]]
// PPC64-NEXT:    [[BF_LOAD257:%.*]] = load i24, ptr [[ATOMIC_TEMP248]], align 1, !dbg [[DBG140]]
// PPC64-NEXT:    [[BF_VALUE258:%.*]] = and i24 [[TMP168]], 16383, !dbg [[DBG140]]
// PPC64-NEXT:    [[BF_SHL259:%.*]] = shl i24 [[BF_VALUE258]], 7, !dbg [[DBG140]]
// PPC64-NEXT:    [[BF_CLEAR260:%.*]] = and i24 [[BF_LOAD257]], -2097025, !dbg [[DBG140]]
// PPC64-NEXT:    [[BF_SET261:%.*]] = or i24 [[BF_CLEAR260]], [[BF_SHL259]], !dbg [[DBG140]]
// PPC64-NEXT:    store i24 [[BF_SET261]], ptr [[ATOMIC_TEMP248]], align 1, !dbg [[DBG140]]
// PPC64-NEXT:    [[CALL262:%.*]] = call zeroext i1 @__atomic_compare_exchange(i64 noundef 3, ptr noundef @bfx3_packed, ptr noundef [[ATOMIC_TEMP246]], ptr noundef [[ATOMIC_TEMP248]], i32 noundef signext 0, i32 noundef signext 0), !dbg [[DBG140]]
// PPC64-NEXT:    br i1 [[CALL262]], label [[ATOMIC_EXIT263:%.*]], label [[ATOMIC_CONT247]], !dbg [[DBG140]]
// PPC64:       atomic_exit263:
// PPC64-NEXT:    store i32 [[CONV256]], ptr @iv, align 4, !dbg [[DBG140]]
// PPC64-NEXT:    [[TMP169:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG143:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD264:%.*]] = load atomic i64, ptr @bfx4 monotonic, align 8, !dbg [[DBG144:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT265:%.*]], !dbg [[DBG144]]
// PPC64:       atomic_cont265:
// PPC64-NEXT:    [[TMP170:%.*]] = phi i64 [ [[ATOMIC_LOAD264]], [[ATOMIC_EXIT263]] ], [ [[TMP174:%.*]], [[ATOMIC_CONT265]] ], !dbg [[DBG144]]
// PPC64-NEXT:    store i64 [[TMP170]], ptr [[ATOMIC_TEMP266]], align 8, !dbg [[DBG144]]
// PPC64-NEXT:    store i64 [[TMP170]], ptr [[ATOMIC_TEMP267]], align 8, !dbg [[DBG144]]
// PPC64-NEXT:    [[BF_LOAD268:%.*]] = load i64, ptr [[ATOMIC_TEMP267]], align 8, !dbg [[DBG144]]
// PPC64-NEXT:    [[BF_SHL269:%.*]] = shl i64 [[BF_LOAD268]], 48, !dbg [[DBG144]]
// PPC64-NEXT:    [[BF_ASHR270:%.*]] = ashr i64 [[BF_SHL269]], 63, !dbg [[DBG144]]
// PPC64-NEXT:    [[BF_CAST271:%.*]] = trunc i64 [[BF_ASHR270]] to i32, !dbg [[DBG144]]
// PPC64-NEXT:    [[CONV272:%.*]] = sitofp i32 [[BF_CAST271]] to ppc_fp128, !dbg [[DBG145:![0-9]+]]
// PPC64-NEXT:    [[MUL273:%.*]] = fmul ppc_fp128 [[CONV272]], [[TMP169]], !dbg [[DBG146:![0-9]+]]
// PPC64-NEXT:    [[CONV274:%.*]] = fptosi ppc_fp128 [[MUL273]] to i32, !dbg [[DBG145]]
// PPC64-NEXT:    [[TMP171:%.*]] = zext i32 [[CONV274]] to i64, !dbg [[DBG144]]
// PPC64-NEXT:    [[BF_LOAD275:%.*]] = load i64, ptr [[ATOMIC_TEMP266]], align 8, !dbg [[DBG144]]
// PPC64-NEXT:    [[BF_VALUE276:%.*]] = and i64 [[TMP171]], 1, !dbg [[DBG144]]
// PPC64-NEXT:    [[BF_SHL277:%.*]] = shl i64 [[BF_VALUE276]], 15, !dbg [[DBG144]]
// PPC64-NEXT:    [[BF_CLEAR278:%.*]] = and i64 [[BF_LOAD275]], -32769, !dbg [[DBG144]]
// PPC64-NEXT:    [[BF_SET279:%.*]] = or i64 [[BF_CLEAR278]], [[BF_SHL277]], !dbg [[DBG144]]
// PPC64-NEXT:    store i64 [[BF_SET279]], ptr [[ATOMIC_TEMP266]], align 8, !dbg [[DBG144]]
// PPC64-NEXT:    [[TMP172:%.*]] = load i64, ptr [[ATOMIC_TEMP266]], align 8, !dbg [[DBG144]]
// PPC64-NEXT:    [[TMP173:%.*]] = cmpxchg ptr @bfx4, i64 [[TMP170]], i64 [[TMP172]] monotonic monotonic, align 8, !dbg [[DBG144]]
// PPC64-NEXT:    [[TMP174]] = extractvalue { i64, i1 } [[TMP173]], 0, !dbg [[DBG144]]
// PPC64-NEXT:    [[TMP175:%.*]] = extractvalue { i64, i1 } [[TMP173]], 1, !dbg [[DBG144]]
// PPC64-NEXT:    br i1 [[TMP175]], label [[ATOMIC_EXIT280:%.*]], label [[ATOMIC_CONT265]], !dbg [[DBG144]]
// PPC64:       atomic_exit280:
// PPC64-NEXT:    store i32 [[CONV274]], ptr @iv, align 4, !dbg [[DBG144]]
// PPC64-NEXT:    [[TMP176:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG147:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD281:%.*]] = load atomic i8, ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED:%.*]], ptr @bfx4_packed, i32 0, i32 1) monotonic, align 1, !dbg [[DBG148:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT282:%.*]], !dbg [[DBG148]]
// PPC64:       atomic_cont282:
// PPC64-NEXT:    [[TMP177:%.*]] = phi i8 [ [[ATOMIC_LOAD281]], [[ATOMIC_EXIT280]] ], [ [[TMP181:%.*]], [[ATOMIC_CONT282]] ], !dbg [[DBG148]]
// PPC64-NEXT:    store i8 [[TMP177]], ptr [[ATOMIC_TEMP283]], align 1, !dbg [[DBG148]]
// PPC64-NEXT:    store i8 [[TMP177]], ptr [[ATOMIC_TEMP284]], align 1, !dbg [[DBG148]]
// PPC64-NEXT:    [[BF_LOAD285:%.*]] = load i8, ptr [[ATOMIC_TEMP284]], align 1, !dbg [[DBG148]]
// PPC64-NEXT:    [[BF_ASHR286:%.*]] = ashr i8 [[BF_LOAD285]], 7, !dbg [[DBG148]]
// PPC64-NEXT:    [[BF_CAST287:%.*]] = sext i8 [[BF_ASHR286]] to i32, !dbg [[DBG148]]
// PPC64-NEXT:    [[CONV288:%.*]] = sitofp i32 [[BF_CAST287]] to ppc_fp128, !dbg [[DBG149:![0-9]+]]
// PPC64-NEXT:    [[SUB289:%.*]] = fsub ppc_fp128 [[CONV288]], [[TMP176]], !dbg [[DBG150:![0-9]+]]
// PPC64-NEXT:    [[CONV290:%.*]] = fptosi ppc_fp128 [[SUB289]] to i32, !dbg [[DBG149]]
// PPC64-NEXT:    [[TMP178:%.*]] = trunc i32 [[CONV290]] to i8, !dbg [[DBG148]]
// PPC64-NEXT:    [[BF_LOAD291:%.*]] = load i8, ptr [[ATOMIC_TEMP283]], align 1, !dbg [[DBG148]]
// PPC64-NEXT:    [[BF_VALUE292:%.*]] = and i8 [[TMP178]], 1, !dbg [[DBG148]]
// PPC64-NEXT:    [[BF_SHL293:%.*]] = shl i8 [[BF_VALUE292]], 7, !dbg [[DBG148]]
// PPC64-NEXT:    [[BF_CLEAR294:%.*]] = and i8 [[BF_LOAD291]], 127, !dbg [[DBG148]]
// PPC64-NEXT:    [[BF_SET295:%.*]] = or i8 [[BF_CLEAR294]], [[BF_SHL293]], !dbg [[DBG148]]
// PPC64-NEXT:    store i8 [[BF_SET295]], ptr [[ATOMIC_TEMP283]], align 1, !dbg [[DBG148]]
// PPC64-NEXT:    [[TMP179:%.*]] = load i8, ptr [[ATOMIC_TEMP283]], align 1, !dbg [[DBG148]]
// PPC64-NEXT:    [[TMP180:%.*]] = cmpxchg ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1), i8 [[TMP177]], i8 [[TMP179]] monotonic monotonic, align 1, !dbg [[DBG148]]
// PPC64-NEXT:    [[TMP181]] = extractvalue { i8, i1 } [[TMP180]], 0, !dbg [[DBG148]]
// PPC64-NEXT:    [[TMP182:%.*]] = extractvalue { i8, i1 } [[TMP180]], 1, !dbg [[DBG148]]
// PPC64-NEXT:    br i1 [[TMP182]], label [[ATOMIC_EXIT296:%.*]], label [[ATOMIC_CONT282]], !dbg [[DBG148]]
// PPC64:       atomic_exit296:
// PPC64-NEXT:    store i32 [[BF_CAST287]], ptr @iv, align 4, !dbg [[DBG148]]
// PPC64-NEXT:    [[TMP183:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG151:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD297:%.*]] = load atomic i64, ptr @bfx4 monotonic, align 8, !dbg [[DBG152:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT298:%.*]], !dbg [[DBG152]]
// PPC64:       atomic_cont298:
// PPC64-NEXT:    [[TMP184:%.*]] = phi i64 [ [[ATOMIC_LOAD297]], [[ATOMIC_EXIT296]] ], [ [[TMP187:%.*]], [[ATOMIC_CONT298]] ], !dbg [[DBG152]]
// PPC64-NEXT:    store i64 [[TMP184]], ptr [[ATOMIC_TEMP299]], align 8, !dbg [[DBG152]]
// PPC64-NEXT:    store i64 [[TMP184]], ptr [[ATOMIC_TEMP300]], align 8, !dbg [[DBG152]]
// PPC64-NEXT:    [[BF_LOAD301:%.*]] = load i64, ptr [[ATOMIC_TEMP300]], align 8, !dbg [[DBG152]]
// PPC64-NEXT:    [[BF_SHL302:%.*]] = shl i64 [[BF_LOAD301]], 49, !dbg [[DBG152]]
// PPC64-NEXT:    [[BF_ASHR303:%.*]] = ashr i64 [[BF_SHL302]], 57, !dbg [[DBG152]]
// PPC64-NEXT:    [[CONV304:%.*]] = sitofp i64 [[BF_ASHR303]] to ppc_fp128, !dbg [[DBG153:![0-9]+]]
// PPC64-NEXT:    [[DIV305:%.*]] = fdiv ppc_fp128 [[CONV304]], [[TMP183]], !dbg [[DBG154:![0-9]+]]
// PPC64-NEXT:    [[CONV306:%.*]] = fptosi ppc_fp128 [[DIV305]] to i64, !dbg [[DBG153]]
// PPC64-NEXT:    [[BF_LOAD307:%.*]] = load i64, ptr [[ATOMIC_TEMP299]], align 8, !dbg [[DBG152]]
// PPC64-NEXT:    [[BF_VALUE308:%.*]] = and i64 [[CONV306]], 127, !dbg [[DBG152]]
// PPC64-NEXT:    [[BF_SHL309:%.*]] = shl i64 [[BF_VALUE308]], 8, !dbg [[DBG152]]
// PPC64-NEXT:    [[BF_CLEAR310:%.*]] = and i64 [[BF_LOAD307]], -32513, !dbg [[DBG152]]
// PPC64-NEXT:    [[BF_SET311:%.*]] = or i64 [[BF_CLEAR310]], [[BF_SHL309]], !dbg [[DBG152]]
// PPC64-NEXT:    store i64 [[BF_SET311]], ptr [[ATOMIC_TEMP299]], align 8, !dbg [[DBG152]]
// PPC64-NEXT:    [[TMP185:%.*]] = load i64, ptr [[ATOMIC_TEMP299]], align 8, !dbg [[DBG152]]
// PPC64-NEXT:    [[TMP186:%.*]] = cmpxchg ptr @bfx4, i64 [[TMP184]], i64 [[TMP185]] release monotonic, align 8, !dbg [[DBG152]]
// PPC64-NEXT:    [[TMP187]] = extractvalue { i64, i1 } [[TMP186]], 0, !dbg [[DBG152]]
// PPC64-NEXT:    [[TMP188:%.*]] = extractvalue { i64, i1 } [[TMP186]], 1, !dbg [[DBG152]]
// PPC64-NEXT:    br i1 [[TMP188]], label [[ATOMIC_EXIT312:%.*]], label [[ATOMIC_CONT298]], !dbg [[DBG152]]
// PPC64:       atomic_exit312:
// PPC64-NEXT:    [[CONV313:%.*]] = trunc i64 [[CONV306]] to i32, !dbg [[DBG152]]
// PPC64-NEXT:    store i32 [[CONV313]], ptr @iv, align 4, !dbg [[DBG152]]
// PPC64-NEXT:    [[TMP189:%.*]] = load ppc_fp128, ptr @ldv, align 16, !dbg [[DBG155:![0-9]+]]
// PPC64-NEXT:    [[ATOMIC_LOAD314:%.*]] = load atomic i8, ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1) acquire, align 1, !dbg [[DBG156:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT315:%.*]], !dbg [[DBG156]]
// PPC64:       atomic_cont315:
// PPC64-NEXT:    [[TMP190:%.*]] = phi i8 [ [[ATOMIC_LOAD314]], [[ATOMIC_EXIT312]] ], [ [[TMP194:%.*]], [[ATOMIC_CONT315]] ], !dbg [[DBG156]]
// PPC64-NEXT:    store i8 [[TMP190]], ptr [[ATOMIC_TEMP316]], align 1, !dbg [[DBG156]]
// PPC64-NEXT:    store i8 [[TMP190]], ptr [[ATOMIC_TEMP317]], align 1, !dbg [[DBG156]]
// PPC64-NEXT:    [[BF_LOAD318:%.*]] = load i8, ptr [[ATOMIC_TEMP317]], align 1, !dbg [[DBG156]]
// PPC64-NEXT:    [[BF_SHL319:%.*]] = shl i8 [[BF_LOAD318]], 1, !dbg [[DBG156]]
// PPC64-NEXT:    [[BF_ASHR320:%.*]] = ashr i8 [[BF_SHL319]], 1, !dbg [[DBG156]]
// PPC64-NEXT:    [[BF_CAST321:%.*]] = sext i8 [[BF_ASHR320]] to i64, !dbg [[DBG156]]
// PPC64-NEXT:    [[CONV322:%.*]] = sitofp i64 [[BF_CAST321]] to ppc_fp128, !dbg [[DBG157:![0-9]+]]
// PPC64-NEXT:    [[ADD323:%.*]] = fadd ppc_fp128 [[CONV322]], [[TMP189]], !dbg [[DBG158:![0-9]+]]
// PPC64-NEXT:    [[CONV324:%.*]] = fptosi ppc_fp128 [[ADD323]] to i64, !dbg [[DBG157]]
// PPC64-NEXT:    [[TMP191:%.*]] = trunc i64 [[CONV324]] to i8, !dbg [[DBG156]]
// PPC64-NEXT:    [[BF_LOAD325:%.*]] = load i8, ptr [[ATOMIC_TEMP316]], align 1, !dbg [[DBG156]]
// PPC64-NEXT:    [[BF_VALUE326:%.*]] = and i8 [[TMP191]], 127, !dbg [[DBG156]]
// PPC64-NEXT:    [[BF_CLEAR327:%.*]] = and i8 [[BF_LOAD325]], -128, !dbg [[DBG156]]
// PPC64-NEXT:    [[BF_SET328:%.*]] = or i8 [[BF_CLEAR327]], [[BF_VALUE326]], !dbg [[DBG156]]
// PPC64-NEXT:    store i8 [[BF_SET328]], ptr [[ATOMIC_TEMP316]], align 1, !dbg [[DBG156]]
// PPC64-NEXT:    [[TMP192:%.*]] = load i8, ptr [[ATOMIC_TEMP316]], align 1, !dbg [[DBG156]]
// PPC64-NEXT:    [[TMP193:%.*]] = cmpxchg ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1), i8 [[TMP190]], i8 [[TMP192]] acquire acquire, align 1, !dbg [[DBG156]]
// PPC64-NEXT:    [[TMP194]] = extractvalue { i8, i1 } [[TMP193]], 0, !dbg [[DBG156]]
// PPC64-NEXT:    [[TMP195:%.*]] = extractvalue { i8, i1 } [[TMP193]], 1, !dbg [[DBG156]]
// PPC64-NEXT:    br i1 [[TMP195]], label [[ATOMIC_EXIT329:%.*]], label [[ATOMIC_CONT315]], !dbg [[DBG156]]
// PPC64:       atomic_exit329:
// PPC64-NEXT:    [[CONV330:%.*]] = trunc i64 [[CONV324]] to i32, !dbg [[DBG156]]
// PPC64-NEXT:    store i32 [[CONV330]], ptr @iv, align 4, !dbg [[DBG156]]
// PPC64-NEXT:    [[TMP196:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG159:![0-9]+]]
// PPC64-NEXT:    [[CONV331:%.*]] = uitofp i64 [[TMP196]] to float, !dbg [[DBG159]]
// PPC64-NEXT:    [[ATOMIC_LOAD332:%.*]] = load atomic i64, ptr @float2x acquire, align 8, !dbg [[DBG160:![0-9]+]]
// PPC64-NEXT:    br label [[ATOMIC_CONT333:%.*]], !dbg [[DBG160]]
// PPC64:       atomic_cont333:
// PPC64-NEXT:    [[TMP197:%.*]] = phi i64 [ [[ATOMIC_LOAD332]], [[ATOMIC_EXIT329]] ], [ [[TMP205:%.*]], [[ATOMIC_CONT333]] ], !dbg [[DBG160]]
// PPC64-NEXT:    store i64 [[TMP197]], ptr [[ATOMIC_TEMP334]], align 8, !dbg [[DBG160]]
// PPC64-NEXT:    [[TMP198:%.*]] = bitcast i64 [[TMP197]] to <2 x float>, !dbg [[DBG160]]
// PPC64-NEXT:    store <2 x float> [[TMP198]], ptr [[ATOMIC_TEMP335]], align 8, !dbg [[DBG160]]
// PPC64-NEXT:    [[TMP199:%.*]] = load <2 x float>, ptr [[ATOMIC_TEMP335]], align 8, !dbg [[DBG160]]
// PPC64-NEXT:    [[TMP200:%.*]] = extractelement <2 x float> [[TMP199]], i64 0, !dbg [[DBG160]]
// PPC64-NEXT:    [[SUB336:%.*]] = fsub float [[CONV331]], [[TMP200]], !dbg [[DBG161:![0-9]+]]
// PPC64-NEXT:    [[TMP201:%.*]] = load <2 x float>, ptr [[ATOMIC_TEMP334]], align 8, !dbg [[DBG160]]
// PPC64-NEXT:    [[TMP202:%.*]] = insertelement <2 x float> [[TMP201]], float [[SUB336]], i64 0, !dbg [[DBG160]]
// PPC64-NEXT:    store <2 x float> [[TMP202]], ptr [[ATOMIC_TEMP334]], align 8, !dbg [[DBG160]]
// PPC64-NEXT:    [[TMP203:%.*]] = load i64, ptr [[ATOMIC_TEMP334]], align 8, !dbg [[DBG160]]
// PPC64-NEXT:    [[TMP204:%.*]] = cmpxchg ptr @float2x, i64 [[TMP197]], i64 [[TMP203]] acq_rel acquire, align 8, !dbg [[DBG160]]
// PPC64-NEXT:    [[TMP205]] = extractvalue { i64, i1 } [[TMP204]], 0, !dbg [[DBG160]]
// PPC64-NEXT:    [[TMP206:%.*]] = extractvalue { i64, i1 } [[TMP204]], 1, !dbg [[DBG160]]
// PPC64-NEXT:    br i1 [[TMP206]], label [[ATOMIC_EXIT337:%.*]], label [[ATOMIC_CONT333]], !dbg [[DBG160]]
// PPC64:       atomic_exit337:
// PPC64-NEXT:    store float [[TMP200]], ptr @fv, align 4, !dbg [[DBG160]]
// PPC64-NEXT:    ret i32 0, !dbg [[DBG162:![0-9]+]]
//
//
// AARCH64-LABEL: define {{[^@]+}}@main
// AARCH64-SAME: () #[[ATTR0:[0-9]+]] !dbg [[DBG5:![0-9]+]] {
// AARCH64-NEXT:  entry:
// AARCH64-NEXT:    [[RETVAL:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca i16, align 2
// AARCH64-NEXT:    [[ATOMIC_TEMP10:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP14:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP18:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP22:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP28:%.*]] = alloca double, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP34:%.*]] = alloca fp128, align 16
// AARCH64-NEXT:    [[ATOMIC_TEMP38:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP40:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP44:%.*]] = alloca { float, float }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP46:%.*]] = alloca { float, float }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP51:%.*]] = alloca { double, double }, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP53:%.*]] = alloca { double, double }, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP63:%.*]] = alloca i8, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP72:%.*]] = alloca i8, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP80:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP87:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP91:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP93:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP105:%.*]] = alloca float, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP111:%.*]] = alloca double, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP115:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP117:%.*]] = alloca { i32, i32 }, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP127:%.*]] = alloca i16, align 2
// AARCH64-NEXT:    [[ATOMIC_TEMP135:%.*]] = alloca i8, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP148:%.*]] = alloca i8, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP163:%.*]] = alloca <4 x i32>, align 16
// AARCH64-NEXT:    [[ATOMIC_TEMP164:%.*]] = alloca <4 x i32>, align 16
// AARCH64-NEXT:    [[ATOMIC_TEMP169:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP170:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP176:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP178:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP179:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP194:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP195:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP209:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP210:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP224:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP225:%.*]] = alloca i32, align 4
// AARCH64-NEXT:    [[ATOMIC_TEMP238:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP240:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP241:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP258:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP259:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP275:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP276:%.*]] = alloca i32, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP291:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP292:%.*]] = alloca i64, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP308:%.*]] = alloca i64, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP309:%.*]] = alloca i64, align 1
// AARCH64-NEXT:    [[ATOMIC_TEMP326:%.*]] = alloca <2 x float>, align 8
// AARCH64-NEXT:    [[ATOMIC_TEMP327:%.*]] = alloca <2 x float>, align 8
// AARCH64-NEXT:    store i32 0, ptr [[RETVAL]], align 4
// AARCH64-NEXT:    [[TMP0:%.*]] = atomicrmw add ptr @bx, i8 1 monotonic, align 1, !dbg [[DBG9:![0-9]+]]
// AARCH64-NEXT:    store i8 [[TMP0]], ptr @bv, align 1, !dbg [[DBG9]]
// AARCH64-NEXT:    [[TMP1:%.*]] = atomicrmw add ptr @cx, i8 1 monotonic, align 1, !dbg [[DBG10:![0-9]+]]
// AARCH64-NEXT:    [[CONV:%.*]] = sext i8 [[TMP1]] to i32, !dbg [[DBG11:![0-9]+]]
// AARCH64-NEXT:    [[ADD:%.*]] = add nsw i32 [[CONV]], 1, !dbg [[DBG12:![0-9]+]]
// AARCH64-NEXT:    [[CONV1:%.*]] = trunc i32 [[ADD]] to i8, !dbg [[DBG11]]
// AARCH64-NEXT:    store i8 [[CONV1]], ptr @cv, align 1, !dbg [[DBG10]]
// AARCH64-NEXT:    [[TMP2:%.*]] = atomicrmw sub ptr @ucx, i8 1 monotonic, align 1, !dbg [[DBG13:![0-9]+]]
// AARCH64-NEXT:    store i8 [[TMP2]], ptr @ucv, align 1, !dbg [[DBG13]]
// AARCH64-NEXT:    [[TMP3:%.*]] = atomicrmw sub ptr @sx, i16 1 monotonic, align 2, !dbg [[DBG14:![0-9]+]]
// AARCH64-NEXT:    [[CONV2:%.*]] = sext i16 [[TMP3]] to i32, !dbg [[DBG15:![0-9]+]]
// AARCH64-NEXT:    [[SUB:%.*]] = sub nsw i32 [[CONV2]], 1, !dbg [[DBG16:![0-9]+]]
// AARCH64-NEXT:    [[CONV3:%.*]] = trunc i32 [[SUB]] to i16, !dbg [[DBG15]]
// AARCH64-NEXT:    store i16 [[CONV3]], ptr @sv, align 2, !dbg [[DBG14]]
// AARCH64-NEXT:    [[TMP4:%.*]] = load i16, ptr @usv, align 2, !dbg [[DBG17:![0-9]+]]
// AARCH64-NEXT:    [[CONV4:%.*]] = zext i16 [[TMP4]] to i32, !dbg [[DBG17]]
// AARCH64-NEXT:    [[ATOMIC_LOAD:%.*]] = load atomic i16, ptr @usx monotonic, align 2, !dbg [[DBG18:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT:%.*]], !dbg [[DBG18]]
// AARCH64:       atomic_cont:
// AARCH64-NEXT:    [[TMP5:%.*]] = phi i16 [ [[ATOMIC_LOAD]], [[ENTRY:%.*]] ], [ [[TMP8:%.*]], [[ATOMIC_CONT]] ], !dbg [[DBG18]]
// AARCH64-NEXT:    [[CONV5:%.*]] = zext i16 [[TMP5]] to i32, !dbg [[DBG19:![0-9]+]]
// AARCH64-NEXT:    [[ADD6:%.*]] = add nsw i32 [[CONV5]], [[CONV4]], !dbg [[DBG20:![0-9]+]]
// AARCH64-NEXT:    [[CONV7:%.*]] = trunc i32 [[ADD6]] to i16, !dbg [[DBG19]]
// AARCH64-NEXT:    store i16 [[CONV7]], ptr [[ATOMIC_TEMP]], align 2, !dbg [[DBG18]]
// AARCH64-NEXT:    [[TMP6:%.*]] = load i16, ptr [[ATOMIC_TEMP]], align 2, !dbg [[DBG18]]
// AARCH64-NEXT:    [[TMP7:%.*]] = cmpxchg ptr @usx, i16 [[TMP5]], i16 [[TMP6]] monotonic monotonic, align 2, !dbg [[DBG18]]
// AARCH64-NEXT:    [[TMP8]] = extractvalue { i16, i1 } [[TMP7]], 0, !dbg [[DBG18]]
// AARCH64-NEXT:    [[TMP9:%.*]] = extractvalue { i16, i1 } [[TMP7]], 1, !dbg [[DBG18]]
// AARCH64-NEXT:    br i1 [[TMP9]], label [[ATOMIC_EXIT:%.*]], label [[ATOMIC_CONT]], !dbg [[DBG18]]
// AARCH64:       atomic_exit:
// AARCH64-NEXT:    store i16 [[CONV7]], ptr @sv, align 2, !dbg [[DBG18]]
// AARCH64-NEXT:    [[TMP10:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG21:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD8:%.*]] = load atomic i32, ptr @ix monotonic, align 4, !dbg [[DBG22:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT9:%.*]], !dbg [[DBG22]]
// AARCH64:       atomic_cont9:
// AARCH64-NEXT:    [[TMP11:%.*]] = phi i32 [ [[ATOMIC_LOAD8]], [[ATOMIC_EXIT]] ], [ [[TMP14:%.*]], [[ATOMIC_CONT9]] ], !dbg [[DBG22]]
// AARCH64-NEXT:    [[MUL:%.*]] = mul nsw i32 [[TMP11]], [[TMP10]], !dbg [[DBG23:![0-9]+]]
// AARCH64-NEXT:    store i32 [[MUL]], ptr [[ATOMIC_TEMP10]], align 4, !dbg [[DBG22]]
// AARCH64-NEXT:    [[TMP12:%.*]] = load i32, ptr [[ATOMIC_TEMP10]], align 4, !dbg [[DBG22]]
// AARCH64-NEXT:    [[TMP13:%.*]] = cmpxchg ptr @ix, i32 [[TMP11]], i32 [[TMP12]] monotonic monotonic, align 4, !dbg [[DBG22]]
// AARCH64-NEXT:    [[TMP14]] = extractvalue { i32, i1 } [[TMP13]], 0, !dbg [[DBG22]]
// AARCH64-NEXT:    [[TMP15:%.*]] = extractvalue { i32, i1 } [[TMP13]], 1, !dbg [[DBG22]]
// AARCH64-NEXT:    br i1 [[TMP15]], label [[ATOMIC_EXIT11:%.*]], label [[ATOMIC_CONT9]], !dbg [[DBG22]]
// AARCH64:       atomic_exit11:
// AARCH64-NEXT:    store i32 [[MUL]], ptr @uiv, align 4, !dbg [[DBG22]]
// AARCH64-NEXT:    [[TMP16:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG24:![0-9]+]]
// AARCH64-NEXT:    [[TMP17:%.*]] = atomicrmw sub ptr @uix, i32 [[TMP16]] monotonic, align 4, !dbg [[DBG25:![0-9]+]]
// AARCH64-NEXT:    store i32 [[TMP17]], ptr @iv, align 4, !dbg [[DBG25]]
// AARCH64-NEXT:    [[TMP18:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG26:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD12:%.*]] = load atomic i32, ptr @ix monotonic, align 4, !dbg [[DBG27:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT13:%.*]], !dbg [[DBG27]]
// AARCH64:       atomic_cont13:
// AARCH64-NEXT:    [[TMP19:%.*]] = phi i32 [ [[ATOMIC_LOAD12]], [[ATOMIC_EXIT11]] ], [ [[TMP22:%.*]], [[ATOMIC_CONT13]] ], !dbg [[DBG27]]
// AARCH64-NEXT:    [[SHL:%.*]] = shl i32 [[TMP19]], [[TMP18]], !dbg [[DBG28:![0-9]+]]
// AARCH64-NEXT:    store i32 [[SHL]], ptr [[ATOMIC_TEMP14]], align 4, !dbg [[DBG27]]
// AARCH64-NEXT:    [[TMP20:%.*]] = load i32, ptr [[ATOMIC_TEMP14]], align 4, !dbg [[DBG27]]
// AARCH64-NEXT:    [[TMP21:%.*]] = cmpxchg ptr @ix, i32 [[TMP19]], i32 [[TMP20]] monotonic monotonic, align 4, !dbg [[DBG27]]
// AARCH64-NEXT:    [[TMP22]] = extractvalue { i32, i1 } [[TMP21]], 0, !dbg [[DBG27]]
// AARCH64-NEXT:    [[TMP23:%.*]] = extractvalue { i32, i1 } [[TMP21]], 1, !dbg [[DBG27]]
// AARCH64-NEXT:    br i1 [[TMP23]], label [[ATOMIC_EXIT15:%.*]], label [[ATOMIC_CONT13]], !dbg [[DBG27]]
// AARCH64:       atomic_exit15:
// AARCH64-NEXT:    store i32 [[SHL]], ptr @uiv, align 4, !dbg [[DBG27]]
// AARCH64-NEXT:    [[TMP24:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG29:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD16:%.*]] = load atomic i32, ptr @uix monotonic, align 4, !dbg [[DBG30:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT17:%.*]], !dbg [[DBG30]]
// AARCH64:       atomic_cont17:
// AARCH64-NEXT:    [[TMP25:%.*]] = phi i32 [ [[ATOMIC_LOAD16]], [[ATOMIC_EXIT15]] ], [ [[TMP28:%.*]], [[ATOMIC_CONT17]] ], !dbg [[DBG30]]
// AARCH64-NEXT:    [[SHR:%.*]] = lshr i32 [[TMP25]], [[TMP24]], !dbg [[DBG31:![0-9]+]]
// AARCH64-NEXT:    store i32 [[SHR]], ptr [[ATOMIC_TEMP18]], align 4, !dbg [[DBG30]]
// AARCH64-NEXT:    [[TMP26:%.*]] = load i32, ptr [[ATOMIC_TEMP18]], align 4, !dbg [[DBG30]]
// AARCH64-NEXT:    [[TMP27:%.*]] = cmpxchg ptr @uix, i32 [[TMP25]], i32 [[TMP26]] monotonic monotonic, align 4, !dbg [[DBG30]]
// AARCH64-NEXT:    [[TMP28]] = extractvalue { i32, i1 } [[TMP27]], 0, !dbg [[DBG30]]
// AARCH64-NEXT:    [[TMP29:%.*]] = extractvalue { i32, i1 } [[TMP27]], 1, !dbg [[DBG30]]
// AARCH64-NEXT:    br i1 [[TMP29]], label [[ATOMIC_EXIT19:%.*]], label [[ATOMIC_CONT17]], !dbg [[DBG30]]
// AARCH64:       atomic_exit19:
// AARCH64-NEXT:    store i32 [[SHR]], ptr @iv, align 4, !dbg [[DBG30]]
// AARCH64-NEXT:    [[TMP30:%.*]] = load i64, ptr @lv, align 8, !dbg [[DBG32:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD20:%.*]] = load atomic i64, ptr @lx monotonic, align 8, !dbg [[DBG33:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT21:%.*]], !dbg [[DBG33]]
// AARCH64:       atomic_cont21:
// AARCH64-NEXT:    [[TMP31:%.*]] = phi i64 [ [[ATOMIC_LOAD20]], [[ATOMIC_EXIT19]] ], [ [[TMP34:%.*]], [[ATOMIC_CONT21]] ], !dbg [[DBG33]]
// AARCH64-NEXT:    [[DIV:%.*]] = sdiv i64 [[TMP31]], [[TMP30]], !dbg [[DBG34:![0-9]+]]
// AARCH64-NEXT:    store i64 [[DIV]], ptr [[ATOMIC_TEMP22]], align 8, !dbg [[DBG33]]
// AARCH64-NEXT:    [[TMP32:%.*]] = load i64, ptr [[ATOMIC_TEMP22]], align 8, !dbg [[DBG33]]
// AARCH64-NEXT:    [[TMP33:%.*]] = cmpxchg ptr @lx, i64 [[TMP31]], i64 [[TMP32]] monotonic monotonic, align 8, !dbg [[DBG33]]
// AARCH64-NEXT:    [[TMP34]] = extractvalue { i64, i1 } [[TMP33]], 0, !dbg [[DBG33]]
// AARCH64-NEXT:    [[TMP35:%.*]] = extractvalue { i64, i1 } [[TMP33]], 1, !dbg [[DBG33]]
// AARCH64-NEXT:    br i1 [[TMP35]], label [[ATOMIC_EXIT23:%.*]], label [[ATOMIC_CONT21]], !dbg [[DBG33]]
// AARCH64:       atomic_exit23:
// AARCH64-NEXT:    store i64 [[TMP31]], ptr @ulv, align 8, !dbg [[DBG33]]
// AARCH64-NEXT:    [[TMP36:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG35:![0-9]+]]
// AARCH64-NEXT:    [[TMP37:%.*]] = atomicrmw and ptr @ulx, i64 [[TMP36]] monotonic, align 8, !dbg [[DBG36:![0-9]+]]
// AARCH64-NEXT:    [[AND:%.*]] = and i64 [[TMP37]], [[TMP36]], !dbg [[DBG37:![0-9]+]]
// AARCH64-NEXT:    store i64 [[AND]], ptr @lv, align 8, !dbg [[DBG36]]
// AARCH64-NEXT:    [[TMP38:%.*]] = load i64, ptr @llv, align 8, !dbg [[DBG38:![0-9]+]]
// AARCH64-NEXT:    [[TMP39:%.*]] = atomicrmw xor ptr @llx, i64 [[TMP38]] monotonic, align 8, !dbg [[DBG39:![0-9]+]]
// AARCH64-NEXT:    [[XOR:%.*]] = xor i64 [[TMP39]], [[TMP38]], !dbg [[DBG40:![0-9]+]]
// AARCH64-NEXT:    store i64 [[XOR]], ptr @ullv, align 8, !dbg [[DBG39]]
// AARCH64-NEXT:    [[TMP40:%.*]] = load i64, ptr @ullv, align 8, !dbg [[DBG41:![0-9]+]]
// AARCH64-NEXT:    [[TMP41:%.*]] = atomicrmw or ptr @ullx, i64 [[TMP40]] monotonic, align 8, !dbg [[DBG42:![0-9]+]]
// AARCH64-NEXT:    [[OR:%.*]] = or i64 [[TMP41]], [[TMP40]], !dbg [[DBG43:![0-9]+]]
// AARCH64-NEXT:    store i64 [[OR]], ptr @llv, align 8, !dbg [[DBG42]]
// AARCH64-NEXT:    [[TMP42:%.*]] = load float, ptr @fv, align 4, !dbg [[DBG44:![0-9]+]]
// AARCH64-NEXT:    [[TMP43:%.*]] = atomicrmw fadd ptr @fx, float [[TMP42]] monotonic, align 4, !dbg [[DBG45:![0-9]+]]
// AARCH64-NEXT:    [[ADD24:%.*]] = fadd float [[TMP43]], [[TMP42]], !dbg [[DBG46:![0-9]+]]
// AARCH64-NEXT:    [[CONV25:%.*]] = fpext float [[ADD24]] to double, !dbg [[DBG45]]
// AARCH64-NEXT:    store double [[CONV25]], ptr @dv, align 8, !dbg [[DBG45]]
// AARCH64-NEXT:    [[TMP44:%.*]] = load double, ptr @dv, align 8, !dbg [[DBG47:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD26:%.*]] = load atomic i64, ptr @dx monotonic, align 8, !dbg [[DBG48:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT27:%.*]], !dbg [[DBG48]]
// AARCH64:       atomic_cont27:
// AARCH64-NEXT:    [[TMP45:%.*]] = phi i64 [ [[ATOMIC_LOAD26]], [[ATOMIC_EXIT23]] ], [ [[TMP49:%.*]], [[ATOMIC_CONT27]] ], !dbg [[DBG48]]
// AARCH64-NEXT:    [[TMP46:%.*]] = bitcast i64 [[TMP45]] to double, !dbg [[DBG48]]
// AARCH64-NEXT:    [[SUB29:%.*]] = fsub double [[TMP44]], [[TMP46]], !dbg [[DBG49:![0-9]+]]
// AARCH64-NEXT:    store double [[SUB29]], ptr [[ATOMIC_TEMP28]], align 8, !dbg [[DBG48]]
// AARCH64-NEXT:    [[TMP47:%.*]] = load i64, ptr [[ATOMIC_TEMP28]], align 8, !dbg [[DBG48]]
// AARCH64-NEXT:    [[TMP48:%.*]] = cmpxchg ptr @dx, i64 [[TMP45]], i64 [[TMP47]] monotonic monotonic, align 8, !dbg [[DBG48]]
// AARCH64-NEXT:    [[TMP49]] = extractvalue { i64, i1 } [[TMP48]], 0, !dbg [[DBG48]]
// AARCH64-NEXT:    [[TMP50:%.*]] = extractvalue { i64, i1 } [[TMP48]], 1, !dbg [[DBG48]]
// AARCH64-NEXT:    br i1 [[TMP50]], label [[ATOMIC_EXIT30:%.*]], label [[ATOMIC_CONT27]], !dbg [[DBG48]]
// AARCH64:       atomic_exit30:
// AARCH64-NEXT:    [[CONV31:%.*]] = fptrunc double [[TMP46]] to float, !dbg [[DBG48]]
// AARCH64-NEXT:    store float [[CONV31]], ptr @fv, align 4, !dbg [[DBG48]]
// AARCH64-NEXT:    [[TMP51:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG50:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD32:%.*]] = load atomic i128, ptr @ldx monotonic, align 16, !dbg [[DBG51:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT33:%.*]], !dbg [[DBG51]]
// AARCH64:       atomic_cont33:
// AARCH64-NEXT:    [[TMP52:%.*]] = phi i128 [ [[ATOMIC_LOAD32]], [[ATOMIC_EXIT30]] ], [ [[TMP56:%.*]], [[ATOMIC_CONT33]] ], !dbg [[DBG51]]
// AARCH64-NEXT:    [[TMP53:%.*]] = bitcast i128 [[TMP52]] to fp128, !dbg [[DBG51]]
// AARCH64-NEXT:    [[MUL35:%.*]] = fmul fp128 [[TMP53]], [[TMP51]], !dbg [[DBG52:![0-9]+]]
// AARCH64-NEXT:    store fp128 [[MUL35]], ptr [[ATOMIC_TEMP34]], align 16, !dbg [[DBG51]]
// AARCH64-NEXT:    [[TMP54:%.*]] = load i128, ptr [[ATOMIC_TEMP34]], align 16, !dbg [[DBG51]]
// AARCH64-NEXT:    [[TMP55:%.*]] = cmpxchg ptr @ldx, i128 [[TMP52]], i128 [[TMP54]] monotonic monotonic, align 16, !dbg [[DBG51]]
// AARCH64-NEXT:    [[TMP56]] = extractvalue { i128, i1 } [[TMP55]], 0, !dbg [[DBG51]]
// AARCH64-NEXT:    [[TMP57:%.*]] = extractvalue { i128, i1 } [[TMP55]], 1, !dbg [[DBG51]]
// AARCH64-NEXT:    br i1 [[TMP57]], label [[ATOMIC_EXIT36:%.*]], label [[ATOMIC_CONT33]], !dbg [[DBG51]]
// AARCH64:       atomic_exit36:
// AARCH64-NEXT:    [[CONV37:%.*]] = fptrunc fp128 [[MUL35]] to double, !dbg [[DBG51]]
// AARCH64-NEXT:    store double [[CONV37]], ptr @dv, align 8, !dbg [[DBG51]]
// AARCH64-NEXT:    [[CIV_REAL:%.*]] = load i32, ptr @civ, align 4, !dbg [[DBG53:![0-9]+]]
// AARCH64-NEXT:    [[CIV_IMAG:%.*]] = load i32, ptr getelementptr inbounds nuw ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG53]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP38]], i32 noundef 0), !dbg [[DBG54:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT39:%.*]], !dbg [[DBG54]]
// AARCH64:       atomic_cont39:
// AARCH64-NEXT:    [[ATOMIC_TEMP38_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP38]], i32 0, i32 0, !dbg [[DBG54]]
// AARCH64-NEXT:    [[ATOMIC_TEMP38_REAL:%.*]] = load i32, ptr [[ATOMIC_TEMP38_REALP]], align 4, !dbg [[DBG54]]
// AARCH64-NEXT:    [[ATOMIC_TEMP38_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP38]], i32 0, i32 1, !dbg [[DBG54]]
// AARCH64-NEXT:    [[ATOMIC_TEMP38_IMAG:%.*]] = load i32, ptr [[ATOMIC_TEMP38_IMAGP]], align 4, !dbg [[DBG54]]
// AARCH64-NEXT:    [[TMP58:%.*]] = mul i32 [[CIV_REAL]], [[ATOMIC_TEMP38_REAL]], !dbg [[DBG55:![0-9]+]]
// AARCH64-NEXT:    [[TMP59:%.*]] = mul i32 [[CIV_IMAG]], [[ATOMIC_TEMP38_IMAG]], !dbg [[DBG55]]
// AARCH64-NEXT:    [[TMP60:%.*]] = add i32 [[TMP58]], [[TMP59]], !dbg [[DBG55]]
// AARCH64-NEXT:    [[TMP61:%.*]] = mul i32 [[ATOMIC_TEMP38_REAL]], [[ATOMIC_TEMP38_REAL]], !dbg [[DBG55]]
// AARCH64-NEXT:    [[TMP62:%.*]] = mul i32 [[ATOMIC_TEMP38_IMAG]], [[ATOMIC_TEMP38_IMAG]], !dbg [[DBG55]]
// AARCH64-NEXT:    [[TMP63:%.*]] = add i32 [[TMP61]], [[TMP62]], !dbg [[DBG55]]
// AARCH64-NEXT:    [[TMP64:%.*]] = mul i32 [[CIV_IMAG]], [[ATOMIC_TEMP38_REAL]], !dbg [[DBG55]]
// AARCH64-NEXT:    [[TMP65:%.*]] = mul i32 [[CIV_REAL]], [[ATOMIC_TEMP38_IMAG]], !dbg [[DBG55]]
// AARCH64-NEXT:    [[TMP66:%.*]] = sub i32 [[TMP64]], [[TMP65]], !dbg [[DBG55]]
// AARCH64-NEXT:    [[TMP67:%.*]] = sdiv i32 [[TMP60]], [[TMP63]], !dbg [[DBG55]]
// AARCH64-NEXT:    [[TMP68:%.*]] = sdiv i32 [[TMP66]], [[TMP63]], !dbg [[DBG55]]
// AARCH64-NEXT:    [[ATOMIC_TEMP40_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP40]], i32 0, i32 0, !dbg [[DBG54]]
// AARCH64-NEXT:    [[ATOMIC_TEMP40_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP40]], i32 0, i32 1, !dbg [[DBG54]]
// AARCH64-NEXT:    store i32 [[TMP67]], ptr [[ATOMIC_TEMP40_REALP]], align 4, !dbg [[DBG54]]
// AARCH64-NEXT:    store i32 [[TMP68]], ptr [[ATOMIC_TEMP40_IMAGP]], align 4, !dbg [[DBG54]]
// AARCH64-NEXT:    [[CALL:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP38]], ptr noundef [[ATOMIC_TEMP40]], i32 noundef 0, i32 noundef 0), !dbg [[DBG54]]
// AARCH64-NEXT:    br i1 [[CALL]], label [[ATOMIC_EXIT41:%.*]], label [[ATOMIC_CONT39]], !dbg [[DBG54]]
// AARCH64:       atomic_exit41:
// AARCH64-NEXT:    [[CONV42:%.*]] = sitofp i32 [[TMP67]] to float, !dbg [[DBG54]]
// AARCH64-NEXT:    [[CONV43:%.*]] = sitofp i32 [[TMP68]] to float, !dbg [[DBG54]]
// AARCH64-NEXT:    store float [[CONV42]], ptr @cfv, align 4, !dbg [[DBG54]]
// AARCH64-NEXT:    store float [[CONV43]], ptr getelementptr inbounds nuw ({ float, float }, ptr @cfv, i32 0, i32 1), align 4, !dbg [[DBG54]]
// AARCH64-NEXT:    [[CFV_REAL:%.*]] = load float, ptr @cfv, align 4, !dbg [[DBG56:![0-9]+]]
// AARCH64-NEXT:    [[CFV_IMAG:%.*]] = load float, ptr getelementptr inbounds nuw ({ float, float }, ptr @cfv, i32 0, i32 1), align 4, !dbg [[DBG56]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cfx, ptr noundef [[ATOMIC_TEMP44]], i32 noundef 0), !dbg [[DBG57:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT45:%.*]], !dbg [[DBG57]]
// AARCH64:       atomic_cont45:
// AARCH64-NEXT:    [[ATOMIC_TEMP44_REALP:%.*]] = getelementptr inbounds nuw { float, float }, ptr [[ATOMIC_TEMP44]], i32 0, i32 0, !dbg [[DBG57]]
// AARCH64-NEXT:    [[ATOMIC_TEMP44_REAL:%.*]] = load float, ptr [[ATOMIC_TEMP44_REALP]], align 4, !dbg [[DBG57]]
// AARCH64-NEXT:    [[ATOMIC_TEMP44_IMAGP:%.*]] = getelementptr inbounds nuw { float, float }, ptr [[ATOMIC_TEMP44]], i32 0, i32 1, !dbg [[DBG57]]
// AARCH64-NEXT:    [[ATOMIC_TEMP44_IMAG:%.*]] = load float, ptr [[ATOMIC_TEMP44_IMAGP]], align 4, !dbg [[DBG57]]
// AARCH64-NEXT:    [[ADD_R:%.*]] = fadd float [[CFV_REAL]], [[ATOMIC_TEMP44_REAL]], !dbg [[DBG58:![0-9]+]]
// AARCH64-NEXT:    [[ADD_I:%.*]] = fadd float [[CFV_IMAG]], [[ATOMIC_TEMP44_IMAG]], !dbg [[DBG58]]
// AARCH64-NEXT:    [[ATOMIC_TEMP46_REALP:%.*]] = getelementptr inbounds nuw { float, float }, ptr [[ATOMIC_TEMP46]], i32 0, i32 0, !dbg [[DBG57]]
// AARCH64-NEXT:    [[ATOMIC_TEMP46_IMAGP:%.*]] = getelementptr inbounds nuw { float, float }, ptr [[ATOMIC_TEMP46]], i32 0, i32 1, !dbg [[DBG57]]
// AARCH64-NEXT:    store float [[ADD_R]], ptr [[ATOMIC_TEMP46_REALP]], align 4, !dbg [[DBG57]]
// AARCH64-NEXT:    store float [[ADD_I]], ptr [[ATOMIC_TEMP46_IMAGP]], align 4, !dbg [[DBG57]]
// AARCH64-NEXT:    [[CALL47:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cfx, ptr noundef [[ATOMIC_TEMP44]], ptr noundef [[ATOMIC_TEMP46]], i32 noundef 0, i32 noundef 0), !dbg [[DBG57]]
// AARCH64-NEXT:    br i1 [[CALL47]], label [[ATOMIC_EXIT48:%.*]], label [[ATOMIC_CONT45]], !dbg [[DBG57]]
// AARCH64:       atomic_exit48:
// AARCH64-NEXT:    [[CONV49:%.*]] = fptosi float [[ATOMIC_TEMP44_REAL]] to i32, !dbg [[DBG57]]
// AARCH64-NEXT:    [[CONV50:%.*]] = fptosi float [[ATOMIC_TEMP44_IMAG]] to i32, !dbg [[DBG57]]
// AARCH64-NEXT:    store i32 [[CONV49]], ptr @civ, align 4, !dbg [[DBG57]]
// AARCH64-NEXT:    store i32 [[CONV50]], ptr getelementptr inbounds nuw ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG57]]
// AARCH64-NEXT:    [[CDV_REAL:%.*]] = load double, ptr @cdv, align 8, !dbg [[DBG59:![0-9]+]]
// AARCH64-NEXT:    [[CDV_IMAG:%.*]] = load double, ptr getelementptr inbounds nuw ({ double, double }, ptr @cdv, i32 0, i32 1), align 8, !dbg [[DBG59]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 16, ptr noundef @cdx, ptr noundef [[ATOMIC_TEMP51]], i32 noundef 5), !dbg [[DBG60:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT52:%.*]], !dbg [[DBG60]]
// AARCH64:       atomic_cont52:
// AARCH64-NEXT:    [[ATOMIC_TEMP51_REALP:%.*]] = getelementptr inbounds nuw { double, double }, ptr [[ATOMIC_TEMP51]], i32 0, i32 0, !dbg [[DBG60]]
// AARCH64-NEXT:    [[ATOMIC_TEMP51_REAL:%.*]] = load double, ptr [[ATOMIC_TEMP51_REALP]], align 8, !dbg [[DBG60]]
// AARCH64-NEXT:    [[ATOMIC_TEMP51_IMAGP:%.*]] = getelementptr inbounds nuw { double, double }, ptr [[ATOMIC_TEMP51]], i32 0, i32 1, !dbg [[DBG60]]
// AARCH64-NEXT:    [[ATOMIC_TEMP51_IMAG:%.*]] = load double, ptr [[ATOMIC_TEMP51_IMAGP]], align 8, !dbg [[DBG60]]
// AARCH64-NEXT:    [[SUB_R:%.*]] = fsub double [[ATOMIC_TEMP51_REAL]], [[CDV_REAL]], !dbg [[DBG61:![0-9]+]]
// AARCH64-NEXT:    [[SUB_I:%.*]] = fsub double [[ATOMIC_TEMP51_IMAG]], [[CDV_IMAG]], !dbg [[DBG61]]
// AARCH64-NEXT:    [[ATOMIC_TEMP53_REALP:%.*]] = getelementptr inbounds nuw { double, double }, ptr [[ATOMIC_TEMP53]], i32 0, i32 0, !dbg [[DBG60]]
// AARCH64-NEXT:    [[ATOMIC_TEMP53_IMAGP:%.*]] = getelementptr inbounds nuw { double, double }, ptr [[ATOMIC_TEMP53]], i32 0, i32 1, !dbg [[DBG60]]
// AARCH64-NEXT:    store double [[SUB_R]], ptr [[ATOMIC_TEMP53_REALP]], align 8, !dbg [[DBG60]]
// AARCH64-NEXT:    store double [[SUB_I]], ptr [[ATOMIC_TEMP53_IMAGP]], align 8, !dbg [[DBG60]]
// AARCH64-NEXT:    [[CALL54:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 16, ptr noundef @cdx, ptr noundef [[ATOMIC_TEMP51]], ptr noundef [[ATOMIC_TEMP53]], i32 noundef 5, i32 noundef 5), !dbg [[DBG60]]
// AARCH64-NEXT:    br i1 [[CALL54]], label [[ATOMIC_EXIT55:%.*]], label [[ATOMIC_CONT52]], !dbg [[DBG60]]
// AARCH64:       atomic_exit55:
// AARCH64-NEXT:    [[CONV56:%.*]] = fptrunc double [[SUB_R]] to float, !dbg [[DBG60]]
// AARCH64-NEXT:    [[CONV57:%.*]] = fptrunc double [[SUB_I]] to float, !dbg [[DBG60]]
// AARCH64-NEXT:    store float [[CONV56]], ptr @cfv, align 4, !dbg [[DBG60]]
// AARCH64-NEXT:    store float [[CONV57]], ptr getelementptr inbounds nuw ({ float, float }, ptr @cfv, i32 0, i32 1), align 4, !dbg [[DBG60]]
// AARCH64-NEXT:    [[TMP69:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG62:![0-9]+]]
// AARCH64-NEXT:    [[LOADEDV:%.*]] = trunc i8 [[TMP69]] to i1, !dbg [[DBG62]]
// AARCH64-NEXT:    [[CONV58:%.*]] = zext i1 [[LOADEDV]] to i64, !dbg [[DBG62]]
// AARCH64-NEXT:    [[TMP70:%.*]] = atomicrmw and ptr @ulx, i64 [[CONV58]] monotonic, align 8, !dbg [[DBG63:![0-9]+]]
// AARCH64-NEXT:    [[AND59:%.*]] = and i64 [[TMP70]], [[CONV58]], !dbg [[DBG64:![0-9]+]]
// AARCH64-NEXT:    store i64 [[AND59]], ptr @ulv, align 8, !dbg [[DBG63]]
// AARCH64-NEXT:    [[TMP71:%.*]] = load i8, ptr @cv, align 1, !dbg [[DBG65:![0-9]+]]
// AARCH64-NEXT:    [[CONV60:%.*]] = sext i8 [[TMP71]] to i32, !dbg [[DBG65]]
// AARCH64-NEXT:    [[ATOMIC_LOAD61:%.*]] = load atomic i8, ptr @bx monotonic, align 1, !dbg [[DBG66:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT62:%.*]], !dbg [[DBG66]]
// AARCH64:       atomic_cont62:
// AARCH64-NEXT:    [[TMP72:%.*]] = phi i8 [ [[ATOMIC_LOAD61]], [[ATOMIC_EXIT55]] ], [ [[TMP75:%.*]], [[ATOMIC_CONT62]] ], !dbg [[DBG66]]
// AARCH64-NEXT:    [[LOADEDV64:%.*]] = trunc i8 [[TMP72]] to i1, !dbg [[DBG66]]
// AARCH64-NEXT:    [[CONV65:%.*]] = zext i1 [[LOADEDV64]] to i32, !dbg [[DBG67:![0-9]+]]
// AARCH64-NEXT:    [[AND66:%.*]] = and i32 [[CONV60]], [[CONV65]], !dbg [[DBG68:![0-9]+]]
// AARCH64-NEXT:    [[TOBOOL:%.*]] = icmp ne i32 [[AND66]], 0, !dbg [[DBG65]]
// AARCH64-NEXT:    [[STOREDV:%.*]] = zext i1 [[TOBOOL]] to i8, !dbg [[DBG66]]
// AARCH64-NEXT:    store i8 [[STOREDV]], ptr [[ATOMIC_TEMP63]], align 1, !dbg [[DBG66]]
// AARCH64-NEXT:    [[TMP73:%.*]] = load i8, ptr [[ATOMIC_TEMP63]], align 1, !dbg [[DBG66]]
// AARCH64-NEXT:    [[TMP74:%.*]] = cmpxchg ptr @bx, i8 [[TMP72]], i8 [[TMP73]] monotonic monotonic, align 1, !dbg [[DBG66]]
// AARCH64-NEXT:    [[TMP75]] = extractvalue { i8, i1 } [[TMP74]], 0, !dbg [[DBG66]]
// AARCH64-NEXT:    [[TMP76:%.*]] = extractvalue { i8, i1 } [[TMP74]], 1, !dbg [[DBG66]]
// AARCH64-NEXT:    br i1 [[TMP76]], label [[ATOMIC_EXIT67:%.*]], label [[ATOMIC_CONT62]], !dbg [[DBG66]]
// AARCH64:       atomic_exit67:
// AARCH64-NEXT:    [[STOREDV68:%.*]] = zext i1 [[LOADEDV64]] to i8, !dbg [[DBG66]]
// AARCH64-NEXT:    store i8 [[STOREDV68]], ptr @bv, align 1, !dbg [[DBG66]]
// AARCH64-NEXT:    [[TMP77:%.*]] = load i8, ptr @ucv, align 1, !dbg [[DBG69:![0-9]+]]
// AARCH64-NEXT:    [[CONV69:%.*]] = zext i8 [[TMP77]] to i32, !dbg [[DBG69]]
// AARCH64-NEXT:    [[ATOMIC_LOAD70:%.*]] = load atomic i8, ptr @cx seq_cst, align 1, !dbg [[DBG70:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT71:%.*]], !dbg [[DBG70]]
// AARCH64:       atomic_cont71:
// AARCH64-NEXT:    [[TMP78:%.*]] = phi i8 [ [[ATOMIC_LOAD70]], [[ATOMIC_EXIT67]] ], [ [[TMP81:%.*]], [[ATOMIC_CONT71]] ], !dbg [[DBG70]]
// AARCH64-NEXT:    [[CONV73:%.*]] = sext i8 [[TMP78]] to i32, !dbg [[DBG71:![0-9]+]]
// AARCH64-NEXT:    [[SHR74:%.*]] = ashr i32 [[CONV73]], [[CONV69]], !dbg [[DBG72:![0-9]+]]
// AARCH64-NEXT:    [[CONV75:%.*]] = trunc i32 [[SHR74]] to i8, !dbg [[DBG71]]
// AARCH64-NEXT:    store i8 [[CONV75]], ptr [[ATOMIC_TEMP72]], align 1, !dbg [[DBG70]]
// AARCH64-NEXT:    [[TMP79:%.*]] = load i8, ptr [[ATOMIC_TEMP72]], align 1, !dbg [[DBG70]]
// AARCH64-NEXT:    [[TMP80:%.*]] = cmpxchg ptr @cx, i8 [[TMP78]], i8 [[TMP79]] seq_cst seq_cst, align 1, !dbg [[DBG70]]
// AARCH64-NEXT:    [[TMP81]] = extractvalue { i8, i1 } [[TMP80]], 0, !dbg [[DBG70]]
// AARCH64-NEXT:    [[TMP82:%.*]] = extractvalue { i8, i1 } [[TMP80]], 1, !dbg [[DBG70]]
// AARCH64-NEXT:    br i1 [[TMP82]], label [[ATOMIC_EXIT76:%.*]], label [[ATOMIC_CONT71]], !dbg [[DBG70]]
// AARCH64:       atomic_exit76:
// AARCH64-NEXT:    store i8 [[CONV75]], ptr @cv, align 1, !dbg [[DBG70]]
// AARCH64-NEXT:    [[TMP83:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG73:![0-9]+]]
// AARCH64-NEXT:    [[CONV77:%.*]] = sext i16 [[TMP83]] to i32, !dbg [[DBG73]]
// AARCH64-NEXT:    [[ATOMIC_LOAD78:%.*]] = load atomic i64, ptr @ulx monotonic, align 8, !dbg [[DBG74:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT79:%.*]], !dbg [[DBG74]]
// AARCH64:       atomic_cont79:
// AARCH64-NEXT:    [[TMP84:%.*]] = phi i64 [ [[ATOMIC_LOAD78]], [[ATOMIC_EXIT76]] ], [ [[TMP87:%.*]], [[ATOMIC_CONT79]] ], !dbg [[DBG74]]
// AARCH64-NEXT:    [[SH_PROM:%.*]] = trunc i64 [[TMP84]] to i32, !dbg [[DBG75:![0-9]+]]
// AARCH64-NEXT:    [[SHL81:%.*]] = shl i32 [[CONV77]], [[SH_PROM]], !dbg [[DBG75]]
// AARCH64-NEXT:    [[CONV82:%.*]] = sext i32 [[SHL81]] to i64, !dbg [[DBG73]]
// AARCH64-NEXT:    store i64 [[CONV82]], ptr [[ATOMIC_TEMP80]], align 8, !dbg [[DBG74]]
// AARCH64-NEXT:    [[TMP85:%.*]] = load i64, ptr [[ATOMIC_TEMP80]], align 8, !dbg [[DBG74]]
// AARCH64-NEXT:    [[TMP86:%.*]] = cmpxchg ptr @ulx, i64 [[TMP84]], i64 [[TMP85]] monotonic monotonic, align 8, !dbg [[DBG74]]
// AARCH64-NEXT:    [[TMP87]] = extractvalue { i64, i1 } [[TMP86]], 0, !dbg [[DBG74]]
// AARCH64-NEXT:    [[TMP88:%.*]] = extractvalue { i64, i1 } [[TMP86]], 1, !dbg [[DBG74]]
// AARCH64-NEXT:    br i1 [[TMP88]], label [[ATOMIC_EXIT83:%.*]], label [[ATOMIC_CONT79]], !dbg [[DBG74]]
// AARCH64:       atomic_exit83:
// AARCH64-NEXT:    store i64 [[CONV82]], ptr @ulv, align 8, !dbg [[DBG74]]
// AARCH64-NEXT:    [[TMP89:%.*]] = load i16, ptr @usv, align 2, !dbg [[DBG76:![0-9]+]]
// AARCH64-NEXT:    [[CONV84:%.*]] = zext i16 [[TMP89]] to i64, !dbg [[DBG76]]
// AARCH64-NEXT:    [[ATOMIC_LOAD85:%.*]] = load atomic i64, ptr @lx monotonic, align 8, !dbg [[DBG77:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT86:%.*]], !dbg [[DBG77]]
// AARCH64:       atomic_cont86:
// AARCH64-NEXT:    [[TMP90:%.*]] = phi i64 [ [[ATOMIC_LOAD85]], [[ATOMIC_EXIT83]] ], [ [[TMP93:%.*]], [[ATOMIC_CONT86]] ], !dbg [[DBG77]]
// AARCH64-NEXT:    [[REM:%.*]] = srem i64 [[TMP90]], [[CONV84]], !dbg [[DBG78:![0-9]+]]
// AARCH64-NEXT:    store i64 [[REM]], ptr [[ATOMIC_TEMP87]], align 8, !dbg [[DBG77]]
// AARCH64-NEXT:    [[TMP91:%.*]] = load i64, ptr [[ATOMIC_TEMP87]], align 8, !dbg [[DBG77]]
// AARCH64-NEXT:    [[TMP92:%.*]] = cmpxchg ptr @lx, i64 [[TMP90]], i64 [[TMP91]] monotonic monotonic, align 8, !dbg [[DBG77]]
// AARCH64-NEXT:    [[TMP93]] = extractvalue { i64, i1 } [[TMP92]], 0, !dbg [[DBG77]]
// AARCH64-NEXT:    [[TMP94:%.*]] = extractvalue { i64, i1 } [[TMP92]], 1, !dbg [[DBG77]]
// AARCH64-NEXT:    br i1 [[TMP94]], label [[ATOMIC_EXIT88:%.*]], label [[ATOMIC_CONT86]], !dbg [[DBG77]]
// AARCH64:       atomic_exit88:
// AARCH64-NEXT:    store i64 [[TMP90]], ptr @lv, align 8, !dbg [[DBG77]]
// AARCH64-NEXT:    [[TMP95:%.*]] = load i32, ptr @iv, align 4, !dbg [[DBG79:![0-9]+]]
// AARCH64-NEXT:    [[TMP96:%.*]] = atomicrmw or ptr @uix, i32 [[TMP95]] seq_cst, align 4, !dbg [[DBG80:![0-9]+]]
// AARCH64-NEXT:    [[OR89:%.*]] = or i32 [[TMP95]], [[TMP96]], !dbg [[DBG81:![0-9]+]]
// AARCH64-NEXT:    store i32 [[OR89]], ptr @uiv, align 4, !dbg [[DBG80]]
// AARCH64-NEXT:    [[TMP97:%.*]] = load i32, ptr @uiv, align 4, !dbg [[DBG82:![0-9]+]]
// AARCH64-NEXT:    [[TMP98:%.*]] = atomicrmw and ptr @ix, i32 [[TMP97]] monotonic, align 4, !dbg [[DBG83:![0-9]+]]
// AARCH64-NEXT:    [[AND90:%.*]] = and i32 [[TMP98]], [[TMP97]], !dbg [[DBG84:![0-9]+]]
// AARCH64-NEXT:    store i32 [[AND90]], ptr @iv, align 4, !dbg [[DBG83]]
// AARCH64-NEXT:    [[TMP99:%.*]] = load i64, ptr @lv, align 8, !dbg [[DBG85:![0-9]+]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP91]], i32 noundef 0), !dbg [[DBG86:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT92:%.*]], !dbg [[DBG86]]
// AARCH64:       atomic_cont92:
// AARCH64-NEXT:    [[ATOMIC_TEMP91_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP91]], i32 0, i32 0, !dbg [[DBG86]]
// AARCH64-NEXT:    [[ATOMIC_TEMP91_REAL:%.*]] = load i32, ptr [[ATOMIC_TEMP91_REALP]], align 4, !dbg [[DBG86]]
// AARCH64-NEXT:    [[ATOMIC_TEMP91_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP91]], i32 0, i32 1, !dbg [[DBG86]]
// AARCH64-NEXT:    [[ATOMIC_TEMP91_IMAG:%.*]] = load i32, ptr [[ATOMIC_TEMP91_IMAGP]], align 4, !dbg [[DBG86]]
// AARCH64-NEXT:    [[CONV94:%.*]] = sext i32 [[ATOMIC_TEMP91_REAL]] to i64, !dbg [[DBG87:![0-9]+]]
// AARCH64-NEXT:    [[CONV95:%.*]] = sext i32 [[ATOMIC_TEMP91_IMAG]] to i64, !dbg [[DBG87]]
// AARCH64-NEXT:    [[ADD_R96:%.*]] = add i64 [[TMP99]], [[CONV94]], !dbg [[DBG88:![0-9]+]]
// AARCH64-NEXT:    [[ADD_I97:%.*]] = add i64 0, [[CONV95]], !dbg [[DBG88]]
// AARCH64-NEXT:    [[CONV98:%.*]] = trunc i64 [[ADD_R96]] to i32, !dbg [[DBG85]]
// AARCH64-NEXT:    [[CONV99:%.*]] = trunc i64 [[ADD_I97]] to i32, !dbg [[DBG85]]
// AARCH64-NEXT:    [[ATOMIC_TEMP93_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP93]], i32 0, i32 0, !dbg [[DBG86]]
// AARCH64-NEXT:    [[ATOMIC_TEMP93_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP93]], i32 0, i32 1, !dbg [[DBG86]]
// AARCH64-NEXT:    store i32 [[CONV98]], ptr [[ATOMIC_TEMP93_REALP]], align 4, !dbg [[DBG86]]
// AARCH64-NEXT:    store i32 [[CONV99]], ptr [[ATOMIC_TEMP93_IMAGP]], align 4, !dbg [[DBG86]]
// AARCH64-NEXT:    [[CALL100:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP91]], ptr noundef [[ATOMIC_TEMP93]], i32 noundef 0, i32 noundef 0), !dbg [[DBG86]]
// AARCH64-NEXT:    br i1 [[CALL100]], label [[ATOMIC_EXIT101:%.*]], label [[ATOMIC_CONT92]], !dbg [[DBG86]]
// AARCH64:       atomic_exit101:
// AARCH64-NEXT:    store i32 [[ATOMIC_TEMP91_REAL]], ptr @civ, align 4, !dbg [[DBG86]]
// AARCH64-NEXT:    store i32 [[ATOMIC_TEMP91_IMAG]], ptr getelementptr inbounds nuw ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG86]]
// AARCH64-NEXT:    [[TMP100:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG89:![0-9]+]]
// AARCH64-NEXT:    [[CONV102:%.*]] = uitofp i64 [[TMP100]] to float, !dbg [[DBG89]]
// AARCH64-NEXT:    [[ATOMIC_LOAD103:%.*]] = load atomic i32, ptr @fx monotonic, align 4, !dbg [[DBG90:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT104:%.*]], !dbg [[DBG90]]
// AARCH64:       atomic_cont104:
// AARCH64-NEXT:    [[TMP101:%.*]] = phi i32 [ [[ATOMIC_LOAD103]], [[ATOMIC_EXIT101]] ], [ [[TMP105:%.*]], [[ATOMIC_CONT104]] ], !dbg [[DBG90]]
// AARCH64-NEXT:    [[TMP102:%.*]] = bitcast i32 [[TMP101]] to float, !dbg [[DBG90]]
// AARCH64-NEXT:    [[MUL106:%.*]] = fmul float [[TMP102]], [[CONV102]], !dbg [[DBG91:![0-9]+]]
// AARCH64-NEXT:    store float [[MUL106]], ptr [[ATOMIC_TEMP105]], align 4, !dbg [[DBG90]]
// AARCH64-NEXT:    [[TMP103:%.*]] = load i32, ptr [[ATOMIC_TEMP105]], align 4, !dbg [[DBG90]]
// AARCH64-NEXT:    [[TMP104:%.*]] = cmpxchg ptr @fx, i32 [[TMP101]], i32 [[TMP103]] monotonic monotonic, align 4, !dbg [[DBG90]]
// AARCH64-NEXT:    [[TMP105]] = extractvalue { i32, i1 } [[TMP104]], 0, !dbg [[DBG90]]
// AARCH64-NEXT:    [[TMP106:%.*]] = extractvalue { i32, i1 } [[TMP104]], 1, !dbg [[DBG90]]
// AARCH64-NEXT:    br i1 [[TMP106]], label [[ATOMIC_EXIT107:%.*]], label [[ATOMIC_CONT104]], !dbg [[DBG90]]
// AARCH64:       atomic_exit107:
// AARCH64-NEXT:    store float [[MUL106]], ptr @fv, align 4, !dbg [[DBG90]]
// AARCH64-NEXT:    [[TMP107:%.*]] = load i64, ptr @llv, align 8, !dbg [[DBG92:![0-9]+]]
// AARCH64-NEXT:    [[CONV108:%.*]] = sitofp i64 [[TMP107]] to double, !dbg [[DBG92]]
// AARCH64-NEXT:    [[ATOMIC_LOAD109:%.*]] = load atomic i64, ptr @dx monotonic, align 8, !dbg [[DBG93:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT110:%.*]], !dbg [[DBG93]]
// AARCH64:       atomic_cont110:
// AARCH64-NEXT:    [[TMP108:%.*]] = phi i64 [ [[ATOMIC_LOAD109]], [[ATOMIC_EXIT107]] ], [ [[TMP112:%.*]], [[ATOMIC_CONT110]] ], !dbg [[DBG93]]
// AARCH64-NEXT:    [[TMP109:%.*]] = bitcast i64 [[TMP108]] to double, !dbg [[DBG93]]
// AARCH64-NEXT:    [[DIV112:%.*]] = fdiv double [[TMP109]], [[CONV108]], !dbg [[DBG94:![0-9]+]]
// AARCH64-NEXT:    store double [[DIV112]], ptr [[ATOMIC_TEMP111]], align 8, !dbg [[DBG93]]
// AARCH64-NEXT:    [[TMP110:%.*]] = load i64, ptr [[ATOMIC_TEMP111]], align 8, !dbg [[DBG93]]
// AARCH64-NEXT:    [[TMP111:%.*]] = cmpxchg ptr @dx, i64 [[TMP108]], i64 [[TMP110]] monotonic monotonic, align 8, !dbg [[DBG93]]
// AARCH64-NEXT:    [[TMP112]] = extractvalue { i64, i1 } [[TMP111]], 0, !dbg [[DBG93]]
// AARCH64-NEXT:    [[TMP113:%.*]] = extractvalue { i64, i1 } [[TMP111]], 1, !dbg [[DBG93]]
// AARCH64-NEXT:    br i1 [[TMP113]], label [[ATOMIC_EXIT113:%.*]], label [[ATOMIC_CONT110]], !dbg [[DBG93]]
// AARCH64:       atomic_exit113:
// AARCH64-NEXT:    store double [[DIV112]], ptr @dv, align 8, !dbg [[DBG93]]
// AARCH64-NEXT:    [[TMP114:%.*]] = load i64, ptr @ullv, align 8, !dbg [[DBG95:![0-9]+]]
// AARCH64-NEXT:    [[CONV114:%.*]] = uitofp i64 [[TMP114]] to fp128, !dbg [[DBG95]]
// AARCH64-NEXT:    [[TMP115:%.*]] = atomicrmw fsub ptr @ldx, fp128 [[CONV114]] monotonic, align 16, !dbg [[DBG96:![0-9]+]]
// AARCH64-NEXT:    store fp128 [[TMP115]], ptr @ldv, align 16, !dbg [[DBG96]]
// AARCH64-NEXT:    [[TMP116:%.*]] = load float, ptr @fv, align 4, !dbg [[DBG97:![0-9]+]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP115]], i32 noundef 0), !dbg [[DBG98:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT116:%.*]], !dbg [[DBG98]]
// AARCH64:       atomic_cont116:
// AARCH64-NEXT:    [[ATOMIC_TEMP115_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP115]], i32 0, i32 0, !dbg [[DBG98]]
// AARCH64-NEXT:    [[ATOMIC_TEMP115_REAL:%.*]] = load i32, ptr [[ATOMIC_TEMP115_REALP]], align 4, !dbg [[DBG98]]
// AARCH64-NEXT:    [[ATOMIC_TEMP115_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP115]], i32 0, i32 1, !dbg [[DBG98]]
// AARCH64-NEXT:    [[ATOMIC_TEMP115_IMAG:%.*]] = load i32, ptr [[ATOMIC_TEMP115_IMAGP]], align 4, !dbg [[DBG98]]
// AARCH64-NEXT:    [[CONV118:%.*]] = sitofp i32 [[ATOMIC_TEMP115_REAL]] to float, !dbg [[DBG99:![0-9]+]]
// AARCH64-NEXT:    [[CONV119:%.*]] = sitofp i32 [[ATOMIC_TEMP115_IMAG]] to float, !dbg [[DBG99]]
// AARCH64-NEXT:    [[CALL120:%.*]] = call { float, float } @__divsc3(float noundef [[TMP116]], float noundef 0.000000e+00, float noundef [[CONV118]], float noundef [[CONV119]]) #[[ATTR2:[0-9]+]], !dbg [[DBG100:![0-9]+]]
// AARCH64-NEXT:    [[TMP117:%.*]] = extractvalue { float, float } [[CALL120]], 0, !dbg [[DBG100]]
// AARCH64-NEXT:    [[TMP118:%.*]] = extractvalue { float, float } [[CALL120]], 1, !dbg [[DBG100]]
// AARCH64-NEXT:    [[CONV121:%.*]] = fptosi float [[TMP117]] to i32, !dbg [[DBG97]]
// AARCH64-NEXT:    [[CONV122:%.*]] = fptosi float [[TMP118]] to i32, !dbg [[DBG97]]
// AARCH64-NEXT:    [[ATOMIC_TEMP117_REALP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP117]], i32 0, i32 0, !dbg [[DBG98]]
// AARCH64-NEXT:    [[ATOMIC_TEMP117_IMAGP:%.*]] = getelementptr inbounds nuw { i32, i32 }, ptr [[ATOMIC_TEMP117]], i32 0, i32 1, !dbg [[DBG98]]
// AARCH64-NEXT:    store i32 [[CONV121]], ptr [[ATOMIC_TEMP117_REALP]], align 4, !dbg [[DBG98]]
// AARCH64-NEXT:    store i32 [[CONV122]], ptr [[ATOMIC_TEMP117_IMAGP]], align 4, !dbg [[DBG98]]
// AARCH64-NEXT:    [[CALL123:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 8, ptr noundef @cix, ptr noundef [[ATOMIC_TEMP115]], ptr noundef [[ATOMIC_TEMP117]], i32 noundef 0, i32 noundef 0), !dbg [[DBG98]]
// AARCH64-NEXT:    br i1 [[CALL123]], label [[ATOMIC_EXIT124:%.*]], label [[ATOMIC_CONT116]], !dbg [[DBG98]]
// AARCH64:       atomic_exit124:
// AARCH64-NEXT:    store i32 [[CONV121]], ptr @civ, align 4, !dbg [[DBG98]]
// AARCH64-NEXT:    store i32 [[CONV122]], ptr getelementptr inbounds nuw ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG98]]
// AARCH64-NEXT:    [[TMP119:%.*]] = load double, ptr @dv, align 8, !dbg [[DBG101:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD125:%.*]] = load atomic i16, ptr @sx monotonic, align 2, !dbg [[DBG102:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT126:%.*]], !dbg [[DBG102]]
// AARCH64:       atomic_cont126:
// AARCH64-NEXT:    [[TMP120:%.*]] = phi i16 [ [[ATOMIC_LOAD125]], [[ATOMIC_EXIT124]] ], [ [[TMP123:%.*]], [[ATOMIC_CONT126]] ], !dbg [[DBG102]]
// AARCH64-NEXT:    [[CONV128:%.*]] = sext i16 [[TMP120]] to i32, !dbg [[DBG103:![0-9]+]]
// AARCH64-NEXT:    [[CONV129:%.*]] = sitofp i32 [[CONV128]] to double, !dbg [[DBG103]]
// AARCH64-NEXT:    [[ADD130:%.*]] = fadd double [[CONV129]], [[TMP119]], !dbg [[DBG104:![0-9]+]]
// AARCH64-NEXT:    [[CONV131:%.*]] = fptosi double [[ADD130]] to i16, !dbg [[DBG103]]
// AARCH64-NEXT:    store i16 [[CONV131]], ptr [[ATOMIC_TEMP127]], align 2, !dbg [[DBG102]]
// AARCH64-NEXT:    [[TMP121:%.*]] = load i16, ptr [[ATOMIC_TEMP127]], align 2, !dbg [[DBG102]]
// AARCH64-NEXT:    [[TMP122:%.*]] = cmpxchg ptr @sx, i16 [[TMP120]], i16 [[TMP121]] monotonic monotonic, align 2, !dbg [[DBG102]]
// AARCH64-NEXT:    [[TMP123]] = extractvalue { i16, i1 } [[TMP122]], 0, !dbg [[DBG102]]
// AARCH64-NEXT:    [[TMP124:%.*]] = extractvalue { i16, i1 } [[TMP122]], 1, !dbg [[DBG102]]
// AARCH64-NEXT:    br i1 [[TMP124]], label [[ATOMIC_EXIT132:%.*]], label [[ATOMIC_CONT126]], !dbg [[DBG102]]
// AARCH64:       atomic_exit132:
// AARCH64-NEXT:    store i16 [[CONV131]], ptr @sv, align 2, !dbg [[DBG102]]
// AARCH64-NEXT:    [[TMP125:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG105:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD133:%.*]] = load atomic i8, ptr @bx monotonic, align 1, !dbg [[DBG106:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT134:%.*]], !dbg [[DBG106]]
// AARCH64:       atomic_cont134:
// AARCH64-NEXT:    [[TMP126:%.*]] = phi i8 [ [[ATOMIC_LOAD133]], [[ATOMIC_EXIT132]] ], [ [[TMP129:%.*]], [[ATOMIC_CONT134]] ], !dbg [[DBG106]]
// AARCH64-NEXT:    [[LOADEDV136:%.*]] = trunc i8 [[TMP126]] to i1, !dbg [[DBG106]]
// AARCH64-NEXT:    [[CONV137:%.*]] = zext i1 [[LOADEDV136]] to i32, !dbg [[DBG107:![0-9]+]]
// AARCH64-NEXT:    [[CONV138:%.*]] = sitofp i32 [[CONV137]] to fp128, !dbg [[DBG107]]
// AARCH64-NEXT:    [[MUL139:%.*]] = fmul fp128 [[TMP125]], [[CONV138]], !dbg [[DBG108:![0-9]+]]
// AARCH64-NEXT:    [[TOBOOL140:%.*]] = fcmp une fp128 [[MUL139]], 0xL00000000000000000000000000000000, !dbg [[DBG105]]
// AARCH64-NEXT:    [[STOREDV141:%.*]] = zext i1 [[TOBOOL140]] to i8, !dbg [[DBG106]]
// AARCH64-NEXT:    store i8 [[STOREDV141]], ptr [[ATOMIC_TEMP135]], align 1, !dbg [[DBG106]]
// AARCH64-NEXT:    [[TMP127:%.*]] = load i8, ptr [[ATOMIC_TEMP135]], align 1, !dbg [[DBG106]]
// AARCH64-NEXT:    [[TMP128:%.*]] = cmpxchg ptr @bx, i8 [[TMP126]], i8 [[TMP127]] monotonic monotonic, align 1, !dbg [[DBG106]]
// AARCH64-NEXT:    [[TMP129]] = extractvalue { i8, i1 } [[TMP128]], 0, !dbg [[DBG106]]
// AARCH64-NEXT:    [[TMP130:%.*]] = extractvalue { i8, i1 } [[TMP128]], 1, !dbg [[DBG106]]
// AARCH64-NEXT:    br i1 [[TMP130]], label [[ATOMIC_EXIT142:%.*]], label [[ATOMIC_CONT134]], !dbg [[DBG106]]
// AARCH64:       atomic_exit142:
// AARCH64-NEXT:    [[STOREDV143:%.*]] = zext i1 [[LOADEDV136]] to i8, !dbg [[DBG106]]
// AARCH64-NEXT:    store i8 [[STOREDV143]], ptr @bv, align 1, !dbg [[DBG106]]
// AARCH64-NEXT:    [[CIV_REAL144:%.*]] = load i32, ptr @civ, align 4, !dbg [[DBG109:![0-9]+]]
// AARCH64-NEXT:    [[CIV_IMAG145:%.*]] = load i32, ptr getelementptr inbounds nuw ({ i32, i32 }, ptr @civ, i32 0, i32 1), align 4, !dbg [[DBG109]]
// AARCH64-NEXT:    [[ATOMIC_LOAD146:%.*]] = load atomic i8, ptr @bx monotonic, align 1, !dbg [[DBG110:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT147:%.*]], !dbg [[DBG110]]
// AARCH64:       atomic_cont147:
// AARCH64-NEXT:    [[TMP131:%.*]] = phi i8 [ [[ATOMIC_LOAD146]], [[ATOMIC_EXIT142]] ], [ [[TMP134:%.*]], [[ATOMIC_CONT147]] ], !dbg [[DBG110]]
// AARCH64-NEXT:    [[LOADEDV149:%.*]] = trunc i8 [[TMP131]] to i1, !dbg [[DBG110]]
// AARCH64-NEXT:    [[CONV150:%.*]] = zext i1 [[LOADEDV149]] to i32, !dbg [[DBG111:![0-9]+]]
// AARCH64-NEXT:    [[SUB_R151:%.*]] = sub i32 [[CIV_REAL144]], [[CONV150]], !dbg [[DBG112:![0-9]+]]
// AARCH64-NEXT:    [[SUB_I152:%.*]] = sub i32 [[CIV_IMAG145]], 0, !dbg [[DBG112]]
// AARCH64-NEXT:    [[TOBOOL153:%.*]] = icmp ne i32 [[SUB_R151]], 0, !dbg [[DBG109]]
// AARCH64-NEXT:    [[TOBOOL154:%.*]] = icmp ne i32 [[SUB_I152]], 0, !dbg [[DBG109]]
// AARCH64-NEXT:    [[TOBOOL155:%.*]] = or i1 [[TOBOOL153]], [[TOBOOL154]], !dbg [[DBG109]]
// AARCH64-NEXT:    [[STOREDV156:%.*]] = zext i1 [[TOBOOL155]] to i8, !dbg [[DBG110]]
// AARCH64-NEXT:    store i8 [[STOREDV156]], ptr [[ATOMIC_TEMP148]], align 1, !dbg [[DBG110]]
// AARCH64-NEXT:    [[TMP132:%.*]] = load i8, ptr [[ATOMIC_TEMP148]], align 1, !dbg [[DBG110]]
// AARCH64-NEXT:    [[TMP133:%.*]] = cmpxchg ptr @bx, i8 [[TMP131]], i8 [[TMP132]] monotonic monotonic, align 1, !dbg [[DBG110]]
// AARCH64-NEXT:    [[TMP134]] = extractvalue { i8, i1 } [[TMP133]], 0, !dbg [[DBG110]]
// AARCH64-NEXT:    [[TMP135:%.*]] = extractvalue { i8, i1 } [[TMP133]], 1, !dbg [[DBG110]]
// AARCH64-NEXT:    br i1 [[TMP135]], label [[ATOMIC_EXIT157:%.*]], label [[ATOMIC_CONT147]], !dbg [[DBG110]]
// AARCH64:       atomic_exit157:
// AARCH64-NEXT:    [[STOREDV158:%.*]] = zext i1 [[TOBOOL155]] to i8, !dbg [[DBG110]]
// AARCH64-NEXT:    store i8 [[STOREDV158]], ptr @bv, align 1, !dbg [[DBG110]]
// AARCH64-NEXT:    [[TMP136:%.*]] = load i16, ptr @sv, align 2, !dbg [[DBG113:![0-9]+]]
// AARCH64-NEXT:    [[TMP137:%.*]] = load i8, ptr @bv, align 1, !dbg [[DBG114:![0-9]+]]
// AARCH64-NEXT:    [[LOADEDV159:%.*]] = trunc i8 [[TMP137]] to i1, !dbg [[DBG114]]
// AARCH64-NEXT:    [[CONV160:%.*]] = zext i1 [[LOADEDV159]] to i32, !dbg [[DBG114]]
// AARCH64-NEXT:    [[ATOMIC_LOAD161:%.*]] = load atomic i128, ptr @int4x monotonic, align 16, !dbg [[DBG115:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT162:%.*]], !dbg [[DBG115]]
// AARCH64:       atomic_cont162:
// AARCH64-NEXT:    [[TMP138:%.*]] = phi i128 [ [[ATOMIC_LOAD161]], [[ATOMIC_EXIT157]] ], [ [[TMP144:%.*]], [[ATOMIC_CONT162]] ], !dbg [[DBG115]]
// AARCH64-NEXT:    store i128 [[TMP138]], ptr [[ATOMIC_TEMP163]], align 16, !dbg [[DBG115]]
// AARCH64-NEXT:    [[TMP139:%.*]] = bitcast i128 [[TMP138]] to <4 x i32>, !dbg [[DBG115]]
// AARCH64-NEXT:    store <4 x i32> [[TMP139]], ptr [[ATOMIC_TEMP164]], align 16, !dbg [[DBG115]]
// AARCH64-NEXT:    [[TMP140:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP164]], align 16, !dbg [[DBG115]]
// AARCH64-NEXT:    [[VECEXT:%.*]] = extractelement <4 x i32> [[TMP140]], i16 [[TMP136]], !dbg [[DBG115]]
// AARCH64-NEXT:    [[OR165:%.*]] = or i32 [[VECEXT]], [[CONV160]], !dbg [[DBG116:![0-9]+]]
// AARCH64-NEXT:    [[TMP141:%.*]] = load <4 x i32>, ptr [[ATOMIC_TEMP163]], align 16, !dbg [[DBG115]]
// AARCH64-NEXT:    [[VECINS:%.*]] = insertelement <4 x i32> [[TMP141]], i32 [[OR165]], i16 [[TMP136]], !dbg [[DBG115]]
// AARCH64-NEXT:    store <4 x i32> [[VECINS]], ptr [[ATOMIC_TEMP163]], align 16, !dbg [[DBG115]]
// AARCH64-NEXT:    [[TMP142:%.*]] = load i128, ptr [[ATOMIC_TEMP163]], align 16, !dbg [[DBG115]]
// AARCH64-NEXT:    [[TMP143:%.*]] = cmpxchg ptr @int4x, i128 [[TMP138]], i128 [[TMP142]] monotonic monotonic, align 16, !dbg [[DBG115]]
// AARCH64-NEXT:    [[TMP144]] = extractvalue { i128, i1 } [[TMP143]], 0, !dbg [[DBG115]]
// AARCH64-NEXT:    [[TMP145:%.*]] = extractvalue { i128, i1 } [[TMP143]], 1, !dbg [[DBG115]]
// AARCH64-NEXT:    br i1 [[TMP145]], label [[ATOMIC_EXIT166:%.*]], label [[ATOMIC_CONT162]], !dbg [[DBG115]]
// AARCH64:       atomic_exit166:
// AARCH64-NEXT:    store i32 [[OR165]], ptr @iv, align 4, !dbg [[DBG115]]
// AARCH64-NEXT:    [[TMP146:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG117:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD167:%.*]] = load atomic i32, ptr getelementptr (i8, ptr @bfx, i64 4) monotonic, align 4, !dbg [[DBG118:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT168:%.*]], !dbg [[DBG118]]
// AARCH64:       atomic_cont168:
// AARCH64-NEXT:    [[TMP147:%.*]] = phi i32 [ [[ATOMIC_LOAD167]], [[ATOMIC_EXIT166]] ], [ [[TMP150:%.*]], [[ATOMIC_CONT168]] ], !dbg [[DBG118]]
// AARCH64-NEXT:    store i32 [[TMP147]], ptr [[ATOMIC_TEMP169]], align 4, !dbg [[DBG118]]
// AARCH64-NEXT:    store i32 [[TMP147]], ptr [[ATOMIC_TEMP170]], align 4, !dbg [[DBG118]]
// AARCH64-NEXT:    [[BF_LOAD:%.*]] = load i32, ptr [[ATOMIC_TEMP170]], align 4, !dbg [[DBG118]]
// AARCH64-NEXT:    [[BF_SHL:%.*]] = shl i32 [[BF_LOAD]], 1, !dbg [[DBG118]]
// AARCH64-NEXT:    [[BF_ASHR:%.*]] = ashr i32 [[BF_SHL]], 1, !dbg [[DBG118]]
// AARCH64-NEXT:    [[CONV171:%.*]] = sitofp i32 [[BF_ASHR]] to fp128, !dbg [[DBG119:![0-9]+]]
// AARCH64-NEXT:    [[SUB172:%.*]] = fsub fp128 [[CONV171]], [[TMP146]], !dbg [[DBG120:![0-9]+]]
// AARCH64-NEXT:    [[CONV173:%.*]] = fptosi fp128 [[SUB172]] to i32, !dbg [[DBG119]]
// AARCH64-NEXT:    [[BF_LOAD174:%.*]] = load i32, ptr [[ATOMIC_TEMP169]], align 4, !dbg [[DBG118]]
// AARCH64-NEXT:    [[BF_VALUE:%.*]] = and i32 [[CONV173]], 2147483647, !dbg [[DBG118]]
// AARCH64-NEXT:    [[BF_CLEAR:%.*]] = and i32 [[BF_LOAD174]], -2147483648, !dbg [[DBG118]]
// AARCH64-NEXT:    [[BF_SET:%.*]] = or i32 [[BF_CLEAR]], [[BF_VALUE]], !dbg [[DBG118]]
// AARCH64-NEXT:    store i32 [[BF_SET]], ptr [[ATOMIC_TEMP169]], align 4, !dbg [[DBG118]]
// AARCH64-NEXT:    [[TMP148:%.*]] = load i32, ptr [[ATOMIC_TEMP169]], align 4, !dbg [[DBG118]]
// AARCH64-NEXT:    [[TMP149:%.*]] = cmpxchg ptr getelementptr (i8, ptr @bfx, i64 4), i32 [[TMP147]], i32 [[TMP148]] monotonic monotonic, align 4, !dbg [[DBG118]]
// AARCH64-NEXT:    [[TMP150]] = extractvalue { i32, i1 } [[TMP149]], 0, !dbg [[DBG118]]
// AARCH64-NEXT:    [[TMP151:%.*]] = extractvalue { i32, i1 } [[TMP149]], 1, !dbg [[DBG118]]
// AARCH64-NEXT:    br i1 [[TMP151]], label [[ATOMIC_EXIT175:%.*]], label [[ATOMIC_CONT168]], !dbg [[DBG118]]
// AARCH64:       atomic_exit175:
// AARCH64-NEXT:    store i32 [[CONV173]], ptr @iv, align 4, !dbg [[DBG118]]
// AARCH64-NEXT:    [[TMP152:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG121:![0-9]+]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 4, ptr noundef getelementptr (i8, ptr @bfx_packed, i64 4), ptr noundef [[ATOMIC_TEMP176]], i32 noundef 0), !dbg [[DBG122:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT177:%.*]], !dbg [[DBG122]]
// AARCH64:       atomic_cont177:
// AARCH64-NEXT:    [[TMP153:%.*]] = load i32, ptr [[ATOMIC_TEMP176]], align 1, !dbg [[DBG122]]
// AARCH64-NEXT:    store i32 [[TMP153]], ptr [[ATOMIC_TEMP178]], align 1, !dbg [[DBG122]]
// AARCH64-NEXT:    [[TMP154:%.*]] = load i32, ptr [[ATOMIC_TEMP176]], align 1, !dbg [[DBG122]]
// AARCH64-NEXT:    store i32 [[TMP154]], ptr [[ATOMIC_TEMP179]], align 4, !dbg [[DBG122]]
// AARCH64-NEXT:    [[BF_LOAD180:%.*]] = load i32, ptr [[ATOMIC_TEMP179]], align 1, !dbg [[DBG122]]
// AARCH64-NEXT:    [[BF_SHL181:%.*]] = shl i32 [[BF_LOAD180]], 1, !dbg [[DBG122]]
// AARCH64-NEXT:    [[BF_ASHR182:%.*]] = ashr i32 [[BF_SHL181]], 1, !dbg [[DBG122]]
// AARCH64-NEXT:    [[CONV183:%.*]] = sitofp i32 [[BF_ASHR182]] to fp128, !dbg [[DBG123:![0-9]+]]
// AARCH64-NEXT:    [[MUL184:%.*]] = fmul fp128 [[CONV183]], [[TMP152]], !dbg [[DBG124:![0-9]+]]
// AARCH64-NEXT:    [[CONV185:%.*]] = fptosi fp128 [[MUL184]] to i32, !dbg [[DBG123]]
// AARCH64-NEXT:    [[BF_LOAD186:%.*]] = load i32, ptr [[ATOMIC_TEMP178]], align 1, !dbg [[DBG122]]
// AARCH64-NEXT:    [[BF_VALUE187:%.*]] = and i32 [[CONV185]], 2147483647, !dbg [[DBG122]]
// AARCH64-NEXT:    [[BF_CLEAR188:%.*]] = and i32 [[BF_LOAD186]], -2147483648, !dbg [[DBG122]]
// AARCH64-NEXT:    [[BF_SET189:%.*]] = or i32 [[BF_CLEAR188]], [[BF_VALUE187]], !dbg [[DBG122]]
// AARCH64-NEXT:    store i32 [[BF_SET189]], ptr [[ATOMIC_TEMP178]], align 1, !dbg [[DBG122]]
// AARCH64-NEXT:    [[CALL190:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 4, ptr noundef getelementptr (i8, ptr @bfx_packed, i64 4), ptr noundef [[ATOMIC_TEMP176]], ptr noundef [[ATOMIC_TEMP178]], i32 noundef 0, i32 noundef 0), !dbg [[DBG122]]
// AARCH64-NEXT:    br i1 [[CALL190]], label [[ATOMIC_EXIT191:%.*]], label [[ATOMIC_CONT177]], !dbg [[DBG122]]
// AARCH64:       atomic_exit191:
// AARCH64-NEXT:    store i32 [[BF_ASHR182]], ptr @iv, align 4, !dbg [[DBG122]]
// AARCH64-NEXT:    [[TMP155:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG125:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD192:%.*]] = load atomic i32, ptr @bfx2 monotonic, align 4, !dbg [[DBG126:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT193:%.*]], !dbg [[DBG126]]
// AARCH64:       atomic_cont193:
// AARCH64-NEXT:    [[TMP156:%.*]] = phi i32 [ [[ATOMIC_LOAD192]], [[ATOMIC_EXIT191]] ], [ [[TMP159:%.*]], [[ATOMIC_CONT193]] ], !dbg [[DBG126]]
// AARCH64-NEXT:    store i32 [[TMP156]], ptr [[ATOMIC_TEMP194]], align 4, !dbg [[DBG126]]
// AARCH64-NEXT:    store i32 [[TMP156]], ptr [[ATOMIC_TEMP195]], align 4, !dbg [[DBG126]]
// AARCH64-NEXT:    [[BF_LOAD196:%.*]] = load i32, ptr [[ATOMIC_TEMP195]], align 4, !dbg [[DBG126]]
// AARCH64-NEXT:    [[BF_ASHR197:%.*]] = ashr i32 [[BF_LOAD196]], 31, !dbg [[DBG126]]
// AARCH64-NEXT:    [[CONV198:%.*]] = sitofp i32 [[BF_ASHR197]] to fp128, !dbg [[DBG127:![0-9]+]]
// AARCH64-NEXT:    [[SUB199:%.*]] = fsub fp128 [[CONV198]], [[TMP155]], !dbg [[DBG128:![0-9]+]]
// AARCH64-NEXT:    [[CONV200:%.*]] = fptosi fp128 [[SUB199]] to i32, !dbg [[DBG127]]
// AARCH64-NEXT:    [[BF_LOAD201:%.*]] = load i32, ptr [[ATOMIC_TEMP194]], align 4, !dbg [[DBG126]]
// AARCH64-NEXT:    [[BF_VALUE202:%.*]] = and i32 [[CONV200]], 1, !dbg [[DBG126]]
// AARCH64-NEXT:    [[BF_SHL203:%.*]] = shl i32 [[BF_VALUE202]], 31, !dbg [[DBG126]]
// AARCH64-NEXT:    [[BF_CLEAR204:%.*]] = and i32 [[BF_LOAD201]], 2147483647, !dbg [[DBG126]]
// AARCH64-NEXT:    [[BF_SET205:%.*]] = or i32 [[BF_CLEAR204]], [[BF_SHL203]], !dbg [[DBG126]]
// AARCH64-NEXT:    store i32 [[BF_SET205]], ptr [[ATOMIC_TEMP194]], align 4, !dbg [[DBG126]]
// AARCH64-NEXT:    [[TMP157:%.*]] = load i32, ptr [[ATOMIC_TEMP194]], align 4, !dbg [[DBG126]]
// AARCH64-NEXT:    [[TMP158:%.*]] = cmpxchg ptr @bfx2, i32 [[TMP156]], i32 [[TMP157]] monotonic monotonic, align 4, !dbg [[DBG126]]
// AARCH64-NEXT:    [[TMP159]] = extractvalue { i32, i1 } [[TMP158]], 0, !dbg [[DBG126]]
// AARCH64-NEXT:    [[TMP160:%.*]] = extractvalue { i32, i1 } [[TMP158]], 1, !dbg [[DBG126]]
// AARCH64-NEXT:    br i1 [[TMP160]], label [[ATOMIC_EXIT206:%.*]], label [[ATOMIC_CONT193]], !dbg [[DBG126]]
// AARCH64:       atomic_exit206:
// AARCH64-NEXT:    store i32 [[CONV200]], ptr @iv, align 4, !dbg [[DBG126]]
// AARCH64-NEXT:    [[TMP161:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG129:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD207:%.*]] = load atomic i8, ptr getelementptr (i8, ptr @bfx2_packed, i64 3) monotonic, align 1, !dbg [[DBG130:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT208:%.*]], !dbg [[DBG130]]
// AARCH64:       atomic_cont208:
// AARCH64-NEXT:    [[TMP162:%.*]] = phi i8 [ [[ATOMIC_LOAD207]], [[ATOMIC_EXIT206]] ], [ [[TMP166:%.*]], [[ATOMIC_CONT208]] ], !dbg [[DBG130]]
// AARCH64-NEXT:    store i8 [[TMP162]], ptr [[ATOMIC_TEMP209]], align 1, !dbg [[DBG130]]
// AARCH64-NEXT:    store i8 [[TMP162]], ptr [[ATOMIC_TEMP210]], align 1, !dbg [[DBG130]]
// AARCH64-NEXT:    [[BF_LOAD211:%.*]] = load i8, ptr [[ATOMIC_TEMP210]], align 1, !dbg [[DBG130]]
// AARCH64-NEXT:    [[BF_ASHR212:%.*]] = ashr i8 [[BF_LOAD211]], 7, !dbg [[DBG130]]
// AARCH64-NEXT:    [[BF_CAST:%.*]] = sext i8 [[BF_ASHR212]] to i32, !dbg [[DBG130]]
// AARCH64-NEXT:    [[CONV213:%.*]] = sitofp i32 [[BF_CAST]] to fp128, !dbg [[DBG131:![0-9]+]]
// AARCH64-NEXT:    [[DIV214:%.*]] = fdiv fp128 [[TMP161]], [[CONV213]], !dbg [[DBG132:![0-9]+]]
// AARCH64-NEXT:    [[CONV215:%.*]] = fptosi fp128 [[DIV214]] to i32, !dbg [[DBG129]]
// AARCH64-NEXT:    [[TMP163:%.*]] = trunc i32 [[CONV215]] to i8, !dbg [[DBG130]]
// AARCH64-NEXT:    [[BF_LOAD216:%.*]] = load i8, ptr [[ATOMIC_TEMP209]], align 1, !dbg [[DBG130]]
// AARCH64-NEXT:    [[BF_VALUE217:%.*]] = and i8 [[TMP163]], 1, !dbg [[DBG130]]
// AARCH64-NEXT:    [[BF_SHL218:%.*]] = shl i8 [[BF_VALUE217]], 7, !dbg [[DBG130]]
// AARCH64-NEXT:    [[BF_CLEAR219:%.*]] = and i8 [[BF_LOAD216]], 127, !dbg [[DBG130]]
// AARCH64-NEXT:    [[BF_SET220:%.*]] = or i8 [[BF_CLEAR219]], [[BF_SHL218]], !dbg [[DBG130]]
// AARCH64-NEXT:    store i8 [[BF_SET220]], ptr [[ATOMIC_TEMP209]], align 1, !dbg [[DBG130]]
// AARCH64-NEXT:    [[TMP164:%.*]] = load i8, ptr [[ATOMIC_TEMP209]], align 1, !dbg [[DBG130]]
// AARCH64-NEXT:    [[TMP165:%.*]] = cmpxchg ptr getelementptr (i8, ptr @bfx2_packed, i64 3), i8 [[TMP162]], i8 [[TMP164]] monotonic monotonic, align 1, !dbg [[DBG130]]
// AARCH64-NEXT:    [[TMP166]] = extractvalue { i8, i1 } [[TMP165]], 0, !dbg [[DBG130]]
// AARCH64-NEXT:    [[TMP167:%.*]] = extractvalue { i8, i1 } [[TMP165]], 1, !dbg [[DBG130]]
// AARCH64-NEXT:    br i1 [[TMP167]], label [[ATOMIC_EXIT221:%.*]], label [[ATOMIC_CONT208]], !dbg [[DBG130]]
// AARCH64:       atomic_exit221:
// AARCH64-NEXT:    store i32 [[CONV215]], ptr @iv, align 4, !dbg [[DBG130]]
// AARCH64-NEXT:    [[TMP168:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG133:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD222:%.*]] = load atomic i32, ptr @bfx3 monotonic, align 4, !dbg [[DBG134:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT223:%.*]], !dbg [[DBG134]]
// AARCH64:       atomic_cont223:
// AARCH64-NEXT:    [[TMP169:%.*]] = phi i32 [ [[ATOMIC_LOAD222]], [[ATOMIC_EXIT221]] ], [ [[TMP172:%.*]], [[ATOMIC_CONT223]] ], !dbg [[DBG134]]
// AARCH64-NEXT:    store i32 [[TMP169]], ptr [[ATOMIC_TEMP224]], align 4, !dbg [[DBG134]]
// AARCH64-NEXT:    store i32 [[TMP169]], ptr [[ATOMIC_TEMP225]], align 4, !dbg [[DBG134]]
// AARCH64-NEXT:    [[BF_LOAD226:%.*]] = load i32, ptr [[ATOMIC_TEMP225]], align 4, !dbg [[DBG134]]
// AARCH64-NEXT:    [[BF_SHL227:%.*]] = shl i32 [[BF_LOAD226]], 7, !dbg [[DBG134]]
// AARCH64-NEXT:    [[BF_ASHR228:%.*]] = ashr i32 [[BF_SHL227]], 18, !dbg [[DBG134]]
// AARCH64-NEXT:    [[CONV229:%.*]] = sitofp i32 [[BF_ASHR228]] to fp128, !dbg [[DBG135:![0-9]+]]
// AARCH64-NEXT:    [[DIV230:%.*]] = fdiv fp128 [[CONV229]], [[TMP168]], !dbg [[DBG136:![0-9]+]]
// AARCH64-NEXT:    [[CONV231:%.*]] = fptosi fp128 [[DIV230]] to i32, !dbg [[DBG135]]
// AARCH64-NEXT:    [[BF_LOAD232:%.*]] = load i32, ptr [[ATOMIC_TEMP224]], align 4, !dbg [[DBG134]]
// AARCH64-NEXT:    [[BF_VALUE233:%.*]] = and i32 [[CONV231]], 16383, !dbg [[DBG134]]
// AARCH64-NEXT:    [[BF_SHL234:%.*]] = shl i32 [[BF_VALUE233]], 11, !dbg [[DBG134]]
// AARCH64-NEXT:    [[BF_CLEAR235:%.*]] = and i32 [[BF_LOAD232]], -33552385, !dbg [[DBG134]]
// AARCH64-NEXT:    [[BF_SET236:%.*]] = or i32 [[BF_CLEAR235]], [[BF_SHL234]], !dbg [[DBG134]]
// AARCH64-NEXT:    store i32 [[BF_SET236]], ptr [[ATOMIC_TEMP224]], align 4, !dbg [[DBG134]]
// AARCH64-NEXT:    [[TMP170:%.*]] = load i32, ptr [[ATOMIC_TEMP224]], align 4, !dbg [[DBG134]]
// AARCH64-NEXT:    [[TMP171:%.*]] = cmpxchg ptr @bfx3, i32 [[TMP169]], i32 [[TMP170]] monotonic monotonic, align 4, !dbg [[DBG134]]
// AARCH64-NEXT:    [[TMP172]] = extractvalue { i32, i1 } [[TMP171]], 0, !dbg [[DBG134]]
// AARCH64-NEXT:    [[TMP173:%.*]] = extractvalue { i32, i1 } [[TMP171]], 1, !dbg [[DBG134]]
// AARCH64-NEXT:    br i1 [[TMP173]], label [[ATOMIC_EXIT237:%.*]], label [[ATOMIC_CONT223]], !dbg [[DBG134]]
// AARCH64:       atomic_exit237:
// AARCH64-NEXT:    store i32 [[BF_ASHR228]], ptr @iv, align 4, !dbg [[DBG134]]
// AARCH64-NEXT:    [[TMP174:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG137:![0-9]+]]
// AARCH64-NEXT:    call void @__atomic_load(i64 noundef 3, ptr noundef getelementptr (i8, ptr @bfx3_packed, i64 1), ptr noundef [[ATOMIC_TEMP238]], i32 noundef 0), !dbg [[DBG138:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT239:%.*]], !dbg [[DBG138]]
// AARCH64:       atomic_cont239:
// AARCH64-NEXT:    [[TMP175:%.*]] = load i24, ptr [[ATOMIC_TEMP238]], align 1, !dbg [[DBG138]]
// AARCH64-NEXT:    store i24 [[TMP175]], ptr [[ATOMIC_TEMP240]], align 1, !dbg [[DBG138]]
// AARCH64-NEXT:    [[TMP176:%.*]] = load i24, ptr [[ATOMIC_TEMP238]], align 1, !dbg [[DBG138]]
// AARCH64-NEXT:    store i24 [[TMP176]], ptr [[ATOMIC_TEMP241]], align 1, !dbg [[DBG138]]
// AARCH64-NEXT:    [[BF_LOAD242:%.*]] = load i24, ptr [[ATOMIC_TEMP241]], align 1, !dbg [[DBG138]]
// AARCH64-NEXT:    [[BF_SHL243:%.*]] = shl i24 [[BF_LOAD242]], 7, !dbg [[DBG138]]
// AARCH64-NEXT:    [[BF_ASHR244:%.*]] = ashr i24 [[BF_SHL243]], 10, !dbg [[DBG138]]
// AARCH64-NEXT:    [[BF_CAST245:%.*]] = sext i24 [[BF_ASHR244]] to i32, !dbg [[DBG138]]
// AARCH64-NEXT:    [[CONV246:%.*]] = sitofp i32 [[BF_CAST245]] to fp128, !dbg [[DBG139:![0-9]+]]
// AARCH64-NEXT:    [[ADD247:%.*]] = fadd fp128 [[CONV246]], [[TMP174]], !dbg [[DBG140:![0-9]+]]
// AARCH64-NEXT:    [[CONV248:%.*]] = fptosi fp128 [[ADD247]] to i32, !dbg [[DBG139]]
// AARCH64-NEXT:    [[TMP177:%.*]] = trunc i32 [[CONV248]] to i24, !dbg [[DBG138]]
// AARCH64-NEXT:    [[BF_LOAD249:%.*]] = load i24, ptr [[ATOMIC_TEMP240]], align 1, !dbg [[DBG138]]
// AARCH64-NEXT:    [[BF_VALUE250:%.*]] = and i24 [[TMP177]], 16383, !dbg [[DBG138]]
// AARCH64-NEXT:    [[BF_SHL251:%.*]] = shl i24 [[BF_VALUE250]], 3, !dbg [[DBG138]]
// AARCH64-NEXT:    [[BF_CLEAR252:%.*]] = and i24 [[BF_LOAD249]], -131065, !dbg [[DBG138]]
// AARCH64-NEXT:    [[BF_SET253:%.*]] = or i24 [[BF_CLEAR252]], [[BF_SHL251]], !dbg [[DBG138]]
// AARCH64-NEXT:    store i24 [[BF_SET253]], ptr [[ATOMIC_TEMP240]], align 1, !dbg [[DBG138]]
// AARCH64-NEXT:    [[CALL254:%.*]] = call i1 @__atomic_compare_exchange(i64 noundef 3, ptr noundef getelementptr (i8, ptr @bfx3_packed, i64 1), ptr noundef [[ATOMIC_TEMP238]], ptr noundef [[ATOMIC_TEMP240]], i32 noundef 0, i32 noundef 0), !dbg [[DBG138]]
// AARCH64-NEXT:    br i1 [[CALL254]], label [[ATOMIC_EXIT255:%.*]], label [[ATOMIC_CONT239]], !dbg [[DBG138]]
// AARCH64:       atomic_exit255:
// AARCH64-NEXT:    store i32 [[CONV248]], ptr @iv, align 4, !dbg [[DBG138]]
// AARCH64-NEXT:    [[TMP178:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG141:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD256:%.*]] = load atomic i64, ptr @bfx4 monotonic, align 8, !dbg [[DBG142:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT257:%.*]], !dbg [[DBG142]]
// AARCH64:       atomic_cont257:
// AARCH64-NEXT:    [[TMP179:%.*]] = phi i64 [ [[ATOMIC_LOAD256]], [[ATOMIC_EXIT255]] ], [ [[TMP183:%.*]], [[ATOMIC_CONT257]] ], !dbg [[DBG142]]
// AARCH64-NEXT:    store i64 [[TMP179]], ptr [[ATOMIC_TEMP258]], align 8, !dbg [[DBG142]]
// AARCH64-NEXT:    store i64 [[TMP179]], ptr [[ATOMIC_TEMP259]], align 8, !dbg [[DBG142]]
// AARCH64-NEXT:    [[BF_LOAD260:%.*]] = load i64, ptr [[ATOMIC_TEMP259]], align 8, !dbg [[DBG142]]
// AARCH64-NEXT:    [[BF_SHL261:%.*]] = shl i64 [[BF_LOAD260]], 47, !dbg [[DBG142]]
// AARCH64-NEXT:    [[BF_ASHR262:%.*]] = ashr i64 [[BF_SHL261]], 63, !dbg [[DBG142]]
// AARCH64-NEXT:    [[BF_CAST263:%.*]] = trunc i64 [[BF_ASHR262]] to i32, !dbg [[DBG142]]
// AARCH64-NEXT:    [[CONV264:%.*]] = sitofp i32 [[BF_CAST263]] to fp128, !dbg [[DBG143:![0-9]+]]
// AARCH64-NEXT:    [[MUL265:%.*]] = fmul fp128 [[CONV264]], [[TMP178]], !dbg [[DBG144:![0-9]+]]
// AARCH64-NEXT:    [[CONV266:%.*]] = fptosi fp128 [[MUL265]] to i32, !dbg [[DBG143]]
// AARCH64-NEXT:    [[TMP180:%.*]] = zext i32 [[CONV266]] to i64, !dbg [[DBG142]]
// AARCH64-NEXT:    [[BF_LOAD267:%.*]] = load i64, ptr [[ATOMIC_TEMP258]], align 8, !dbg [[DBG142]]
// AARCH64-NEXT:    [[BF_VALUE268:%.*]] = and i64 [[TMP180]], 1, !dbg [[DBG142]]
// AARCH64-NEXT:    [[BF_SHL269:%.*]] = shl i64 [[BF_VALUE268]], 16, !dbg [[DBG142]]
// AARCH64-NEXT:    [[BF_CLEAR270:%.*]] = and i64 [[BF_LOAD267]], -65537, !dbg [[DBG142]]
// AARCH64-NEXT:    [[BF_SET271:%.*]] = or i64 [[BF_CLEAR270]], [[BF_SHL269]], !dbg [[DBG142]]
// AARCH64-NEXT:    store i64 [[BF_SET271]], ptr [[ATOMIC_TEMP258]], align 8, !dbg [[DBG142]]
// AARCH64-NEXT:    [[TMP181:%.*]] = load i64, ptr [[ATOMIC_TEMP258]], align 8, !dbg [[DBG142]]
// AARCH64-NEXT:    [[TMP182:%.*]] = cmpxchg ptr @bfx4, i64 [[TMP179]], i64 [[TMP181]] monotonic monotonic, align 8, !dbg [[DBG142]]
// AARCH64-NEXT:    [[TMP183]] = extractvalue { i64, i1 } [[TMP182]], 0, !dbg [[DBG142]]
// AARCH64-NEXT:    [[TMP184:%.*]] = extractvalue { i64, i1 } [[TMP182]], 1, !dbg [[DBG142]]
// AARCH64-NEXT:    br i1 [[TMP184]], label [[ATOMIC_EXIT272:%.*]], label [[ATOMIC_CONT257]], !dbg [[DBG142]]
// AARCH64:       atomic_exit272:
// AARCH64-NEXT:    store i32 [[CONV266]], ptr @iv, align 4, !dbg [[DBG142]]
// AARCH64-NEXT:    [[TMP185:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG145:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD273:%.*]] = load atomic i8, ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED:%.*]], ptr @bfx4_packed, i32 0, i32 1) monotonic, align 1, !dbg [[DBG146:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT274:%.*]], !dbg [[DBG146]]
// AARCH64:       atomic_cont274:
// AARCH64-NEXT:    [[TMP186:%.*]] = phi i8 [ [[ATOMIC_LOAD273]], [[ATOMIC_EXIT272]] ], [ [[TMP190:%.*]], [[ATOMIC_CONT274]] ], !dbg [[DBG146]]
// AARCH64-NEXT:    store i8 [[TMP186]], ptr [[ATOMIC_TEMP275]], align 1, !dbg [[DBG146]]
// AARCH64-NEXT:    store i8 [[TMP186]], ptr [[ATOMIC_TEMP276]], align 1, !dbg [[DBG146]]
// AARCH64-NEXT:    [[BF_LOAD277:%.*]] = load i8, ptr [[ATOMIC_TEMP276]], align 1, !dbg [[DBG146]]
// AARCH64-NEXT:    [[BF_SHL278:%.*]] = shl i8 [[BF_LOAD277]], 7, !dbg [[DBG146]]
// AARCH64-NEXT:    [[BF_ASHR279:%.*]] = ashr i8 [[BF_SHL278]], 7, !dbg [[DBG146]]
// AARCH64-NEXT:    [[BF_CAST280:%.*]] = sext i8 [[BF_ASHR279]] to i32, !dbg [[DBG146]]
// AARCH64-NEXT:    [[CONV281:%.*]] = sitofp i32 [[BF_CAST280]] to fp128, !dbg [[DBG147:![0-9]+]]
// AARCH64-NEXT:    [[SUB282:%.*]] = fsub fp128 [[CONV281]], [[TMP185]], !dbg [[DBG148:![0-9]+]]
// AARCH64-NEXT:    [[CONV283:%.*]] = fptosi fp128 [[SUB282]] to i32, !dbg [[DBG147]]
// AARCH64-NEXT:    [[TMP187:%.*]] = trunc i32 [[CONV283]] to i8, !dbg [[DBG146]]
// AARCH64-NEXT:    [[BF_LOAD284:%.*]] = load i8, ptr [[ATOMIC_TEMP275]], align 1, !dbg [[DBG146]]
// AARCH64-NEXT:    [[BF_VALUE285:%.*]] = and i8 [[TMP187]], 1, !dbg [[DBG146]]
// AARCH64-NEXT:    [[BF_CLEAR286:%.*]] = and i8 [[BF_LOAD284]], -2, !dbg [[DBG146]]
// AARCH64-NEXT:    [[BF_SET287:%.*]] = or i8 [[BF_CLEAR286]], [[BF_VALUE285]], !dbg [[DBG146]]
// AARCH64-NEXT:    store i8 [[BF_SET287]], ptr [[ATOMIC_TEMP275]], align 1, !dbg [[DBG146]]
// AARCH64-NEXT:    [[TMP188:%.*]] = load i8, ptr [[ATOMIC_TEMP275]], align 1, !dbg [[DBG146]]
// AARCH64-NEXT:    [[TMP189:%.*]] = cmpxchg ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1), i8 [[TMP186]], i8 [[TMP188]] monotonic monotonic, align 1, !dbg [[DBG146]]
// AARCH64-NEXT:    [[TMP190]] = extractvalue { i8, i1 } [[TMP189]], 0, !dbg [[DBG146]]
// AARCH64-NEXT:    [[TMP191:%.*]] = extractvalue { i8, i1 } [[TMP189]], 1, !dbg [[DBG146]]
// AARCH64-NEXT:    br i1 [[TMP191]], label [[ATOMIC_EXIT288:%.*]], label [[ATOMIC_CONT274]], !dbg [[DBG146]]
// AARCH64:       atomic_exit288:
// AARCH64-NEXT:    store i32 [[BF_CAST280]], ptr @iv, align 4, !dbg [[DBG146]]
// AARCH64-NEXT:    [[TMP192:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG149:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD289:%.*]] = load atomic i64, ptr @bfx4 monotonic, align 8, !dbg [[DBG150:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT290:%.*]], !dbg [[DBG150]]
// AARCH64:       atomic_cont290:
// AARCH64-NEXT:    [[TMP193:%.*]] = phi i64 [ [[ATOMIC_LOAD289]], [[ATOMIC_EXIT288]] ], [ [[TMP196:%.*]], [[ATOMIC_CONT290]] ], !dbg [[DBG150]]
// AARCH64-NEXT:    store i64 [[TMP193]], ptr [[ATOMIC_TEMP291]], align 8, !dbg [[DBG150]]
// AARCH64-NEXT:    store i64 [[TMP193]], ptr [[ATOMIC_TEMP292]], align 8, !dbg [[DBG150]]
// AARCH64-NEXT:    [[BF_LOAD293:%.*]] = load i64, ptr [[ATOMIC_TEMP292]], align 8, !dbg [[DBG150]]
// AARCH64-NEXT:    [[BF_SHL294:%.*]] = shl i64 [[BF_LOAD293]], 40, !dbg [[DBG150]]
// AARCH64-NEXT:    [[BF_ASHR295:%.*]] = ashr i64 [[BF_SHL294]], 57, !dbg [[DBG150]]
// AARCH64-NEXT:    [[CONV296:%.*]] = sitofp i64 [[BF_ASHR295]] to fp128, !dbg [[DBG151:![0-9]+]]
// AARCH64-NEXT:    [[DIV297:%.*]] = fdiv fp128 [[CONV296]], [[TMP192]], !dbg [[DBG152:![0-9]+]]
// AARCH64-NEXT:    [[CONV298:%.*]] = fptosi fp128 [[DIV297]] to i64, !dbg [[DBG151]]
// AARCH64-NEXT:    [[BF_LOAD299:%.*]] = load i64, ptr [[ATOMIC_TEMP291]], align 8, !dbg [[DBG150]]
// AARCH64-NEXT:    [[BF_VALUE300:%.*]] = and i64 [[CONV298]], 127, !dbg [[DBG150]]
// AARCH64-NEXT:    [[BF_SHL301:%.*]] = shl i64 [[BF_VALUE300]], 17, !dbg [[DBG150]]
// AARCH64-NEXT:    [[BF_CLEAR302:%.*]] = and i64 [[BF_LOAD299]], -16646145, !dbg [[DBG150]]
// AARCH64-NEXT:    [[BF_SET303:%.*]] = or i64 [[BF_CLEAR302]], [[BF_SHL301]], !dbg [[DBG150]]
// AARCH64-NEXT:    store i64 [[BF_SET303]], ptr [[ATOMIC_TEMP291]], align 8, !dbg [[DBG150]]
// AARCH64-NEXT:    [[TMP194:%.*]] = load i64, ptr [[ATOMIC_TEMP291]], align 8, !dbg [[DBG150]]
// AARCH64-NEXT:    [[TMP195:%.*]] = cmpxchg ptr @bfx4, i64 [[TMP193]], i64 [[TMP194]] release monotonic, align 8, !dbg [[DBG150]]
// AARCH64-NEXT:    [[TMP196]] = extractvalue { i64, i1 } [[TMP195]], 0, !dbg [[DBG150]]
// AARCH64-NEXT:    [[TMP197:%.*]] = extractvalue { i64, i1 } [[TMP195]], 1, !dbg [[DBG150]]
// AARCH64-NEXT:    br i1 [[TMP197]], label [[ATOMIC_EXIT304:%.*]], label [[ATOMIC_CONT290]], !dbg [[DBG150]]
// AARCH64:       atomic_exit304:
// AARCH64-NEXT:    [[CONV305:%.*]] = trunc i64 [[CONV298]] to i32, !dbg [[DBG150]]
// AARCH64-NEXT:    store i32 [[CONV305]], ptr @iv, align 4, !dbg [[DBG150]]
// AARCH64-NEXT:    [[TMP198:%.*]] = load fp128, ptr @ldv, align 16, !dbg [[DBG153:![0-9]+]]
// AARCH64-NEXT:    [[ATOMIC_LOAD306:%.*]] = load atomic i8, ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1) acquire, align 1, !dbg [[DBG154:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT307:%.*]], !dbg [[DBG154]]
// AARCH64:       atomic_cont307:
// AARCH64-NEXT:    [[TMP199:%.*]] = phi i8 [ [[ATOMIC_LOAD306]], [[ATOMIC_EXIT304]] ], [ [[TMP203:%.*]], [[ATOMIC_CONT307]] ], !dbg [[DBG154]]
// AARCH64-NEXT:    store i8 [[TMP199]], ptr [[ATOMIC_TEMP308]], align 1, !dbg [[DBG154]]
// AARCH64-NEXT:    store i8 [[TMP199]], ptr [[ATOMIC_TEMP309]], align 1, !dbg [[DBG154]]
// AARCH64-NEXT:    [[BF_LOAD310:%.*]] = load i8, ptr [[ATOMIC_TEMP309]], align 1, !dbg [[DBG154]]
// AARCH64-NEXT:    [[BF_ASHR311:%.*]] = ashr i8 [[BF_LOAD310]], 1, !dbg [[DBG154]]
// AARCH64-NEXT:    [[BF_CAST312:%.*]] = sext i8 [[BF_ASHR311]] to i64, !dbg [[DBG154]]
// AARCH64-NEXT:    [[CONV313:%.*]] = sitofp i64 [[BF_CAST312]] to fp128, !dbg [[DBG155:![0-9]+]]
// AARCH64-NEXT:    [[ADD314:%.*]] = fadd fp128 [[CONV313]], [[TMP198]], !dbg [[DBG156:![0-9]+]]
// AARCH64-NEXT:    [[CONV315:%.*]] = fptosi fp128 [[ADD314]] to i64, !dbg [[DBG155]]
// AARCH64-NEXT:    [[TMP200:%.*]] = trunc i64 [[CONV315]] to i8, !dbg [[DBG154]]
// AARCH64-NEXT:    [[BF_LOAD316:%.*]] = load i8, ptr [[ATOMIC_TEMP308]], align 1, !dbg [[DBG154]]
// AARCH64-NEXT:    [[BF_VALUE317:%.*]] = and i8 [[TMP200]], 127, !dbg [[DBG154]]
// AARCH64-NEXT:    [[BF_SHL318:%.*]] = shl i8 [[BF_VALUE317]], 1, !dbg [[DBG154]]
// AARCH64-NEXT:    [[BF_CLEAR319:%.*]] = and i8 [[BF_LOAD316]], 1, !dbg [[DBG154]]
// AARCH64-NEXT:    [[BF_SET320:%.*]] = or i8 [[BF_CLEAR319]], [[BF_SHL318]], !dbg [[DBG154]]
// AARCH64-NEXT:    store i8 [[BF_SET320]], ptr [[ATOMIC_TEMP308]], align 1, !dbg [[DBG154]]
// AARCH64-NEXT:    [[TMP201:%.*]] = load i8, ptr [[ATOMIC_TEMP308]], align 1, !dbg [[DBG154]]
// AARCH64-NEXT:    [[TMP202:%.*]] = cmpxchg ptr getelementptr inbounds nuw ([[STRUCT_BITFIELDS4_PACKED]], ptr @bfx4_packed, i32 0, i32 1), i8 [[TMP199]], i8 [[TMP201]] acquire acquire, align 1, !dbg [[DBG154]]
// AARCH64-NEXT:    [[TMP203]] = extractvalue { i8, i1 } [[TMP202]], 0, !dbg [[DBG154]]
// AARCH64-NEXT:    [[TMP204:%.*]] = extractvalue { i8, i1 } [[TMP202]], 1, !dbg [[DBG154]]
// AARCH64-NEXT:    br i1 [[TMP204]], label [[ATOMIC_EXIT321:%.*]], label [[ATOMIC_CONT307]], !dbg [[DBG154]]
// AARCH64:       atomic_exit321:
// AARCH64-NEXT:    [[CONV322:%.*]] = trunc i64 [[CONV315]] to i32, !dbg [[DBG154]]
// AARCH64-NEXT:    store i32 [[CONV322]], ptr @iv, align 4, !dbg [[DBG154]]
// AARCH64-NEXT:    [[TMP205:%.*]] = load i64, ptr @ulv, align 8, !dbg [[DBG157:![0-9]+]]
// AARCH64-NEXT:    [[CONV323:%.*]] = uitofp i64 [[TMP205]] to float, !dbg [[DBG157]]
// AARCH64-NEXT:    [[ATOMIC_LOAD324:%.*]] = load atomic i64, ptr @float2x acquire, align 8, !dbg [[DBG158:![0-9]+]]
// AARCH64-NEXT:    br label [[ATOMIC_CONT325:%.*]], !dbg [[DBG158]]
// AARCH64:       atomic_cont325:
// AARCH64-NEXT:    [[TMP206:%.*]] = phi i64 [ [[ATOMIC_LOAD324]], [[ATOMIC_EXIT321]] ], [ [[TMP214:%.*]], [[ATOMIC_CONT325]] ], !dbg [[DBG158]]
// AARCH64-NEXT:    store i64 [[TMP206]], ptr [[ATOMIC_TEMP326]], align 8, !dbg [[DBG158]]
// AARCH64-NEXT:    [[TMP207:%.*]] = bitcast i64 [[TMP206]] to <2 x float>, !dbg [[DBG158]]
// AARCH64-NEXT:    store <2 x float> [[TMP207]], ptr [[ATOMIC_TEMP327]], align 8, !dbg [[DBG158]]
// AARCH64-NEXT:    [[TMP208:%.*]] = load <2 x float>, ptr [[ATOMIC_TEMP327]], align 8, !dbg [[DBG158]]
// AARCH64-NEXT:    [[TMP209:%.*]] = extractelement <2 x float> [[TMP208]], i64 0, !dbg [[DBG158]]
// AARCH64-NEXT:    [[SUB328:%.*]] = fsub float [[CONV323]], [[TMP209]], !dbg [[DBG159:![0-9]+]]
// AARCH64-NEXT:    [[TMP210:%.*]] = load <2 x float>, ptr [[ATOMIC_TEMP326]], align 8, !dbg [[DBG158]]
// AARCH64-NEXT:    [[TMP211:%.*]] = insertelement <2 x float> [[TMP210]], float [[SUB328]], i64 0, !dbg [[DBG158]]
// AARCH64-NEXT:    store <2 x float> [[TMP211]], ptr [[ATOMIC_TEMP326]], align 8, !dbg [[DBG158]]
// AARCH64-NEXT:    [[TMP212:%.*]] = load i64, ptr [[ATOMIC_TEMP326]], align 8, !dbg [[DBG158]]
// AARCH64-NEXT:    [[TMP213:%.*]] = cmpxchg ptr @float2x, i64 [[TMP206]], i64 [[TMP212]] acq_rel acquire, align 8, !dbg [[DBG158]]
// AARCH64-NEXT:    [[TMP214]] = extractvalue { i64, i1 } [[TMP213]], 0, !dbg [[DBG158]]
// AARCH64-NEXT:    [[TMP215:%.*]] = extractvalue { i64, i1 } [[TMP213]], 1, !dbg [[DBG158]]
// AARCH64-NEXT:    br i1 [[TMP215]], label [[ATOMIC_EXIT329:%.*]], label [[ATOMIC_CONT325]], !dbg [[DBG158]]
// AARCH64:       atomic_exit329:
// AARCH64-NEXT:    store float [[TMP209]], ptr @fv, align 4, !dbg [[DBG158]]
// AARCH64-NEXT:    ret i32 0, !dbg [[DBG160:![0-9]+]]
//
